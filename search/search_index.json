{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"High-performance computing at AAU <p>Explore the high-performance computing (HPC) resources available for AAU students and researchers, how they work and what they can be used for in your projects. HPC provides the necessary power to train machine learning models, run simulations, perform data analysis, and conduct modeling, among other tasks</p>"},{"location":"#aau-hpc","title":"AAU HPCStratoUCloudAI CloudAI-LAB","text":"<p>Find the most suitable system for your project. You can also complete the HPC Decision Tree Quiz or check out the HPC Comparison Table to assist you in exploring the HPC options fitting your specific needs.</p> For researchers <p>Strato provides virtual machines users can launch as needed, accessible from a terminal on their local computer.</p> About Strato How to access Application form For researchers <p>UCloud is a research platform providing high-performance computing with an easy-to-use interface for data analytics.</p> About UCloud How to access Application form For researchers <p>AI Cloud is a GPU cluster designed for demanding machine learning workloads, accessed via terminal for job submission.</p> About AI Cloud How to access Application form For students <p>AI-LAB offers Aalborg University students HPC access, ideal for deep learning, simulations, and fast data analysis.</p> About AI-LAB How to access Application form <p>News: National DeiC HPC call H2-2026 now open</p> <p>Has your research outgrown your computer\u2019s capacity and do our local facilities and budgets no longer meet your computational needs?  </p> <p>Then this news is for you. Through competitive calls, researchers can apply for access to DeiC National HPC resources, Denmark\u2019s national pool of high-performance computing systems.</p> <ul> <li>Application period: 13 January 2026 \u2013 10 March 2026</li> <li>Resources available: 1 July 2026</li> <li>HPC systems in the call: DeiC Interactive HPC/UCloud, Sophia, GenomeDK, Computerome 2 andLUMI</li> </ul> <p>For more information, see: DeiC national resources page and the official DeiC H2-2026 call announcement</p>"},{"location":"#external-hpc","title":"External HPCDeiC Throughput HPCLUMIEuroHPC","text":"<p>DeiC Throughput HPC offers queued job execution on large CPU clusters, including DTU Sophia, GenomeDK, and Computerome 2.0.</p> About Deic HPC Application form <p>LUMI is AAU\u2019s largest supercomputer, providing CPU and GPU processing via a queue-based, containerized job system.</p> About LUMI Application form <p>Aalborg University researchers can access EuroHPC supercomputers by applying for computing time, like external research funding.</p> About EuroHPC"},{"location":"claaudia-llm/","title":"CLAAUDIA LLM","text":"<p>This is a PoC for a local LLM platform at AAU. The platform runs on Strato with 6 NVIDIA T4 GPUs and utilizes Open WebUI and Ollama for model management and interaction. Open WebUI provides a user-friendly interface, while Ollama handles model execution and optimization. Researchers can create groups and collaborate on RAG systems by integrating their own datasets. The goal is to create a flexible, GPU-optimized solution for research use.</p>"},{"location":"claaudia-llm/#installation","title":"Installation","text":"<ol> <li>Start an instance on Strato with Cuda Ubuntu 24.04 with Docker image</li> <li>Go to Security Groups and add a new. Make a new TCP rule to port 3000. Add the security Group to the instance.</li> <li>Install NVIDIA toolkit:     https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-with-apt</li> <li>Configure with Docker:     https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#configuring-docker</li> <li>Enter the following to run Open WebUI:     sudo docker run -d --restart unless-stopped -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui-llm --privileged ghcr.io/open-webui/open-webui:ollama</li> <li>Check that its running at: http://replace with server IP:3000 (it make take 5 minutes before its running)</li> </ol> <p>Update server: 1. sudo docker stop open-webui-llm 2. sudo docker rm open-webui-llm 3. sudo docker pull ghcr.io/open-webui/open-webui:ollama 4. sudo docker run -d --restart unless-stopped -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui-llm --privileged ghcr.io/open-webui/open-webui:ollama</p> <p>Nice commands: 1. sudo docker ps: checks the status of the Docker container</p>"},{"location":"claaudia-llm/#getting-started","title":"Getting started","text":"<p>To start using the CLAAUDIA LLM platform, please follow these steps:</p> <ol> <li>Ensure you are connected to the AAU network (including VPN).</li> <li>Go to http://10.92.1.195:3000/.</li> <li>Sign up as a new user.</li> <li>Wait for an approval email.</li> <li>Refer to the Open WebUI documentation for more how-to guides</li> </ol>"},{"location":"claaudia-llm/#api-endpoints","title":"API Endpoints","text":"<p>Cerate a new Bearer API key from Settings &gt; Account. To test the connection you can fetch all models by using:</p> <pre><code>curl -H \"Authorization: Bearer YOUR_API_KEY\" http://10.92.1.195:3000/api/models\n</code></pre> <p>Replace <code>YOUR_API_KEY</code> with the API Key you created. To send a chat request, you can do so by using:</p> <pre><code>curl -X POST http://10.92.1.195:3000/api/chat/completions \\\n-H \"Authorization: Bearer YOUR_API_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n      \"model\": \"mistral:7b\",\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"Why is the sky blue?\"\n        }\n      ]\n    }'\n</code></pre>"},{"location":"claaudia-llm/#python-guide","title":"Python Guide","text":""},{"location":"claaudia-llm/#overview","title":"Overview","text":"<p>This guide explains how to use the Ollama OpenWebUI API with Python. It supports two methods:</p> <ol> <li>Using the <code>openai</code> Python library (for compatibility with existing OpenAI-compatible codebases).</li> <li>Using the <code>requests</code> library (for a simpler, direct approach).</li> </ol>"},{"location":"claaudia-llm/#installation-configuration","title":"Installation &amp; Configuration","text":""},{"location":"claaudia-llm/#installing-dependencies","title":"Installing Dependencies","text":"<p>Ensure you have the required Python libraries installed: <pre><code>pip install openai requests\n</code></pre></p>"},{"location":"claaudia-llm/#configuring-your-api","title":"Configuring Your API","text":"<ul> <li>Ensure your Ollama OpenWebUI instance is running and accessible via the URL:   <pre><code>http://10.92.1.195:3000/api\n</code></pre></li> <li>Obtain your API token (<code>sk-xxx</code>) from your Ollama configuration.</li> </ul>"},{"location":"claaudia-llm/#using-the-openai-python-library","title":"Using the <code>openai</code> Python Library","text":"<pre><code>from openai import OpenAI\n\nclient = OpenAI(\n    base_url=\"http://10.92.1.195:3000/api\",\n    api_key=\"sk-xxx\"  # Replace with your actual API key\n)\n\nresponse = client.chat.completions.create(\n    model=\"mistral:7b\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Why is the sky blue?\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"claaudia-llm/#using-the-requests-library","title":"Using the <code>requests</code> Library","text":"<pre><code>import requests\n\ntoken= \"sk-xxx\"  # Replace with your actual API key\n\ndef chat_with_model(token):\n    url = 'http://10.92.1.195:3000/api/chat/completions'\n    headers = {\n        'Authorization': f'Bearer {token}',\n        'Content-Type': 'application/json'\n    }\n\n    data = {\n        \"model\": \"mistral:7b\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"Why is the sky blue?\"}\n        ]\n    }\n\n    response = requests.post(url, headers=headers, json=data)\n    return response.json()\n\nresult = chat_with_model(token)\nprint(result[\"choices\"][0][\"message\"][\"content\"])\n</code></pre>"},{"location":"claaudia-llm/#explanation","title":"Explanation","text":"<ul> <li><code>openai</code> Library: Uses the standard OpenAI client library for compatibility with existing tools.</li> <li><code>requests</code> Library: Direct interaction with the API, providing more flexibility.</li> </ul>"},{"location":"hpc-comparison-table/","title":"HPC Comparison Table","text":"Feature Strato UCloud AI Cloud AI-LAB Available to researchers - Available to students - - - Sensitive data - - - Ideal for Model training, simulations First-time users, data processing Deep learning, large datasets Student projects, deep learning CPU processing - - GPU processing Unlimitted GPU usage - - Access interface Terminal Web browser Terminal Terminal Possible to add GUI - - Working interactively - - Pre-installed apps - - Recommended skills Linux, SSH None Linux, Containerization Linux, Containerization Collaboration friendly"},{"location":"ood-setup/","title":"Set up Open OnDemand, Slurm and Singularity on an Ubuntu 24.04 server.","text":""},{"location":"ood-setup/#install-open-ondemand","title":"Install Open OnDemand","text":"<p>https://osc.github.io/ood-documentation/latest/installation/install-software.html</p>"},{"location":"ood-setup/#1-install-dependencies","title":"1. Install Dependencies","text":"<pre><code>sudo apt install apt-transport-https ca-certificates\nwget -O /tmp/ondemand-release-web_4.0.0-noble_all.deb https://apt.osc.edu/ondemand/4.0/ondemand-release-web_4.0.0-noble_all.deb\nsudo apt install /tmp/ondemand-release-web_4.0.0-noble_all.deb\nsudo apt update\nsudo apt install ondemand\nsudo systemctl start apache2\nsudo systemctl enable apache2\n</code></pre> <p>Verify that you see the default Apache page on the servers IP address in a browser</p>"},{"location":"ood-setup/#2-add-servername","title":"2. Add servername","text":"<pre><code>sudo nano /etc/apache2/conf-available/servername.conf\n</code></pre> <p>Add:</p> servername.conf<pre><code>ServerName http://10.92.0.250/\n</code></pre> <p>Replace <code>10.92.0.250</code> with the servers IP</p> <pre><code>sudo a2enconf servername\nsudo systemctl restart apache2\nsudo systemctl reload apache2\n</code></pre>"},{"location":"ood-setup/#3-edit-open-ondemand-configurations","title":"3. Edit Open OnDemand configurations:","text":"<pre><code>sudo nano /etc/ood/config/ood_portal.yml\n</code></pre> <p>Add:</p> servername.conf<pre><code>servername: 10.92.0.250\nauth:\n  - 'AuthType Basic'\n  - 'AuthName \"Open OnDemand\"'\n  - 'AuthUserFile /etc/ood/passwd'\n  - 'Require valid-user'\n</code></pre> <p>Place it under the <code>---</code> and Replace <code>10.92.0.250</code> with the servers public IP or URL.</p>"},{"location":"ood-setup/#4-set-up-testuser","title":"4. Set up testuser","text":"<pre><code>sudo htpasswd -c /etc/ood/passwd ubuntu\nsudo /opt/ood/ood-portal-generator/sbin/update_ood_portal\nsudo systemctl restart apache2\n</code></pre> <p>Now you should be able to open Open OnDemand interface and login with the user you created.</p>"},{"location":"ood-setup/#install-slurm","title":"Install Slurm","text":""},{"location":"ood-setup/#1-install-dependencies_1","title":"1. Install Dependencies","text":"<pre><code>sudo apt update\nsudo apt install -y build-essential munge libmunge-dev libmunge2 libhwloc-dev libhdf5-dev libopenmpi-dev libpam0g-dev libcurl4-openssl-dev libjson-c-dev man2html mariadb-server mariadb-client python3-pip git libdbus-1-dev libsystemd-dev\n</code></pre>"},{"location":"ood-setup/#2-set-up-munge-authentication","title":"2. Set up MUNGE Authentication","text":"<pre><code>sudo apt install -y munge   \nsudo dd if=/dev/urandom bs=1 count=1024 | sudo tee /etc/munge/munge.key &gt; /dev/null\nsudo chown munge: /etc/munge/munge.key\nsudo chmod 400 /etc/munge/munge.key \nsudo systemctl enable --now munge\n</code></pre> <p>Verify that you see <code>STATUS: Success (0)</code> when running <code>munge -n | unmunge</code></p>"},{"location":"ood-setup/#3-create-slurm-user-and-directories","title":"3. Create Slurm User and Directories","text":"<pre><code>sudo useradd -m slurm\nsudo mkdir -p /etc/slurm /var/spool/slurmd /var/log/slurm\nsudo chown slurm: /var/spool/slurmd /var/log/slurm  \n</code></pre>"},{"location":"ood-setup/#4-download-slurm-and-build-slurm-from-source","title":"4. Download Slurm and Build Slurm from Source","text":"<pre><code>cd /usr/local/src\nsudo git clone https://github.com/SchedMD/slurm.git\ncd slurm\nsudo git checkout slurm-23.11\nsudo ./configure\nsudo make -j$(nproc)\nsudo make install\n</code></pre>"},{"location":"ood-setup/#5-create-slurm-config-file","title":"5. Create Slurm Config File","text":"<p>Replace <code>open-ondemand-v2</code> in <code>SlurmctldHost</code>, <code>NodeName</code>, and <code>PartitionName</code> with your hostname (type <code>hostname</code> to check). Also replace <code>NodeAddr=10.92.0.134</code> with the IP of your server</p> <pre><code>sudo tee /etc/slurm/slurm.conf &gt; /dev/null &lt;&lt;EOF\nTaskPlugin=task/none\nClusterName=singlecluster\nSlurmctldHost=open-ondemand-v2\nSlurmUser=slurm\nSlurmdUser=root\nStateSaveLocation=/var/spool/slurmd\nSlurmdSpoolDir=/var/spool/slurmd\nSlurmctldPidFile=/var/run/slurmctld.pid\nSlurmdPidFile=/var/run/slurmd.pid\nProctrackType=proctrack/pgid\nReturnToService=1\nSlurmctldPort=6817\nSlurmdPort=6818\nAuthType=auth/munge\nCryptoType=crypto/munge\nSchedulerType=sched/backfill\nSelectType=select/linear\nNodeName=open-ondemand-v2 NodeAddr=10.92.0.134 CPUs=8 State=UNKNOWN\nPartitionName=debug Nodes=open-ondemand-v2 Default=YES MaxTime=INFINITE State=UP\nEOF\n</code></pre> <pre><code>sudo mkdir -p /usr/local/etc\nsudo ln -s /etc/slurm/slurm.conf /usr/local/etc/slurm.conf\n</code></pre>"},{"location":"ood-setup/#6-start-slurm-as-a-services","title":"6. Start Slurm as a services","text":"<pre><code>sudo nano /etc/systemd/system/slurmctld.service\n</code></pre> <p>Add:</p> slurmctld.service<pre><code>[Unit]\nDescription=Slurm controller daemon\nAfter=munge.service network.target\nRequires=munge.service\n\n[Service]\nType=simple\nUser=slurm\nGroup=slurm\nExecStart=/usr/local/sbin/slurmctld -D\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <pre><code>sudo nano /etc/systemd/system/slurmd.service\n</code></pre> <p>Add:</p> slurmd.service<pre><code>[Unit]\nDescription=Slurm node daemon\nAfter=munge.service network.target\nRequires=munge.service\n\n[Service]\nType=simple\nUser=root\nGroup=root\nExecStart=/usr/local/sbin/slurmd -D\nRestart=on-failure\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <pre><code>sudo systemctl daemon-reload\nsudo systemctl restart slurmctld slurmd\nsudo systemctl status slurmctld\nsudo systemctl status slurmd\n</code></pre> <p>Then verify that everything is working with <code>sinfo</code> and <code>srun hostname</code></p>"},{"location":"ood-setup/#install-singularity","title":"Install Singularity","text":"<p>https://github.com/sylabs/singularity/blob/main/INSTALL.md</p>"},{"location":"ood-setup/#1-install-dependencies_2","title":"1. Install Dependencies","text":"<pre><code>sudo apt-get update\nsudo apt-get install -y autoconf automake cryptsetup fuse2fs git fuse3 libfuse3-dev libseccomp-dev libtool pkg-config runc squashfs-tools squashfs-tools-ng uidmap wget zlib1g-dev\nsudo apt-get install -y libsubid-dev\n</code></pre>"},{"location":"ood-setup/#2-install-go","title":"2. Install Go","text":"<pre><code>cd ~\nexport VERSION=1.24.4 OS=linux ARCH=amd64\nwget -O /tmp/go${VERSION}.${OS}-${ARCH}.tar.gz https://dl.google.com/go/go${VERSION}.${OS}-${ARCH}.tar.gz\nsudo tar -C /usr/local -xzf /tmp/go${VERSION}.${OS}-${ARCH}.tar.gz\necho 'export PATH=$PATH:/usr/local/go/bin' &gt;&gt; ~/.bashrc \nsource ~/.bashrc\n</code></pre>"},{"location":"ood-setup/#3-clone-the-repo","title":"3. Clone the repo","text":"<pre><code>sudo git clone --recurse-submodules https://github.com/sylabs/singularity.git\ncd singularity\ngit submodule update \u2013init\ngit config --global --add safe.directory /home/ubuntu/singularity\nsudo chown -R ubuntu:ubuntu /home/ubuntu/singularity\ngit submodule update --init\ngit checkout --recurse-submodules v4.3.2\n./mconfig\nmake -C builddir\nsudo make -C builddir install\n</code></pre> <p>Verify installation with <code>singularity --version</code></p>"},{"location":"ood-setup/#enable-developer-mode-for-user-on-open-ondemand","title":"Enable developer mode for user on Open OnDemand","text":"<p>If you would like developer capabilities for creating apps or tools like restarting the web server, then follow this guide:</p> <pre><code>sudo mkdir -p /var/www/ood/apps/dev/ubuntu\ncd /var/www/ood/apps/dev/ubuntu\nsudo ln -s /home/ubuntu/ondemand/dev gateway\nsudo systemctl restart apache2\n</code></pre> <p>Replace <code>ubuntu</code> with the username.</p> <p>Now you are able to restart Open OnDemand service directly on the website by clicking <code>Develop</code> then <code>Restart Web Server</code>.</p>"},{"location":"ood-setup/#setup-slurm-integration-with-open-ondemand","title":"Setup Slurm integration with Open OnDemand","text":"<pre><code>sudo mkdir -p /etc/ood/config/clusters.d\n</code></pre> <pre><code>sudo nano /etc/ood/config/clusters.d/singlecluster.yml\n</code></pre> <p>Add:</p> singlecluster.yml<pre><code>---\nv2:\n  metadata:\n    title: \"AI-LAB Cluster\"\n    url: \"https://hpc.aau.dk/ai-lab/\"\n    hidden: false\n\n  login:\n    host: \"open-ondemand-v2\"\n\n  job:\n    adapter: \"slurm\"\n    bin: \"/usr/local/bin\"\n    conf: \"/etc/slurm/slurm.conf\"\n    copy_environment: false\n\n  batch_connect:\n    basic:\n      script_wrapper: |\n        export SLURM_EXPORT_ENV=ALL\n        %s\n    vnc:\n      script_wrapper: |\n        export SLURM_EXPORT_ENV=ALL\n        module load ondemand-vnc\n        %s\n    ssh_allow: true\n</code></pre> <pre><code>sudo systemctl restart apache2\n</code></pre> <p>And <code>Restart Web Server</code> in the browser (remember to enable developer mode first).  You can check if Slurm is configured correctly by submitting <code>salloc</code> and then refreshing <code>Jobs</code> -&gt; <code>Active Jobs</code> to see your job running.</p>"},{"location":"ood-setup/#create-an-app","title":"Create an app","text":""},{"location":"ood-setup/#batch-pytorch-app-example","title":"Batch PyTorch app example","text":"<pre><code>sudo mkdir -p /var/www/ood/apps/sys/pytorch\nsudo chown -R $USER: /var/www/ood/apps/sys/pytorch\n</code></pre> <pre><code>sudo nano /var/www/ood/apps/sys/pytorch/manifest.yml\n</code></pre> <p>Add:</p> manifest.yml<pre><code>---\nname: \"pytorch\"\ncategory: \"Batch Apps\"\nrole: \"batch_connect\"\ndescription: \"Run PyTorch scripts inside a Singularity container.\"\n</code></pre> <pre><code>sudo nano /var/www/ood/apps/sys/pytorch/form.yml\n</code></pre> <p>Add:</p> form.yml<pre><code>---\ncluster: \"singlecluster\"\n\nform:\n  - python_script\n\nattributes:\n  python_script:\n    label: \"Python script to run\"\n    help: \"Relative path under your $HOME (e.g. 'myscript.py') or absolute path (e.g. '/home/ubuntu/script.py')\"\n    required: true\n    widget: text_field\n</code></pre> <pre><code>sudo nano /var/www/ood/apps/sys/pytorch/submit.yml.erb\n</code></pre> <p>Add:</p> submit.yml.erb<pre><code>---\nbatch_connect:\n  template: \"basic\"\n\nscript:\n  wall_time: 3600\n  copy_environment: true\n</code></pre> <pre><code>sudo mkdir /var/www/ood/apps/sys/pytorch/template\n</code></pre> <pre><code>sudo nano /var/www/ood/apps/sys/pytorch/template/script.sh.erb\n</code></pre> <p>Add:</p> script.sh.erb<pre><code>#!/bin/bash\nset -e\n\n# Path to the Singularity image\nSINGULARITY_IMAGE=\"/home/ubuntu/containers/pytorch_25.04.sif\"\n\n# Path to the user Python script (expanded from form attribute)\nSCRIPT_PATH=\"$HOME/&lt;%= context.python_script %&gt;\"\n\necho \"Running Python script inside Singularity container: $SCRIPT_PATH\"\n\nsingularity exec \"$SINGULARITY_IMAGE\" python3 \"$SCRIPT_PATH\"\n</code></pre> <p>Add a simple python script in your own directory:</p> <pre><code>nano script.py\n</code></pre> <p>Add:</p> script.py<pre><code>print(\"Hello from PyTorch Container!\")\n</code></pre> <p>Now go to Open OnDemand dashboard -&gt; <code>HPC Apps</code> -&gt; <code>pytorch</code>. Then enter <code>script.py</code> and hit <code>Launch</code>.</p> <p>Your job should now start and when completet, click on the <code>Session ID</code> and click on <code>output.log</code>. You should see <code>Hello from PyTorch Container!</code>.</p>"},{"location":"ood-setup/#pin-the-app-to-the-dashboard","title":"Pin the app to the dashboard","text":"<p>https://osc.github.io/ood-documentation/latest/customizations.html#pinning-applications-to-the-dashboard <pre><code>sudo nano /etc/ood/config/ondemand.d/ondemand.yml\n</code></pre></p> ondemand.yml<pre><code>pinned_apps:\n  - sys/pytorch\n</code></pre>"},{"location":"ood-setup/#choose-an-image-and-shown-title-for-the-application","title":"Choose an image and shown title for the application","text":"<p>First create this directory to store images in, if not already there:</p> <pre><code>sudo mkdir /var/www/ood/public/images\n</code></pre> <p>Then move some image in this folder, in this example a PyTorch logo <code>pytorch.png</code></p> <p>Then modify the apps manifest file:</p> <pre><code>sudo nano /var/www/ood/apps/sys/pytorch/manifest.yml\n</code></pre> <p>Add the following:</p> manifest.yml<pre><code>tile:\n  title: \"PyTorch\"\n  icon: \"/public/images/pytorch.png\"\n</code></pre> <p>Reload the server with <code>sudo systemctl restart apache2</code> and restart OOD in the browser to see the changes.</p>"},{"location":"ood-setup/#change-configurations-and-design-of-ood","title":"Change configurations and design of OOD:","text":""},{"location":"ood-setup/#override-css-styling","title":"Override CSS styling:","text":"<pre><code>sudo nano /var/www/ood/public/styles.css\n</code></pre> styles.css<pre><code>.navbar-dark {\n    background-color: #211A52;\n}\n</code></pre> <p>Create a new configuration file:</p> <pre><code>sudo nano /etc/ood/config/ondemand.d/customizations.yml\n</code></pre> customizations.yml<pre><code>custom_css_files: [\"/styles.css\"]\n</code></pre> <p>Reload the server with <code>sudo systemctl restart apache2</code> and restart OOD in the browser to see the changes.</p>"},{"location":"ood-setup/#change-footer","title":"Change footer","text":"<pre><code>sudo mkdir -p /etc/ood/config/apps/dashboard/views/layouts\n</code></pre> <pre><code>sudo nano /etc/ood/config/apps/dashboard/views/layouts/_footer.html.erb\n</code></pre> _footer.html.erb<pre><code>&lt;div&gt;\n  My custom footer\n&lt;div&gt;\n</code></pre>"},{"location":"ood-setup/#hideshow-items-in-navigation","title":"Hide/show items in navigation","text":"<pre><code>sudo nano /etc/ood/config/ondemand.d/customizations.yml\n</code></pre> <p>Add the following somewhere:</p> customizations.yml<pre><code>nav_categories: ['Apps', 'Files', 'Jobs']\n</code></pre>"},{"location":"service-windows/","title":"Service windows","text":"<p>Four times a year, all of our platforms are subject to service windows where changes and security upgrades are implemented. During these, we reserve an entire day for maintainance of the systems.</p> <p>It should be expected that the platforms are offline for the entire day from 00:01 until 23:59 - but they may come online by the end of the days, as the work is finished.</p>"},{"location":"service-windows/#schedule","title":"Schedule","text":"<p>A service window will take place on the following dates:</p> <p>AI Cloud, Strato, UCloud VM's &amp; UCloud Kubernetes</p> 2025 2026 2027 2028 11/02 10/02 09/02 08/02 13/05 12/05 11/05 09/05 16/09 15/09 14/09 12/09 02/12 01/12 30/11 28/11 <p>AI-LAB</p> 2025 2026 2027 2028 13/02 12/02 11/02 10/02 15/05 14/05 13/05 11/05 18/09 17/09 16/09 14/09 04/12 03/12 02/12 30/11 <p>TAAURUS</p> 2026 2027 2028 2029 03/02 - - - - - - - - - - - - - - - <p>Sign up for notifications on serviceinfo.dk</p> <p>Click this link to go to serviceinfo.dk. Then select Aalborg University, and under the tab Subscribe (or Abonn\u00e9r), select CLAAUDIA. Select email, SMS or calendar, according to your preferences:</p> <p> Go to ServiceInfo.dk</p>"},{"location":"service-windows/#platform-specific-information","title":"Platform specific information","text":""},{"location":"service-windows/#strato-and-ucloud-virtual-machines","title":"Strato and UCloud virtual machines","text":"<p>Be sure to save your work no later than the end of the day before the service window begins, as all virtual machines will be automatically shut down during the service window and any unsaved data will be lost.</p> <p>Usage Management Process </p> <p>1. Servers will NOT restart automatically after service windows     - All servers in the AAU availability zone will be shut down during service windows and will not restart automatically, unless they have been registered for automatic restart before the service window.      - You can easily restart your servers manually after the service window.</p> <p>2. Automatic server resizing after 48 hours of inactivity     - Servers that remain shut down for more than 48 hours will be automatically resized to the smallest CPU configuration.     - You will receive a notification when your instance has been resized.</p> <p>3. Automatic server deletion after 30 days of inactivity     - Servers that remain shut down for 30 days will be permanently deleted, but their volumes will be preserved.     - You will be notified in advance about any affected instances.</p> <p>4. Unused volume cleanup     - Volumes not attached to any server for 30 days will be deleted.     - A notification will be sent before deletion.</p> <p>All virtual machines should be removed when not in use.  Basic rule: keep your volumes, delete your unused VMs, and only run a VM with the size you really need right now. Please consult the page 'Delete and restart an instance from the volume' for instructions on how to do this.</p> <p>Apply for automatic restart of your Strato server</p> <p>Note: The deadline for requesting inclusion in the automatic restart list has now passed for the service window on the 2nd december.</p> <p>You could request automatic restarts for your server if all of the following conditions were met:</p> <ul> <li>The server is part of a Strato Project</li> <li>You can provide a valid motivation for needing automatic restart</li> <li>The server is in one of these availability zones:<ul> <li>AAU</li> <li>AAU-T4</li> <li>AAU-A10</li> <li>AAU-A40</li> </ul> </li> </ul> <p>Servers running in personal project spaces (such as default quota projects, e.g. <code>GK83DJ@aau.dk</code>) cannot be included. If you want to move your project, you can find instructions on how to apply for a Strato Project</p> <p>The application form for inclusion in the automatic restart list closed on November 25th: Strato service window: Automatic server restart inclusion form</p> <p>Link to Strato's web-interface: strato-new.claaudia.aau.dk</p>"},{"location":"service-windows/#ai-cloud","title":"AI Cloud","text":"<p>In the days leading up to the service window, a reservation will be put in place for the entire cluster. The entirety of the cluster will therefore be unavailable for that day, but may come back online by the end of the day.</p> <p>You can still submit jobs in the days leading up to the service window. Since the <code>batch</code> and <code>prioritized</code> partitions have time limits of 12 hours and 6 days respectively, you will only be able to launch new jobs if you add the <code>--time</code> parameter to your Slurm command. If you do not set this parameter, and there are 5 days until the day of the service window, your job will not start until after the service window. You will thus need to calculate how much time there is left, and then submit the job with this parameter added. </p> <p>To submit a job that runs for 1 day and 8 hours, you can simply add <code>--time=1-08:00:00</code> to your Slurm command. </p> <p>Additionally you can read about our recommendations for using checkpointing to work with time limits.</p>"},{"location":"service-windows/#ai-lab","title":"AI-LAB","text":"<p>In the days leading up to the service window, a time limit will be imposed, which will prevent you from launching jobs with end dates that surpass the date of the service window. </p> <p>In this period, you will only be able to launch new jobs, if you add the <code>--time</code> parameter to your Slurm command. If the time parameter is not included, Slurm assumes you ask for the default maximum time for the partition. You will thus have to calculate how much time you have before the service window, and then submit a job with this parameter added. </p> <p>To submit a job that runs for 12 hours, you should add: <code>--time=12:00:00</code>. Not setting the <code>--time</code> parameter will place your job in the queue, where it will wait until the service window has been completed.</p> <p>IMPORTANT: You can still run jobs in the days leading up to the service window</p> <p>If you have any questions, please open a case with us on serviceportal.aau.dk</p>"},{"location":"service-windows/#ucloud-aauk8s","title":"UCloud (AAU/K8s)","text":"<p>The UCloud (AAU/K8s) cluster will be unavailable for the entire duration of the service window and may become available again by the end of the day. While it may be technically possible to start jobs on the day of the service window, please note that any running jobs will be terminated as part of the scheduled maintenance activities performed by the administrators. We recommend planning your work accordingly to avoid interruptions.</p>"},{"location":"terms-and-conditions/","title":"Terms and conditions","text":""},{"location":"terms-and-conditions/#high-performance-computing-systems-at-aau-are-subjects-limited-by-the-ever-changing-availability-of-the-resources-dependant-on-the-users-thus-having-resources-granted-does-not-consequently-mean-that-it-is-possible-to-use-them-right-away-learn-about-the-guidelines-and-rules-to-ensure-a-smooth-and-efficient-computing-experience","title":"High-Performance Computing systems at AAU are subjects limited by the ever-changing availability of the resources, dependant on the users. Thus, having resources granted does not consequently mean that it is possible to use them right away. Learn about the guidelines and rules to ensure a smooth and efficient computing experience.","text":"<p>General principles and definitions of terms</p> <p>As a general principle, the HPC resources are intended to provide additional computational power to AAU researchers and staff.</p> <ul> <li>We refers to CLAAUDIA and or any other part of the Information Technology Services (ITS) department that is responsible for the provision, maintenance or support of HPC RESOURCES at Aalborg University.</li> <li>You refers to you the user, which may be an individual or other legal person.</li> <li>HPC refers to High Performance Computing resources</li> </ul> <p>What are the systems not intended for?</p> <ul> <li>They are not designed for long term storage of research data.</li> <li>They are not designed for production.</li> <li>They are not intended to host long term shared research projects.</li> </ul> <p>We offer custom solutions If you are in need of larger research project solutions, production virtual machines, or long term storage, please submit a request CLAAUDIA support team.</p>"},{"location":"terms-and-conditions/#1-access-and-responsibility","title":"1. Access and Responsibility","text":"<p>The use of HPC RESOURCES requires that you are employed at AAU. You are responsible for any actions taken on these systems including the responsibility for ensuring that access is restricted to the appropriate individuals. Users are responsible for ensuring that their activities align with the guidelines and best practices outlined in the respective documentation of each platform.</p> <p>Only users authorized via the CLAAUDIA application form may have administrative access to the applied resources.</p>"},{"location":"terms-and-conditions/#2-fair-and-sustainable-use-of-platforms","title":"2. Fair and Sustainable Use of Platforms","text":"<p>Responsibility for following guidelines</p> <p>It is imperative to follow the guidelines for virtual machine usage and resource allocation in AI Cloud, and to always prioritize consideration for fellow researchers when using these resources.</p>"},{"location":"terms-and-conditions/#21-strato","title":"2.1. Strato","text":"<p>Active virtual machines prevent other users from accessing those resources. A virtual machine should only be kept running while it is in current and active use. Active use requires that the machine will be used for research purposes within the coming 48 hours. The setup of each virtual machine is stored on a block device volume, which can be used to new virtual machines \u201cfrom volumes\u201d at a later stage. All virtual machines that are not in use must be deleted. </p> <p>See this guide</p>"},{"location":"terms-and-conditions/#22-ai-cloud","title":"2.2. AI Cloud","text":"<p>Users should be considerate of fellow researchers when allocating jobs in AI Cloud. Jobs should only run if they are actively utilising the computation resources that have been allocated to them. I.e. Interactive jobs should only be used very briefly for development purposes, and no job should allocate any GPU resources that are not used by the job. Users should test their applications for effective utilisation of GPU resources before starting any resource-heavy jobs.</p>"},{"location":"terms-and-conditions/#3-gdpr-compliance-and-data-responsibility","title":"3. GDPR Compliance and Data Responsibility","text":"<p>Adherence to GDPR</p> <p>You must adhere to the General Data Protection Act (GDPR) regulations, e.g. gain consent when needed - links are available below in sections 3.1. and 3.2.. You are personally responsible for any data stored on any of the HPC RESOURCES.</p>"},{"location":"terms-and-conditions/#31-gdpr-compliance-for-aau-employees","title":"3.1. GDPR compliance for AAU employees","text":"<p>If you are interested in using HPC RESOURCES in your research work as an AAU employee, you need to go to the GDPR website and complete and submit a notification of your data collection.</p> <p>You can find more information at AAU's website for GDPR related info for employees.</p>"},{"location":"terms-and-conditions/#4-confidentiality-and-sensitivity-of-data","title":"4. Confidentiality and Sensitivity of Data","text":"<p>AI Cloud and virtual machines on Strato or UCloud must not be used to store confidential and/or sensitive data.</p> <p>UCloud projects with sensitive data</p> <p>Please read the procedure for working with sensitive data on UCloud that has been agreed upon with the Department of Grants and Contracts. </p>"},{"location":"terms-and-conditions/#5-deletion-of-accounts-and-data","title":"5. Deletion of Accounts and Data","text":"<p>With regards to data stored on any of the HPC RESOURCES, it will automatically be deleted if the user is no longer registered as an active student or staff member.</p>"},{"location":"terms-and-conditions/#51-deletion-of-strato-and-ai-cloud-student-accounts-and-data-extraction-responsibilities","title":"5.1. Deletion of Strato and AI Cloud Student Accounts and Data Extraction Responsibilities","text":"<p>All Strato and AI Cloud student accounts will be deleted at the end of each semester (01 February, and 01 August). Students are responsible for the extraction or saving of all data that is of value to them prior to these dates.</p>"},{"location":"terms-and-conditions/#52-extract-or-delete-inactive-data","title":"5.2 Extract or delete inactive data","text":"<p>Once you\u2019ve finished processing your data, please make sure to either extract it or delete it\u2014\u201cfinished data\u201d means anything you\u2019re no longer actively working on. HPC platforms aren\u2019t meant for long-term storage, so when you\u2019re done, move your data to a dedicated storage solution like Datadeposit.</p>"},{"location":"terms-and-conditions/#6-prohibited-usage-and-consequences","title":"6. Prohibited Usage and Consequences","text":"<p>HPC RESOURCES may not, under any circumstances, be used for any purpose outside the scope of staff research, teaching or administrative functions. Any misuse of the HPC RESOURCES will result in an immediate and permanent ban of the use of any HPC RESOURCES. Criminal or unlawful activity will be reported to the appropriate authorities.</p>"},{"location":"terms-and-conditions/#7-service-windows","title":"7. Service Windows","text":"<p>What is a service window?</p> <p>A service window is a scheduled time when maintenance work is done on AAU's HPC systems that disrupt normal use. This maintenance can make the system temporarily unavailable or some resources unusable. AAU informs users in advance so they can plan their work around it. Once it's done, the system returns to normal and users can resume their work.</p> <ul> <li>Scheduled service windows: Four entire days each year are reserved for security updates. </li> <li>Planned service windows: Occur when sub-system maintenance is required between the existing scheduled service windows.</li> <li>Emergency service windows: All systems may be subject to emergency service windows. In the case of an accute emergency, all users will be informed of the nature and expected duration of the window.</li> </ul>"},{"location":"terms-and-conditions/#71-scheduled-service-windows-for-strato-and-ai-cloud","title":"7.1. Scheduled service windows for Strato and AI Cloud","text":"<p>Four entire days each year are reserved for security updates. This may require that all hosts are restarted. Users should expect that all virtual machines will be shut off during this service window and the job queue will be cleared.</p> <p>Proposed schedule of service windows (these dates are subjects to change):</p> <p>2024 17/09, 03/12</p> <p>2025 11/02, 13/05, 16/09, 02/12</p> <p>2026 10/02, 12/05, 15/09, 01/12</p> <p>2027 09/02, 11/05, 14/09, 30/11</p> <p>2028 08/02, 09/05, 12/09, 28/11</p> <p>Check ServiceInfo.dk to learn more about current service windows</p>"},{"location":"terms-and-conditions/#72-right-to-maintenance-and-modification-of-systems","title":"7.2. Right to maintenance and modification of systems","text":"<p>We reserve the right to periodically shut off entire systems for maintenance or security purposes. These systems require maintenance and updates at regular intervals, and we commit, where possible, to provide a minimum of two calendar weeks warning before any shut down period commences.</p> <p>We reserve the right to modify, redesign, disable or remove any of the existing services. Where possible, users will be notified of major modifications to the existing systems a minimum of three calendar months before these changes are implemented. Updates, upgrades and shutdown periods are not considered major modifications.</p>"},{"location":"terms-and-conditions/#73-communication-policy-around-service-windows","title":"7.3. Communication policy around service windows","text":"Scheduled IT disruptionsPlanned IT disruptionsEmergency communication timeframes <ol> <li> <p>Service window date reminder email</p> <ul> <li>Sent to all users of Strato, AI Cloud</li> <li>Dispatched 6-8 weeks before service window</li> </ul> </li> <li> <p>Orientation email about service window</p> <ul> <li>Sent to the internal CLAAUDIA and ITS management list</li> <li>Dispatched 2 weeks before service window</li> </ul> </li> <li> <p>Notice of service window pre arranged on ServiceInfo.dk</p> <ul> <li>Put on 1 week before the service window.</li> </ul> </li> <li> <p>Orientation email to system owner forum, key stakeholders or research group leaders</p> <ul> <li>Dispatched 2 weeks before service window.</li> </ul> </li> <li> <p>Orientation email to all users</p> <ul> <li>Dispatched 1 week before service window.</li> </ul> </li> <li> <p>Completion of planned work changed on ServiceInfo.dk</p> <ul> <li>Changed on first working day after the service window.</li> </ul> </li> </ol> <ol> <li> <p>Service window date reminder email</p> <ul> <li>Sent to all users of Strato, AI Cloud</li> <li>Dispatched 6-8 weeks before service window</li> </ul> </li> <li> <p>Orientation email about service window</p> <ul> <li>Sent to the internal CLAAUDIA and ITS management list</li> <li>Dispatched 4 weeks before service window</li> </ul> </li> <li> <p>Notice of service window pre arranged on ServiceInfo.dk</p> <ul> <li>Put on 2-3 weeks before the service window</li> </ul> </li> <li> <p>Orientation email to system owner forum, key stakeholders or research group leaders</p> <ul> <li>Dispatched 3 weeks before service window.</li> </ul> </li> <li> <p>Orientation email to all users</p> <ul> <li>Dispatched 2 weeks before service window.</li> </ul> </li> <li> <p>Completion of planned work changed on ServiceInfo.dk</p> <ul> <li>Changed on first working day after the service window.</li> </ul> </li> </ol> <ol> <li> <p>After 1st hour</p> <ul> <li>Out of order notice posted on ServiceInfo.dk.</li> </ul> </li> <li> <p>Unresolved problems at end of day</p> <ul> <li>Update on status - even if no change has occurred.</li> </ul> </li> <li> <p>After problem resolution</p> <ul> <li>The issue will be marked as resolved on ServiceInfo.dk</li> </ul> </li> </ol>"},{"location":"terms-and-conditions/#8-loan-of-physical-equipment","title":"8. Loan of physical equipment","text":""},{"location":"terms-and-conditions/#81-responsibility-and-liability-for-physical-equipment-loaned-by-aau","title":"8.1. Responsibility and Liability for Physical Equipment Loaned by AAU","text":"<p>With regards to physical equipment, you are solely responsible for damage to or loss of the equipment during the loan period. In the event of damage, AAU determines whether the equipment shall be repaired or replaced. If AAU determines that it is not viable to repair the equipment or if the equipment is lost, you shall compensate AAU for the value of the equipment.</p> <p>If AAU determines that the equipment can be repaired, you shall pay for the repair.</p>"},{"location":"terms-and-conditions/#82-ethical-use-and-legal-responsibility-for-physical-kits-with-cameras","title":"8.2. Ethical Use and Legal Responsibility for Physical Kits with Cameras","text":"<p>Physical kits are delivered with a camera. Please act ethically and refrain from using them in places where other people may consider it unpleasant or annoying. You are responsible for acting according to the legislation of the country in which you use the equipment and the Danish legal and ethical rules.</p>"},{"location":"terms-and-conditions/#9-updates-to-terms-and-conditions","title":"9. Updates to Terms and Conditions","text":"<p>We reserve the right to make periodic changes to these terms and conditions, and commit to inform users of the changes made.</p>"},{"location":"terms-and-conditions/#appendix","title":"Appendix","text":""},{"location":"terms-and-conditions/#procedure-for-working-with-sensitive-data-on-ucloud-projects","title":"Procedure for working with sensitive data on UCloud projects","text":"<p>CLAAUDIA, Aalborg University</p> <p>2023-10-10</p> <p>v1.0</p> <p>As a user on the UCloud platform you have a workspace called \"My workspace\".</p> <p>It is also possible to apply for a separate \"Project\" workspace on the UCloud platform. Projects on UCloud allow for collaboration with separate storage, compute resources and management of user rights and responsibilities on the UCloud platform.</p> <p>The project environment is required for the following types of work on UCloud:</p> <ol> <li> <p>For employed researchers at AAU (VIP)</p> <p>a.  Sensitive data: All work on the UCloud platform that involves     research data in classification levels 2. a 2.  All users</p> <p>a.  GPU access on UCloud: All access to GPU resources on UCloud     require a project.</p> <p>b.  Additional compute resources that are allocated out of the AAU     pool of UCloud resources.</p> </li> </ol> <p>UCloud users at AAU must be familiar with the details of the following codes of conduct and policies:</p> <ol> <li> <p>The Danish Code of Conduct for Research     Integrity</p> </li> <li> <p>The AAU Policy for Research Data     Management</p> </li> <li> <p>The AAU policies with regards to     GDPR     (Available in English for     researchers     (VIP) and     teachers     (VIP);     Only in Danish for administration (TAP)     employees)</p> </li> <li> <p>The AAU data management     recommendations</p> </li> </ol> <p>These policies cover the general rules all researchers (and TAP staff for point 3.) should abide by with regards to what kind of data may be kept, for how long, whether data can be re-used or recycled, and how long it should be archived for, etc.</p> <p>Sensitive data: Registration of research projects at Grants and Contracts</p> <p>For researchers at AAU, working with sensitive personal data requires that you register your research project with \"Grants and Contracts\" by completing the digital form that matches your role in relation to the data, for example Data Controller or Data processor.</p> <p>Data processing agreement between AAU and the EScience center at SDU</p> <p>For AAU users, data analysis and processing may then take place on the UCloud platform according to the data processing agreement between AAU and EScience center at SDU.</p> <p>Steps required to working with projects on the UCloud platform</p> <ol> <li> <p>Identify the data classification of your data by reviewing the AAU     data classification     model.</p> </li> <li> <p>If you are a researcher, and working with personally identifiable information, you must register a research project with Grants and Contracts     using the relevant registration     form.</p> <p>a.  Once you have registered your research activity at Grants and     Contracts, you will get a receipt that contains a \"WorkZone case     number\" (To be included in your UCloud project application).</p> </li> </ol> <ol> <li> <p>All applicants for projects on UCloud must complete the CLAAUDIA     application form for DeiC Interactive HPC resources.</p> </li> <li> <p>Once approved, you will receive a UCloud project     number, and you must apply for a project in the UCloud     Interface,     including the resources that you had approved in the CLAAUDIA     application. (You can apply for additional resources later if     needed.)</p> <p>a.  As project applicant you will be the Principal Investigator for     the project, and you should be aware of your roles and     responsibilities.</p> <p>b. The project must use the same project title as provided in the CLAAUDIA application, and both the DeiC project number and the Grants and Contracts reference number should be included:</p> <pre><code>i. The DeiC project number should be entered in the \"DeiC Interactive HPC project number\" field.\nii. The WorkZone case number should be entered in the \"WorkZone reference number\" field.\n</code></pre> <p>c.  Once your project is approved, you will get access to project     storage (Drive(s)) on UCloud that is separate from your \"My     Workspace\" storage. No sensitive data may be stored in the \"My     workspace\" drives.</p> </li> <li> <p>Adding data to the UCloud platform:</p> <p>a.  Any data added to the project should be in a project folder and     this must be marked according to the level of data sensitivity,     as described in the AAU data classification     model.</p> <pre><code>i.  On the UCloud platform the corresponding classifications are\n    as follows:\n\n    - AAU Level 1  \u2192 UCloud: Inherit\n    - AAU Level 2  \u2192 UCloud: Private/Confidential\n    - AAU Level 3  \u2192 UCloud: Sensitive (Only permitted to be added to your registered \n    and approved project folder.) Sensitive data may **NOT** be added to My Workspace.\n    - AAU Level 4  \u2192 Not allowed\n</code></pre> </li> <li> <p>Collaboration on UCloud within projects: Fellow AAU persons</p> <p>a.  Only persons named in the project registered with Grants and     Contracts may be added to the UCloud project.</p> </li> <li> <p>Collaboration on UCloud within projects: Persons from outside     AAU</p> <p>a.  The collaborator's employer must have a Data Processing     agreement with SDU (SDU are hosting UCloud), or</p> <pre><code>i.  Where there is an agreement of shared data responsibility\n    (Agreement on Joint data controlling), that states that it\n    is agreed to use DeiC/SDU as the data processor, then it is\n    sufficient that AAU has an existing data processing\n    agreement with DeiC/SDU. In these cases AAU will be\n    responsible for the data processing agreement with DeiC/SDU.\n</code></pre> <p>b.  If this is not the case, you cannot invite the collaborator     inside the project folder in UCloud.</p> <p>c.  No person(s) that are not included in the data processing     agreement or the agreement on joint data controlling may be     invited to the project.</p> </li> <li> <p>UCloud project members and roles should be set appropriately.</p> <p>a.  Project \"admins\" can see all member files by activating the     \"show member files\" option. The Principal Investigator is     responsible for ensuring that all roles and     responsibilities     are properly assigned.</p> </li> <li> <p>Read and write privileges on UCloud</p> <p>a.  If collaborators are only allowed read or write to specific     parts of the data / dataset, you will need to follow the     following steps:</p> <pre><code>i.  Within the project, you will need to create a new \"Drive\".\n    (As drives are the only level to which you can specify read\n    and write permissions.)\n\n    1.  Only project \"admins\" can create new drives within a\n        project.\n\nii. Name the drive and then click the \"...\" button to modify the\n    permissions. Then choose the permissions (None / Read /\n    Write).\n</code></pre> </li> <li> <p>Permitted applications and uses</p> <p>a. Only the SDU/K8 provider is permitted for working with data classifications 2 and 3.</p> <p>b. The AAU/K8 and AAU virtual machine providers are only permitted to be used for data classified as level 1.</p> </li> <li> <p>On completion the project\u00a0</p> <p>a.  All data on the UCloud platform should be deleted.</p> <p>b.  The project should then be archived with a final date that     corresponds with the GDPR notification with 'Grants and     Contracts'.</p> <p>c.  All files in trash folders should be permanently deleted.</p> <p>d.  All complete data sets and metadata should be stored in a data     repository in accordance with The AAU Policy for Research Data     Management.     As of 2023-January, AAU     DataDeposit     as a local archiving solution, while a national solution is     under development.</p> </li> </ol>"},{"location":"ai-cloud/","title":"AI Cloud","text":"Researchers Indicates if the platform is accessible for researchers (e.g., PhD students, postdocs, faculty) for research purposes. Students Indicates if the platform is accessible to students for educational purposes (e.g., coursework, projects, thesis). Sensitive Data Whether the platform supports processing and storing sensitive or confidential data CPU processing Indicates if the platform supports computational tasks that only require CPU resources. GPU processing Indicates if the platform supports computational tasks that require GPU resources for acceleration (e.g., deep learning). Unlimited compute Whether the platform allows unrestricted compute usage, without limitations on the amount of usage time. Terminal interface The method used to access the platform. Pre-installed apps Indicates if the platform comes with pre-installed applications or frameworks for convenience (e.g., Ansys, PyTorch, TensorFlow). Collaboration friendly Indicates if the platform supports collaborative work (e.g., sharing resources, co-editing, team projects). Working interactively Indicates if the platform supports interactive workflows where users can interact with running processes (e.g., Jupyter notebooks). Possible to add GUI Whether it is possible to run graphical user interfaces (GUIs) on the platform (e.g., remote desktops, JupyterLab). Not for storage This platform is not designed for long term storage of research data."},{"location":"ai-cloud/#introduction","title":"Introduction","text":"<p>AI Cloud is a GPU cluster made up of a collecton of NVIDIA GPU's, designed for processing GPU-demanding machine learning workloads. The platform is accessed through a terminal application on the user's local machine. From here the user logs in to a front end node, where files management and job submission to the compute nodes takes place.</p>"},{"location":"ai-cloud/#getting-started","title":"Getting Started","text":"<p>How to access</p> <p>Learn how to access AI Cloud</p> <p>Guides for AI Cloud</p> <p>Learn the basics on how to use AI Cloud</p> <p>Terms and Conditions</p> <p>Get an overview of the Terms and Conditions for AI Cloud</p>"},{"location":"ai-cloud/#key-features","title":"Key FeaturesHigh-Performance GPU ClusterContainerization for FlexibilityEfficient Batch Processing","text":"<p>Harness powerful NVIDIA GPUs for efficient processing of large datasets and complex models.</p> <p>Ensure consistent software environments across nodes, supporting diverse and customizable computational workflows.</p> <p>AI Cloud uses Slurm for seamless job scheduling, enabling easy batch processing and background task management.</p>"},{"location":"ai-cloud/#common-use-cases","title":"Common Use Cases","text":"<p>Training deep learning models</p> <p>GPU access for AI projects</p> <p>Fine-tuning large language models</p> <p>Training speech models for PhD</p> <p>AI research with CT images</p> <p>Drug discovery acceleration</p> <p>MI models for question answering</p> <p>Knowledge graph embedding models</p> <p>Machine vision system development</p>"},{"location":"ai-cloud/#important-information","title":"Important Information","text":"<p>Not for confidential or sensitive data</p> <p>With AI Cloud you are only allowed to work with level 1 data according to AAU\u2019s data classification model.</p> <p>If you would like to work with level 2 or 3 data, then we support using another HPC platform called UCloud.</p> <p>Not suitable for CPU-only computational tasks</p> <p>The powerful GPU processors allow users to process large datasets much more efficiently than would be the case with pure CPU processing - given that your application can be parallelised in a GPU compatible manner. At the same time, the AI Cloud platform is not designed for CPU-only computational tasks, and we have alternative recommended platforms, such as UCloud or Strato for those needs.</p> <p>Review the terms and conditions</p> <p>Before getting started, take a few moments to review the terms and conditions of using AI Cloud, and don't hesitate to reach out to our support team if you have any questions or concerns.</p>"},{"location":"ai-cloud/fair-usage/","title":"Fair usage","text":"<p>The CLAAUDIA team is responsible for system administration and user support. We work closely with the infrastructure team in ITS, which takes care of hardware and system maintainance.</p> <p>We do recognise that we are a learning institution and that much of the work carried out on AI Cloud is learning-by-doing. We welcome this. Users are encouraged to experiment with features that they do not yet master, and we encourage them to reach out to us if they want our help with utilising the platform.</p> <p>It is a priority for us to help our users utilise the platform, and we are therefore happy to answer any questions you might have. Don't hesistate to reach out to us if you have any questions (find the \"Get Support\" button in the top right corner of this page).</p>"},{"location":"ai-cloud/fair-usage/#enforcement-of-rules","title":"Enforcement of rules","text":"<p>If we find indications of violations of the rules and principles layed out on this page, CLAAUDIA will contact you to learn more about your situation.</p> <p>As a general rule CLAAUDIA does not cancel jobs without the user's permission. That being said - we do reserve the right to do so, if the situation compromises the platform or service we are able to provide. We will always get in touch with the user.</p> <p>We ask our users not to interfere with our system administration. It is entirely up to CLAAUDIA to make objections to our users and no individual user has the authority to do so. Should you have any concerns, you are very welcome to get in touch with us.</p>"},{"location":"ai-cloud/fair-usage/#responsible-use-of-the-platform","title":"Responsible use of the platform","text":"<p>In addition to the default resource limitations that are in place on the platform, we encourage you to use the resources responsibly.</p>"},{"location":"ai-cloud/fair-usage/#recommendations","title":"Recommendations:","text":"<ul> <li> <p>Always launch your jobs as batch-jobs that require no interference from the user. A batch job is one that has clearly defined start and stop conditions; the job should should execute some script and then release the resources when it's finished.</p> </li> <li> <p>Ensure that your jobs occupy resources only as long as they are needed.</p> </li> <li> <p>Do not allocate GPU's do your job, if it does not need them. Run on them on the CPU partition instead.</p> </li> <li> <p>If you intend to allocate multiple GPU's to your job, it is your responsibility to ensure that your project is able to make use of the increased number of GPU-devices in a meaningful way.</p> </li> <li> <p>If possible, we recomend making good use of the time scheduler features in Slurm. Launch jobs in periods with low demand - ie. times outside of office hours; on weekends, during holidays, during the night, etc. The parameter <code>--begin</code> can be added to your Slurm command for this purpose.</p> </li> <li> <p>Keep in mind that AI Cloud is a multi-user system, and that it is entirely possible for one user to destabilize the front-end node by launching resource-intensive operations. Ensuring that we have a stable platform is a shared responsibility.</p> </li> </ul>"},{"location":"ai-cloud/fair-usage/#disencouraged-use-of-the-platform","title":"Disencouraged use of the platform","text":""},{"location":"ai-cloud/fair-usage/#interactive-sessions","title":"Interactive sessions","text":"<p>AI Cloud is designed for launching unattended batch jobs, and thus we do not allow interactive development sessions. Interactive development sessions are defined as any session, that is opened on a compute node and idles until the user initiates a proces.</p> <ul> <li> <p>Launching jobs from within interactive shell sessions </p> <p>It is considered bad practice to launch unattended jobs from within interactive shell sessions. This would be opening a shell session (with something like <code>srun --pty</code>), and then interactively typing in the commands for loading the container and executing the traning proces. This not only occupies resources for longer than needed, but also makes it dependent on the shell session on the front end node, which will crash your job if the front end node were to crash. Read our guide Getting started &gt; Run Jobs to learn what to do instead.</p> </li> <li> <p>Interactive development sessions</p> <p>We do not allow interactive development sessions. By interactive development we mean opening an interactive shell session with something like <code>srun --pty -G 1 singularity --nv &lt;shell/exec&gt; image.sif</code>, and only occassionally execute commands be that directly from the console or from an IDE like Jupyter Notebook, Spyder or VS Code. This does not guarantee that resources are released automatically, when they are no longer needed, and thus resources are occupied for longer than needed.</p> <p>We understand that this can sometimes be necessary for very specific troubleshooting cases, but even this is in most cases preferable to do from within an unattended batch job (launched with <code>sbatch</code>). The reason for this is that interactive development sessions have very ineffective utilisation of resources, which limits the overall resource availability of the system.</p> <p>Do know that interactive development is allowed on UCloud.</p> </li> </ul>"},{"location":"ai-cloud/fair-usage/#vs-code-sessions","title":"VS Code sessions","text":"<p>Increasingly we find that users are logging in to the platform with the Remote SSH-extension for VS Code (and forks thereof; Cursor, Kiro, etc.). This puts immense pressure on the front end node, which results in the node becoming sluggish and unresponsive for all users on the system. </p> <p>This is certainly a cool feature, and one that we do plan on supporting in the future - but as of now, we do not support it fully. We therefore ask our user's to take great care when using this feature.</p> <p>If we find that platform responsiveness is challanged by the use of this feature, we will act in accordance with the practice layed out in Enforcement of rules.</p>"},{"location":"ai-cloud/faq/","title":"Faq","text":"How can I extend or increase my allocated storage? I\u2019m struggling to build or use my own container for AI Cloud I need GPUs for my project or thesis (e.g., training large models, requesting a special GPU partition). How do I obtain or regain access? Is there a scratch drive or high-speed storage area available, and how can I use it? Why are my partitions or group memberships suddenly unavailable, causing \u2018not permitted to use this partition\u2019 errors? Can you re-add me? I\u2019m having Python package or version mismatches inside a container (e.g., pip not found or conflicting Python versions). How do I fix this? I keep running out of space while building containers (\u2018No space left on device\u2019). What are ways to resolve that? Our group or team needs HPC/AI Cloud resources for our bachelor/master/research project. How do we set up or request the server for group use? I'm facing node failures or broken drivers (e.g., GPU not initializing, Fabric Manager issues, or NVML library mismatches). Can you help? I cannot connect via SSH or WinSCP (password rejected / unresponsive / \u2018permission denied\u2019). How do I troubleshoot login problems? Can I be removed from a specific mailing list or distribution list? I have large-scale data (or HPC-level demands) and need bigger allocations or HPC solutions beyond local GPU clusters. Are there other HPC resources (like LUMI) I can apply for? AI Cloud or the transfer speed is extremely slow or unresponsive (e.g., scp takes hours, pip installs crash). Is there a known fix? Some users are occupying all the GPUs (or CPU resources). Is there a way to limit usage so everyone can get resources? I need to run specialized software (e.g., MATLAB, custom HPC frameworks) or have HPC environment questions. Where can I find help or examples?"},{"location":"ai-cloud/how-to-access/","title":"How to access","text":""},{"location":"ai-cloud/how-to-access/#who-can-request-access","title":"Who can request access?","text":"<ul> <li>Researchers are granted access upon filling out our access request form.</li> <li>Students are refered to using AI-LAB - a similar platform dedicated to students.</li> </ul>"},{"location":"ai-cloud/how-to-access/#how-to-request-access","title":"How to request access","text":"<ul> <li>Fill out the access request form. </li> <li>The request is processed manually, so please expect a bit of delay before you can start using AI Cloud.</li> </ul>"},{"location":"ai-cloud/resource-quotas/","title":"Resource quotas","text":""},{"location":"ai-cloud/resource-quotas/#the-default-quota","title":"The default quota","text":"<p>We enforce a standard quota which allows each user to run 12 simultaneous jobs, with a maximum of 12 GPU's. An unlimited number of jobs can be queued.</p> Name Max jobs Max GPU's Access requirement Special notes Default 12 12 None -"},{"location":"ai-cloud/resource-quotas/#beyond-the-default-quota","title":"Beyond the default quota","text":"<p>Once you have submitted the maximum number of jobs allowed by the default quota, you can launch additional jobs in other access modes:</p> Name Additional jobs Additional GPU's Access requirement Special notes Deadline 12 12 Approved applicants Requires application Unprivileged Infinite Infinite None Jobs are preemptible AI Centre Infinite Infinite AI Center affiliation -"},{"location":"ai-cloud/resource-quotas/#deadline-access","title":"Deadline access","text":"<p>In case you are working under a deadline, it's possible to apply for deadline resources. This is effectively a doubling of the default quota, which grants you access to additional resources for a limited time - totalling to 24 jobs running simultaneously and 24 GPU's for up to 14 days. Once granted it is not possible to reapply for another 14 says.</p> <p>This option is not meant to become a permanent solution for research projects with large resource needs - if this is the case with your research project, we encourage you to consider applying for a grant at an external HPC facility. Read more about that oppurtunity on our page for External HPC.</p> <ul> <li>Find the application form: AI Cloud: Request access to deadline resources.</li> <li>Learn more about launching jobs in deadline mode.</li> </ul>"},{"location":"ai-cloud/resource-quotas/#unprivileged-access","title":"Unprivileged access","text":"<p>It's possible to run an unlimited number of jobs in unprivileged mode. You must however understand, that your jobs can be interrupted if a request is made for the same resources. Once they free up again, your job is automatically requeued.</p> <ul> <li>Learn more about launching jobs in unprivileged mode.</li> <li>Learn more about launching unprivileged jobs on proprietary nodes.</li> </ul>"},{"location":"ai-cloud/resource-quotas/#proprietary-nodes","title":"Proprietary nodes","text":"<p>Resarchers with affiliation to the Pioneer Centre for AI can be granted special access to the <code>aicentre</code> and <code>aicentre-a100</code> partitions. If you are affiliated with this group, speak to your group leader about this.</p> <ul> <li>Learn more about launching privileged jobs on proprietary nodes.</li> </ul>"},{"location":"ai-cloud/service-windows/","title":"Service windows","text":"<p>Four times a year, all of our platforms are subject to service windows where changes and security upgrades are implemented. During these, we reserve an entire day for maintainance of the systems.</p> <p>It should be expected that the platforms are offline for the entire day from 00:01 until 23:59 - but they may come online by the end of the days, as the work is finished.</p>"},{"location":"ai-cloud/service-windows/#schedule","title":"Schedule","text":"<p>A service window will take place on the following dates:</p> <p>AI Cloud, Strato, UCloud VM's &amp; UCloud Kubernetes</p> 2025 2026 2027 2028 11/02 10/02 09/02 08/02 13/05 12/05 11/05 09/05 16/09 15/09 14/09 12/09 02/12 01/12 30/11 28/11 <p>AI-LAB</p> 2025 2026 2027 2028 13/02 12/02 11/02 10/02 15/05 14/05 13/05 11/05 18/09 17/09 16/09 14/09 04/12 03/12 02/12 30/11 <p>TAAURUS</p> 2026 2027 2028 2029 03/02 - - - - - - - - - - - - - - - <p>Sign up for notifications on serviceinfo.dk</p> <p>Click this link to go to serviceinfo.dk. Then select Aalborg University, and under the tab Subscribe (or Abonn\u00e9r), select CLAAUDIA. Select email, SMS or calendar, according to your preferences:</p> <p> Go to ServiceInfo.dk</p>"},{"location":"ai-cloud/service-windows/#platform-specific-information","title":"Platform specific information","text":""},{"location":"ai-cloud/service-windows/#strato-and-ucloud-virtual-machines","title":"Strato and UCloud virtual machines","text":"<p>Be sure to save your work no later than the end of the day before the service window begins, as all virtual machines will be automatically shut down during the service window and any unsaved data will be lost.</p> <p>Usage Management Process </p> <p>1. Servers will NOT restart automatically after service windows     - All servers in the AAU availability zone will be shut down during service windows and will not restart automatically, unless they have been registered for automatic restart before the service window.      - You can easily restart your servers manually after the service window.</p> <p>2. Automatic server resizing after 48 hours of inactivity     - Servers that remain shut down for more than 48 hours will be automatically resized to the smallest CPU configuration.     - You will receive a notification when your instance has been resized.</p> <p>3. Automatic server deletion after 30 days of inactivity     - Servers that remain shut down for 30 days will be permanently deleted, but their volumes will be preserved.     - You will be notified in advance about any affected instances.</p> <p>4. Unused volume cleanup     - Volumes not attached to any server for 30 days will be deleted.     - A notification will be sent before deletion.</p> <p>All virtual machines should be removed when not in use.  Basic rule: keep your volumes, delete your unused VMs, and only run a VM with the size you really need right now. Please consult the page 'Delete and restart an instance from the volume' for instructions on how to do this.</p> <p>Apply for automatic restart of your Strato server</p> <p>Note: The deadline for requesting inclusion in the automatic restart list has now passed for the service window on the 2nd december.</p> <p>You could request automatic restarts for your server if all of the following conditions were met:</p> <ul> <li>The server is part of a Strato Project</li> <li>You can provide a valid motivation for needing automatic restart</li> <li>The server is in one of these availability zones:<ul> <li>AAU</li> <li>AAU-T4</li> <li>AAU-A10</li> <li>AAU-A40</li> </ul> </li> </ul> <p>Servers running in personal project spaces (such as default quota projects, e.g. <code>GK83DJ@aau.dk</code>) cannot be included. If you want to move your project, you can find instructions on how to apply for a Strato Project</p> <p>The application form for inclusion in the automatic restart list closed on November 25th: Strato service window: Automatic server restart inclusion form</p> <p>Link to Strato's web-interface: strato-new.claaudia.aau.dk</p>"},{"location":"ai-cloud/service-windows/#ai-cloud","title":"AI Cloud","text":"<p>In the days leading up to the service window, a reservation will be put in place for the entire cluster. The entirety of the cluster will therefore be unavailable for that day, but may come back online by the end of the day.</p> <p>You can still submit jobs in the days leading up to the service window. Since the <code>batch</code> and <code>prioritized</code> partitions have time limits of 12 hours and 6 days respectively, you will only be able to launch new jobs if you add the <code>--time</code> parameter to your Slurm command. If you do not set this parameter, and there are 5 days until the day of the service window, your job will not start until after the service window. You will thus need to calculate how much time there is left, and then submit the job with this parameter added. </p> <p>To submit a job that runs for 1 day and 8 hours, you can simply add <code>--time=1-08:00:00</code> to your Slurm command. </p> <p>Additionally you can read about our recommendations for using checkpointing to work with time limits.</p>"},{"location":"ai-cloud/service-windows/#ai-lab","title":"AI-LAB","text":"<p>In the days leading up to the service window, a time limit will be imposed, which will prevent you from launching jobs with end dates that surpass the date of the service window. </p> <p>In this period, you will only be able to launch new jobs, if you add the <code>--time</code> parameter to your Slurm command. If the time parameter is not included, Slurm assumes you ask for the default maximum time for the partition. You will thus have to calculate how much time you have before the service window, and then submit a job with this parameter added. </p> <p>To submit a job that runs for 12 hours, you should add: <code>--time=12:00:00</code>. Not setting the <code>--time</code> parameter will place your job in the queue, where it will wait until the service window has been completed.</p> <p>IMPORTANT: You can still run jobs in the days leading up to the service window</p> <p>If you have any questions, please open a case with us on serviceportal.aau.dk</p>"},{"location":"ai-cloud/service-windows/#ucloud-aauk8s","title":"UCloud (AAU/K8s)","text":"<p>The UCloud (AAU/K8s) cluster will be unavailable for the entire duration of the service window and may become available again by the end of the day. While it may be technically possible to start jobs on the day of the service window, please note that any running jobs will be terminated as part of the scheduled maintenance activities performed by the administrators. We recommend planning your work accordingly to avoid interruptions.</p>"},{"location":"ai-cloud/system-overview/","title":"System overview","text":"<p>AI Cloud platform is built around several key components, including a front-end node for managing tasks and code, and 27 compute nodes equipped with diverse hardware options. In this overview, you will find a description of each of the platforms major components.</p> <p>Below, is a diagram illustrating the architecture of the AI Cloud platform:</p> <pre><code>flowchart LR\n  subgraph id1[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Compute nodes&lt;/p&gt;]\n  direction TB\n  A[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\"  width='25' height='25' &gt;&lt;p&gt;a256-t4-[01-03]&lt;/p&gt;&lt;p&gt;i256-a10-[06-10]&lt;/p&gt;&lt;p&gt;a256-a40-[04-07]&lt;/p&gt;&lt;p&gt;i256-a40-[01-02]&lt;/p&gt;&lt;p&gt;a512-l4-06&lt;/p&gt;&lt;p&gt;nv-ai-[01-03]&lt;/p&gt;&lt;p&gt;nv-ai-04&lt;/p&gt;&lt;p&gt;a768-l40s-[01-06]&lt;/p&gt;&lt;p&gt;a512-mi100-01&lt;/p&gt;\n  &lt;/span&gt;\"]\n  end\n\n  subgraph id2[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 16px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 10px;\"&gt;AI Cloud&lt;/p&gt;]\n  direction TB\n  subgraph id3[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Front-end node&lt;/p&gt;]\n    direction TB\n    G[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;ai-fe02&lt;/span&gt;\"]\n    end\n  id3 --&gt; id1 \n\n  subgraph id4[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;File storage&lt;/p&gt;]\n    direction TB\n    E[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Ceph&lt;/span&gt;\"]\n    end\n\n  id1 &amp; id3 &lt;--&gt; id4\n  end\n\n  F[&lt;span&gt;&lt;img src=\"/assets/img/person.svg\" width='25' height='25'&gt;User laptop&lt;/span&gt;]-- SSH --&gt; id3\n</code></pre>"},{"location":"ai-cloud/system-overview/#hardware","title":"Hardware","text":""},{"location":"ai-cloud/system-overview/#front-end-node","title":"Front-end node","text":"<p>You start by logging into a front-end node, <code>ai-fe02.srv.aau.dk</code>. This node acts as the gateway to the cluster. Here, you can manage files, write and edit code, and prepare your computational tasks. It is important to note that the front-end node is not intended for heavy computations, as it is a node with a very modest amount of resources, and that crashing the node, will affect all users on the system.</p>"},{"location":"ai-cloud/system-overview/#compute-nodes","title":"Compute nodes","text":"<p>AI Cloud consists the following compute nodes:</p> Nodes Nodes in total CPU cores per node CPU type RAM per node GPUs per node GPU type RAM per GPU Local Disk NVLINK <code>a256-t4-[01-03]</code> 3 32 AMD EPYC 256 GB 6 NVIDIA T4 16 GB <code>a256-a40-[04-07]</code> 4 32 AMD EPYC 256 GB 3 NVIDIA A40 48 GB <code>i256-a10-[06-10]</code> 5 32 Intel Xeon 256 GB 4 NVIDIA A10 24 GB <code>i256-a40-[01-02]</code> 2 24 Intel Xeon 256 GB 4 NVIDIA A40 48 GB 6.4 TB <code>a512-l4-06</code> 1 64 AMD EPYC 512 GB 8 NVIDIA L4 24 GB <code>a768-l40s-[01-06]</code> 6 64 AMD EPYC 768 GB 8 NVIDIA L40s 48 GB <code>nv-ai-[02-03]</code> 3 48 Intel Xeon 1470 GB 16 NVIDIA V100 32 GB 30 TB <code>nv-ai-04</code> 1 128 AMD EPYC 980 GB 8 NVIDIA A100 40 GB 14 TB <p>Further inspection of hardware</p> <p>It's also possible to inspect the compute node hardware using the following commands:</p> <p>A detailed overview of the CPU <pre><code>srun -w a768-l40s-01 lscpu\n</code></pre> An overview of the host RAM: <pre><code>srun -w a768-l40s-01 free -h\n</code></pre> An overview of the GPU (only shows the number of GPU devices you ask for): <pre><code>srun -w a768-l40s-01 -G 1 nvidia-smi\n</code></pre></p> <p>The compute nodes <code>i256-a40-01</code>, <code>i256-a40-02</code> and <code>nv-ai-04</code> are owned by specific research groups, and  members of these groups have first-priority access to these. Other users can access them on a limited basis via the \"batch\" partition (use option <code>--partition=batch</code> for your jobs). These jobs will run until, a member from the aforementioned research groups makes a request for them, at which point the batch-job, will be interrupted.</p>"},{"location":"ai-cloud/system-overview/#software","title":"Software","text":"<p>AI Cloud is essentially just a cluster of Linux servers that use Ubuntu as their operating system. </p> <p>The recommended way of interacting with the platform is using the command line - find the essential commands for doing this on linuxjourney.com.</p> <p>The platform leverages two primary software components: Slurm and Singularity. Learning how to use these tools, is an integral part of learning how to use the system. As they are commonly found on most HPC systems, learning how to use them will also open up the possibility of scaling your project to a larger supercomputer.</p>"},{"location":"ai-cloud/system-overview/#slurm","title":"Slurm","text":"<p>Slurm is the queueing mechanism used for scheduling and managing resources on AI Cloud. It provides essential features such as:</p> <ul> <li>Job Scheduling: Allocating resources to jobs based on user requests and system policies.</li> <li>Resource Management: Tracking and managing compute resources, ensuring optimal utilization.</li> <li>Queue Management: Organizing jobs into queues, prioritizing and executing them based on policies and resource availability.</li> </ul> <p>On AI Cloud, Slurm is responsible for managing the allocation and scheduling of compute resources, ensuring that user jobs are executed efficiently and fairly.</p>"},{"location":"ai-cloud/system-overview/#singularity","title":"Singularity","text":"<p>Singularity is a container platform designed for running applications on AI Cloud. Containers are portable and reproducible environments that bundle an application's code, libraries, and dependencies. Key features of Singularity include:</p> <ul> <li>Compatibility: Running containers with high-performance computing workloads without requiring root privileges.</li> <li>Portability: Enabling the same container to run on different systems without modification.</li> <li>Integration with HPC Systems: Designed to work seamlessly with HPC job schedulers like Slurm.</li> </ul>"},{"location":"ai-cloud/system-overview/#interconnection-of-slurm-and-singularity","title":"Interconnection of Slurm and Singularity","text":"<p>On AI Cloud, Slurm and Singularity work together. Slurm handles the job scheduling and resource allocation, while Singularity ensures that the specified container environment is instantiated and the application runs with all its dependencies.</p> <pre><code>flowchart LR\n  A[&lt;span&gt;&lt;img src=\"/assets/img/person.svg\" width='25' height='25'&gt;User laptop&lt;/span&gt;]\n  B[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Front-end node&lt;/span&gt;\"]\n  C[\"&lt;span&gt;&lt;img src=\"/assets/img/container.svg\" width='25' height='25'&gt;Singularity container&lt;/span&gt;\"]\n  D[\"&lt;span&gt;&lt;img src=\"/assets/img/queue.svg\" width='25' height='25'&gt;Slurm&lt;/span&gt;\"]\n  E[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Compute node&lt;/span&gt;\"]\n\n  A-- SSH --&gt; B  --&gt; D --&gt; E --&gt; C-- Result --&gt; B\n\n  style C stroke-dasharray: 5 5\n  style D stroke-dasharray: 5 5\n</code></pre>"},{"location":"ai-cloud/system-overview/#storage","title":"Storage","text":""},{"location":"ai-cloud/system-overview/#network-drive-storage","title":"Network drive storage","text":"<p>All nodes in the cluster are connected to the same network storage system. This ensures that all nodes in the cluster have access to the same files. There's no need to specify additional parameters to make your files available on the compute nodes or in container environments.</p> <p>Check out our page Overview of directories to learn more.</p>"},{"location":"ai-cloud/terms-and-conditions/","title":"Terms and Conditions","text":""},{"location":"ai-cloud/terms-and-conditions/#high-performance-computing-systems-at-aau-are-subjects-limited-by-the-ever-changing-availability-of-the-resources-dependant-on-the-users-thus-having-resources-granted-does-not-consequently-mean-that-it-is-possible-to-use-them-right-away-learn-about-the-guidelines-and-rules-to-ensure-a-smooth-and-efficient-computing-experience","title":"High-Performance Computing systems at AAU are subjects limited by the ever-changing availability of the resources, dependant on the users. Thus, having resources granted does not consequently mean that it is possible to use them right away. Learn about the guidelines and rules to ensure a smooth and efficient computing experience.","text":"<p>General principles and definitions of terms</p> <p>As a general principle, the HPC resources are intended to provide additional computational power to AAU researchers and staff.</p> <ul> <li>We refers to CLAAUDIA and or any other part of the Information Technology Services (ITS) department that is responsible for the provision, maintenance or support of HPC RESOURCES at Aalborg University.</li> <li>You refers to you the user, which may be an individual or other legal person.</li> <li>HPC refers to High Performance Computing resources</li> </ul> <p>What are the systems not intended for?</p> <ul> <li>They are not designed for long term storage of research data.</li> <li>They are not designed for production.</li> <li>They are not intended to host long term shared research projects.</li> </ul> <p>We offer custom solutions If you are in need of larger research project solutions, production virtual machines, or long term storage, please submit a request CLAAUDIA support team.</p>"},{"location":"ai-cloud/terms-and-conditions/#1-access-and-responsibility","title":"1. Access and Responsibility","text":"<p>The use of HPC RESOURCES requires that you are employed at AAU. You are responsible for any actions taken on these systems including the responsibility for ensuring that access is restricted to the appropriate individuals. Users are responsible for ensuring that their activities align with the guidelines and best practices outlined in the respective documentation of each platform.</p> <p>Only users authorized via the CLAAUDIA application form may have administrative access to the applied resources.</p>"},{"location":"ai-cloud/terms-and-conditions/#2-fair-and-sustainable-use-of-platforms","title":"2. Fair and Sustainable Use of Platforms","text":"<p>Responsibility for following guidelines</p> <p>It is imperative to follow the guidelines for virtual machine usage and resource allocation in AI Cloud, and to always prioritize consideration for fellow researchers when using these resources.</p>"},{"location":"ai-cloud/terms-and-conditions/#21-strato","title":"2.1. Strato","text":"<p>Active virtual machines prevent other users from accessing those resources. A virtual machine should only be kept running while it is in current and active use. Active use requires that the machine will be used for research purposes within the coming 48 hours. The setup of each virtual machine is stored on a block device volume, which can be used to new virtual machines \u201cfrom volumes\u201d at a later stage. All virtual machines that are not in use must be deleted. </p> <p>See this guide</p>"},{"location":"ai-cloud/terms-and-conditions/#22-ai-cloud","title":"2.2. AI Cloud","text":"<p>Users should be considerate of fellow researchers when allocating jobs in AI Cloud. Jobs should only run if they are actively utilising the computation resources that have been allocated to them. I.e. Interactive jobs should only be used very briefly for development purposes, and no job should allocate any GPU resources that are not used by the job. Users should test their applications for effective utilisation of GPU resources before starting any resource-heavy jobs.</p>"},{"location":"ai-cloud/terms-and-conditions/#3-gdpr-compliance-and-data-responsibility","title":"3. GDPR Compliance and Data Responsibility","text":"<p>Adherence to GDPR</p> <p>You must adhere to the General Data Protection Act (GDPR) regulations, e.g. gain consent when needed - links are available below in sections 3.1. and 3.2.. You are personally responsible for any data stored on any of the HPC RESOURCES.</p>"},{"location":"ai-cloud/terms-and-conditions/#31-gdpr-compliance-for-aau-employees","title":"3.1. GDPR compliance for AAU employees","text":"<p>If you are interested in using HPC RESOURCES in your research work as an AAU employee, you need to go to the GDPR website and complete and submit a notification of your data collection.</p> <p>You can find more information at AAU's website for GDPR related info for employees.</p>"},{"location":"ai-cloud/terms-and-conditions/#4-confidentiality-and-sensitivity-of-data","title":"4. Confidentiality and Sensitivity of Data","text":"<p>AI Cloud and virtual machines on Strato or UCloud must not be used to store confidential and/or sensitive data.</p> <p>UCloud projects with sensitive data</p> <p>Please read the procedure for working with sensitive data on UCloud that has been agreed upon with the Department of Grants and Contracts. </p>"},{"location":"ai-cloud/terms-and-conditions/#5-deletion-of-accounts-and-data","title":"5. Deletion of Accounts and Data","text":"<p>With regards to data stored on any of the HPC RESOURCES, it will automatically be deleted if the user is no longer registered as an active student or staff member.</p>"},{"location":"ai-cloud/terms-and-conditions/#51-deletion-of-strato-and-ai-cloud-student-accounts-and-data-extraction-responsibilities","title":"5.1. Deletion of Strato and AI Cloud Student Accounts and Data Extraction Responsibilities","text":"<p>All Strato and AI Cloud student accounts will be deleted at the end of each semester (01 February, and 01 August). Students are responsible for the extraction or saving of all data that is of value to them prior to these dates.</p>"},{"location":"ai-cloud/terms-and-conditions/#52-extract-or-delete-inactive-data","title":"5.2 Extract or delete inactive data","text":"<p>Once you\u2019ve finished processing your data, please make sure to either extract it or delete it\u2014\u201cfinished data\u201d means anything you\u2019re no longer actively working on. HPC platforms aren\u2019t meant for long-term storage, so when you\u2019re done, move your data to a dedicated storage solution like Datadeposit.</p>"},{"location":"ai-cloud/terms-and-conditions/#6-prohibited-usage-and-consequences","title":"6. Prohibited Usage and Consequences","text":"<p>HPC RESOURCES may not, under any circumstances, be used for any purpose outside the scope of staff research, teaching or administrative functions. Any misuse of the HPC RESOURCES will result in an immediate and permanent ban of the use of any HPC RESOURCES. Criminal or unlawful activity will be reported to the appropriate authorities.</p>"},{"location":"ai-cloud/terms-and-conditions/#7-service-windows","title":"7. Service Windows","text":"<p>What is a service window?</p> <p>A service window is a scheduled time when maintenance work is done on AAU's HPC systems that disrupt normal use. This maintenance can make the system temporarily unavailable or some resources unusable. AAU informs users in advance so they can plan their work around it. Once it's done, the system returns to normal and users can resume their work.</p> <ul> <li>Scheduled service windows: Four entire days each year are reserved for security updates. </li> <li>Planned service windows: Occur when sub-system maintenance is required between the existing scheduled service windows.</li> <li>Emergency service windows: All systems may be subject to emergency service windows. In the case of an accute emergency, all users will be informed of the nature and expected duration of the window.</li> </ul>"},{"location":"ai-cloud/terms-and-conditions/#71-scheduled-service-windows-for-strato-and-ai-cloud","title":"7.1. Scheduled service windows for Strato and AI Cloud","text":"<p>Four entire days each year are reserved for security updates. This may require that all hosts are restarted. Users should expect that all virtual machines will be shut off during this service window and the job queue will be cleared.</p> <p>Proposed schedule of service windows (these dates are subjects to change):</p> <p>2024 17/09, 03/12</p> <p>2025 11/02, 13/05, 16/09, 02/12</p> <p>2026 10/02, 12/05, 15/09, 01/12</p> <p>2027 09/02, 11/05, 14/09, 30/11</p> <p>2028 08/02, 09/05, 12/09, 28/11</p> <p>Check ServiceInfo.dk to learn more about current service windows</p>"},{"location":"ai-cloud/terms-and-conditions/#72-right-to-maintenance-and-modification-of-systems","title":"7.2. Right to maintenance and modification of systems","text":"<p>We reserve the right to periodically shut off entire systems for maintenance or security purposes. These systems require maintenance and updates at regular intervals, and we commit, where possible, to provide a minimum of two calendar weeks warning before any shut down period commences.</p> <p>We reserve the right to modify, redesign, disable or remove any of the existing services. Where possible, users will be notified of major modifications to the existing systems a minimum of three calendar months before these changes are implemented. Updates, upgrades and shutdown periods are not considered major modifications.</p>"},{"location":"ai-cloud/terms-and-conditions/#73-communication-policy-around-service-windows","title":"7.3. Communication policy around service windows","text":"Scheduled IT disruptionsPlanned IT disruptionsEmergency communication timeframes <ol> <li> <p>Service window date reminder email</p> <ul> <li>Sent to all users of Strato, AI Cloud</li> <li>Dispatched 6-8 weeks before service window</li> </ul> </li> <li> <p>Orientation email about service window</p> <ul> <li>Sent to the internal CLAAUDIA and ITS management list</li> <li>Dispatched 2 weeks before service window</li> </ul> </li> <li> <p>Notice of service window pre arranged on ServiceInfo.dk</p> <ul> <li>Put on 1 week before the service window.</li> </ul> </li> <li> <p>Orientation email to system owner forum, key stakeholders or research group leaders</p> <ul> <li>Dispatched 2 weeks before service window.</li> </ul> </li> <li> <p>Orientation email to all users</p> <ul> <li>Dispatched 1 week before service window.</li> </ul> </li> <li> <p>Completion of planned work changed on ServiceInfo.dk</p> <ul> <li>Changed on first working day after the service window.</li> </ul> </li> </ol> <ol> <li> <p>Service window date reminder email</p> <ul> <li>Sent to all users of Strato, AI Cloud</li> <li>Dispatched 6-8 weeks before service window</li> </ul> </li> <li> <p>Orientation email about service window</p> <ul> <li>Sent to the internal CLAAUDIA and ITS management list</li> <li>Dispatched 4 weeks before service window</li> </ul> </li> <li> <p>Notice of service window pre arranged on ServiceInfo.dk</p> <ul> <li>Put on 2-3 weeks before the service window</li> </ul> </li> <li> <p>Orientation email to system owner forum, key stakeholders or research group leaders</p> <ul> <li>Dispatched 3 weeks before service window.</li> </ul> </li> <li> <p>Orientation email to all users</p> <ul> <li>Dispatched 2 weeks before service window.</li> </ul> </li> <li> <p>Completion of planned work changed on ServiceInfo.dk</p> <ul> <li>Changed on first working day after the service window.</li> </ul> </li> </ol> <ol> <li> <p>After 1st hour</p> <ul> <li>Out of order notice posted on ServiceInfo.dk.</li> </ul> </li> <li> <p>Unresolved problems at end of day</p> <ul> <li>Update on status - even if no change has occurred.</li> </ul> </li> <li> <p>After problem resolution</p> <ul> <li>The issue will be marked as resolved on ServiceInfo.dk</li> </ul> </li> </ol>"},{"location":"ai-cloud/terms-and-conditions/#8-loan-of-physical-equipment","title":"8. Loan of physical equipment","text":""},{"location":"ai-cloud/terms-and-conditions/#81-responsibility-and-liability-for-physical-equipment-loaned-by-aau","title":"8.1. Responsibility and Liability for Physical Equipment Loaned by AAU","text":"<p>With regards to physical equipment, you are solely responsible for damage to or loss of the equipment during the loan period. In the event of damage, AAU determines whether the equipment shall be repaired or replaced. If AAU determines that it is not viable to repair the equipment or if the equipment is lost, you shall compensate AAU for the value of the equipment.</p> <p>If AAU determines that the equipment can be repaired, you shall pay for the repair.</p>"},{"location":"ai-cloud/terms-and-conditions/#82-ethical-use-and-legal-responsibility-for-physical-kits-with-cameras","title":"8.2. Ethical Use and Legal Responsibility for Physical Kits with Cameras","text":"<p>Physical kits are delivered with a camera. Please act ethically and refrain from using them in places where other people may consider it unpleasant or annoying. You are responsible for acting according to the legislation of the country in which you use the equipment and the Danish legal and ethical rules.</p>"},{"location":"ai-cloud/terms-and-conditions/#9-updates-to-terms-and-conditions","title":"9. Updates to Terms and Conditions","text":"<p>We reserve the right to make periodic changes to these terms and conditions, and commit to inform users of the changes made.</p>"},{"location":"ai-cloud/terms-and-conditions/#appendix","title":"Appendix","text":""},{"location":"ai-cloud/terms-and-conditions/#procedure-for-working-with-sensitive-data-on-ucloud-projects","title":"Procedure for working with sensitive data on UCloud projects","text":"<p>CLAAUDIA, Aalborg University</p> <p>2023-10-10</p> <p>v1.0</p> <p>As a user on the UCloud platform you have a workspace called \"My workspace\".</p> <p>It is also possible to apply for a separate \"Project\" workspace on the UCloud platform. Projects on UCloud allow for collaboration with separate storage, compute resources and management of user rights and responsibilities on the UCloud platform.</p> <p>The project environment is required for the following types of work on UCloud:</p> <ol> <li> <p>For employed researchers at AAU (VIP)</p> <p>a.  Sensitive data: All work on the UCloud platform that involves     research data in classification levels 2. a 2.  All users</p> <p>a.  GPU access on UCloud: All access to GPU resources on UCloud     require a project.</p> <p>b.  Additional compute resources that are allocated out of the AAU     pool of UCloud resources.</p> </li> </ol> <p>UCloud users at AAU must be familiar with the details of the following codes of conduct and policies:</p> <ol> <li> <p>The Danish Code of Conduct for Research     Integrity</p> </li> <li> <p>The AAU Policy for Research Data     Management</p> </li> <li> <p>The AAU policies with regards to     GDPR     (Available in English for     researchers     (VIP) and     teachers     (VIP);     Only in Danish for administration (TAP)     employees)</p> </li> <li> <p>The AAU data management     recommendations</p> </li> </ol> <p>These policies cover the general rules all researchers (and TAP staff for point 3.) should abide by with regards to what kind of data may be kept, for how long, whether data can be re-used or recycled, and how long it should be archived for, etc.</p> <p>Sensitive data: Registration of research projects at Grants and Contracts</p> <p>For researchers at AAU, working with sensitive personal data requires that you register your research project with \"Grants and Contracts\" by completing the digital form that matches your role in relation to the data, for example Data Controller or Data processor.</p> <p>Data processing agreement between AAU and the EScience center at SDU</p> <p>For AAU users, data analysis and processing may then take place on the UCloud platform according to the data processing agreement between AAU and EScience center at SDU.</p> <p>Steps required to working with projects on the UCloud platform</p> <ol> <li> <p>Identify the data classification of your data by reviewing the AAU     data classification     model.</p> </li> <li> <p>If you are a researcher, and working with personally identifiable information, you must register a research project with Grants and Contracts     using the relevant registration     form.</p> <p>a.  Once you have registered your research activity at Grants and     Contracts, you will get a receipt that contains a \"WorkZone case     number\" (To be included in your UCloud project application).</p> </li> </ol> <ol> <li> <p>All applicants for projects on UCloud must complete the CLAAUDIA     application form for DeiC Interactive HPC resources.</p> </li> <li> <p>Once approved, you will receive a UCloud project     number, and you must apply for a project in the UCloud     Interface,     including the resources that you had approved in the CLAAUDIA     application. (You can apply for additional resources later if     needed.)</p> <p>a.  As project applicant you will be the Principal Investigator for     the project, and you should be aware of your roles and     responsibilities.</p> <p>b. The project must use the same project title as provided in the CLAAUDIA application, and both the DeiC project number and the Grants and Contracts reference number should be included:</p> <pre><code>i. The DeiC project number should be entered in the \"DeiC Interactive HPC project number\" field.\nii. The WorkZone case number should be entered in the \"WorkZone reference number\" field.\n</code></pre> <p>c.  Once your project is approved, you will get access to project     storage (Drive(s)) on UCloud that is separate from your \"My     Workspace\" storage. No sensitive data may be stored in the \"My     workspace\" drives.</p> </li> <li> <p>Adding data to the UCloud platform:</p> <p>a.  Any data added to the project should be in a project folder and     this must be marked according to the level of data sensitivity,     as described in the AAU data classification     model.</p> <pre><code>i.  On the UCloud platform the corresponding classifications are\n    as follows:\n\n    - AAU Level 1  \u2192 UCloud: Inherit\n    - AAU Level 2  \u2192 UCloud: Private/Confidential\n    - AAU Level 3  \u2192 UCloud: Sensitive (Only permitted to be added to your registered \n    and approved project folder.) Sensitive data may **NOT** be added to My Workspace.\n    - AAU Level 4  \u2192 Not allowed\n</code></pre> </li> <li> <p>Collaboration on UCloud within projects: Fellow AAU persons</p> <p>a.  Only persons named in the project registered with Grants and     Contracts may be added to the UCloud project.</p> </li> <li> <p>Collaboration on UCloud within projects: Persons from outside     AAU</p> <p>a.  The collaborator's employer must have a Data Processing     agreement with SDU (SDU are hosting UCloud), or</p> <pre><code>i.  Where there is an agreement of shared data responsibility\n    (Agreement on Joint data controlling), that states that it\n    is agreed to use DeiC/SDU as the data processor, then it is\n    sufficient that AAU has an existing data processing\n    agreement with DeiC/SDU. In these cases AAU will be\n    responsible for the data processing agreement with DeiC/SDU.\n</code></pre> <p>b.  If this is not the case, you cannot invite the collaborator     inside the project folder in UCloud.</p> <p>c.  No person(s) that are not included in the data processing     agreement or the agreement on joint data controlling may be     invited to the project.</p> </li> <li> <p>UCloud project members and roles should be set appropriately.</p> <p>a.  Project \"admins\" can see all member files by activating the     \"show member files\" option. The Principal Investigator is     responsible for ensuring that all roles and     responsibilities     are properly assigned.</p> </li> <li> <p>Read and write privileges on UCloud</p> <p>a.  If collaborators are only allowed read or write to specific     parts of the data / dataset, you will need to follow the     following steps:</p> <pre><code>i.  Within the project, you will need to create a new \"Drive\".\n    (As drives are the only level to which you can specify read\n    and write permissions.)\n\n    1.  Only project \"admins\" can create new drives within a\n        project.\n\nii. Name the drive and then click the \"...\" button to modify the\n    permissions. Then choose the permissions (None / Read /\n    Write).\n</code></pre> </li> <li> <p>Permitted applications and uses</p> <p>a. Only the SDU/K8 provider is permitted for working with data classifications 2 and 3.</p> <p>b. The AAU/K8 and AAU virtual machine providers are only permitted to be used for data classified as level 1.</p> </li> <li> <p>On completion the project\u00a0</p> <p>a.  All data on the UCloud platform should be deleted.</p> <p>b.  The project should then be archived with a final date that     corresponds with the GDPR notification with 'Grants and     Contracts'.</p> <p>c.  All files in trash folders should be permanently deleted.</p> <p>d.  All complete data sets and metadata should be stored in a data     repository in accordance with The AAU Policy for Research Data     Management.     As of 2023-January, AAU     DataDeposit     as a local archiving solution, while a national solution is     under development.</p> </li> </ol>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/","title":"Batch LLM Inference","text":"<p>This guide explains how to run batch LLM inference using vLLM on AI Cloud, covering:</p> <ul> <li>Setting up and running the vLLM container</li> <li>Submitting inference jobs via Slurm</li> </ul> <p>What is Batch LLM Inference?</p> <p>Batch LLM inference refers to processing multiple input prompts in a single inference pass rather than handling them individually. This approach enhances GPU utilization, increases throughput, and reduces overall latency, making it ideal for large-scale text processing tasks on a GPU cluster.</p> <p>What is vLLM?</p> <p>vLLM is an optimized inference engine for large language models, designed to improve performance and efficiency. Using vLLM on AI Cloud ensures efficient model execution, particularly when multiple users or jobs run concurrently.</p>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#obtaining-a-hugging-face-access-token","title":"Obtaining a Hugging Face Access Token","text":"<p>Many models on Hugging Face are restricted. To use them, you need an access token.</p> <ol> <li>Go to Hugging Face and log in or create an account.</li> <li> <p>Navigate to Hugging Face tokens and click Create new token.</p> <p></p> </li> <li> <p>Under Token Type, select <code>Read</code>, enter a Token Name, and click Create Token.</p> <p></p> </li> <li> <p>Copy the token value and click Done.</p> <p></p> </li> <li> <p>On AI Cloud, add the token to your <code>~/.bashrc</code> to ensure it is always available:</p> <pre><code>echo 'export HF_TOKEN=\"YOUR_TOKEN\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> </li> <li> <p>Replace <code>YOUR_TOKEN</code> with your actual token.</p> </li> <li> <p>Verify the token is set correctly:</p> <pre><code>echo $HF_TOKEN\n</code></pre> </li> </ol>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#running-vllm-with-slurm","title":"Running vLLM with Slurm","text":"<p>Now that access is set up, we can submit a job via Slurm. The example below demonstrates the basic usage of vLLM to generate text.</p>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#creating-a-python-script-for-vllm-inference","title":"Creating a Python Script for vLLM Inference","text":"<p>Create a new file called <code>basic.py</code> with the following code:</p> basic.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n# - Explicitly set the token before initializing LLM:\n\nfrom vllm import LLM, SamplingParams\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\n# Sample prompts.\nprompts = [\n    \"Hello, my name is\",\n    \"The president of the United States is\",\n    \"The capital of France is\",\n    \"The future of AI is\",\n]\n\n# Create a sampling params object.\nsampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n\n# Create an LLM instance.\nllm = LLM(model=\"facebook/opt-125m\")\n\n# Generate text.\noutputs = llm.generate(prompts, sampling_params)\n\n# Print results.\nfor output in outputs:\n    print(f\"Prompt: {output.prompt!r}, Generated text: {output.outputs[0].text!r}\")\n</code></pre> <p>This script initializes vLLM's engine using the facebook/opt-125m model and generates text based on the given prompts. For more details, refer to the vLLM documentation.</p>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#submitting-a-slurm-job","title":"Submitting a Slurm Job","text":"<p>A pre-built vLLM container is available on AI Cloud at <code>/home/container/vllm-openai_latest.sif</code>. This container includes vLLM and all necessary dependencies.</p> <p>Create a Slurm batch script <code>run_vllm.sh</code>:</p> run_vllm.sh<pre><code>#!/bin/bash\n#SBATCH --job-name=vllm_textgen\n#SBATCH --output=vllm_textgen_output.log\n#SBATCH --error=vllm_textgen_error.log\n#SBATCH --gres=gpu:1\n#SBATCH --mem=40G\n#SBATCH --time=04:00:00\n\nsingularity exec --nv /home/container/vllm-openai_latest.sif python3 basic.py\n</code></pre> <p>Submit the job using:</p> <pre><code>sbatch run_vllm.sh\n</code></pre> <p>The job should complete quickly (~2 minutes). Check the <code>vllm_textgen_output.log</code> file for results:</p> <pre><code>Prompt: 'Hello, my name is', Generated text: ' Joel, my dad is my friend and we are in a relationship. I am'\nPrompt: 'The president of the United States is', Generated text: ' speaking out against the release of some State Department documents which show the Russians were involved'\nPrompt: 'The capital of France is', Generated text: ' the most populous city in the world, with an annual population of nearly 3 million'\nPrompt: 'The future of AI is', Generated text: ' at stake\\nThe world is going to change in the next 20 years, and'\n</code></pre> <p>Restricted Model Access Error</p> <p>If you encounter an error such as:</p> <pre><code>Access to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list.\n</code></pre> <p>You need to request access on Hugging Face. Visit the model page, such as meta-llama/Llama-3.2-1B-Instruct, and click Agree and access repository.</p> <p></p> <p>This guide provides the foundation for running batch LLM inference using vLLM on AI Cloud. Explore the official vLLM documentation for further customization and optimizations.</p>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#additional-vllm-examples","title":"Additional vLLM Examples","text":"<p>Below are additional examples demonstrating different vLLM use cases. More advanced examples can be found in the vLLM GitHub repository.</p> chat.py chat.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: dict):\n    # Pop arguments not used by LLM\n    max_tokens = args.pop(\"max_tokens\")\n    temperature = args.pop(\"temperature\")\n    top_p = args.pop(\"top_p\")\n    top_k = args.pop(\"top_k\")\n    chat_template_path = args.pop(\"chat_template_path\")\n\n    # Create an LLM\n    llm = LLM(**args)\n\n    # Create sampling params object\n    sampling_params = llm.get_default_sampling_params()\n    if max_tokens is not None:\n        sampling_params.max_tokens = max_tokens\n    if temperature is not None:\n        sampling_params.temperature = temperature\n    if top_p is not None:\n        sampling_params.top_p = top_p\n    if top_k is not None:\n        sampling_params.top_k = top_k\n\n    def print_outputs(outputs):\n        for output in outputs:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            print(f\"Prompt: {prompt!r}\")\n            print(f\"Generated text: {generated_text!r}\")\n        print(\"-\" * 80)\n\n    print(\"=\" * 80)\n\n    # In this script, we demonstrate how to pass input to the chat method:\n    conversation = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello\"\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"Hello! How can I assist you today?\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\":\n            \"Write an essay about the importance of higher education.\",\n        },\n    ]\n    outputs = llm.chat(conversation, sampling_params, use_tqdm=False)\n    print_outputs(outputs)\n\n    # You can run batch inference with llm.chat API\n    conversations = [conversation for _ in range(10)]\n\n    # We turn on tqdm progress bar to verify it's indeed running batch inference\n    outputs = llm.chat(conversations, sampling_params, use_tqdm=True)\n    print_outputs(outputs)\n\n    # A chat template can be optionally supplied.\n    # If not, the model will use its default chat template.\n    if chat_template_path is not None:\n        with open(chat_template_path) as f:\n            chat_template = f.read()\n\n        outputs = llm.chat(\n            conversations,\n            sampling_params,\n            use_tqdm=False,\n            chat_template=chat_template,\n        )\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    # Add engine args\n    engine_group = parser.add_argument_group(\"Engine arguments\")\n    EngineArgs.add_cli_args(engine_group)\n    engine_group.set_defaults(model=\"meta-llama/Llama-3.2-1B-Instruct\")\n    # Add sampling params\n    sampling_group = parser.add_argument_group(\"Sampling parameters\")\n    sampling_group.add_argument(\"--max-tokens\", type=int)\n    sampling_group.add_argument(\"--temperature\", type=float)\n    sampling_group.add_argument(\"--top-p\", type=float)\n    sampling_group.add_argument(\"--top-k\", type=int)\n    # Add example params\n    parser.add_argument(\"--chat-template-path\", type=str)\n    args: dict = vars(parser.parse_args())\n    main(args)\n</code></pre> classify.py classify.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom argparse import Namespace\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: Namespace):\n    # Sample prompts.\n    prompts = [\n        \"Hello, my name is\",\n        \"The president of the United States is\",\n        \"The capital of France is\",\n        \"The future of AI is\",\n    ]\n\n    # Create an LLM.\n    # You should pass task=\"classify\" for classification models\n    model = LLM(**vars(args))\n\n    # Generate logits. The output is a list of ClassificationRequestOutputs.\n    outputs = model.classify(prompts)\n\n    # Print the outputs.\n    for prompt, output in zip(prompts, outputs):\n        probs = output.outputs.probs\n        probs_trimmed = ((str(probs[:16])[:-1] +\n                        \", ...]\") if len(probs) &gt; 16 else probs)\n        print(f\"Prompt: {prompt!r} | \"\n            f\"Class Probabilities: {probs_trimmed} (size={len(probs)})\")\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    parser = EngineArgs.add_cli_args(parser)\n    # Set example specific arguments\n    parser.set_defaults(model=\"jason9693/Qwen2.5-1.5B-apeach\",\n                        task=\"classify\",\n                        enforce_eager=True)\n    args = parser.parse_args()\n    main(args)\n</code></pre> embed.py embed.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom argparse import Namespace\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: Namespace):\n    # Sample prompts.\n    prompts = [\n        \"Hello, my name is\",\n        \"The president of the United States is\",\n        \"The capital of France is\",\n        \"The future of AI is\",\n    ]\n\n    # Create an LLM.\n    # You should pass task=\"embed\" for embedding models\n    model = LLM(**vars(args))\n\n    # Generate embedding. The output is a list of EmbeddingRequestOutputs.\n    outputs = model.embed(prompts)\n\n    # Print the outputs.\n    for prompt, output in zip(prompts, outputs):\n        embeds = output.outputs.embedding\n        embeds_trimmed = ((str(embeds[:16])[:-1] +\n                        \", ...]\") if len(embeds) &gt; 16 else embeds)\n        print(f\"Prompt: {prompt!r} | \"\n            f\"Embeddings: {embeds_trimmed} (size={len(embeds)})\")\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    parser = EngineArgs.add_cli_args(parser)\n    # Set example specific arguments\n    parser.set_defaults(model=\"intfloat/e5-mistral-7b-instruct\",\n                        task=\"embed\",\n                        enforce_eager=True)\n    args = parser.parse_args()\n    main(args)\n</code></pre> generate.py generate.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: dict):\n    # Pop arguments not used by LLM\n    max_tokens = args.pop(\"max_tokens\")\n    temperature = args.pop(\"temperature\")\n    top_p = args.pop(\"top_p\")\n    top_k = args.pop(\"top_k\")\n\n    # Create an LLM\n    llm = LLM(**args)\n\n    # Create a sampling params object\n    sampling_params = llm.get_default_sampling_params()\n    if max_tokens is not None:\n        sampling_params.max_tokens = max_tokens\n    if temperature is not None:\n        sampling_params.temperature = temperature\n    if top_p is not None:\n        sampling_params.top_p = top_p\n    if top_k is not None:\n        sampling_params.top_k = top_k\n\n    # Generate texts from the prompts. The output is a list of RequestOutput\n    # objects that contain the prompt, generated text, and other information.\n    prompts = [\n        \"Hello, my name is\",\n        \"The president of the United States is\",\n        \"The capital of France is\",\n        \"The future of AI is\",\n    ]\n    outputs = llm.generate(prompts, sampling_params)\n    # Print the outputs.\n    for output in outputs:\n        prompt = output.prompt\n        generated_text = output.outputs[0].text\n        print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    # Add engine args\n    engine_group = parser.add_argument_group(\"Engine arguments\")\n    EngineArgs.add_cli_args(engine_group)\n    engine_group.set_defaults(model=\"meta-llama/Llama-3.2-1B-Instruct\")\n    # Add sampling params\n    sampling_group = parser.add_argument_group(\"Sampling parameters\")\n    sampling_group.add_argument(\"--max-tokens\", type=int)\n    sampling_group.add_argument(\"--temperature\", type=float)\n    sampling_group.add_argument(\"--top-p\", type=float)\n    sampling_group.add_argument(\"--top-k\", type=int)\n    args: dict = vars(parser.parse_args())\n    main(args)\n</code></pre> score.py score.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom argparse import Namespace\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: Namespace):\n    # Sample prompts.\n    text_1 = \"What is the capital of France?\"\n    texts_2 = [\n        \"The capital of Brazil is Brasilia.\",\n        \"The capital of France is Paris.\",\n    ]\n\n    # Create an LLM.\n    # You should pass task=\"score\" for cross-encoder models\n    model = LLM(**vars(args))\n\n    # Generate scores. The output is a list of ScoringRequestOutputs.\n    outputs = model.score(text_1, texts_2)\n\n    # Print the outputs.\n    for text_2, output in zip(texts_2, outputs):\n        score = output.outputs.score\n        print(f\"Pair: {[text_1, text_2]!r} | Score: {score}\")\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    parser = EngineArgs.add_cli_args(parser)\n    # Set example specific arguments\n    parser.set_defaults(model=\"BAAI/bge-reranker-v2-m3\",\n                        task=\"score\",\n                        enforce_eager=True)\n    args = parser.parse_args()\n    main(args)\n</code></pre>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#multi-gpu-utilization","title":"Multi-GPU Utilization","text":"<p>Some models like <code>meta-llama/Llama-3.3-70B-Instruct</code> is too large to fit in a single GPU on AI Cloud and you will get an out-of-memory (OOM) error.  vLLM supports tensor parallelism, which allows the model to be distributed across multiple GPUs. To enable it, pass <code>tensor_parallel_size</code> to the EngineArgs in your script:</p> <pre><code>engine_group.set_defaults(model=\"meta-llama/Llama-3.3-70B-Instruct\", tensor_parallel_size=4)\n</code></pre> <p>And don't forget to set <code>--gres=gpu</code> to the number of GPUs you want to utilize, in this instance <code>--gres=gpu:l40s:4</code>. This will allocate 4 GPUs to the job on a arbitrary <code>l40s</code> node on AI Cloud.</p>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#batch-reasoning-with-deepseek-r1","title":"Batch Reasoning with DeepSeek R1","text":"<p>vLLM offers support for reasoning models like DeepSeek R1, which are designed to generate outputs containing both reasoning steps and final conclusions. This guide explains how to use the DeepSeek model with batch processing on. It includes setting up the vLLM server, running inference, and using guided decoding for structured outputs.</p>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#step-1-writing-the-inference-script","title":"Step 1: Writing the Inference Script","text":"<p>Create a Python script (<code>run_inference.py</code>) to interact with the vLLM server:</p> <pre><code>from openai import OpenAI\nfrom pydantic import BaseModel\n\n# Modify OpenAI's API key and API base to use vLLM's API server.\nopenai_api_key = \"EMPTY\"\nopenai_api_base = \"http://localhost:8000/v1\"\n\n# Initialize OpenAI client for vLLM\nclient = OpenAI(\n    api_key=openai_api_key,\n    base_url=openai_api_base,\n)\n\n# List available models\nmodels = client.models.list()\nmodel = models.data[0].id  # Assumes the first model is the correct one\n\n# Simple chat completion request\nprompt = \"What is the capital of France?\"\nresponse = client.chat.completions.create(\n    model=model,\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n    extra_body={\"guided_regex\": \"(Paris|London)\"},  # Example of guided decoding\n)\n\nprint(\"Reasoning:\", response.choices[0].message.reasoning_content)\nprint(\"Response:\", response.choices[0].message.content)\n\n# Guided decoding using JSON schema\nclass People(BaseModel):\n    name: str\n    age: int\n\njson_schema = People.model_json_schema()\n\nprompt = \"Generate a JSON with the name and age of one random person.\"\nresponse = client.chat.completions.create(\n    model=model,\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n    extra_body={\"guided_json\": json_schema},\n)\n\nprint(\"Reasoning:\", response.choices[0].message.reasoning_content)\nprint(\"Response:\", response.choices[0].message.content)\n</code></pre>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#step-2-creating-the-slurm-job-script","title":"Step 2: Creating the Slurm Job Script","text":"<p>Create a Slurm batch script (<code>submit_vllm.sh</code>) to run the inference job:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=vllm_reasoning\n#SBATCH --gres=gpu:1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=32G\n#SBATCH --time=01:00:00\n#SBATCH --output=vllm_output_%j.log\n#SBATCH --error=vllm_error_%j.log\n\n# Path to vLLM container\nVLLM_CONTAINER=\"/home/container/vllm-openai_latest.sif\"\n\n# Start the vLLM server in the background\nsingularity exec --nv $VLLM_CONTAINER vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B \\\n    --enable-reasoning --reasoning-parser deepseek_r1 &amp;\n\n# Get the PID of the server\nVLLM_PID=$!\n\n# Wait for server to be ready\necho \"Waiting for vLLM server to start...\"\nwhile ! curl -s http://localhost:8000/v1/models &gt;/dev/null; do\n    sleep 2  # Check every 2 seconds\ndone\n\n# Run inference script\nsingularity exec --nv $VLLM_CONTAINER python3 run_inference.py\n\n# Stop the server after inference is done\necho \"Stopping vLLM server...\"\nkill $VLLM_PID\n</code></pre>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#step-3-submitting-the-job","title":"Step 3: Submitting the Job","text":"<p>Run the following command to submit the job to Slurm:</p> <pre><code>sbatch submit_vllm.sh\n</code></pre>"},{"location":"ai-cloud/additional-guides/batch-llm-inference/#step-4-monitoring-and-debugging","title":"Step 4: Monitoring and Debugging","text":"<p>Check job status:</p> <pre><code>squeue --me\n</code></pre> <p>Check job logs:</p> <pre><code>tail -f vllm_output_&lt;job_id&gt;.log\n</code></pre> <p>If there are errors, inspect the error log:</p> <pre><code>tail -f vllm_error_&lt;job_id&gt;.log\n</code></pre> <p>This guide provides the foundation for running batch LLM inference using vLLM on AI Cloud. Explore the official vLLM documentation for further customization and optimizations.</p>"},{"location":"ai-cloud/additional-guides/building-your-own-container-image/","title":"Building your own container image","text":"<p>It is generally considered good practice to build your own Singularity containers, to contain the software environment for a project you wish to run on an HPC system. This is because containers represent a solution that allows robustness and reproducibility.</p>"},{"location":"ai-cloud/additional-guides/building-your-own-container-image/#create-a-definition-file","title":"Create a definition file","text":"<p>First we need to create a definition to build our container image from. We will provide a basic example, but it also be helpful to read the official documentation page on building container images.</p> torch.def<pre><code>Bootstrap: docker\nFrom: ubuntu:22.04\n\n%post\n    # This section is where you install software packages\n\n    # Update the package manager (apt)\n    apt update\n\n    # install the latest Python and pip version\n    apt install -y python3-pip python3-dev\n\n    # use pip to install torch\n    pip3 install torch torchvision torchaudio\n</code></pre>"},{"location":"ai-cloud/additional-guides/building-your-own-container-image/#create-a-batch-script-to-build-from","title":"Create a batch script to build from","text":"<p>We can now create a batch script to launch our build:</p> build_torch.sh<pre><code>#!/usr/bin/env bash\n\n#SBATCH --job-name=build_torch\n#SBATCH --output=build_torch.out\n#SBATCH --error=build_torch.err\n#SBATCH --cpus-per-task=32\n#SBATCH --mem=80G\n\nexport SINGULARITY_TMPDIR=$HOME/.singularity/tmp\nexport SINGULARITY_CACHEDIR=$HOME/.singularity/cache\nmkdir -p $SINGULARITY_CACHEDIR $SINGULARITY_TMPDIR\n\n# The path to the definition file\ninput_def=\"torch.def\"\n\n# The resulting container image\noutput_sif=\"torch.sif\"\n\nsingularity build --fakeroot $output_sif $input_def\n</code></pre> <p>We can now build the container by launching our batch script with: </p> <pre><code>sbatch build_torch.sh\n</code></pre> <p>After our file has been built we can test it with:</p> <pre><code>srun --gres=gpu:1 singularity exec --nv torch.sif python3 -c \"import torch ; print(torch.cuda.is_available())\"\n</code></pre> <p>Which should output:</p> <pre><code>srun: job 767374 queued and waiting for resources\nsrun: job 767374 has been allocated resources\nTrue\n</code></pre>"},{"location":"ai-cloud/additional-guides/cancelling-jobs/","title":"Cancelling jobs","text":"<p>There are several scenarios where you might need to cancel jobs, such as when a job is stuck, running longer than expected, or you realize that the job parameters were set incorrectly. Here\u2019s a guide on how to cancel jobs with Slurm.</p>"},{"location":"ai-cloud/additional-guides/cancelling-jobs/#cancelling-a-single-job","title":"Cancelling a Single Job","text":"<p>Before cancelling a job, it\u2019s often useful to check its current status or job ID. You can list your currently running or queued jobs using the squeue command:</p> <pre><code>squeue --me\n</code></pre> <p>To cancel a specific job, use the <code>scancel</code> command followed by the job ID. For example, if your job ID is <code>12345</code>, you can cancel it by running:</p> <pre><code>scancel 12345\n</code></pre>"},{"location":"ai-cloud/additional-guides/cancelling-jobs/#cancelling-multiple-jobs","title":"Cancelling Multiple Jobs","text":"<p>If you need to cancel all your jobs, you can cancel all jobs belonging to your user by using:</p> <pre><code>scancel --user=$USER\n</code></pre> <p>This command is particularly useful if you have submitted a large number of jobs and need to cancel them all simultaneously.</p>"},{"location":"ai-cloud/additional-guides/checking-gpu-utilisation/","title":"Checking GPU utilisation","text":"<p>When you have launched a job on a GPU, it is good practice to verify that it is indeed utilising the GPU.</p> <p>We can do this by logging in to the compute node, and calling the <code>nvidia-smi</code> command.</p> <p>Start by locating the node, that your job is running on: <pre><code>squeue --me\n</code></pre></p> <p>Which returns the following table: <pre><code>             JOBID  PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n            768059  prioritiz  aicloud   nobody  R    0:06:02      1 a256-t4-01\n</code></pre></p> <p>In the column <code>NODELIST(REASON)</code> read which node your job is running on.</p> <p>Then log in to the node:</p> <pre><code>ssh -l user@domain.aau.dk a256-t4-01.srv.aau.dk\n</code></pre> <p>And call:</p> <pre><code>nvidia-smi\n</code></pre> <p>Which prints a table:</p> <pre><code>+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   4  NVIDIA L40S                    Off |   00000000:03:00.0 Off |                    0 |\n| N/A   72C    P0            287W /  350W |   27963MiB /  46068MiB |     89%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n</code></pre> <p>This table is a snapshot of the GPU devices (physical GPU's) allocated to your Slurm job, and the values represent measures of a sampling period of 1 second.</p> <p>The most important parameters to note are:</p> <ul> <li> <p>Volatile GPU-Util: How much of the sampling period the GPU was actively computing. As computations normally take place in batches, it is normal to see this value fluctuate.</p> </li> <li> <p>Memory usage: How much of the available GPU-ram is being consumed. Note that this is expressed in mebibytes (that's MiB not MB), which more accurately represents memory values (binary).</p> </li> </ul>"},{"location":"ai-cloud/additional-guides/checking-gpu-utilisation/#bonus-tips","title":"Bonus tips:","text":"<p>Continuous updates</p> <p>Prepending the <code>watch</code> command, will execute the <code>nvidia-smi</code> command every 2 seconds - allowing us to get continuous updates to the GPU activity:</p> <pre><code>watch nvidia-smi \n</code></pre> <p>Print only the important bits</p> <p>Instead of printing the whole table, we can print only select values:</p> <pre><code>nvidia-smi --query-gpu=index,utilization.memory,utilization.gpu --format=csv\n</code></pre> <p>The <code>watch</code> command can of course also be prepended in order to get continuous updates.</p>"},{"location":"ai-cloud/additional-guides/checking-the-queue/","title":"Checking the queue","text":"<p>When using the cluster, you typically wish to see an overview of what is currently in the queue. For example to see how many jobs might be waiting ahead of you or to get an overview of your own jobs.</p> <p>The command <code>squeue</code> can be used to get a general overview:</p> <pre><code>squeue\n\nJOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n31623     batch     DRSC xxxxxxxx  R    6:45:14      1 i256-a10-10\n31693     batch singular yyyyyyyy  R      24:20      1 i256-a40-01\n31694     batch singular yyyyyyyy  R      24:20      1 i256-a40-01\n31695     batch singular yyyyyyyy  R      24:20      1 i256-a40-01\n31696     batch singular yyyyyyyy  R      24:20      1 i256-a40-01\n31502 prioritiz runQHGK. zzzzzzzz PD       0:00      1 (Dependency)\n31504 prioritiz runQHGK. zzzzzzzz PD       0:00      1 (Dependency)\n</code></pre> <ol> <li><code>JOBID</code> shows the <code>ID</code> number of each job in queue.</li> <li><code>PARTITION</code> shows which partition each job is running in.</li> <li><code>NAME</code> is the name of the job which can be specified by the user creating it.</li> <li><code>USER</code> is the username of the user who created the job.</li> <li><code>ST</code> is the current state of each job; for example <code>R</code> means a job is running and <code>PD</code> means pending. There are other states as well - see <code>man squeue</code> for more details (under <code>JOB STATE CODES</code>).</li> <li><code>TIME</code> shows how long each job has been running.</li> <li><code>NODES</code> shows how many nodes are involved in each job allocation.</li> <li><code>NODELIST</code> shows which node(s) each job is running on, or alternatively, why it is not running yet.</li> </ol> <p>Showing your own jobs only:</p> <pre><code>squeue --me\n</code></pre> <p><code>squeue</code> can show many other details about jobs as well. Run <code>man squeue</code> to see detailed documentation on how to do this.</p>"},{"location":"ai-cloud/additional-guides/checking-the-status-of-compute-nodes/","title":"Checking the status of compute nodes","text":"<p>It is often desirable to monitor the resource status of the compute nodes when you wish to run a job. </p> <p>The <code>sinfo</code> command shows basic information about partitions in the queue system and what the states of nodes in these partitions are.</p> <pre><code>sinfo\n\nPARTITION   AVAIL  TIMELIMIT  NODES  STATE NODELIST\nbatch*         up   12:00:00      1    mix nv-ai-04\nbatch*         up   12:00:00      8   idle a256-t4-[01-02],i256-a10-06,i256-a40-[01-02]...\nprioritized    up 6-00:00:00      8   idle a256-t4-[01-02],i256-a10-06,i256-a40-[01-02]...\n</code></pre> <ol> <li><code>PARTITION</code> can be understood as distinct categories or groups of compute nodes, essentially serving as separate queues for jobs.</li> <li><code>AVAIL</code> shows the availability of the partition where <code>up</code> is normal, working state where you can submit jobs to it.</li> <li><code>TIMELIMIT</code> shows the time limit imposed by each partition in <code>HH:MM:SS</code> format.</li> <li><code>NODES</code> shows how many nodes are in the shown state in the specific partition.</li> <li><code>STATE</code> shows which state the listed nodes are in: <code>mix</code> means that the nodes are partially full - some jobs are running on them and they still have available resources; <code>idle</code> means that they are completely vacant and have all resources available; <code>allocated</code> means that they are completely occupied. Many other states are possible, most of which mean that something is wrong.</li> <li><code>NODELIST</code> shows the specific compute nodes that is affected by the job.</li> </ol> <p>You can also use the command <code>scontrol show node</code> or <code>scontrol show node &lt;node name&gt;</code> to show details about all nodes or a specific node, respectively.</p> <pre><code>scontrol show node a256-t4-01\n\nNodeName=a256-t4-01 Arch=x86_64 CoresPerSocket=16 \nCPUAlloc=12 CPUTot=64 CPULoad=0.50\nAvailableFeatures=(null)\nActiveFeatures=(null)\nGres=gpu:t4:6\n...\n</code></pre> <p>The two commands <code>sinfo</code> and <code>scontrol show node</code> provide information which is either too little or way too much detail in most situations. As an alternative, we provide the tool <code>nodesummary</code> to show a hopefully more intuitive overview of the used/available resources.</p> <pre><code>nodesummary\n</code></pre> <p></p>"},{"location":"ai-cloud/additional-guides/checkpointing/","title":"Checkpointing","text":"<p>Checkpointing is a technique used to ensure that your computational jobs can be resumed from a previously saved state in case of interruptions or failures. This guide outlines how to implement and use checkpointing effectively within your jobs using different applications.</p> <p>Why checkpointing matters</p> <p>Service Windows: There are times when the platform undergoes maintenance or updates, during which jobs cannot be run. Checkpointing enables you to pause training during these service windows and resume later without losing progress.</p> <p>Platform Errors: Platform errors can also sometimes occur, leading to job cancellations. Checkpointing mitigates this risk by saving your model's state at regular intervals, so you can recover and continue training from the point of interruption.</p>"},{"location":"ai-cloud/additional-guides/checkpointing/#python-data-checkpointing","title":"Python data checkpointing","text":"<p>The following Python script demonstrates a basic checkpointing mechanism using the standard Python module pickle to periodically save the data of a process to a file.</p> <p><pre><code>import pickle\nimport os\n\ndef save_checkpoint(data, filename):\n    \"\"\"Save the checkpoint data to a file.\"\"\"\n    with open(filename, 'wb') as f:\n        pickle.dump(data, f)\n\ndef load_checkpoint(filename):\n    \"\"\"Load the checkpoint data from a file.\"\"\"\n    with open(filename, 'rb') as f:\n        return pickle.load(f)\n\n# Check if there is a checkpoint file\nif os.path.exists('checkpoint.pkl'):\n    # If there is, load the checkpoint\n    data = load_checkpoint('checkpoint.pkl')\n    print(\"Resuming from checkpoint:\")\nelse:\n    # If there isn't, initialize data\n    data = {'counter': 0}\n\ntry:\n    # Simulate some long-running process\n    while True:\n        data['counter'] += 1\n        print(\"Current counter value:\", data['counter'])\n        # Save checkpoint every 5 iterations\n        if data['counter'] % 5 == 0:\n            save_checkpoint(data, 'checkpoint.pkl')\n        # Simulate some work\n        # Replace this with your actual process\n        import time\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    # Save checkpoint if the process is interrupted\n    save_checkpoint(data, 'checkpoint.pkl')\n    print(\"\\nCheckpoint saved. Exiting...\")\n</code></pre> </p>"},{"location":"ai-cloud/additional-guides/checkpointing/#breakdown-of-the-key-components","title":"Breakdown of the key components:","text":"<p>First, the script checks if a checkpoint file named <code>checkpoint.pkl</code> exists using <code>os.path.exists()</code>. If the file exists, it loads the checkpoint data using <code>load_checkpoint</code> function and assigns it to data. If not, it initializes data with a dictionary containing a single key <code>counter</code> initialized to 0. </p> <p>Then, it enters an infinite loop (simulating a long-running process), where it increments the <code>counter</code> key of the data dictionary, prints the current counter value, and simulates some work (in this case, a 1-second delay using <code>time.sleep(1)</code>).</p> <p>Every 5 iterations (<code>if data['counter'] % 5 == 0)</code>, it saves the checkpoint by calling <code>save_checkpoint</code>. If the process is interrupted by a keyboard interrupt (Ctrl+C), it saves the current checkpoint and prints a message before exiting.</p>"},{"location":"ai-cloud/additional-guides/checkpointing/#tensorflow-model-checkpointing","title":"TensorFlow model checkpointing","text":"<p>TensorFlow provides native support for checkpointing during model training, allowing you to save the model's weights at specific intervals. More information about TensorFlow checkpointing can be found here</p> <p>The following code example demonstrates training of a simple neural network model using TensorFlow and Keras on the MNIST dataset. However, the primary focus is on the marked lines indicating checkpointing implementation, using the <code>ModelCheckpoint</code> callback. </p> <pre><code>    import os\n    import sys\n    import os.path\n    import tensorflow as tf\n    from tensorflow import keras\n\n    #####Get an example dataset - we'll use the MNIST dataset first 1000 examples:\n    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n\n    train_labels = train_labels[:5000]\n    test_labels = test_labels[:5000]\n\n    train_images = train_images[:5000].reshape(-1, 28 * 28) / 255.0\n    test_images = test_images[:5000].reshape(-1, 28 * 28) / 255.0\n\n    ##epoch number of steps for each job:\n    epoch_steps=20\n\n    ####Define a simple sequential model:\n    def create_model():\n        model = tf.keras.models.Sequential([\n            keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(10)\n        ])\n\n        model.compile(optimizer='adam',\n                        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n                        metrics=[tf.metrics.SparseCategoricalAccuracy()])\n\n        return model\n\n\n    # Create a new model instance\n    model = create_model()\n\n    # Include the epoch in the file name (uses `str.format`)\n    checkpoint_path = \"checkpoints/{epoch:d}.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    # Create a callback that saves the model's weights every epoch (period=1)\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, \n        verbose=1, \n        save_weights_only=True,\n        period=1)\n\n    # Check if there are existing checkpoints\n    if os.path.exists(checkpoint_dir):\n        # If there are existing checkpoints, load the latest one\n        latest = tf.train.latest_checkpoint(checkpoint_dir)\n        # Load the previously saved weights, if there are any:\n        model.load_weights(latest)\n\n        # Re-evaluate the model\n        loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n        print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n\n        # Get the step number from the latest checkpoint\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir) \n        step = int(os.path.basename(ckpt.model_checkpoint_path).split('.')[0])\n        print('Continuing calculation from epoch step:' + str(step)) \n        # Set the initial epoch to the last recovered epoch\n        initialEpoch=step\n    else:\n        initialEpoch=0\n        # Save the weights for the initial epoch\n        model.save_weights(checkpoint_path.format(epoch=0))\n\n    # Train the model with the new callback\n    model.fit(train_images, \n            train_labels,\n            epochs=epoch_steps, \n            initial_epoch=initialEpoch,\n            callbacks=[cp_callback],\n            validation_data=(test_images,test_labels),\n            verbose=1)\n</code></pre> <p></p>"},{"location":"ai-cloud/additional-guides/checkpointing/#breakdown-of-the-key-components_1","title":"Breakdown of the key components:","text":"<p><code>checkpoint_path</code>: Specify the path where checkpoints will be saved. You can include dynamic elements such as epoch number in the file name to differentiate between checkpoints, like <code>checkpoints/{epoch:d}.ckpt</code></p> <p><code>cp_callback</code>: Create a ModelCheckpoint callback, which will save the model's weights at specified intervals during training. You can customize various parameters such as the file path, verbosity, and whether to save only the weights or the entire model.</p> <p><code>model.load_weights(latest)</code>: Before starting training, check if there are existing checkpoints. If so, load the latest one to resume training from the last saved state. This ensures continuity in training even if interrupted.</p>"},{"location":"ai-cloud/additional-guides/checkpointing/#pytorch-model-checkpointing","title":"PyTorch model checkpointing","text":"<p>Checkpointing in PyTorch is a crucial technique used to save the state of your model and optimizer at various points, enabling you to resume training from a specific epoch in case of interruptions or to fine-tune models from previously saved states. More information about PyTorch checkpointing can be found here</p> <p>This following script demonstrates a simple feedforward neural network using PyTorch. However, the primary focus is on the marked lines indicating checkpointing implementation.</p> <pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\n# Define a simple feedforward neural network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(784, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Load MNIST dataset\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('data', train=True, download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.1307,), (0.3081,))\n                ])),\n    batch_size=64, shuffle=True)\n\n# Define the model\nmodel = SimpleNN()\n\n# Define the optimizer and loss function\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# Checkpoint directory\ncheckpoint_dir = 'checkpoints'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n##epoch number of steps\nepoch_steps = 20\n\n# Check if there are existing checkpoints\nif os.listdir(checkpoint_dir):\n    # If there are existing checkpoints, load the latest one\n    latest_checkpoint = max([int(file.split('.')[0]) for file in os.listdir(checkpoint_dir)])\n    checkpoint = torch.load(os.path.join(checkpoint_dir, f'{latest_checkpoint}.pt'))\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    start_epoch = latest_checkpoint + 1\nelse:\n    start_epoch = 0\n\n# Training loop\nfor epoch in range(start_epoch, epoch_steps):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        data = data.view(data.size(0), -1)\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch}: Loss {loss.item()}')\n\n    # Save checkpoint every epoch\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss\n    }, os.path.join(checkpoint_dir, f'{epoch}.pt'))\n</code></pre> <p></p>"},{"location":"ai-cloud/additional-guides/checkpointing/#breakdown-of-the-key-components_2","title":"Breakdown of the key components:","text":"<p>Checkpoint Directory Setup (line 39-41): Creating a directory for storing checkpoints.</p> <p>Checking for Existing Checkpoints (line 46-55): Checking for existing checkpoints and loading the latest one if available.</p> <p>Saving Checkpoints (line 69-75): Saving the model's state, optimizer's state, and current loss at the end of each epoch to a uniquely named file based on the epoch number.</p>"},{"location":"ai-cloud/additional-guides/cpu-gpu-and-memory-allocation/","title":"CPU, GPU, and memory allocation","text":"<p>To effectively run jobs, it's important to understand the hardware configuration and set appropriate parameters for resource allocation. Here\u2019s a detailed guide on setting Slurm parameters based on the specified hardware on the platform:</p>"},{"location":"ai-cloud/additional-guides/cpu-gpu-and-memory-allocation/#memory-per-job","title":"Memory per job","text":"<p><code>--mem</code> specifies the memory allocated to the job. Example:</p> <pre><code>srun --mem=60G singularity exec --nv tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre>"},{"location":"ai-cloud/additional-guides/cpu-gpu-and-memory-allocation/#cpus-per-task","title":"CPUs per task","text":"<p><code>--cpus-per-task</code> specifies the number of CPUs allocated to each task. Example:</p> <pre><code>srun --cpus-per-task=15 singularity exec --nv tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre>"},{"location":"ai-cloud/additional-guides/cpu-gpu-and-memory-allocation/#gpus-per-job","title":"GPUs per job","text":"<p><code>--gres=gpu</code> specifies the number of GPUs required for the jobs. Example:</p> <pre><code>srun --gres=gpu:4 singularity exec --nv tensorflow_24.03-tf2-py3.sif python3 benchmark_tensorflow.py\n</code></pre> <p>Request only the number of GPUs your job can effectively utilize. Over-requesting can lead to resource underutilization and longer queue times. Some applications may need adjustments to scale effectively across multiple GPUs. Here is an example of a PyTorch script that can handle multiple GPUs. </p> <p>Monitor GPU usage</p> <p>You can use the NVIDIA GPU monitoring command <code>nvidia-smi</code> to output GPU usage information. Learn how to use it in this guide.</p>"},{"location":"ai-cloud/additional-guides/cpu-gpu-and-memory-allocation/#number-of-tasks-to-be-run","title":"Number of tasks to be run","text":"<p><code>--ntasks</code> specifies the number of tasks to be run. Each task typically corresponds to an independent execution of your program or script. If your job can be parallelized across multiple tasks, set the number of tasks to e.g. <code>--ntasks=4</code> for running 4 parallel tasks. Each task gets its allocation of resources (CPU, memory, etc.) based on other parameters like <code>--cpus-per-task</code>, <code>--mem</code>, and <code>--gres=gpu</code>.</p>"},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/","title":"Creating a conda environment","text":"<p>Cotainr is a tool that allows for easily extending Singularity container images with conda environments.</p>"},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/#requirements","title":"Requirements","text":"<p>Cotainr is relatively straight forward provided that either:</p> <p>1) The package you want to use can be found on either anaconda.org or PyPI.</p> <p>2) Your are able to provide a conda environment YAML-file (eg. by calling <code>conda export &gt; environment.yml</code> from within your environment) .</p> <p>Where to find Cotainr</p> <p>We have made Cotainr available in <code>/home/container/cotainr</code>.</p> <p>Cotainr can also be found on their official Github - note that on AI Cloud the newest supported version is 2024.10.0.</p>"},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/#prepare-the-conda-environment","title":"Prepare the Conda environment","text":""},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/#option-1-export-an-existing-environment","title":"Option 1: Export an existing environment","text":"<p>If you already have a working conda environment on another platform, simply call <code>conda env export &gt; environment.yml</code> from within the Conda environment.</p>"},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/#option-2-gather-the-environment-manually","title":"Option 2: Gather the environment manually","text":"<p>If you do not have a working conda environment, you can create the yaml-file manually. In this case it will be preferable to only specify a minimal number of packages, and rely on Anacondas ability to gather the necessary dependencies in the most stable way.</p> <p>It is preferable to start by by verifying that the package can be found on anaconda.org. If the package can not be found here, check if it can be installed from PyPI (using <code>pip</code>).</p> <p>Create/edit the YAML-file with nano</p> <p>Open a text editor like <code>nano</code> to start creating the file. When you are finished, press <code>CTRL + O</code> enter a file name, e.g. <code>environment.yml</code> and exit by pressing <code>CTRL + X</code>. Now you should have <code>environment.yml</code> in your directory. </p> <p>If the package can be found on anaconda.org, we would specify it like so:</p> <p>environment.yml<pre><code>name: cupy\nchannels:\n  - conda-forge\ndependencies:\n  - cupy\n</code></pre> In case we want to install modules with pip, we could say:</p> environment.yml<pre><code>name: cupy\nchannels:\n  - conda-forge\ndependencies:\n  - pip\n  - pip:\n    - cupy\n</code></pre>"},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/#build-the-container-image","title":"Build the container image","text":"<p>Let's create the following batch script for our build:</p> build_cupy.sif<pre><code>#!/bin/bash\n\n#SBATCH --job-name=build_cupy\n#SBATCH --cpus-per-task=32\n#SBATCH --time=04:00:00\n#SBATCH --output=out.%x\n#SBATCH --error=err.%x\n\nexport SINGULARITY_TMPDIR=$HOME/.singularity/tmp\nexport SINGULARITY_CACHEDIR=$HOME/.singularity/cache\nmkdir -p $SINGULARITY_CACHEDIR $SINGULARITY_TMPDIR\n\n# The location of the cotainr executable\ncotainr_path=\"/home/container/cotainr\"\n\n# The base image which build on top of\nbase_image=\"docker://ubuntu:24.04\"\n\n# The conda environment file from which we build\nrequirements=\"environment.yml\"\n\n# The resulting container\noutput_sif=\"cupy.sif\"\n\n# Call the build instructions\n$cotainr_path build $output_sif --base-image=$base_image --conda-env=$requirements --accept-licenses\n</code></pre> <p>Initiate the build proces with:</p> <pre><code>sbatch build_cupy.sh\n</code></pre> <p>A few minutes later you should have <code>cupy.sif</code> container image in your directory.</p>"},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/#test-out-the-container-image","title":"Test out the container image","text":"<p>You can access the conda image and run code using the dependencies you set up. Lets try to see if it works by printing the numpy version: <pre><code>srun singularity exec cupy.sif python3 -c 'import cupy; print(cupy.__version__)'\n</code></pre></p> <p>This should print the Cupy version out to the console, verifying that was indeed installed to our Container image.</p>"},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/#troubleshooting","title":"Troubleshooting","text":"<p>Out of memory?</p> <p>In case your build did not complete, and exited with an \"out of memory\" error (the OOM-killer), we can attempt to allocate more memory to our job. Remember we don't want to be overly greedy, so let's try bumping up from the default 40G to 60G. Adjust this incrementally as you need.</p> <p>Ensure the character encoding is correct</p> <p>If you are trying to build from an environment export from a Windows system, you should ensure that the character encoding is correct. After having uploaded the file to the server, inspect the file with: <pre><code>file environment.yml\n</code></pre></p> <p>If this command outputs: <code>ASCII text, with CRLF line terminators</code> you need to convert the file to a Linux supported character encoding: <pre><code>iconv -ct ascii environment.yml | sed 's/\\r$//' &gt; converted_environment.yml`\n</code></pre></p> <p>Create a YAML-file with only installed on request</p> <p>If you encounter difficulties building the container image, it may be helpful to export only the modules that were explicitly installed (ie. excluding dependencies installed automatically by Conda).</p> <pre><code>conda env export --from-history &gt; environment.yml\n</code></pre> <p>This should result in a shorter list without pinned version numbers.</p>"},{"location":"ai-cloud/additional-guides/creating-a-conda-environment/#are-you-still-experiencing-issues","title":"Are you still experiencing issues?","text":"<p>Reach out to CLAAUDIA at serviceportal.aau.dk</p>"},{"location":"ai-cloud/additional-guides/creating-a-virtual-environment/","title":"Creating a virtual environment","text":"<p>To enhance the functionality of a containerized environment, you can add additional Python packages using a virtual environment. This guide outlines the steps to create and utilize a virtual environment within a Singularity container to ensure compatibility between different Python versions.</p>"},{"location":"ai-cloud/additional-guides/creating-a-virtual-environment/#step-1-create-a-virtual-environment-inside-a-singularity-container","title":"Step 1: Create a virtual environment inside a Singularity container.","text":"<p>Create the virtual environment using the installed <code>virtualenv</code> tool. Remember to replace <code>python_3.10.sif</code> with your container path.</p> <pre><code>srun singularity exec python_3.10.sif virtualenv ~/my-virtual-env\n</code></pre> <p>This ensures that the virtual environment is set up using the correct Python version from the container.</p> <p>Missing <code>virtualenv</code> package?</p> <p>If the command fails due to missing <code>virtualenv</code> dependency, try installing the package in the container:</p> <pre><code>srun singularity exec python_3.10.sif pip install --user virtualenv\n</code></pre> <p>Then run:</p> <pre><code>srun singularity exec python_3.10.sif ~/.local/bin/virtualenv ~/my-virtual-env\n</code></pre>"},{"location":"ai-cloud/additional-guides/creating-a-virtual-environment/#step-2-install-python-packages-inside-the-virtual-environment","title":"Step 2: Install Python packages inside the virtual environment","text":"<p>With the virtual environment created, you can now install the necessary Python packages within it.</p> <pre><code>srun singularity exec --bind ~/my-virtual-env:/my-virtual-env python_3.10.sif /bin/bash -c \"source /my-virtual-env/bin/activate &amp;&amp; pip install numpy pandas matplotlib\"\n</code></pre> <p>Here\u2019s what happens in this command: - The <code>--bind</code> option mounts the virtual environment directory inside the container. - The virtual environment is activated using <code>source</code>. - The required Python packages (<code>numpy</code>, <code>pandas</code>, <code>matplotlib</code>) are installed using <code>pip</code>.</p>"},{"location":"ai-cloud/additional-guides/creating-a-virtual-environment/#step-3-verify-the-installation","title":"Step 3: Verify the installation","text":"<p>After installing the packages, you can verify that they are correctly installed inside the virtual environment.</p> <pre><code>srun singularity exec --bind ~/my-virtual-env:/my-virtual-env python_3.10.sif /bin/bash -c \"source /my-virtual-env/bin/activate &amp;&amp; python -c 'import matplotlib; print(matplotlib.__version__)'\"\n</code></pre> <p>This command runs a short Python script inside the virtual environment to check if <code>matplotlib</code> is properly installed.</p>"},{"location":"ai-cloud/additional-guides/creating-a-virtual-environment/#step-4-use-the-virtual-environment-for-running-scripts","title":"Step 4: Use the virtual environment for running scripts","text":"<p>Now that the virtual environment is set up and populated with the necessary packages, you can use it to run your Python scripts inside the Singularity container.</p> <pre><code>srun singularity exec --bind ~/my-virtual-env:/my-virtual-env python_3.10.sif /bin/bash -c \"source /my-virtual-env/bin/activate &amp;&amp; python my_script.py\"\n</code></pre> <p>This ensures that <code>my_script.py</code> runs with the correct Python version and installed dependencies.</p> <p>Remember to always use the virtual environment when running Python scripts</p> <p>Always make sure to activate the virtual environment (<code>source /my-virtual-env/bin/activate</code>) inside the Singularity container before running any Python scripts to ensure they use the correct dependencies.</p>"},{"location":"ai-cloud/additional-guides/directories-overview/","title":"Directories overview","text":""},{"location":"ai-cloud/additional-guides/directories-overview/#home-directory","title":"Home directory","text":"<p>Each time you log in to AI Cloud, you are landed in your user's home directory. This directory serves as the primary location for storing project files and data. The path to this directory can always be referenced with the variable <code>$HOME</code>.</p> <ul> <li> / root <ul> <li> home  home directories <ul> <li> domain e.g es.aau.dk <ul> <li> user your user directory</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>The user directory is private by default, and users can there not access your files. In case you need to make files accessible for other users, we recommend putting them in a Shared project directory</p> <p>Storage quota expansions</p> <p>When users log in to AI Cloud for the first time, a user directory is created for them. These directories are allocated 1 TB of storage by default. This should be plenty for most users, but should you need additional space, it is possible to apply for storage quota expansions for a limited time using our Storage quota expansions form.</p>"},{"location":"ai-cloud/additional-guides/directories-overview/#shared-project-directories","title":"Shared project directories","text":"<p>AI Cloud fosters collaborative work through shared project directories in <code>/home/project</code>:</p> <ul> <li> /home AI Cloud's file system <ul> <li> project shared project directories <ul> <li> my_shared_project             </li> </ul> </li> </ul> </li> </ul> <p>Users are welcome to create directories for their groups themselves, but they are encouraged to name the directories in a meaningful way (ie. after your group or project name).</p> <p>Go in to the project directory <pre><code>cd /home/project\n</code></pre> Before going ahead and creating a directory for group project, please consider naming the directory in a meaningful manner (ie. after your group or research project). A project directory can be created in the following manner (swap out <code>&lt;name&gt;</code> for the actual name of your project). <pre><code>mkdir &lt;name&gt; \n</code></pre> Please remember, that these directories should be deleted when your project is finished, and you no longer need them. They are not intended for long term data storage.</p>"},{"location":"ai-cloud/additional-guides/directories-overview/#local-storage","title":"Local storage","text":"<p>A handful of compute nodes have local scratch space (as opposed to network drives), which can be utilised for faster I/O operations. These storage volumes are physically attached to each individual compute nodes, and can only be accessed from that specific node.</p> <p>The nodes in question are:</p> <ul> <li><code>i256-a40-[01-02]</code>: 6.4 TB total</li> <li><code>nv-ai-[02-03]</code>:  30 TB total</li> <li><code>nv-ai-04</code>:  14 TB total</li> </ul> <p>Warning</p> <p>This space is not intended for long term storage. Please remove your files when you are finished. We reserve the right to delete directories that have been left untouched for 90 days.</p>"},{"location":"ai-cloud/additional-guides/directories-overview/#create-a-directory","title":"Create a directory","text":"<p>In order to make use of this drive, we need to identify which node we want to work on.</p> <p>In this example, we will be targetting <code>nv-ai-02</code>.</p> <p>The following command will create a directory for you on the network drive, and set the permissions so the directory is only accessible for you.</p> <pre><code>sbatch -w nv-ai-02 --wrap=\"mkdir -p /raid/$USER &amp;&amp; chmod o= /raid/$USER\"\n</code></pre>"},{"location":"ai-cloud/additional-guides/directories-overview/#file-transfer","title":"File transfer","text":"<p>In order to be able to transfer our files, we will need to be able to SSH in to the node. We can only do this if we have a job running on the node.</p> <p>We therefore launch job that runs in the background for 15 minutes (900 seconds) - or however long you believe it will take for you to transfer your files. If you have a job running already, this is not necessary.</p> <pre><code>sbatch -w nv-ai-02 --wrap=\"sleep 900\"\n</code></pre> <p>The hostname will always be the name of the node with <code>srv.aau.dk</code> added to the end.</p> <p>Now transfer your files: <pre><code>scp xs98kl@domain.aau.dk@nv-ai-02.srv.aau.dk:/raid/xs98kl@domain.aau.dk\n</code></pre></p> <p>Other file transfer methods (as described in the File transfer) section will also work. Just change the hostname from <code>ai-fe02.srv.aau.dk</code> to e.g. <code>nv-ai-03.srv.aau.dk</code>.</p> <p>Remember to stay mindful of your fellow resarchers, and cancel the job you created for the file transfer when you are finished.</p>"},{"location":"ai-cloud/additional-guides/directories-overview/#working-with-the-local-scratch-space","title":"Working with the local scratch space","text":"<p>Given that you have acquired a job allocation on the specific node you are working on, just reference this newly created directory.</p> <p>There is no need to bind the directory to your container environment.</p>"},{"location":"ai-cloud/additional-guides/directories-overview/#remote-storage","title":"Remote storage","text":"<p>We do generally support mounting remote network drives on AI Cloud. Mounting remote drives and making them available on all compute nodes, requires a considerable effort from our infrastructure and network departments. In addition to that the read/write speeeds from remote drives would be bottlenecked by the network routing, which would impair GPU performance.</p> <p>Instead we recomend transferring files between locations. In case your file transfer is very large, or if there are any special requirements - you are welcome to contact CLAAUDIA at serviceportal.aau.dk.</p>"},{"location":"ai-cloud/additional-guides/download-container-images/","title":"Pulling container images from the internet","text":"<p>In this section we explain, how we can pull Docker containers from online repositories. </p> <p>Using the command <code>singularity pull</code>, we can download them and automatically convert them into Singularity containers.</p>"},{"location":"ai-cloud/additional-guides/download-container-images/#find-a-container","title":"Find a container","text":""},{"location":"ai-cloud/additional-guides/download-container-images/#find-a-container-on-the-nvidia-ngc-catalog","title":"Find a container on the NVIDIA NGC Catalog:","text":"<ol> <li>Visit NGC Catalog</li> <li>Search for your framework (e.g., \"TensorFlow\", \"PyTorch\")</li> <li>Click \"Get Container\" to get the URL</li> <li>Copy the URL (e.g., <code>nvcr.io/nvidia/tensorflow:24.11-tf2-py3</code>)</li> </ol>"},{"location":"ai-cloud/additional-guides/download-container-images/#find-a-container-on-docker-hub","title":"Find a container on Docker Hub:","text":"<ol> <li>Visit Docker Hub</li> <li>Search for your container</li> <li>Click on \"Tags\" to see available versions</li> <li>Copy the URL (e.g., <code>tensorflow/tensorflow:nightly-jupyter</code>)</li> </ol>"},{"location":"ai-cloud/additional-guides/download-container-images/#downloading-the-container-image","title":"Downloading the container image","text":"<p>Now that we have found a container image, we can create the following batch script:</p> pull-pytorch.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=build_basic\n#SBATCH --cpus-per-task=32\n#SBATCH --mem=60G\n#SBATCH --time=02:00:00\n#SBATCH --output=out.%x\n#SBATCH --error=err.%x\n\nexport SINGULARITY_TMPDIR=$HOME/.singularity/tmp\nexport SINGULARITY_CACHEDIR=$HOME/.singularity/cache\nmkdir -p $SINGULARITY_CACHEDIR $SINGULARITY_TMPDIR\n\n# URI of container to pull\nuri=\"nvcr.io/nvidia/pytorch:25.10-py3\"\n\n# Name of the resulting container\noutput_sif=\"pytorch_25.10.sif\"\n\n# Call the build instructions\nsingularity pull $output_sif docker://$uri\n</code></pre> <p>Some options we can set in the batch script.</p> <ul> <li> <p>The memory paramater:</p> <p>From experience we know that the conversion between Docker and Singularity formats can be a memory consuming operation. If our build fails because of insufficient memory, we may need to adjust the memory parameter. In this example we have set it to 60 gb.</p> </li> <li> <p>Environment variables:</p> <p>Before pulling the container image, we need to set the <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code> environment variables. If these are not set, Singularity assumes that we have lots of space in <code>/tmp</code> on the host system - which is not the case. If they are set, Singularity will use this directory for storing temporary files and cached data during container operations. These are mandatory.</p> </li> </ul> <p>Launch the batch script to pull the container image:</p> <pre><code>sbatch pull-pytorch.sh\n</code></pre> <p>Note that this may take ~20-30 minutes to complete.</p>"},{"location":"ai-cloud/additional-guides/edit-text-files-with-nano/","title":"Edit text files with Nano","text":"<p>The most beginner-friendly text editor commonly found on Linux systems is Nano.</p> <p>Opening the file <code>my_file</code> can be done by saing:</p> <pre><code>nano my_file\n</code></pre> <p>This will open up the text editor, which should look like:</p> <pre><code>  GNU nano 4.8                                 my_file                                      \n\n\n\n\n\n\n\n\n\n\n\n^G Get Help   ^O Write Out  ^W Where Is   ^K Cut Text   ^J Justify    ^C Cur Pos    M-U Undo\n^X Exit       ^R Read File  ^\\ Replace    ^U Paste Text ^T To Spell   ^_ Go To Line M-E Redo\n</code></pre>"},{"location":"ai-cloud/additional-guides/edit-text-files-with-nano/#nice-to-know-about-nano","title":"Nice to know about Nano:","text":"<ul> <li>Opening Nano without a target file, will open a buffer that can be saved and named later (just like opening a blank word document). </li> <li>The two lines at the very bottom of the Nano interface will hint at which keyboard shortcuts call which actions.<ul> <li>The symbol <code>^</code> means Ctrl</li> <li>The <code>M</code> means Alt</li> </ul> </li> </ul> Action Keybind Notes  Save Ctrl+S You will be asked to confirm, if you wish to save to the current file. If you have not yet named your file, you will be asked to name the file first. Press Y to confirm, or N to reject  Exit Ctrl+X If you have unsaved changes, you will be asked if you wish to save.  Search Ctrl+W Type in your search term, and press Enter. To repeat press Ctrl+W and Enter again (the search term is automatically repeated)."},{"location":"ai-cloud/additional-guides/multiple-gpus-with-pytorch/","title":"Multiple GPUs with PyTorch","text":"<p>Distributed training across multiple GPUs is essential for accelerating deep learning tasks involving large datasets and complex models. PyTorch provides robust support for distributed computing through its <code>torch.distributed</code> package, facilitating efficient utilization of GPU resources using <code>torch.nn.parallel.DistributedDataParallel</code> (DDP). This guide presents a detailed explanation of how to implement and execute distributed training across multiple GPUs using PyTorch.</p>"},{"location":"ai-cloud/additional-guides/multiple-gpus-with-pytorch/#script-overview","title":"Script Overview","text":"<p>The provided Python script demonstrates how to perform distributed training across multiple GPUs using DDP in PyTorch. Let's break down each part of the script to understand its functionality and how it facilitates multi-GPU training.</p>"},{"location":"ai-cloud/additional-guides/multiple-gpus-with-pytorch/#part-1-imports-and-library-setup","title":"Part 1: Imports and Library Setup","text":"<p>Begin by importing necessary libraries and modules for GPU-accelerated deep learning tasks with PyTorch. The key module for distributed computing is <code>torch.distributed</code>.</p> <pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transforms as transforms\nimport time\nimport argparse\n</code></pre>"},{"location":"ai-cloud/additional-guides/multiple-gpus-with-pytorch/#part-2-distributed-setup","title":"Part 2: Distributed Setup","text":"<p>Next, we create a function called <code>setup</code> that initializes the distributed environment necessary for multi-GPU training:</p> <pre><code>def setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n    torch.cuda.set_device(rank)\n</code></pre> <ul> <li><code>MASTER_ADDR</code> and <code>MASTER_PORT</code> are set to establish communication between different processes. This is crucial for coordinating distributed training across multiple GPUs.</li> <li><code>dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)</code> initializes the process group using the NCCL backend, which is optimized for efficient communication on NVIDIA GPUs.<ul> <li><code>rank</code> value is assigned to each proces to distinguish between processes.</li> <li><code>world_size</code> refers to the total number of processes that participate in the distributed training setup.</li> </ul> </li> <li><code>torch.cuda.set_device(rank)</code> ensures each process is assigned a specific GPU device based on its rank, enabling efficient GPU resource management.</li> </ul>"},{"location":"ai-cloud/additional-guides/multiple-gpus-with-pytorch/#part-3-cleanup-function","title":"Part 3: Cleanup Function","text":"<p>We then define a <code>cleanup()</code> function that ensures clean release of distributed training resources after completion, preventing resource leaks.</p> <pre><code>def cleanup():\n    dist.destroy_process_group()\n</code></pre>"},{"location":"ai-cloud/additional-guides/multiple-gpus-with-pytorch/#part-4-training-function","title":"Part 4: Training Function","text":"<p>Finally, we define a <code>train(rank, world_size)</code> function that orchestrates distributed training across multiple GPUs:</p> <pre><code>def train(rank, world_size):\n    # Setup: Initializes the distributed environment using setup(rank, world_size).\n    setup(rank, world_size)\n\n    # Data Loading: Prepares CIFAR-10 dataset with transformations for training.\n    print(f'Rank {rank}: Preparing data..')\n    transform = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n    # Distributed Sampler: Ensures data is divided among GPUs using DistributedSampler.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=world_size, rank=rank)\n\n    # Data Loader: Creates a DataLoader that iterates through batches of data with distributed sampling and batching.\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True, sampler=train_sampler)\n\n    # Model Initialization: Initializes ResNet-50 model (net) and distributes it across GPUs using DistributedDataParallel.\n    print(f'Rank {rank}: Building model..')\n    net = torchvision.models.resnet50().to(rank)\n    net = nn.parallel.DistributedDataParallel(net, device_ids=[rank])\n\n    # Loss and Optimizer: Defines cross-entropy loss (criterion) and SGD optimizer (optimizer).\n    criterion = nn.CrossEntropyLoss().to(rank)\n    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n\n    # Training Loop: Iterates through epochs and batches, performs forward and backward passes, and updates model parameters.\n    def train_epoch(epoch):\n        net.train()\n        train_sampler.set_epoch(epoch)\n        train_loss = 0\n        correct = 0\n        total = 0\n        start_time = time.time()\n        for batch_idx, (inputs, targets) in enumerate(trainloader):\n            inputs, targets = inputs.to(rank), targets.to(rank)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            if batch_idx % 10 == 0:\n                print(f'Rank {rank}, Batch: {batch_idx}, Loss: {train_loss/(batch_idx+1)}, Accuracy: {100.*correct/total}%')\n\n        end_time = time.time()\n        print(f'Rank {rank}: Training time for epoch {epoch}: {end_time - start_time} seconds')\n\n    # Training Execution: Runs training for 1 epoch.\n    for epoch in range(1):\n        train_epoch(epoch)\n\n    # Cleanup: Releases distributed training resources after completion.\n    cleanup()\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='PyTorch Distributed Training Example')\n    # args.world_size is passed as an argument, specifying the number of processes (world_size) for distributed training from the command line.\n    parser.add_argument('--world_size', type=int, default=1, help='Number of processes for distributed training')\n    args = parser.parse_args()\n    # spawn is a utility that facilitates launching multiple processes in a distributed manner.\n    mp.spawn(train, args=(args.world_size,), nprocs=args.world_size, join=True)\n</code></pre>"},{"location":"ai-cloud/additional-guides/multiple-gpus-with-pytorch/#full-script","title":"Full script","text":"<pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transforms as transforms\nimport time\nimport argparse\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n    torch.cuda.set_device(rank)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef train(rank, world_size):\n    # Setup: Initializes the distributed environment using setup(rank, world_size).\n    setup(rank, world_size)\n\n    # Data Loading: Prepares CIFAR-10 dataset with transformations for training.\n    print(f'Rank {rank}: Preparing data..')\n    transform = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n    # Distributed Sampler: Ensures data is divided among GPUs using DistributedSampler.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=world_size, rank=rank)\n\n    # Data Loader: Creates a DataLoader that iterates through batches of data with distributed sampling and batching.\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True, sampler=train_sampler)\n\n    # Model Initialization: Initializes ResNet-50 model (net) and distributes it across GPUs using DistributedDataParallel.\n    print(f'Rank {rank}: Building model..')\n    net = torchvision.models.resnet50().to(rank)\n    net = nn.parallel.DistributedDataParallel(net, device_ids=[rank])\n\n    # Loss and Optimizer: Defines cross-entropy loss (criterion) and SGD optimizer (optimizer).\n    criterion = nn.CrossEntropyLoss().to(rank)\n    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n\n    # Training Loop: Iterates through epochs and batches, performs forward and backward passes, and updates model parameters.\n    def train_epoch(epoch):\n        net.train()\n        train_sampler.set_epoch(epoch)\n        train_loss = 0\n        correct = 0\n        total = 0\n        start_time = time.time()\n        for batch_idx, (inputs, targets) in enumerate(trainloader):\n            inputs, targets = inputs.to(rank), targets.to(rank)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            if batch_idx % 10 == 0:\n                print(f'Rank {rank}, Batch: {batch_idx}, Loss: {train_loss/(batch_idx+1)}, Accuracy: {100.*correct/total}%')\n\n        end_time = time.time()\n        print(f'Rank {rank}: Training time for epoch {epoch}: {end_time - start_time} seconds')\n\n    # Training Execution: Runs training for 1 epoch.\n    for epoch in range(1):\n        train_epoch(epoch)\n\n    # Cleanup: Releases distributed training resources after completion.\n    cleanup()\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='PyTorch Distributed Training Example')\n    # args.world_size is passed as an argument, specifying the number of processes (world_size) for distributed training from the command line.\n    parser.add_argument('--world_size', type=int, default=1, help='Number of processes for distributed training')\n    args = parser.parse_args()\n    # spawn is a utility that facilitates launching multiple processes in a distributed manner.\n    mp.spawn(train, args=(args.world_size,), nprocs=args.world_size, join=True)\n</code></pre>"},{"location":"ai-cloud/additional-guides/multiple-gpus-with-pytorch/#running-the-script","title":"Running the Script","text":"<p>To execute the multi-GPU training script we will use a Bash script (submit_job.sh):</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=ddp_training\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=60G\n#SBATCH --time=02:00:00\n#SBATCH --output=ddp_training.out\n\n# Number of GPUs to allocate (adjust this value as needed)\nnum_gpus=4\n\n# Set the number of tasks and GPUs accordingly\n#SBATCH --ntasks=$num_gpus\n#SBATCH --gres=gpu:$num_gpus\n\n# Execute the job using Singularity\nsrun singularity exec --nv pytorch_24.03-py3.sif python3 multi_gpu.py --world_size=$num_gpus\n</code></pre> <ul> <li><code>--job-name</code>: Specifies the name of the job.</li> <li><code>-partition</code>: Defines the partition or queue to submit the job to (l4 in this example).</li> <li><code>--cpus-per-task</code>: Specifies the number of CPUs allocated to each task.</li> <li><code>--mem</code>: Specifies the memory allocated to the job.</li> <li><code>--time</code>: Adjust these settings based on your specific resource requirements.</li> <li><code>num_gpus</code>: Modify this variable to specify the number of GPUs (--ntasks and --gres=gpu) allocated for your job.</li> <li><code>srun singularity exec --nv pytorch_24.03-py3.sif python3 multi_gpu.py --world_size=$num_gpus</code>: Executes the job inside the specified Singularity container (<code>pytorch_24.03-py3.sif</code>) with Python 3, running the <code>multi_gpu.py</code> script and passing <code>--world_size=$num_gpus</code> as an argument to specify the number of GPUs for distributed training.</li> </ul>"},{"location":"ai-cloud/additional-guides/run-jobs-beyond-the-default-qota/","title":"Run jobs beyond the default quota","text":"<p>When we run a job, a number of default parameters are passed to Slurm, and we are granted access to resources in accordance with the default configuration. In some cases we may want to pass different values to some of these paramaters, eg. in order to launch a job on a node with access restrictions, or if we want to access the default resources on different terms.</p>"},{"location":"ai-cloud/additional-guides/run-jobs-beyond-the-default-qota/#resource-control-features","title":"Resource control features","text":"<p>On AI Cloud we use a variety of features to control access to resources:</p> <ul> <li>Nodes in the cluster can belong to one or more <code>partitions</code></li> <li>Access to these partitions may be restricted to certain <code>accounts</code></li> <li>The term <code>quality of serivce</code> (abbreviated <code>QOS</code>) can determine the amount of resources that can be accessed at any given time. On this page, we will give you a demonstration of what is possible.</li> </ul>"},{"location":"ai-cloud/additional-guides/run-jobs-beyond-the-default-qota/#the-default-access-mode","title":"The default access mode","text":"<p>For reference, let's launch a job with the default settings:</p> <pre><code>srun hostname\n</code></pre> <p>This job is run with the parameters <code>--account=aau</code>, <code>--qos=normal</code> and <code>--partition=prioritized</code>. These parameters are the defaults, and do not have to be passed to your launch command.</p> <p>Excercise: Verify the Slurm parameters</p> <p>If you want to view the values passed to the mentioned arguments, you can run the command:</p> <pre><code>srun bash -c 'env | grep SLURM'\n</code></pre> <p>This returns the Slurm environment variables. Among these we should be able to find <code>SLURM_JOB_PARTITION=prioritized</code>, <code>SLURM_JOB_ACCOUNT=aau</code> and <code>SLURM_JOB_QOS=normal</code> which can serve as an interesting comparison in this section. As we did not pass any arguments to the srun command, these are the defaults. </p>"},{"location":"ai-cloud/additional-guides/run-jobs-beyond-the-default-qota/#unprivileged-access","title":"Unprivileged access","text":"<p>An infinite number of jobs can be launched using the flag <code>--qos=unprivileged</code>.</p> <pre><code>srun --qos=unprivileged --time=2-00:00:00 hostname\n</code></pre> <p>It's important to note that <code>unprivileged</code> jobs are preemptable. If a request for the same resources is made, the job will be interrupted and placed in the queue, where it will remain until the resources become available again.</p>"},{"location":"ai-cloud/additional-guides/run-jobs-beyond-the-default-qota/#deadline-access","title":"Deadline access","text":"<p>In the <code>deadline</code> account users are allowed to have an additional 12 simultaneous jobs with an additional 12 GPU's for a period of up to 14 days. To run a job with deadline resources, we must specify <code>--account=deadline</code>.</p> <pre><code>srun --account=deadline hostname\n</code></pre> <p>In order to gain access to the deadline account, users must submit an application found on serviceportal.aau.dk \u2192 AI Cloud: Request access to deadline resources. We will try to process applications on the same day.</p> <p>This option is for researchers who are working towards a deadline, and is not intended to become a permanent solution for projects with large resource needs. Once granted it will not be possible to reapply for another 14 days. If your project requires a large amount of resources, you should consider applying for a grant for an external HPC system.</p>"},{"location":"ai-cloud/additional-guides/run-jobs-on-proprietary-nodes/","title":"Running jobs on proprietary nodes","text":"<p>Research groups who have made use of the buy-in option (bought own hardware to be hosted in AI Cloud) will have privileged access to their nodes.</p> <p>Other users can also make use of the resources with unprivileged access.</p>"},{"location":"ai-cloud/additional-guides/run-jobs-on-proprietary-nodes/#privileged-access","title":"Privileged access","text":""},{"location":"ai-cloud/additional-guides/run-jobs-on-proprietary-nodes/#ai-centre","title":"AI Centre","text":"<p>Researchers with affiliation to the Pioneer Centre for AI can be added to the following privileged accounts:</p> <ul> <li> <p><code>aicentre</code></p> <p>This account gives access to the partition of the same name <code>aicentre</code> containing the nodes <code>i256-a40-01</code> and <code>i256-a40-02</code>.</p> <p>To launch a privileged job on this node, the <code>--account=</code> and <code>--partition=</code> arguments must be added to your launch command:</p> <pre><code>\u276f srun --partition=aicentre --account=aicentre hostname\nsrun: job 793360 queued and waiting for resources\nsrun: job 793360 has been allocated resources\ni256-a40-01.srv.aau.dk\n</code></pre> </li> <li> <p><code>aicentre-a100</code></p> <p>This account gives access to the partition of the same name <code>aicentre-a100</code> containing the node <code>nv-ai-04</code>.</p> <p>To launch a privileged job on this node, the <code>--account=</code> and <code>--partition=</code> arguments must be added to your launch command:</p> <pre><code>\u276f srun --partition=aicentre-a100 --account=aicentre-a100 hostname\nsrun: job 793361 queued and waiting for resources\nsrun: job 793361 has been allocated resources\nnv-ai-04.srv.aau.dk\n</code></pre> </li> </ul>"},{"location":"ai-cloud/additional-guides/run-jobs-on-proprietary-nodes/#unprivileged-access","title":"Unprivileged access","text":"<p>If you want wish to launch an unprivileged job on a proprietary node, you must specify the arguments; <code>--partition=</code>, <code>--qos=</code> and <code>--time</code> arguments:</p> <pre><code>\u276f srun --qos=unprivileged --partition=aicentre --time=0-00:01:00 hostname\nsrun: job 793362 queued and waiting for resources\nsrun: job 793362 has been allocated resources\ni256-a40-01.srv.aau.dk\n</code></pre> <p>Please note:</p> <ul> <li> <p>The <code>--time=</code> parameter can be set to a maximum of <code>6-00:00:00</code> (6 days).</p> </li> <li> <p>Unprivileged jobs are preemtable. If a request is made for the same resources, the job will be interrupted until the resources free up again.</p> </li> </ul>"},{"location":"ai-cloud/additional-guides/setting-a-time-limit/","title":"Setting a time limit","text":"<p>Sometimes, jobs may get stuck or encounter unforeseen issues, causing them to run indefinitely. Setting a time limit ensures that such jobs are automatically terminated after a certain duration, preventing them from consuming resources unnecessarily.</p> <p>You can add a <code>--time</code> parameter to your Slurm command, e.g. <code>--time=0-08:00:00</code> to run a job for maximum 8 hours:</p> <pre><code>srun --time=08:00:00 hostname\n</code></pre>"},{"location":"ai-cloud/additional-guides/setting-a-time-limit/#time-limits-before-service-windows","title":"Time limits before service windows","text":"<p>Setting a time limit is particularly important when a service window is approaching. On the day of the service window, the entire cluster will be reserved for maintainance. As you may remember, jobs can be run in the <code>prioritized</code> partition for 6 consecutive days. If there are fewer than 6 days until the service window, and you do not specify the <code>--time</code> parameter, your job will only start after the service window has been completed. To run jobs in the days leading up to the service window, you will need to calculate how much time is left, and add this value to the <code>--time</code> argument to your Slurm command.</p>"},{"location":"ai-cloud/additional-guides/understanding-linux-cli/","title":"Understanding the Linux CLI","text":"<p>On this page our goal is to help you understand the most fundamental concepts of operating a Linux server. This page is not designed as a collection of useful commands, and neither is this a tutorial on operating a Linux server. Think of this page as a concept glossary that will help you understand how a Linux server works.</p> <p>After having read this page you should be much better equipped to work on AI Cloud (and other HPC systems).</p>"},{"location":"ai-cloud/additional-guides/understanding-linux-cli/#referencing-file-paths","title":"Referencing file paths","text":"<p>The directory <code>/home/domain/user/subdirectory</code> can thus be broken up into: <code>/</code>, <code>home</code>, <code>domain</code>, <code>user</code>.  Note that the first <code>/</code> is the root, and the following directories are subdirectories to each other.</p> <p>We can reference file paths in two ways. Suppose we want to list the files in <code>/home/domain/user/subdirectory</code></p> <ul> <li> <p>Relative paths: If we are standing in <code>/home/domain/user</code>, we can call <code>ls -l subdirectory</code></p> </li> <li> <p>Absolute paths: If we are standing in a completely different location, we can always target its' absolute path <code>ls -l /home/domain/user/subdirectory</code></p> </li> </ul> <p>Why is this useful knowledge</p> <p>This is the most fundamental concept of navigating the command line - not much can be done without this understanding.</p>"},{"location":"ai-cloud/additional-guides/understanding-linux-cli/#executing-commands-and-programs","title":"Executing commands and programs","text":"<p>Commands can either be shell builtins or programs. For the most part it is not important to be able to distinguish between them, but it is important to understand that in most cases commands are programs, which we can execute because the system knows where to find them. In other words: every command is an executable file with a valid filepath on the system (technically with a few exceptions - but don't worry about that right now).</p> <p>When we call a command, the operating system will search for it in the directories in the <code>$PATH</code> variable. If there is not a matching executable in one of these directories we can not call the program. If there are multiple matches, the first one will be selected.</p> <p>Consider this: we can print the full path to <code>python3</code> with:</p> <pre><code>\u276f which python3\n/usr/bin/python3\n</code></pre> <p>But as we see here, there are multiple python executables in <code>$PATH</code>.</p> <pre><code>\u276f type -a python3\npython3 is /usr/bin/python3\npython3 is /bin/python3\n</code></pre> <p>Calling <code>wich</code> is useful for confirming which version we are getting.</p> <p>But how do we target a specific executable then? There are two solutions:</p> <ul> <li> <p>Referencing the absolute path to the executable. In the example above calling <code>python3</code> is equivalent to calling <code>/usr/bin/python3</code>. This is the most straight forward solution.</p> </li> <li> <p>Adding the directory with the executable to the environment variable <code>$PATH</code> so that it comes first, with: <code>export PATH=\"/path/to/dir:$PATH\"</code>.</p> </li> </ul> <p>Why is this useful knowledge?</p> <p>This is important to understand because operating an HPC system involves jumping between sessions/environments (eg. nodes and software containers), whereby the software environment changes, and we may want to confirm that we are indeed calling the desired command (ie. from the desired path).</p> <p>Enviroment managing</p> <p>In essence this is also how environment managers like <code>conda</code> or <code>venv</code> work. However our goal here is to demonstrate how Linux operating systems work - not to make recomendations for working with Python. If you want to activate a Python virtual environment or a Conda environment, please refer to more specific instructions.</p>"},{"location":"ai-cloud/additional-guides/understanding-linux-cli/#processes","title":"Processes","text":"<p>Whenever a program (or command) is executed it uses system resources (cpu, gpu, ram, disk) to deliver on the programs instructions. This is called a proces.</p> <p>In Linux operating systems, we can get an overview of all running processes with a program called <code>top</code>, and we can view our own processes only with <code>top -u $USER</code>. The latter command is especially convenient on a multi user system. It should be noted, that is normal for programs to launch one or more child/sister processes, and therefore monitoring the exact resource consumption may not always be straight forward.</p> <p>Why is this useful knowledge?</p> <p>We can use this view to get an indication of what the system is doing under the hood, and wether or not our program has actually started. </p>"},{"location":"ai-cloud/additional-guides/understanding-linux-cli/#sessions","title":"Sessions","text":"<p>When you log in to the system, you start in an interactive shell session. This means that you are standing somewhere on a host system, and you can interact with the system by executing commands and viewing their outputs.</p> <p>Interactive shell sessions are kept alive, for as long as the user keeps it alive. You can exit a shell session with the keybinding Ctrl+D or with the command <code>exit</code>.</p> <p>Sessions can be nested inside each other - meaning that a session can be started from within another session. This is useful to understand because: Whenever we start a job on a compute node with <code>srun</code>, we start a new session on the compute node. This session on the compute node is nested inside the session on the front-end node, meaning that it will only run for as long as the parent session is alive.</p> <p>Why is this useful knowledge?</p> <p>It's also useful to understand this, because sessions can differ from each other with regards to which variables are loaded or which commmands/programs can be executed. When we understand this, we can work with it.</p>"},{"location":"ai-cloud/additional-guides/understanding-linux-cli/#variables","title":"Variables","text":"<p>A number of variables are loaded into the session when you log in to the system. Additional variables can be set by the user in order to set paths or options.</p> <pre><code>env\n</code></pre> <p>Assign a variable: <pre><code>var=\"hello world\"\n</code></pre></p> <p>Print the content of a variable: <pre><code>\u276f echo $var\nhello world\n</code></pre></p> <p>Notice that after the variable has been assigned, we must reference it with a prepended <code>$</code>. When we make the assignment, we must not do this.</p> <p>Prepending <code>export</code> to the assignment makes the variable accessible to child processes (and nested sessions). Suppose we prepended <code>export</code> to the assignment of <code>$var</code> in a batch-script:</p> <pre><code>export var=\"hello world\"\n</code></pre> <p>This makes <code>$var</code> accessible on the compute node. We can confirm this by calling <code>env</code> (or in Python with: <code>\u00ecmport os ; os.environ.items()</code>).</p> <p>Why is this useful knowledge?</p> <ul> <li> <p>We can control program settings:</p> <p>When we build Singularity containers, we can set the variables <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code> to override the default directories for these. This serves as an example of a program, that reads settings from variables. See these in action here.</p> </li> <li> <p>We can gather information on the current session:</p> <p>Notice that calling <code>srun env</code> (printing all variables in a compute node job), shows a large number of <code>SLURM</code> variables. These variables convey information about the current session, and we can use them to gather (or log) details about our job.</p> </li> <li> <p>Increase script readability:</p> <p>Using variables to reference files and directories is good practice, because it increases readability and maintainability:</p> <pre><code># Project directory\nproject_dir=/home/domain/user/project_1    \n\n# The container image we want to launch:\ncontainer_image=\"$project_dir/pytorch_25.04.sif\"\n\n# The file we want to process on the compute node:\nfile=\"$project_dir/is-available.py\"\n\n# Execute job\nsrun singularity exec --nv $container_image python3 $file\n</code></pre> </li> </ul>"},{"location":"ai-cloud/additional-guides/useful-commands/","title":"Useful commands","text":"Command Description Useful flags Notes <code>ls</code> list files <code>-l</code> long format, <code>-a</code> all files (including dotfiles) <code>pwd</code> print working directory <code>cd</code> change working directory Passing no destination, will land you in <code>$HOME</code> <code>rm</code> remove file/directory <code>-f</code> to force the action (ignore permissions), -r to remove recursively (all subdirectories) <code>cp</code> copy file/directory <code>-R</code> to copy recursively <code>mv</code> move file/directory <code>touch</code> create file <code>mkdir</code> make directory <code>-p</code> create parent dirs <code>cat</code> print file <code>head</code> print the first 5 lines of a file <code>-n 10</code> to print the first 10 lines (and so on) <code>tail</code> print the last 5 lines of a file <code>-n 10</code> to print the last 10 lines (and so on) <code>watch</code> run command every 2 seconds <code>-n 4</code> to run the command every 4 sec"},{"location":"ai-cloud/getting-started/","title":"Prerequisites","text":"<p>Before attempting to log in to AI Cloud, please ensure that you have completed the following:</p>"},{"location":"ai-cloud/getting-started/#1-review-our-terms-and-conditions-and-fair-usage-guidelines","title":"1. Review our terms and conditions and fair usage guidelines","text":"<ul> <li>Read through our Fair usage guidelines.</li> <li> <p>Read our Terms and Conditions - especially noting the following points:</p> <ul> <li>AI Cloud is not intended for working with level 2 and level 3 data.</li> <li>AI Cloud is not designed for long term storage of research data.</li> </ul> </li> </ul>"},{"location":"ai-cloud/getting-started/#2-request-access","title":"2. Request access","text":"<p>If you haven't done so yet, please visit how to access to learn how to get approved for using AI Cloud.</p>"},{"location":"ai-cloud/getting-started/#3-connect-to-the-aau-network","title":"3. Connect to the AAU network","text":"<p>AI Cloud is only reachable from within the AAU network. Before attempting to connect to AI Cloud, please ensure that you are connected to the AAU network - either by using the campus WiFi (or a wired ethernet connection) - or, if you are not able to reach the campus network physically, use AAU's VPN or our SSH gateway service.</p>"},{"location":"ai-cloud/getting-started/#4-find-a-terminal-application","title":"4. Find a terminal application","text":"<p>Interacting with AI Cloud is done over the SSH protocol and you will need to find an application that has SSH capability. This will depend on the operating system of your local machine:</p> <p>If you are a Windows user, we recomend Powershell.</p> <p>If you are a MacOS or Linux user, we recommend the default terminal application that comes with your OS.</p> <p>With these preparations in place, lets get started </p>"},{"location":"ai-cloud/getting-started/container-images/","title":"Container images","text":"<p>When we want to launch jobs in a multi-user environment like AI Cloud, we can not install software directly on to the platform, since every project has different requirements. Instead we must bundle the software into container images, which are stand-alone files into which contain all the dependencies. On AI Cloud we use the container framework Singularity for this purpose.</p>"},{"location":"ai-cloud/getting-started/container-images/#how-to-get-containers","title":"How to get containers","text":"<p>We recommend one of three different approaches to the software environment:</p>"},{"location":"ai-cloud/getting-started/container-images/#use-a-pre-built-container-image","title":"Use a pre-built container image","text":"<p>A handful of ready-to-launch container images have been made available in: <code>/home/container</code>. If there's a container image you would like us to make available per default - reach out to us.</p>"},{"location":"ai-cloud/getting-started/container-images/#pull-container-images-from-the-internet","title":"Pull container images from the internet","text":"<p>Head over to our section Additional guides &gt; Pull containers from the internet.</p>"},{"location":"ai-cloud/getting-started/container-images/#build-your-own-container-images","title":"Build your own container images","text":"<p>Head over to our section Additional guides &gt; Building your own container image.</p> <p>Now that you've learned how to obtain containers, you are ready to learn how to run jobs </p>"},{"location":"ai-cloud/getting-started/file-management/","title":"File transfer","text":""},{"location":"ai-cloud/getting-started/file-management/#transfer-files-between-a-server-and-a-local-computer","title":"Transfer files between a server and a local computer","text":"<p>On this page you will learn how to transfer files from your local computer to AI Cloud.</p> Linux/MacOSWindows <p>You can transfer files between your local computer and AI Cloud using the command line utility <code>scp</code>. This will only work if you call the command from your local computer and not the server.</p> <pre><code>scp some-file user@domain.aau.dk@ai-fe02.srv.aau.dk:~/some-dir\n</code></pre> <p>Replace <code>user@domain.aau.dk</code> with your AAU email address.</p> <p>Here, <code>~</code> represents your user directory on AI Cloud and <code>/some-dir</code> a folder in your directory. </p> <p>To copy files from AI Cloud to your local computer, use:</p> <pre><code>scp user@domain.aau.dk@ai-fe02.srv.aau.dk:~/some-folder/some-subfolder/some-file .\n</code></pre> <p>Replace <code>user@domain.aau.dk</code> with your AAU email address.</p> <p>Here, <code>.</code> represents the current directory on your local computer.</p> <p>Error</p> <p>Please keep in mind that this a network operation, where files are transferred over the SSH protocol. Before attempting to reach the server with WinSCP, please ensure that you are conencted to the AAU network - either by being physically on campus grounds or using the VPN service</p> <p>From a Windows PC you can transfer files to AI Cloud using WinSCP - or in the command line using <code>scp</code>.</p> <ol> <li> <p>Start by downloading and installing WinSCP.</p> </li> <li> <p>Open WinSCp - this will greet you with a login interface.</p> </li> </ol> <p></p> <p>Configure the connection as follows:</p> <ul> <li>Host name: <code>ai-fe02.srv.aau.dk</code></li> <li>User name: Your AAU email address</li> <li> <p>Password: Your AAU password</p> </li> <li> <p>Click Login and a new window should open.</p> </li> </ul> <p>Now that you know the basics of file transfer, lets proceed to learn how to obtain container images </p>"},{"location":"ai-cloud/getting-started/file-management/#success","title":"Success!","text":"<p>You should now be able to drag and drop files between your local computer and AI Cloud.</p> <p>Tip</p> <p>Yay want to display hidden files in WinSCP (such as files starting with a dot on Linux systems). Go to Options \u2192 Preferences... \u2192 Panels and turn on \"Show hidden files\".</p> <p>Can't login?</p> <p>Please keep in mind that this a network operation, where files are transferred over the SSH protocol. Before attempting to reach the server with WinSCP, please ensure that you are conencted to the AAU network - either by being physically on campus grounds or using the VPN service</p>"},{"location":"ai-cloud/getting-started/login/","title":"Log in","text":"<p>Logging in to the platform is done with an SSH connection to the front end node.</p> <p>Find an SSH-capable terminal application and run the command: <pre><code>ssh -l user@domain.aau.dk ai-fe02.srv.aau.dk\n</code></pre> Replace <code>user@domain.aau.dk</code> with your AAU email address.</p> <p>Enter your AAU password when prompted.</p> <p>Accept the fingerprint?</p> <p>The first time you connect, you will get the following message: <pre><code>The authenticity of host 'ai-fe02.srv.aau.dk (172.21.131.1300)' can't be established.\nED25519 key fingerprint is SHA256:xosJtOSfQyyW16c6RtpN8tAi/91XHCR3GxM9/KJEogg.\nThis key is not known by any other names.\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\n</code></pre></p> <p>Confirm by typing <code>yes</code> to proceed with the connection.</p>"},{"location":"ai-cloud/getting-started/login/#success","title":"Success!","text":"<p>When your prompt changes to: <code>user@domain.aau.dk@ai-fe02:~$</code> - you are successfully logged in.</p>"},{"location":"ai-cloud/getting-started/login/#troubleshooting","title":"Troubleshooting","text":"<p>Having trouble with logging in?</p> <ul> <li> <p>In most cases where users have trouble logging in, they are not connected to the AAU network. See the section: Before you begin.</p> </li> <li> <p>If it's still not working, create a case with us on serviceportal.aau.dk. Please share the command output with us in the case, as this gives us a better oppurtunity to understand what is going on. Add the flag <code>-vv</code> to the command, like so: <pre><code>ssh -vv -l user@domain.aau.dk ai-fe02.srv.aau.dk\n</code></pre></p> </li> </ul>"},{"location":"ai-cloud/getting-started/login/#bonus-tips","title":"Bonus tips","text":"<p>The ssh-gateway</p> <p>AAU provides an ssh-gateway service, that can be used as an alternative to the VPN service. This requires only a small change to your command:</p> <pre><code>ssh -J user@domain.aau.dk@sshgw.aau.dk -l user@domain.aau.dk ai-fe02.srv.aau.dk\n</code></pre> <p>Easy access with ~/.ssh/config</p> <p>It's possible to store your credentials in a file in your <code>~/.ssh</code> directory, called <code>config</code>. Open this file and add the following: <pre><code>Host sshgw\n  HostName sshgw.aau.dk\n  User user@domain.aau.dk\n\nHost aicloud\n  HostName ai-fe02.srv.aau.dk\n  User user@domain.aau.dk\n  Proxyjump sshgw\n</code></pre></p> <p>Now we can log in to AI Cloud, simply by typing:</p> <pre><code>ssh aicloud\n</code></pre> <p>You are now ready to proceed to look around </p>"},{"location":"ai-cloud/getting-started/look-around/","title":"Look around","text":"<p>In this section our goal is to provide you with a fundamental understanding of the platform, and to present you with a few of the fundamental commands used for interacting with the system..</p>"},{"location":"ai-cloud/getting-started/look-around/#system-overview","title":"System overview","text":"<p>Find the diagram in the section System overview illustrating how the nodes in the cluster are structured.</p> <p>Before going on, you should make sure that you understand the following:</p> <ul> <li> <p>a front-end node used for logging in, managing files and submitting your jobs to the queue.</p> </li> <li> <p>several compute nodes which each contain several GPU devices.</p> </li> <li> <p>all nodes are connected to a network drive</p> </li> </ul>"},{"location":"ai-cloud/getting-started/look-around/#overview-of-compute-nodes","title":"Overview of compute nodes","text":"<p>GPU resources are in high demand, and it can be useful to get an overview of how busy the cluster is at the moment.</p> <p>Try running the following commands to see the traffic right now</p> <ul> <li> <p>The command <code>nodesummary</code> will print each node, together with a bar chart indicating how much memory, how many CPU's and many GPU's on the node are available.</p> </li> <li> <p>The command <code>squeue</code> will print all jobs in the queue.</p> </li> <li> <p>The command <code>sinfo</code> will print a list of the partitions and the nodes in the cluster.</p> </li> </ul>"},{"location":"ai-cloud/getting-started/look-around/#overview-of-directories","title":"Overview of directories","text":"<p>Become acquinted with the platform's directory structure. Head over to our section Additional Guides &gt; Directories overview</p>"},{"location":"ai-cloud/getting-started/look-around/#overview-of-the-linux-cli","title":"Overview of the Linux CLI","text":"<p>Head over to our section Additional Guides &gt; Understanding the Linux CLI to learn more. Try a few of the commands for your self.</p> <p></p> <p>Now that you've become acquainted with the platform, head over to ** transfer files **</p>"},{"location":"ai-cloud/getting-started/run-jobs/","title":"Run jobs","text":"<p>Jobs can be delegated to compute nodes, by submitting them to the queueing mechanism Slurm. There are two different commands for doing this, which can be useful in different situations.</p> <ul> <li><code>srun</code>: the output is printed directly to the console.</li> <li><code>sbatch</code>: the output is written to a file.</li> </ul>"},{"location":"ai-cloud/getting-started/run-jobs/#run-jobs-with-srun","title":"Run jobs with srun","text":"<p>First we will be exploring how we can launch attended jobs with the srun command</p>"},{"location":"ai-cloud/getting-started/run-jobs/#execute-a-command-on-a-compute-node","title":"Execute a command on a compute node","text":"<p>Assuming that we have logged in to the front end node, we can execute the following command to return the name of the node it ran on.</p> <pre><code>\u276f hostname\nai-fe02.srv.aau.dk\n</code></pre> <p>If we instead wanted to execute the same command on a compute node, we could use the <code>srun</code> command:</p> <pre><code>\u276f srun hostname\nsrun: job 767369 queued and waiting for resources\nsrun: job 767369 has been allocated resources\na256-t4-02.srv.aau.dk\n</code></pre> <p>We see here that the output is different from before, proving that we did indeed reach a compute node before executing the command.</p> <p>Don't compute on front-end</p> <p>It is important to note that the front-end node is not intended for heavy computations, as it is a virtual server with a very modest amount of resources. Crashing the node, will affect all users on the system.</p>"},{"location":"ai-cloud/getting-started/run-jobs/#execute-a-command-in-a-singularity-container","title":"Execute a command in a Singularity container","text":"<p>The preferred way to assemble different software environments on AI Cloud is with Singularity containers.</p> <p>Let's use on of the pre-built containers in the directory <code>/home/container</code>.</p> <pre><code>\u276f srun singularity exec /home/container/pytorch/pytorch_25.04.sif python3 -c \"print('hello world')\"\nsrun: job 767229 queued and waiting for resources\nsrun: job 767229 has been allocated resources\nhello world\n</code></pre> <p>Here you should especially note that the command has three components:</p> <ol> <li> <p>The Slurm component: in this case we are simply calling <code>srun</code> and thereby making a request for the default ressource configuration.</p> </li> <li> <p>The Singularity component: we call <code>singularity</code> and ask it to execute a <code>.sif</code> file</p> </li> <li> <p>The actual command, we want to execute.: <code>python3 -c \"print('hello worl')\"</code></p> </li> </ol>"},{"location":"ai-cloud/getting-started/run-jobs/#execute-a-command-on-a-gpu","title":"Execute a command on a GPU","text":"<p>If we want to execute a command on a GPU, we need to use software that is able to interact with the GPU. The preferred way to do this on AI Cloud, is to use Singularity containers.</p> <pre><code>\u276f srun --gres=gpu:1 singularity exec --nv /home/container/pytorch/pytorch_25.04.sif python3 -c \"import torch; print(torch.cuda.is_available())\"\nsrun: job 767221 queued and waiting for resources\nsrun: job 767221 has been allocated resources\nTrue\n</code></pre>"},{"location":"ai-cloud/getting-started/run-jobs/#run-jobs-with-sbatch","title":"Run jobs with sbatch","text":"<p>In most cases we do not want to print the output directly to the console, but to write it to a file. We can do this with an batch script, which we can launch with the <code>sbatch</code> command.</p> <p>Let's assume we have the following file:</p> is-available.py<pre><code>import torch\nprint(torch.cuda.is_available())\n</code></pre> <p>In order to launch this job, we can reference it in our batch script:</p> sbatch-test.sh<pre><code>#!/usr/bin/env bash\n\n#SBATCH --job-name=hostname\n#SBATCH --partition=prioritized\n#SBATCH --output=result_%j.out\n#SBATCH --error=error_%j.err\n#SBATCH --gres=gpu:1\n#SBATCH --time=00:01:00\n\n# The container image we want to launch:\ncontainer_image=\"/home/container/pytorch/pytorch_25.04.sif\"\n\n# The file we want to process on the compute node:\nfile=\"is-available.py\"\n\nsingularity exec --nv $container_image python3 $file\n</code></pre> <p>We can now launch the job with:</p> <pre><code>sbatch sbatch-test.sh\n</code></pre> <p>And the following message will confirm, that it was indeed submitted to the queue: <pre><code>Submitted batch job 737223\n</code></pre></p> <p>We can double check that our job was indeed submitted to the queue with:</p> <pre><code>squeue --me\n</code></pre> <p>Once the job is finished, we can use the <code>cat</code> command to print the content of the output file: <pre><code>cat slurm-737223.out\nTrue\n</code></pre></p> <p>Proving that we did indeed manage to launch the job on a GPU node.</p> <p>Bonus tip: Launch unattended jobs on-the-fly</p> <p>It's also possible to launch unattended jobs without a batch script. To do this, we can simply enter the <code>sbatch</code> command (optionally with a resource specification), and then wrapping the command we want to execute:</p> <pre><code>sbatch --gres=gpu:1 --wrap=\"singularity exec --nv /home/container/pytorch/pytorch_25.04.sif python3 -c 'import torch; print(torch.cuda.is_available())'\"\n</code></pre>"},{"location":"ai-cloud/getting-started/run-jobs/#which-one-to-use-srun-vs-sbatch","title":"Which one to use: srun vs sbatch","text":"<p>The most important difference between these two commands is that <code>srun</code> returns command output directly to the console - <code>sbatch</code> writes it to a file.</p> <p>Another important difference has to do with the robustness of your job. If it's launched with <code>srun</code>, it will be dependent on the console session the front end node, and will only run as long as the output can be printed directly to the console. If anything happens to the front-end node or the console session is interrupted, the job is terminated. A job launched with <code>sbatch</code> does not depend on an external process, and will run until it is explicitly cancelled by the user.</p>"},{"location":"ai-cloud/getting-started/run-jobs/#conclusion","title":"Conclusion:","text":"<ul> <li><code>srun</code> is best suited for when you are testing and you want the command output to be printed directly in the console.</li> <li><code>sbatch</code> is best suited for long-running unmaintained jobs.</li> <li>Our recomendation is clear - try to use <code>sbatch</code> as much as possible.</li> </ul> <p> Congratulations! </p> <p>You've mastered the fundamentals of AI Cloud!</p> <ul> <li>Make sure to find our pages in the \"Additional Guides\" (look in the menu on the left) to learn more about running jobs.</li> <li>Do also make sure to respect our rules and recomendations on Fair Usage.</li> <li>Don't forget that you are always welcome to reach out to us at serviceportal.aau.dk if you encounter any issues, or if you just need help getting started.</li> </ul>"},{"location":"ai-lab/","title":"AI-LAB","text":"Researchers Indicates if the platform is accessible for researchers (e.g., PhD students, postdocs, faculty) for research purposes. Students Indicates if the platform is accessible to students for educational purposes (e.g., coursework, projects, thesis). Lecturers Indicates if the platform is accessible to lecturers for teaching purposes. Sensitive Data Whether the platform supports processing and storing sensitive or confidential data CPU processing Indicates if the platform supports computational tasks that only require CPU resources. GPU processing Indicates if the platform supports computational tasks that require GPU resources for acceleration (e.g., deep learning). Unlimited compute Whether the platform allows unrestricted compute usage, without limitations on the amount of usage time. Terminal interface The method used to access the platform. Pre-installed apps Indicates if the platform comes with pre-installed applications or frameworks for convenience (e.g., Ansys, PyTorch, TensorFlow). Collaboration friendly Indicates if the platform supports collaborative work (e.g., sharing resources, co-editing, team projects). Working interactively Indicates if the platform supports interactive workflows where users can interact with running processes (e.g., Jupyter notebooks). Possible to add GUI Whether it is possible to run graphical user interfaces (GUIs) on the platform (e.g., remote desktops, JupyterLab). Not for storage This platform is not designed for long term storage of research data."},{"location":"ai-lab/#introduction","title":"Introduction","text":"<p>AI-LAB is designed exclusively for students at Aalborg University, offering high-performance computing (HPC) right at your fingertips. Think of it as a mini supercomputer, packed with GPUs, making it a perfect playground for training deep learning models, running simulations, and performing high-speed data analysis.</p>"},{"location":"ai-lab/#getting-started","title":"Getting Started","text":"<p>How to access</p> <p>Learn how to access AI-LAB</p> <p>Guides for AI-LAB</p> <p>Learn the basics on how to use AI-LAB</p> <p>Terms and Conditions</p> <p>Get an overview of the Terms and Conditions for AI-LAB</p>"},{"location":"ai-lab/#key-features","title":"Key FeaturesAccess powerful GPUsDeep Learning CapabilitiesEfficient Batch Processing","text":"<p>Access powerful GPUs for training deep learning models, simulations, and large-scale data analysis.</p> <p>Integrated frameworks like PyTorch and TensorFlow, enabling fast experimentation and neural network training.</p> <p>AI-LAB uses Slurm for seamless job scheduling, enabling easy batch processing and background task management.</p>"},{"location":"ai-lab/#common-use-cases","title":"Common Use Cases","text":"<p>Training ML models for projects</p> <p>GPU access for deep learning</p> <p>Course and educational purposes</p> <p>Pilot testing and exploration</p> <p>Fine-tuning large language models</p> <p>Molecular dynamics simulations</p> <p>Group and semester projects</p> <p>AI model development and testing</p> <p>AI-driven research and innovation</p>"},{"location":"ai-lab/#important-information","title":"Important Information","text":"<p>Not for confidential or sensitive data</p> <p>With AI-LAB you are only allowed to work with data classified as level 1 according to AAU\u2019s data classification model. If you would like to work with data classified as levels 2 and 3, then we support another HPC platform called UCloud.</p> <p>Not suitable for CPU-only computational tasks</p> <p>The powerful GPU processors allow users to process large datasets much more efficiently than would be the case with pure CPU processing - given that your application can be parallelised in a GPU compatible manner. At the same time, the AI-LAB platform is not designed for CPU-only computational tasks, and we have alternative recommended platforms, such as UCloud for those needs.</p>"},{"location":"ai-lab/fair-usage/","title":"Fair Usage","text":""},{"location":"ai-lab/fair-usage/#system-administration","title":"System administration","text":"<p>The CLAAUDIA team is responsible for system administration and support. We work closely with the infrastructure team in ITS on maintainance of the system.</p> <p>The overarching principle in our ressource administration is that we aim to strike a balance between high ressource utilisation, while still leaving the majority of users with the feeling that they can get their work done on the platform.</p>"},{"location":"ai-lab/fair-usage/#violations","title":"Violations","text":"<p>If we find indications of violations of these principles, CLAAUDIA will contact you to learn more about your situation.</p> <p>In exceptional cases, if we are unable to reach you, or if your jobs significantly disrupt the system (e.g., submitting an excessive number of jobs, monopolizing all cluster resources, or does not utilizing the cluster correctly), we may be forced to terminate the jobs to ensure fair usage for all users.</p>"},{"location":"ai-lab/fair-usage/#ressource-consumption","title":"Ressource consumption","text":"<p>The overall demand for GPU ressources fluctuates throughout the year, and we understand that demand is also dependent on the schedule of the individual student. We therefore prefer not to set a fixed limit on how many ressources an individual student can consume, as there may be times where they have a legitimate reason for high consumption. Instead we ask our users to be mindful of the overall supply, by making frequent asssesments of the queue.</p>"},{"location":"ai-lab/fair-usage/#gpu-resource-limits","title":"GPU Resource Limits","text":"<p>To ensure fair and efficient use of GPU resources for all users, we have introduced two global limits:</p> <p>1. Maximum 8 GPUs per user at any given time</p> <p>Several users have recently occupied a disproportionate share of the cluster. To guarantee equal access for everyone, each user can now run jobs using a total of up to 8 GPUs simultaneously. This ensures shorter queues and a better experience for the entire community.</p> <p>2. Maximum 4 GPUs per job</p> <p>A single job can now request no more than 4 GPUs, meaning a maximum of <code>--gres=gpu:4</code> or <code>-G 4</code>. We have introduced this limit because many users are not familiar with proper multi-GPU configuration, which often leads to inefficient GPU usage and longer queue times for others.</p> <p>We strongly encourage inexperienced users to allocate only 1 GPU, as most workloads do not speed up automatically with more GPUs. For advanced users who do know how to configure multi-GPU training correctly, up to 4 GPUs per job remain available.</p> <p>These measures help ensure that GPU capacity is shared fairly and used effectively.</p> <p>Responsible ressource consumption also involves taking care with multi-GPU allocations. We encourage our users to experiment with this, but they should take great care to test their applications in order to verify that they can indeed make use of the ressources allocated to their jobs.</p> <p>If possible, we recomend making good use of times with low consumption - ie. times outside of office hours; on weekends, during holidays, during the night, etc. The parameter <code>--begin</code> can be added to your Slurm command for this purpose.</p>"},{"location":"ai-lab/fair-usage/#not-allowed","title":"Not allowed","text":"<p>AI-LAB is designed for processing GPU-demanding batch jobs, that can be executed without the need for user interaction.</p>"},{"location":"ai-lab/fair-usage/#interactive-development-sessions","title":"Interactive development sessions","text":"<p>By interactive development we mean opening jobs, where you have a GPU available to you, but you only ocassinally run commands on the GPU. This results in a very ineffective utilisation of the GPU's, and decreases overall availability. Examples of interactive development session, could be connecting a Jupyter Notebook, Spyder, VS Code to a compute node.</p> <p>Interactive development is allowed on UCloud.</p>"},{"location":"ai-lab/fair-usage/#cpu-demanding-operations","title":"CPU demanding operations","text":"<p>If your application can not make use of the GPU's - or does not require one, AI-LAB is not the correct platform. Instead we recomend making use of one of our other computing platforms. Have a look around this website, or contact CLAAUDIA for guidance on more suitable alternatives.</p>"},{"location":"ai-lab/faq/","title":"Faq","text":"I can\u2019t log in to AI-Lab (e.g., \u2018SSH: could not resolve hostname ailab-fe01.srv.aau.dk\u2019). What should I do? How do I set up a shared project folder or group directory so that everyone in my group can read and edit files? I get \u2018No space left on device\u2019 or environment errors when building container images. How can I resolve these issues? What if I run out of storage space on my project folder (e.g., needing 2\u20133 TB)? How do I request more space or handle large datasets? Why am I seeing \u2018warning: could not lookup the current user\u2019s information\u2019 or \u2018unknown userid\u2019 errors when running jobs? Is it necessary to reapply for AI-Lab access each semester, and do I risk files being deleted? My jobs are stuck in a long queue because someone else is using multiple nodes. Is there a limit on how many nodes a user can occupy? How do I copy entire folders between my local machine and AI-Lab (e.g., using scp without zipping first)? How can I install new Python packages (or older Python versions) using virtual environments, conda environments, or custom containers? I need powerful GPUs or extra resources for my thesis or research\u2014how can I request stronger GPU access or additional compute power? I\u2019m trying to build or pull a container (e.g., from Docker or NVIDIA) on AI-Lab but keep running into version conflicts. What\u2019s the best approach? Can I connect to AI-Lab from outside AAU without VPN or an SSH gateway, for instance to link GitHub Actions or other CI/CD tools? I\u2019m getting \u2018address already in use\u2019 or \u2018cgroup out-of-memory\u2019 errors when running specialized tasks\u2014how do I fix them? Can you assist with data management plans or specify what data storage/sharing solutions we have (including backups)? Which GPUs and CUDA versions are actually available on AI-Lab and how do I confirm what\u2019s installed before training models?"},{"location":"ai-lab/how-to-access/","title":"How to access","text":""},{"location":"ai-lab/how-to-access/#who-can-get-access","title":"Who can get access?","text":"<p>Access\u00a0is available to all students and teachers at Aalborg University.\u00a0</p>"},{"location":"ai-lab/how-to-access/#1-fill-out-the-application-form","title":"1. Fill out the application form","text":"<p>Fill out this application form.</p>"},{"location":"ai-lab/how-to-access/#2-processing-of-your-request","title":"2. Processing of your request","text":"<p>You will recieve an email when your request is approved.\u00a0Expect a delay up to 30 minutes before you can log in to AI-LAB.</p>"},{"location":"ai-lab/how-to-access/#3-follow-our-guides","title":"3. Follow our guides","text":"<p>After getting access, please follow our guides </p>"},{"location":"ai-lab/service-windows/","title":"Service windows","text":"<p>Four times a year, all of our platforms are subject to service windows where changes and security upgrades are implemented. During these, we reserve an entire day for maintainance of the systems.</p> <p>It should be expected that the platforms are offline for the entire day from 00:01 until 23:59 - but they may come online by the end of the days, as the work is finished.</p>"},{"location":"ai-lab/service-windows/#schedule","title":"Schedule","text":"<p>A service window will take place on the following dates:</p> <p>AI Cloud, Strato, UCloud VM's &amp; UCloud Kubernetes</p> 2025 2026 2027 2028 11/02 10/02 09/02 08/02 13/05 12/05 11/05 09/05 16/09 15/09 14/09 12/09 02/12 01/12 30/11 28/11 <p>AI-LAB</p> 2025 2026 2027 2028 13/02 12/02 11/02 10/02 15/05 14/05 13/05 11/05 18/09 17/09 16/09 14/09 04/12 03/12 02/12 30/11 <p>TAAURUS</p> 2026 2027 2028 2029 03/02 - - - - - - - - - - - - - - - <p>Sign up for notifications on serviceinfo.dk</p> <p>Click this link to go to serviceinfo.dk. Then select Aalborg University, and under the tab Subscribe (or Abonn\u00e9r), select CLAAUDIA. Select email, SMS or calendar, according to your preferences:</p> <p> Go to ServiceInfo.dk</p>"},{"location":"ai-lab/service-windows/#platform-specific-information","title":"Platform specific information","text":""},{"location":"ai-lab/service-windows/#strato-and-ucloud-virtual-machines","title":"Strato and UCloud virtual machines","text":"<p>Be sure to save your work no later than the end of the day before the service window begins, as all virtual machines will be automatically shut down during the service window and any unsaved data will be lost.</p> <p>Usage Management Process </p> <p>1. Servers will NOT restart automatically after service windows     - All servers in the AAU availability zone will be shut down during service windows and will not restart automatically, unless they have been registered for automatic restart before the service window.      - You can easily restart your servers manually after the service window.</p> <p>2. Automatic server resizing after 48 hours of inactivity     - Servers that remain shut down for more than 48 hours will be automatically resized to the smallest CPU configuration.     - You will receive a notification when your instance has been resized.</p> <p>3. Automatic server deletion after 30 days of inactivity     - Servers that remain shut down for 30 days will be permanently deleted, but their volumes will be preserved.     - You will be notified in advance about any affected instances.</p> <p>4. Unused volume cleanup     - Volumes not attached to any server for 30 days will be deleted.     - A notification will be sent before deletion.</p> <p>All virtual machines should be removed when not in use.  Basic rule: keep your volumes, delete your unused VMs, and only run a VM with the size you really need right now. Please consult the page 'Delete and restart an instance from the volume' for instructions on how to do this.</p> <p>Apply for automatic restart of your Strato server</p> <p>Note: The deadline for requesting inclusion in the automatic restart list has now passed for the service window on the 2nd december.</p> <p>You could request automatic restarts for your server if all of the following conditions were met:</p> <ul> <li>The server is part of a Strato Project</li> <li>You can provide a valid motivation for needing automatic restart</li> <li>The server is in one of these availability zones:<ul> <li>AAU</li> <li>AAU-T4</li> <li>AAU-A10</li> <li>AAU-A40</li> </ul> </li> </ul> <p>Servers running in personal project spaces (such as default quota projects, e.g. <code>GK83DJ@aau.dk</code>) cannot be included. If you want to move your project, you can find instructions on how to apply for a Strato Project</p> <p>The application form for inclusion in the automatic restart list closed on November 25th: Strato service window: Automatic server restart inclusion form</p> <p>Link to Strato's web-interface: strato-new.claaudia.aau.dk</p>"},{"location":"ai-lab/service-windows/#ai-cloud","title":"AI Cloud","text":"<p>In the days leading up to the service window, a reservation will be put in place for the entire cluster. The entirety of the cluster will therefore be unavailable for that day, but may come back online by the end of the day.</p> <p>You can still submit jobs in the days leading up to the service window. Since the <code>batch</code> and <code>prioritized</code> partitions have time limits of 12 hours and 6 days respectively, you will only be able to launch new jobs if you add the <code>--time</code> parameter to your Slurm command. If you do not set this parameter, and there are 5 days until the day of the service window, your job will not start until after the service window. You will thus need to calculate how much time there is left, and then submit the job with this parameter added. </p> <p>To submit a job that runs for 1 day and 8 hours, you can simply add <code>--time=1-08:00:00</code> to your Slurm command. </p> <p>Additionally you can read about our recommendations for using checkpointing to work with time limits.</p>"},{"location":"ai-lab/service-windows/#ai-lab","title":"AI-LAB","text":"<p>In the days leading up to the service window, a time limit will be imposed, which will prevent you from launching jobs with end dates that surpass the date of the service window. </p> <p>In this period, you will only be able to launch new jobs, if you add the <code>--time</code> parameter to your Slurm command. If the time parameter is not included, Slurm assumes you ask for the default maximum time for the partition. You will thus have to calculate how much time you have before the service window, and then submit a job with this parameter added. </p> <p>To submit a job that runs for 12 hours, you should add: <code>--time=12:00:00</code>. Not setting the <code>--time</code> parameter will place your job in the queue, where it will wait until the service window has been completed.</p> <p>IMPORTANT: You can still run jobs in the days leading up to the service window</p> <p>If you have any questions, please open a case with us on serviceportal.aau.dk</p>"},{"location":"ai-lab/service-windows/#ucloud-aauk8s","title":"UCloud (AAU/K8s)","text":"<p>The UCloud (AAU/K8s) cluster will be unavailable for the entire duration of the service window and may become available again by the end of the day. While it may be technically possible to start jobs on the day of the service window, please note that any running jobs will be terminated as part of the scheduled maintenance activities performed by the administrators. We recommend planning your work accordingly to avoid interruptions.</p>"},{"location":"ai-lab/system-overview/","title":"System overview","text":"<p>AI-LAB is a high-performance computing (HPC) platform developed for students and educators at Aalborg University. It functions like a mini supercomputer, equipped with advanced hardware, including NVIDIA GPUs, designed to handle computationally intensive tasks. Whether you're training deep learning models, analyzing large datasets, processing images and videos, or running complex simulations, AI-LAB provides the necessary power and flexibility.</p> <p>The platform integrates user-friendly software, such as PyTorch, TensorFlow, and MATLAB, and utilizes tools like Slurm for job scheduling and Singularity for containerization, making it accessible even to those with limited technical expertise.</p>"},{"location":"ai-lab/system-overview/#hardware","title":"Hardware","text":"<p>The AI-LAB platform is built around several key components, including two front-end nodes for managing tasks and code, and 11 compute nodes equipped with diverse hardware options.</p> <p>In this overview, you will find a description of each major component of AI-LAB. Below, is a diagram illustrating the architecture of the AI-LAB platform.</p> <pre><code>flowchart LR\n  subgraph id1[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Compute nodes&lt;/p&gt;]\n  direction TB\n  A[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\"  width='25' height='25' &gt;ailab-l4-[01-11]&lt;/span&gt;\"]\n  end\n\n  subgraph id2[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 16px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 10px;\"&gt;AI-LAB&lt;/p&gt;]\n  direction TB\n  subgraph id3[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Front-end nodes&lt;/p&gt;]\n    direction TB\n    G[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;ailab-fe[01-02]&lt;/span&gt;\"]\n    end\n  id3 --&gt; id1 \n\n  subgraph id4[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;File storage&lt;/p&gt;]\n    direction TB\n    E[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Ceph&lt;/span&gt;\"]\n    end\n\n  id1 &amp; id3 &lt;--&gt; id4\n  end\n\n  F[&lt;span&gt;&lt;img src=\"/assets/img/person.svg\" width='25' height='25'&gt;User laptop&lt;/span&gt;]-- SSH --&gt; id3\n</code></pre>"},{"location":"ai-lab/system-overview/#front-end-nodes","title":"Front-end nodes","text":"<p>You start by logging into a front-end node, either <code>ailab-fe01</code> or <code>ailab-fe02</code>. These nodes act as the gateway to the HPC system. Here, you can manage files, write and edit code, and prepare your computational tasks. It is important to note that front-end nodes are not intended for heavy computations; they are optimized for task preparation and interaction with the HPC environment.</p>"},{"location":"ai-lab/system-overview/#compute-nodes","title":"Compute nodes","text":"<p>AI-LAB currently include the following compute nodes:</p> Node name CPU model Sockets Threads (Logical CPUs) Number of GPUs GPU Model RAM pr GPU (GB) ailab-l4-[01-11] AMD EPYC 7543 32-Core 2 128 8 NVIDIA L4 24"},{"location":"ai-lab/system-overview/#software","title":"Software","text":"<p>AI-LAB is based on Ubuntu Linux as its operating system. In practice, working on AI-LAB primarily takes place via a command-line interface.</p> <p>AI-LAB leverages two primary software components: Slurm and Singularity. Understanding these tools and how they work together is crucial for efficiently utilizing the AI-LAB platform.</p>"},{"location":"ai-lab/system-overview/#slurm","title":"Slurm","text":"<p>Slurm is a powerful and highly configurable workload manager used for scheduling and managing compute jobs on AI-LAB. It provides essential features such as:</p> <ul> <li>Job Scheduling: Allocating resources to jobs based on user requests and system policies.</li> <li>Resource Management: Tracking and managing compute resources, ensuring optimal utilization.</li> <li>Queue Management: Organizing jobs into queues, prioritizing and executing them based on policies and resource availability.</li> </ul> <p>On AI-LAB, Slurm is responsible for managing the allocation and scheduling of compute resources, ensuring that user jobs are executed efficiently and fairly.</p> <pre><code>flowchart LR\n  B[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Front-end node&lt;/span&gt;\"]\n\n  C[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 4&lt;/span&gt;\"]\n\n  subgraph slurm[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 16px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 10px;\"&gt;Slurm queue&lt;/p&gt;]\n    direction LR\n    D1[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 4&lt;/span&gt;\"]\n    D2[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 3&lt;/span&gt;\"]\n    D3[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 2&lt;/span&gt;\"]\n    D1 -.- D2 -.- D3\n    end\n\n  subgraph cluster[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Compute nodes&lt;/p&gt;]\n    direction LR\n\n    E1[\"&lt;span&gt;&lt;img src=\"/assets/img/code-file.svg\" width='25' height='25'&gt;Job id 1&lt;/span&gt;\"]\n    E2[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\"  width='25' height='25' &gt;ailab-l4-01&lt;/span&gt;\"]\n\n    E1 --&gt; E2\n    end\n\n  B --&gt; C --&gt; slurm --&gt; cluster\n\n  style D1 stroke-dasharray: 5 5\n</code></pre>"},{"location":"ai-lab/system-overview/#singularity","title":"Singularity","text":"<p>Singularity is a container platform designed for running applications on AI-LAB. Containers are lightweight, portable, and reproducible environments that bundle an application's code, libraries, and dependencies. Key features of Singularity include:</p> <ul> <li>Compatibility: Running containers with high-performance computing workloads without requiring root privileges.</li> <li>Portability: Enabling the same container to run on different systems without modification.</li> <li>Integration with HPC Systems: Designed to work seamlessly with HPC job schedulers like Slurm.</li> </ul> <p></p>"},{"location":"ai-lab/system-overview/#pre-downloaded-containers-on-ai-lab","title":"Pre-Downloaded Containers on AI-LAB","text":"<p>AI-LAB provides a variety of pre-downloaded containers to help users get started quickly. These containers are stored in the <code>/ceph/container</code> directory. The list of available containers is periodically updated, and users can propose new containers by contacting the support team. Currently available container images includes:</p> <ul> <li>PyTorch (CPU/GPU)</li> <li>TensorFlow (CPU/GPU)</li> <li>ImageMagick (CPU)</li> <li>MATLAB (CPU/GPU)</li> </ul>"},{"location":"ai-lab/system-overview/#interconnection-of-slurm-and-singularity","title":"Interconnection of Slurm and Singularity","text":"<p>On AI-LAB, Slurm and Singularity work together. Slurm handles the job scheduling and resource allocation, while Singularity ensures that the specified container environment is instantiated and the application runs with all its dependencies.</p> <pre><code>flowchart LR\n  A[&lt;span&gt;&lt;img src=\"/assets/img/person.svg\" width='25' height='25'&gt;User laptop&lt;/span&gt;]\n  B[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Front-end node&lt;/span&gt;\"]\n  C[\"&lt;span&gt;&lt;img src=\"/assets/img/container.svg\" width='25' height='25'&gt;Singularity container job&lt;/span&gt;\"]\n  D[\"&lt;span&gt;&lt;img src=\"/assets/img/queue.svg\" width='25' height='25'&gt;Slurm&lt;/span&gt;\"]\n  E[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Compute node&lt;/span&gt;\"]\n\n  A-- SSH --&gt; B --&gt; C --&gt; D --&gt; E-- Result --&gt; B\n\n  style C stroke-dasharray: 5 5\n  style D stroke-dasharray: 5 5\n</code></pre>"},{"location":"ai-lab/system-overview/#storage","title":"Storage","text":"<p>AI-LAB utilizes Ceph as its storage solution, providing a robust and scalable file system for your data needs. Your files are organized within the Ceph file system hierarchy, ensuring efficient access and management across the entire platform.</p>"},{"location":"ai-lab/system-overview/#user-directory","title":"User Directory","text":"<p>Your user directory serves as the primary location for storing personal files and data. It is structured within the Ceph file system as follows:</p> <ul> <li> /ceph AI-LAB's file system <ul> <li> home user home directories <ul> <li> [domain] e.g student.aau.dk <ul> <li> [user] your user directory</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Here, [domain] represents your domain or institution (e.g., student.aau.dk), and [user] denotes your unique username on the platform. Any files you store within your user directory are private.</p> <p>Storage quota</p> <p>When users log in to AI-LAB for the first time, a user directory is created for them. These directories are allocated 1 TB of storage by default. When you log in to the platform, you can see your storage usage of the user directory at the very top line:</p> <pre><code>Disk usage and quota for /ceph/home/student.aau.dk/user: 128GiB / 1.0TiB\nWelcome to Ubuntu 22.04.5 LTS (GNU/Linux 5.15.0-131-generic x86_64)\n\n* Documentation:  https://help.ubuntu.com\n* Management:     https://landscape.canonical.com\n* Support:        https://ubuntu.com/pro\n\nSystem information as of Wed Mar 26 07:57:43 CET 2025\n</code></pre>"},{"location":"ai-lab/system-overview/#shared-project-directories","title":"Shared Project Directories","text":"<p>AI-LAB fosters collaborative work through shared project directories. These directories enable multiple users to collaborate on projects by providing a centralized space for data sharing and collaboration. Shared project directories are organized under the project directory within the Ceph file system:</p> <ul> <li> /ceph AI-LAB's file system <ul> <li> project shared project directories <ul> <li> project_X             </li> </ul> </li> </ul> </li> </ul> <p>Read our guide on how to make shared project directories.</p>"},{"location":"ai-lab/system-overview/#course-materials","title":"Course Materials","text":"<p>To support educational activities, AI-LAB hosts course-specific materials within dedicated directories. These materials include lecture notes, assignments, datasets, and any resources relevant to the course curriculum. Course directories are structured under the course directory within the Ceph file system:</p> <ul> <li> /ceph AI-LAB's file system <ul> <li> course directory with course specific material <ul> <li> Course 1. Introduction to TensorFLow                 <ul> <li> Images</li> <li> tensorflow.sif</li> </ul> </li> <li> Course 2. ...             </li> </ul> </li> </ul> </li> </ul> <p>Students and instructors can access course materials effortlessly, enhancing the learning experience and facilitating hands-on exercises.</p>"},{"location":"ai-lab/system-overview/#ready-to-use-applications","title":"Ready-to-Use Applications","text":"<p>For convenience and efficiency, AI-LAB offers a collection of ready-to-use applications packaged as container images that can easily be copied to your user directoty. We aim to consistently update these images to the latest versions.</p> <ul> <li> /ceph         <ul> <li> container directory with ready-to-use applications <ul> <li> tensorflow/tensorflow.sif</li> <li> pytorch/pytorch.sif</li> <li> ...sif</li> </ul> </li> </ul> </li> </ul> <p>If you have specific container image requests, we welcome your input. Please reach out to us via the AAU service portal and include \"CLAAUDIA\" and \"AI-LAB\" in the subject line.</p>"},{"location":"ai-lab/troubleshooting/","title":"Troubleshooting","text":""},{"location":"ai-lab/troubleshooting/#why-do-i-get-error-generating-job-credential-or-unknown-userid-when-running-a-job","title":"Why do I get <code>Error generating job credential</code> or <code>unknown userid</code> when running a job?","text":"<p>Sometimes there are challenges with Active Directory (AD) at Aalborg University where AD fails to translate UIDs to people's usernames. Consequently, Slurm may encounter authentication issues, preventing you from running a job, and you may notice the job hanging when you run <code>sinfo</code>.</p> <p>Solution: Often, the problem resolves itself after some time (~20 minutes), and you will be able to run jobs again. You can also try running the <code>refresh-nodes</code> command to translate the username to UID, which usually gets cached and starts working after a while.</p>"},{"location":"ai-lab/troubleshooting/#why-do-i-get-r-error-when-running-my-python-script","title":"Why do I get <code>\\r</code> error when running my Python script?","text":"<p>If you encounter an error message like: <code>/usr/bin/env python3/r: bad interpreter: No such file or directory</code> while running a .py file, it might be because the file was edited on your local Windows computer before moving it to AI-LAB. Line endings often get converted when files are moved between Linux and Windows. This conversion is a frequent issue as Linux and Unix-like systems use <code>\\n</code> for line breaks, whereas Windows uses <code>\\r\\n</code> (CRLF, Carriage Return + Line Feed). </p> <p>Solution: In code editors such as VS Code or PyCharm, you can switch between LF (Linux endings) and CRLF (Windows endings) from the right-hand side of the status bar at the bottom of the window. Therefore, use LF endings if you wish to move a file to AI-LAB.</p>"},{"location":"ai-lab/troubleshooting/#why-cant-i-connect-to-ai-lab","title":"Why can't I connect to AI-LAB?","text":"<p>If you encounter an error like <code>ssh: Could not resolve hostname ailab-fe01.srv.aau.dk: No such host is known.</code>, you may need to connect through AAU's jump host (SSH gateway).</p> <p>Solution: Use the jump host option with the <code>-J</code> flag:</p> <pre><code>ssh -J user@student.aau.dk@sshgw.aau.dk -l user@student.aau.dk ailab-fe01.srv.aau.dk\n</code></pre> <p>Replace <code>user@student.aau.dk</code> with your actual AAU email address. You will need to enter your password twice and use Microsoft Authenticator in between.</p> <p>If you still encounter issues, try using PuTTY terminal software as an alternative.</p>"},{"location":"ai-lab/additional-guides/adding-python-packages-via-virtual-environment/","title":"Adding python packages via virtual environment","text":"<p>To enhance the functionality of a containerized environment, you can add additional Python packages using a virtual environment. This guide outlines the steps to create and utilize a virtual environment within your directory on AI-LAB.</p>"},{"location":"ai-lab/additional-guides/adding-python-packages-via-virtual-environment/#step-1-create-a-virtual-environment","title":"Step 1: Create a Virtual Environment","text":"<p>Begin by creating a virtual environment in your home directory. This allows you to install packages locally, making them accessible from within your container.</p> <pre><code>python3 -m venv my-virtual-env\n</code></pre>"},{"location":"ai-lab/additional-guides/adding-python-packages-via-virtual-environment/#step-2-activate-the-virtual-environment","title":"Step 2: Activate the Virtual Environment","text":"<p>Activate your virtual environment:</p> <pre><code>source my-virtual-env/bin/activate\n</code></pre> <p>Remember to always activate the virtual environment when you want to use it</p> <p>Remember that you must always activate the virtual environment (<code>source my-virtual-env/bin/activate</code>) to ensure that Python knows where to find the installed packages.</p>"},{"location":"ai-lab/additional-guides/adding-python-packages-via-virtual-environment/#step-3-install-python-packages","title":"Step 3: Install Python Packages","text":"<p>With the virtual environment activated, install the Python packages you need. For example, to install <code>numpy</code>, <code>pandas</code>, and <code>matplotlib</code>:</p> <pre><code>srun --mem=24G --cpus-per-task=15 bash -c \"export TMPDIR=/scratch; pip install numpy pandas matplotlib --no-cache-dir\"\n</code></pre> <p>This command will download and install the specified packages into your virtual environment.</p>"},{"location":"ai-lab/additional-guides/adding-python-packages-via-virtual-environment/#step-4-verify-the-installation","title":"Step 4: Verify the Installation","text":"<p>To confirm that the packages were installed correctly, you can check their versions or run a basic script. For instance, to check the installed version of <code>matplotlib</code>:</p> <pre><code>srun python3 -c \"import matplotlib; print(matplotlib.__version__)\"\n</code></pre>"},{"location":"ai-lab/additional-guides/adding-python-packages-via-virtual-environment/#step-5-use-the-virtual-environment-with-containers","title":"Step 5: Use the Virtual Environment with Containers","text":"<p>You can also use this method to expand containers, such as a PyTorch container.</p> <p>To do this, you will need to use the Singularity <code>--bind</code> option to bind your virtual environment directory to a location inside the container, and point Python to the path where it can find the installed packages.</p> <pre><code>srun singularity exec --bind ~/my-virtual-env:/my-virtual-env /ceph/container/pytorch/pytorch_24.09.sif /my-virtual-env/bin/python3 -c \"import matplotlib; print(matplotlib.__version__)\"\n</code></pre> <p>Here, <code>~/my-virtual-env:/my-virtual-env</code> binds your virtual environment to a new directory inside the container. <code>/my-virtual-env/bin/python3</code> tells Singularity to use the Python interpreter inside your virtual environment.</p>"},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/","title":"Building your own container image locally","text":"<p>This guide is currently in testing phase</p> <p>If you encounter any errors or issues, please provide us with your feedback through the AAU Service Portal. Your input is invaluable in helping us improve this resource. Thank you for your understanding!</p>"},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/#building-your-own-container-image-locally","title":"Building your own container image locally","text":""},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/#this-guide-will-show-you-how-to-use-an-application-called-podman-on-your-local-computer-to-build-containers-transfer-it-to-ai-lab-and-convert-it-into-a-singularity-image","title":"This guide will show you how to use an application called Podman on your local computer to build containers, transfer it to AI-LAB, and convert it into a Singularity image.","text":"<p>Why Use Podman to Build Containers Locally?</p> <p>Building Singularity containers directly on AI-LAB requires root privileges, which users don\u2019t have. To overcome this, we can use an application called Podman to build containers locally on your own machine. Podman is a container management tool similar to Docker, but it doesn't require root privileges to run. Once created, the container can be transferred to AI-LAB and converted into a Singularity image for use on AI-lAB.</p>"},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/#step-1-install-podman-on-your-local-machine","title":"Step 1: Install Podman on your local machine","text":"<p>Before starting, you'll need to install Podman on your local machine to build containers. Podman is available for Windows, macOS, and Linux, and the installation process varies slightly depending on your operating system.</p> WindowsmacOSLinux <ol> <li> <p>Begin by downloading the Podman Windows installer (.exe). Make sure to choose version 4.1 or later for compatibility with the features discussed in this guide.</p> </li> <li> <p>Run the installer and follow the prompts to complete the installation. A system restart may be required.</p> </li> <li> <p>Once installed, open PowerShell and initialize your first Podman machine with the following command:</p> <pre><code>podman machine init\n</code></pre> </li> </ol> <p>Automatic WSL Installation</p> <p>If Windows Subsystem for Linux (WSL) is not already installed, Podman will prompt you to install it automatically during the <code>podman machine init</code> process. Accepting this will install WSL and restart your system. After logging back in, the machine creation will continue. If you prefer, you can install WSL manually before running <code>podman machine init</code>.</p> <p>To start the Podman machine, run:</p> <pre><code>podman machine start\n</code></pre> <p>This starts a virtual machine where containers can be build.</p> <ol> <li> <p>You can either download the latest Podman installer from the Podman GitHub releases or use Homebrew (recommended for macOS users) to install Podman:</p> <pre><code>brew install podman\n</code></pre> </li> <li> <p>Once installed, initialize your first machine:</p> <pre><code>podman machine init\n</code></pre> </li> <li> <p>Start the machine:</p> <pre><code>podman machine start\n</code></pre> <p>This starts a virtual machine where containers can be build.</p> </li> </ol> <p>On most Linux distributions, Podman is available through the package manager. Follow the instructions for your specific distribution below.</p> <ol> <li> <p>Update your system: It's always good practice to update your system before installing new software.</p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade   # Debian-based distros (Ubuntu, etc.)\nsudo dnf update                       # Fedora-based distros\n</code></pre> </li> <li> <p>Install Podman:</p> <ul> <li> <p>Debian-based distributions (Ubuntu, Debian, etc.):</p> <pre><code>sudo apt install podman -y\n</code></pre> </li> <li> <p>Fedora-based distributions (Fedora, CentOS, RHEL): Podman may already be installed on Fedora. If not:</p> <pre><code>sudo dnf install podman -y\n</code></pre> </li> <li> <p>Arch Linux:</p> <pre><code>sudo pacman -S podman\n</code></pre> </li> <li> <p>Other distributions: Refer to the official Podman installation guide for installation instructions for other Linux distributions.</p> </li> </ul> </li> <li> <p>After installation, verify that Podman is installed correctly by checking the version:</p> <pre><code>podman --version\n</code></pre> <p>You should see the installed version of Podman. If successful, you are ready to proceed.</p> </li> </ol>"},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/#step-2-building-a-container-locally-with-podman","title":"Step 2: Building a Container Locally with Podman","text":"<p>To create a container, you first need to define what the container will look like and how it will behave. This is done using a special text file called a Dockerfile. A Dockerfile is essentially a set of instructions that tell Podman how to create the container, such as what software to include and what commands to run when the container starts.</p> <p>Creating the Dockerfile</p> <p>When creating a Dockerfile, it's important that the file has no extension (like <code>.txt</code> or <code>.doc</code>). The file should simply be named Dockerfile. This is because tools like Podman specifically look for a file named <code>Dockerfile</code> to understand how to build the container.</p> <p>Here\u2019s an example of a simple Dockerfile for a Python-based container:</p> Dockerfile<pre><code># Use an official Python image as the base\nFROM python:3.9-slim\n\n# Install necessary Python libraries\nRUN pip install --no-cache-dir numpy scipy\n\n# Set the command to run when the container starts\nCMD [\"python3\"]\n</code></pre> <p>What does this Dockerfile do?</p> <p><code>FROM python:3.9-slim</code>: This tells Podman to start from an existing container image, in this case, a lightweight version of Python 3.9. It provides a base to build your custom container.</p> <p><code>RUN pip install --no-cache-dir numpy scipy</code>: This command installs the Python libraries <code>numpy</code> and <code>scipy</code> inside the container.</p> <p><code>CMD [\"python3\"]</code>: This sets the default action when the container runs\u2014in this case, it starts the Python interpreter.</p> <p>Next, save the Dockerfile in an empty folder on your computer. It's important to create an empty folder to save the Dockerfile in because when you build a container with Podman, it includes all the files from the current directory in the container image by default.</p> <p>In the directory where your Dockerfile is located, run:</p> <pre><code>podman build -t my-python-app .\n</code></pre> <p>INFO: It may require a lot of space</p> <p>Building the container may take up a lot of space on your local computer. A simple PyTorch container can take up approx. 20GB of space.</p> <p>Replace <code>my-python-app</code> with the name you want for your container image.</p>"},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/#step-3-saving-and-exporting-the-container","title":"Step 3: Saving and Exporting the Container","text":"<p>Once your container is built, export it as a TAR file so that it can be transferred to the Slurm cluster:</p> <pre><code>podman save -o my-python-app.tar my-python-app\n</code></pre> <p>This will create a file named <code>my-python-app.tar</code>.</p>"},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/#step-4-transferring-the-container-to-ai-lab","title":"Step 4: Transferring the Container to AI-LAB","text":"<p>Use scp or a similar file transfer method (view examples here) to transfer the TAR file to AI-LAB:</p> <pre><code>scp my-python-app.tar user@student.aau.dk@ailab-fe01.srv.aau.dk:~/some-dir\n</code></pre> <p>Replace <code>user@student.aau.dk</code> with your AAU email address.</p> <p>Here, <code>~</code> represents your user directory on AI-LAB and <code>/some-dir</code> a folder in your directory.</p>"},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/#step-5-converting-the-container-to-singularity","title":"Step 5: Converting the Container to Singularity","text":"<p>Login to AI-LAB. Once on the server, we need to set the <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code> environment variables, to speed up repeated operations. We will use these variables to a temporary directory (<code>$HOME/.singularity/tmp/</code> and <code>$HOME/.singularity/cache/</code>) inside your home directory. <pre><code>export SINGULARITY_TMPDIR=\"$HOME/.singularity/tmp/\"\n</code></pre></p> <pre><code>export SINGULARITY_CACHEDIR=\"$HOME/.singularity/cache/\"\n</code></pre> <p>Then we need to create the directories defined by <code>SINGULARITY_CACHEDIR</code> and <code>SINGULARITY_TMPDIR</code>, if they don\u2019t already exist. The <code>-p</code> flag ensures that the command does not return an error if the directories are already in place.</p> <pre><code>mkdir -p $SINGULARITY_CACHEDIR $SINGULARITY_TMPDIR\n</code></pre> <p>Now, convert the Podman image into a Singularity image:</p> <pre><code>srun singularity build my-python-app.sif docker-archive://my-python-app.tar\n</code></pre> <p>This will convert the container into a Singularity Image File (.sif) that can be used in the cluster.</p>"},{"location":"ai-lab/additional-guides/building-your-own-container-image-locally/#step-6-test-running-the-singularity-container-optional","title":"Step 6: Test running the Singularity Container (optional)","text":"<p>Submit a job to Slurm using the newly converted Singularity image:</p> <pre><code>srun --gres=gpu:1 singularity exec my-python-app.sif python3 --version\n</code></pre>"},{"location":"ai-lab/additional-guides/building-your-own-container-image/","title":"Building your own container image","text":"<p>It is possible to define and build your own container images with Singularity. Lets try creating a simple Singularity container image with Python and pip installed. </p> <p>First we need to create a Singularity definition file (<code>.def</code>). This definition file is a blueprint for how Singularity should build the container image. It includes information about the base OS to build, which software to install and several other options.</p> <p>Lets create an empty text file by using the <code>nano</code> command:</p> <pre><code>nano\n</code></pre> <p>Now we can enter the blueprint needed to install our application:</p> <pre><code>Bootstrap: docker\nFrom: ubuntu:20.04\n\n%post\n    # This section is where you install additional packages or software\n    # Update package list and install the latest Python and pip version\n    apt-get update\n    apt-get install -y python3 python3-pip\n    pip install numpy pandas scikit-learn matplotlib\n\n%test\n    # Define tests to run after the container is built\n    python3 --version\n</code></pre> <p>In this example we will use <code>docker</code> to pull <code>ubuntu:20.04</code> as the base OS of our container image. </p> <p>In the next section,<code>%post</code>, we can define commands that will be executed after the base OS has been installed. In this example, we will update the container and install <code>python3</code> and <code>pip</code> along with <code>numpy pandas scikit-learn matplotlib</code> packages. </p> <p>After that we can define commands to run after the container is built in the <code>%test</code> section. Lets try with <code>python3 --version</code>.</p> <p>You can find more options to use in definition file in the Singularity definition file documentation.</p> <p>To save the file press <code>CTRL + O</code> and enter a filename ending with <code>.def</code> and hit <code>ENTER</code>. In this example, lets call it <code>python3.def</code>.</p>"},{"location":"ai-lab/additional-guides/building-your-own-container-image/#setting-singularity_tmpdir-and-singularity_cachedir","title":"Setting <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code>:","text":"<p>Before building the container image, we need to set the <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code> environment variables, to speed up repeated operations. We will use these variables to a temporary directory (<code>$HOME/.singularity/tmp/</code> and <code>$HOME/.singularity/cache/</code>) inside your home directory. Singularity will use this directory for storing temporary files and cached data during container operations.</p> <pre><code>export SINGULARITY_TMPDIR=\"$HOME/.singularity/tmp/\"\nexport SINGULARITY_CACHEDIR=\"$HOME/.singularity/cache/\"\n</code></pre> <p>Then we need to create the directories defined by <code>SINGULARITY_CACHEDIR</code> and <code>SINGULARITY_TMPDIR</code>, if they don\u2019t already exist. The -p flag ensures that the command does not return an error if the directories are already in place.</p> <pre><code>mkdir -p $SINGULARITY_CACHEDIR $SINGULARITY_TMPDIR\n</code></pre>"},{"location":"ai-lab/additional-guides/building-your-own-container-image/#building-the-container-image","title":"Building the container image","text":"<p>You can now build container images from the <code>python3.def</code> file:</p> <pre><code>srun singularity build --fakeroot python3.sif python3.def\n</code></pre> <p>After some time you should see the <code>Python X.X.X</code> version be printed in the terminal, and you should now have a <code>python3.sif</code> container image ready to run.</p> <p>Lets for example print the matplotlib version:</p> <pre><code>srun singularity exec python3.sif python3 -c \"import matplotlib; print('Matplotlib version:', matplotlib.__version__)\"\n</code></pre> <p>You can find more information about building containers from Singularity definition files here.</p>"},{"location":"ai-lab/additional-guides/cancelling-jobs/","title":"Cancelling jobs","text":"<p>There are several scenarios where you might need to cancel jobs, such as when a job is stuck, running longer than expected, or you realize that the job parameters were set incorrectly. Here\u2019s a guide on how to cancel jobs with Slurm.</p>"},{"location":"ai-lab/additional-guides/cancelling-jobs/#checking-job-status","title":"Checking Job Status","text":"<p>Before cancelling a job, it\u2019s often useful to check its current status or job ID. You can list your currently running or queued jobs using the squeue command:</p> <pre><code>squeue --me\n</code></pre>"},{"location":"ai-lab/additional-guides/cancelling-jobs/#cancelling-a-single-job","title":"Cancelling a Single Job","text":"<p>To cancel a specific job, use the <code>scancel</code> command followed by the job ID. For example, if your job ID is <code>12345</code>, you can cancel it by running:</p> <pre><code>scancel 12345\n</code></pre>"},{"location":"ai-lab/additional-guides/cancelling-jobs/#cancelling-multiple-jobs","title":"Cancelling Multiple Jobs","text":"<p>If you need to cancel all your jobs, you can cancel all jobs belonging to your user by using:</p> <pre><code>scancel --user=$USER\n</code></pre> <p>This command is particularly useful if you have submitted a batch of jobs and need to cancel them all simultaneously.</p>"},{"location":"ai-lab/additional-guides/checking-gpu-usage/","title":"Checking gpu usage","text":"<p>Monitoring GPU usage is a good practice for optimizing the performance of your jobs running, particularly if you intend to utilize multiple GPUs and verify their usage. This guide will provide step-by-step instructions on how to monitor GPU usage using a Python script.</p>"},{"location":"ai-lab/additional-guides/checking-gpu-usage/#start-a-job-with-gpu-allocation","title":"Start a job with GPU allocation","text":"<p>First, submit a job using <code>srun</code> or <code>sbatch</code> with one GPU or more allocated and execute some code inside a Singularity container. In this example we will use the <code>pytorch_24.09.sif</code> container image from <code>/ceph/container/pytorch</code> directory and a PyTorch benchmark script <code>torch_bm.py</code> from <code>/ceph/course/claaudia/docs</code> directory:</p> <pre><code>srun --gres=gpu:1 singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python3 torch_bm.py\n</code></pre>"},{"location":"ai-lab/additional-guides/checking-gpu-usage/#check-job-id","title":"Check job id","text":"<p>Open another AI-LAB terminal session, and check the status of your jobs using <code>squeue --me</code> to find the job ID of the job you just submitted.</p> <pre><code>squeue --me\n</code></pre>"},{"location":"ai-lab/additional-guides/checking-gpu-usage/#connect-to-running-job-interactively","title":"Connect to running job interactively","text":"<p>Once you have identified the job ID (let's assume it's <code>1978</code> in this example), connect to the running job interactively using the following command to start a new shell.</p> <pre><code>srun --jobid 1978 --interactive --pty /bin/bash\n</code></pre>"},{"location":"ai-lab/additional-guides/checking-gpu-usage/#monitor-gpu-usage","title":"Monitor GPU usage","text":"<p>Inside the interactive session of your job, start monitoring GPU usage using the following command:</p> <pre><code>python3 /ceph/course/claaudia/docs/gpu_util.py\n</code></pre> <pre><code>+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA L4                      Off |   00000000:01:00.0 Off |                    0 |\n| N/A   44C    P0             36W /   72W |     245MiB /  23034MiB |     90%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  NVIDIA L4                      Off |   00000000:02:00.0 Off |                    0 |\n| N/A   38C    P8             16W /   72W |       4MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   2  NVIDIA L4                      Off |   00000000:41:00.0 Off |                    0 |\n| N/A   41C    P8             16W /   72W |       1MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n...\n\n+------------------------------------------------------------------------------+\n|  GPU    PID     USER    GPU MEM  %CPU  %MEM      TIME  COMMAND               |\n|    0 232843   user@+     236MiB   100   0.1  01:00:20  /usr/bin/python3 tor  |\n+------------------------------------------------------------------------------+\n</code></pre> <p>The most important parameter to notice here is the <code>GPU-Util</code> metric. Here, you can see that the first GPU is operating at 90% GPU utilization. This indicates excellent utilization of the GPU.</p> <p>You can locate which GPU(s) that belongs to your job, by finding your username below <code>USER</code> and the GPU number under <code>GPU</code>. In this case <code>user@+</code> are utilizing GPU number <code>0</code> in the NVIDIA-SMI list.</p> <pre><code>+------------------------------------------------------------------------------+\n|  GPU    PID     USER    GPU MEM  %CPU  %MEM      TIME  COMMAND               |\n|    0 232843   user@+     236MiB   100   0.1  01:00:20  /usr/bin/python3 tor  |\n+------------------------------------------------------------------------------+\n</code></pre> <p>High Utilization (70-100%)</p> <p>For many GPU-accelerated applications like deep learning training or scientific simulations, a high GPU utilization (often around 70-100%) during compute-intensive tasks is considered good. It indicates that the GPU is efficiently processing tasks without significant idle time.</p> <p>Low to Moderate Utilization (10-40%)</p> <p>In some cases, especially when the workload is less intensive or the application is idle waiting for data or other resources, the GPU utilization might be lower (e.g., 10-40%). This doesn't necessarily mean the GPU is underutilized or performing poorly; it could indicate a natural variation in workload or efficient scheduling of tasks.</p>"},{"location":"ai-lab/additional-guides/checking-the-queue/","title":"Checking the queue","text":"<p>When using the cluster, you typically wish to see an overview of what is currently in the queue. For example to see how many jobs might be waiting ahead of you or to get an overview of your own jobs.</p> <p>The command <code>squeue</code> can be used to get a general overview:</p> <pre><code>squeue\n\nJOBID   PARTITION       NAME      USER    ST      TIME    NODES   NODELIST(REASON)\n42            gpu   interact  xxxxxxxx     R   6:45:14        1        ailab-l4-01\n</code></pre> <ol> <li><code>JOBID</code> shows the <code>ID</code> number of each job in queue.</li> <li><code>PARTITION</code> shows which partition each job is running in.</li> <li><code>NAME</code> is the name of the job which can be specified by the user creating it.</li> <li><code>USER</code> is the username of the user who created the job.</li> <li><code>ST</code> is the current state of each job; for example <code>R</code> means a job is running and <code>PD</code> means pending. There are other states as well - see <code>man squeue</code> for more details (under <code>JOB STATE CODES</code>).</li> <li><code>TIME</code> shows how long each job has been running.</li> <li><code>NODES</code> shows how many nodes are involved in each job allocation.</li> <li><code>NODELIST</code> shows which node(s) each job is running on, or alternatively, why it is not running yet.</li> </ol> <p>Showing your own jobs only:</p> <pre><code>squeue --me\n</code></pre> <p><code>squeue</code> can show many other details about jobs as well. Run <code>man squeue</code> to see detailed documentation on how to do this.</p>"},{"location":"ai-lab/additional-guides/checking-the-status-of-compute-nodes/","title":"Checking the status of compute nodes","text":"<p>It is often desirable to monitor the resource status of the compute nodes when you wish to run a job. </p> <p>The <code>sinfo</code> command shows basic information about partitions in the queue system and what the states of nodes in these partitions are.</p> <pre><code>sinfo\n\nPARTITION       AVAIL      TIMELIMIT      NODES      STATE             NODELIST\nl4*                up       12:00:00         11       idle     ailab-l4-[01-11]\nvmware             up          10:00          4       idle        vmware[01-04]\n</code></pre> <ol> <li><code>PARTITION</code> can be understood as distinct categories or groups of compute nodes, essentially serving as separate queues for jobs.</li> <li><code>AVAIL</code> shows the availability of the partition where <code>up</code> is normal, working state where you can submit jobs to it.</li> <li><code>TIMELIMIT</code> shows the time limit imposed by each partition in <code>HH:MM:SS</code> format.</li> <li><code>NODES</code> shows how many nodes are in the shown state in the specific partition.</li> <li><code>STATE</code> shows which state the listed nodes are in: <code>mix</code> means that the nodes are partially full - some jobs are running on them and they still have available resources; <code>idle</code> means that they are completely vacant and have all resources available; <code>allocated</code> means that they are completely occupied. Many other states are possible, most of which mean that something is wrong.</li> <li><code>NODELIST</code> shows the specific compute nodes that is affected by the job.</li> </ol> <p>You can also use the command <code>scontrol show node</code> or <code>scontrol show node &lt;node name&gt;</code> to show details about all nodes or a specific node, respectively.</p> <pre><code>scontrol show node ailab-l4-04\n\nNodeName=ailab-l4-04 Arch=x86_64 CoresPerSocket=32\nCPUAlloc=0 CPUTot=128 CPULoad=2.00\nAvailableFeatures=(null)\nActiveFeatures=(null)\nGres=gpu:l4:8(S:0-1)\n...\n</code></pre> <p>The two commands <code>sinfo</code> and <code>scontrol show node</code> provide information which is either too little or way too much detail in most situations. As an alternative, we provide the tool <code>nodesummary</code> to show a hopefully more intuitive overview of the used/available resources.</p> <pre><code>nodesummary\n</code></pre> <p></p>"},{"location":"ai-lab/additional-guides/cpu-gpu-and-memory-allocation/","title":"Cpu gpu and memory allocation","text":"<p>To effectively run jobs, it's important to understand the hardware configuration and set appropriate parameters for resource allocation. Here\u2019s a detailed guide on setting Slurm parameters based on the specified hardware on the platform:</p>"},{"location":"ai-lab/additional-guides/cpu-gpu-and-memory-allocation/#memory-per-job","title":"Memory per job","text":"<p><code>--mem</code> specifies the memory allocated to the job. Maximum value is 24 GB per GPU. Example:</p> <pre><code>srun --mem=24G singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python3 /ceph/course/claaudia/docs/torch_bm.py\n</code></pre>"},{"location":"ai-lab/additional-guides/cpu-gpu-and-memory-allocation/#cpus-per-task","title":"CPUs per task","text":"<p><code>--cpus-per-task</code> specifies the number of CPUs allocated to each task. Maximum value is 15 CPUs per GPU. Example:</p> <pre><code>srun --cpus-per-task=15 singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python3 /ceph/course/claaudia/docs/torch_bm.py\n</code></pre> <p>There is actually 16 CPUs per GPU available, but using a maximum of 15 CPUs per GPU, leaves 1 CPU free per GPU for system overhead and non-GPU tasks, which helps in maintaining overall system stability and performance.</p>"},{"location":"ai-lab/additional-guides/cpu-gpu-and-memory-allocation/#gpus-per-job","title":"GPUs per job","text":"<p><code>--gres=gpu</code> specifies the number of GPUs required for the jobs. Maximum value is 4 GPUs per job. Example:</p> <pre><code>srun --gres=gpu:4 singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python3 /ceph/course/claaudia/docs/torch_bm.py\n</code></pre> <p>GPU Resource Limits</p> <p>To ensure fair access for all users, AI-LAB enforces two important limits:</p> <ul> <li>Maximum 4 GPUs per job: A single job can request no more than 4 GPUs (e.g., <code>--gres=gpu:4</code> or <code>-G 4</code>)</li> <li>Maximum 8 GPUs per user: Each user can run jobs using a total of up to 8 GPUs simultaneously across all their running jobs</li> </ul> <p>We strongly encourage inexperienced users to allocate only 1 GPU, as most workloads do not speed up automatically with more GPUs. For advanced users who know how to configure multi-GPU training correctly, up to 4 GPUs per job remain available.</p> <p>Request only the number of GPUs your job can effectively utilize. Over-requesting can lead to resource underutilization and longer queue times. Some applications may need adjustments to scale effectively across multiple GPUs. Here is an example of a PyTorch script that can handle multiple GPUs. </p> <p>Monitor GPU usage</p> <p>You can use the NVIDIA GPU monitoring command <code>nvidia-smi</code> to output GPU usage information. Learn how to use it in this guide.</p>"},{"location":"ai-lab/additional-guides/cpu-gpu-and-memory-allocation/#number-of-tasks-to-be-run","title":"Number of tasks to be run","text":"<p><code>--ntasks</code> specifies the number of tasks to be run. Each task typically corresponds to an independent execution of your program or script. If your job can be parallelized across multiple tasks, set the number of tasks to e.g. <code>--ntasks=4</code> for running 4 parallel tasks. Each task gets its allocation of resources (CPU, memory, etc.) based on other parameters like <code>--cpus-per-task</code>, <code>--mem</code>, and <code>--gres=gpu</code>.</p>"},{"location":"ai-lab/additional-guides/creating-a-conda-environment/","title":"Creating a conda environment","text":"<p>This guide is deprecated!</p> <p>This guide is deprecated for the moment. For alternative guides, please have a look at our guides for Adding python packages via virtual environment or Building your own container image.</p> <p>Creating a conda environment in a container may be easily done using cotainr. </p> <p>About cotainr</p> <p>cotainr is a tool developed by DeiC to ease building of Singularity containers. It can be used to build custom containers with additional software installable by Conda and Pip. This means it is primarily for adding Python packages to a container. It works from a base container image that you specify and then build additional Anaconda and pip packages which you supply as a conda environment specification.</p> <p>Cotainr is included in the <code>/ceph/container</code> directory. To check the current version, enter <code>ls /ceph/container</code>. Currently, the version used in this guide is <code>cotainr-2023.11.0</code>.</p> <p>You can access cotainr by using the path <code>/ceph/container/cotainr-2023.11.0/bin/cotainr</code>. But first we will create a conda environment file, <code>conda_env.yml</code> that contains the conda channels/repositories and packages you need:</p> <p>Type <code>nano</code> and press <code>ENTER</code> (or use the editor of your choice), and enter the packages of your choice in the editor. In this example we will install <code>python=3.11.0</code> and <code>numpy=1.23.5</code>:</p> <pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.11.0\n  - numpy=1.23.5\n</code></pre> <p>Instaling pip packages</p> <p>Cotainr does not allow the direct creation of a container from a pip requirements.txt file. Nevertheless, pip packages can be integrated into a conda environment. For instance, by updating <code>conda_env.yml</code> to include them.</p> <pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.11.0\n  - numpy=1.23.5\n  - pip\n  - pip:\n    - scipy==1.9.3\n</code></pre> <p>Save by pressing <code>CTRL + O</code> enter a file name, e.g. <code>conda_env.yml</code> and exit by pressing <code>CTRL + X</code>. Now you should have <code>conda_env.yml</code> in your directory. </p> <p>We can now build a container (Lets call it <code>conda_container.sif</code>) containing the conda environment specified in <code>conda_env.yml</code> with the following command:</p> <pre><code>srun /ceph/container/cotainr-2023.11.0/bin/cotainr build conda_container.sif --base-image=docker://ubuntu:22.04 --conda-env=conda_env.yml --accept-licenses\n</code></pre> <p>Info</p> <p><code>--base-image=docker://ubuntu:22.04</code> is used because we have to use a base image in which bash is installed, like Ubuntu 22.04 image. </p> <p><code>--accept-licenses</code> is used to acknowledge the Miniforge license terms.</p> <p>After some time you should have <code>conda_container.sif</code> container image in your directory. </p> <p>You can access the conda image and run code using the dependencies you set up. Lets try to see if it works by printing the numpy version:</p> <pre><code>srun singularity exec conda_container.sif python3 -c \"import numpy; print(numpy.__version__)\"\n</code></pre> <p>The terminal should now print <code>1.23.5</code>.</p>"},{"location":"ai-lab/additional-guides/creating-shared-project-directories/","title":"Creating shared project directories","text":""},{"location":"ai-lab/additional-guides/creating-shared-project-directories/#in-ai-lab-semester-groups-can-collaborate-by-creating-shared-project-directories-in-cephproject-follow-this-guide-to-set-up-a-project-directory-and-ensure-that-only-group-members-can-access-it","title":"In AI-LAB, semester groups can collaborate by creating shared project directories in <code>/ceph/project</code>. Follow this guide to set up a project directory and ensure that only group members can access it.","text":"<p>Note: This guide only works between users in a semester group</p> <p>Unfortunately you cannot create a private shared directory for specific users that are not part of a semester group. Therefore, you can only create a public available project directory.</p> <p>Navigate to the <code>/ceph/project</code> directory:</p> <pre><code>cd /ceph/project\n</code></pre> <p>Create your project directory (replace [project_name] with the name of your project):</p> <pre><code>mkdir [project_name]\n</code></pre>"},{"location":"ai-lab/additional-guides/creating-shared-project-directories/#step-1-create-a-project-directory","title":"Step 1: Create a Project Directory","text":"<p>Navigate to the <code>/ceph/project</code> directory:</p> <pre><code>cd /ceph/project\n</code></pre> <p>Create your project directory (replace [project_name] with the name of your project):</p> <pre><code>mkdir [project_name]\n</code></pre>"},{"location":"ai-lab/additional-guides/creating-shared-project-directories/#step-2-set-directory-permissions","title":"Step 2: Set Directory Permissions","text":"<p>Next, set the directory permissions so that only users in your group can access and collaborate in the project directory.</p> <p>Check your group (you can confirm the group with this command):</p> <pre><code>groups\n</code></pre> <p>A semester group could be something like <code>xx-43-xx-9-01@student.aau.dk</code>.</p> <p>Assign the group ownership to your project directory (replace [your_group] with your group\u2019s name):</p> <pre><code>chgrp [your_group] [project_name]\n</code></pre> <p>Set the directory permissions to allow full access for the group:</p> <pre><code>chmod 770 [project_name]\n</code></pre> <p>What does <code>770</code> mean?</p> <p><code>770</code> means:</p> <ul> <li>rwx (read, write, execute) for the owner and the group.</li> <li>No permissions for others.</li> </ul>"},{"location":"ai-lab/additional-guides/creating-shared-project-directories/#step-3-ensure-new-files-inherit-group-permissions","title":"Step 3: Ensure New Files Inherit Group Permissions","text":"<p>To make collaboration easier, you can set the setgid (set group ID) bit on the directory. This ensures that all files and subdirectories created inside will inherit the same group.</p> <p>Set the setgid bit on your project directory:</p> <pre><code>chmod g+s [project_name]\n</code></pre> <p>This ensures that any new files or directories created inside the project will automatically belong to the group.</p>"},{"location":"ai-lab/additional-guides/creating-shared-project-directories/#step-4-verify-permissions","title":"Step 4: Verify Permissions","text":"<p>You can verify that the permissions are correctly set by listing the directory details:</p> <pre><code>ls -ld [project_name]\n</code></pre> <p>You should see something like:</p> <pre><code>drwxrws--- 2 [your_username] [your_group] 4096 Sep 17 12:34 [project_name]\n</code></pre> <p><code>s</code> under the group permissions indicates the setgid bit is enabled.</p> <p>The directory is now only accessible by the owner and the group members.</p>"},{"location":"ai-lab/additional-guides/creating-shared-project-directories/#step-5-collaboration","title":"Step 5: Collaboration","text":"<p>Now that the project directory is set up:</p> <ul> <li>Any group member can access, read, write, and create files within the directory.</li> <li>Users who are not in the group cannot access the directory.</li> </ul> <p>Notes:</p> <ul> <li>No other users outside the group will be able to access this directory.</li> <li>If you need to change the group or add more users, you\u2019ll need administrative assistance.</li> </ul>"},{"location":"ai-lab/additional-guides/download-container-images/","title":"Download container images","text":"<p>You can find and download pre-built container images for various applications from pages such as:</p> <ul> <li>https://catalog.ngc.nvidia.com/</li> <li>https://hub.docker.com/</li> </ul>"},{"location":"ai-lab/additional-guides/download-container-images/#nvidia-ngc-catalog","title":"NVIDIA NGC Catalog","text":"<p>On the NGC page, search or browse for the container image (e.g., TensorFlow), click on \"Get Container\" to get the container image URL (e.g., <code>nvcr.io/nvidia/tensorflow:24.11-tf2-py3-igpu</code>). </p> <p></p>"},{"location":"ai-lab/additional-guides/download-container-images/#docker-hub","title":"Docker Hub","text":"<p>On Docker Hub, search or browse for the container (e.g., TensorFlow), click on the \"Tags\" to get the container image URL (e.g., <code>tensorflow/tensorflow:nightly-jupyter</code>).</p> <p></p>"},{"location":"ai-lab/additional-guides/download-container-images/#setting-up-environment-variables-for-singularity","title":"Setting up Environment Variables for Singularity","text":"<p>Before downloading the container image, set the following environment variables to optimize performance:</p> <pre><code>export SINGULARITY_TMPDIR=\"$HOME/.singularity/tmp/\"\nexport SINGULARITY_CACHEDIR=\"$HOME/.singularity/cache/\"\n</code></pre> <p>Create the required directories if they don\u2019t already exist:</p> <pre><code>mkdir -p $SINGULARITY_CACHEDIR $SINGULARITY_TMPDIR\n</code></pre>"},{"location":"ai-lab/additional-guides/download-container-images/#downloading-the-container-image","title":"Downloading the Container Image","text":"<p>Use the <code>srun</code> command to run Singularity via the Slurm queueing system and download the container image. Replace the example URL below with the link you copied from one of the above pages. You will also need to add <code>docker://</code> before the URL:</p> <pre><code>srun --mem 40G singularity pull docker://nvcr.io/nvidia/tensorflow:24.03-tf2-py3\n</code></pre> <p>The download may take up to 20 minutes.</p>"},{"location":"ai-lab/additional-guides/download-container-images/#command-breakdown","title":"Command Breakdown","text":"<ul> <li><code>srun</code>: Executes the command on a compute node via Slurm.</li> <li><code>--mem 40G</code>: Allocates 40GB of memory (adjust if necessary).</li> <li><code>singularity pull</code>: Downloads and converts the container image to a Singularity-compatible format.</li> <li><code>docker://..</code>.: Specifies the Docker image URL (copied from one of the suggested pages).</li> </ul> <p>After the download completes, you\u2019ll find the container image file (e.g., <code>tensorflow_24.03-tf2-py3.sif</code>) in your current directory.</p>"},{"location":"ai-lab/additional-guides/multiple-gpus-with-pytorch/","title":"Multiple gpus with pytorch","text":"<p>Distributed training across multiple GPUs is essential for accelerating deep learning tasks involving large datasets and complex models. PyTorch provides robust support for distributed computing through its <code>torch.distributed</code> package, facilitating efficient utilization of GPU resources using <code>torch.nn.parallel.DistributedDataParallel</code> (DDP). This guide presents a detailed explanation of how to implement and execute distributed training across multiple GPUs using PyTorch.</p>"},{"location":"ai-lab/additional-guides/multiple-gpus-with-pytorch/#script-overview","title":"Script Overview","text":"<p>The provided Python script demonstrates how to perform distributed training across multiple GPUs using DDP in PyTorch. Let's break down each part of the script to understand its functionality and how it facilitates multi-GPU training.</p>"},{"location":"ai-lab/additional-guides/multiple-gpus-with-pytorch/#part-1-imports-and-library-setup","title":"Part 1: Imports and Library Setup","text":"<p>Begin by importing necessary libraries and modules for GPU-accelerated deep learning tasks with PyTorch. The key module for distributed computing is <code>torch.distributed</code>.</p> <pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transforms as transforms\nimport time\nimport argparse\n</code></pre>"},{"location":"ai-lab/additional-guides/multiple-gpus-with-pytorch/#part-2-distributed-setup","title":"Part 2: Distributed Setup","text":"<p>Next, we create a function called <code>setup</code> that initializes the distributed environment necessary for multi-GPU training:</p> <pre><code>def setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n    torch.cuda.set_device(rank)\n</code></pre> <ul> <li><code>MASTER_ADDR</code> and <code>MASTER_PORT</code> are set to establish communication between different processes. This is crucial for coordinating distributed training across multiple GPUs.</li> <li><code>dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)</code> initializes the process group using the NCCL backend, which is optimized for efficient communication on NVIDIA GPUs.<ul> <li><code>rank</code> value is assigned to each proces to distinguish between processes.</li> <li><code>world_size</code> refers to the total number of processes that participate in the distributed training setup.</li> </ul> </li> <li><code>torch.cuda.set_device(rank)</code> ensures each process is assigned a specific GPU device based on its rank, enabling efficient GPU resource management.</li> </ul>"},{"location":"ai-lab/additional-guides/multiple-gpus-with-pytorch/#part-3-cleanup-function","title":"Part 3: Cleanup Function","text":"<p>We then define a <code>cleanup()</code> function that ensures clean release of distributed training resources after completion, preventing resource leaks.</p> <pre><code>def cleanup():\n    dist.destroy_process_group()\n</code></pre>"},{"location":"ai-lab/additional-guides/multiple-gpus-with-pytorch/#part-4-training-function","title":"Part 4: Training Function","text":"<p>Finally, we define a <code>train(rank, world_size)</code> function that orchestrates distributed training across multiple GPUs:</p> <pre><code>def train(rank, world_size):\n    # Setup: Initializes the distributed environment using setup(rank, world_size).\n    setup(rank, world_size)\n\n    # Data Loading: Prepares CIFAR-10 dataset with transformations for training.\n    print(f'Rank {rank}: Preparing data..')\n    transform = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n    # Distributed Sampler: Ensures data is divided among GPUs using DistributedSampler.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=world_size, rank=rank)\n\n    # Data Loader: Creates a DataLoader that iterates through batches of data with distributed sampling and batching.\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True, sampler=train_sampler)\n\n    # Model Initialization: Initializes ResNet-50 model (net) and distributes it across GPUs using DistributedDataParallel.\n    print(f'Rank {rank}: Building model..')\n    net = torchvision.models.resnet50().to(rank)\n    net = nn.parallel.DistributedDataParallel(net, device_ids=[rank])\n\n    # Loss and Optimizer: Defines cross-entropy loss (criterion) and SGD optimizer (optimizer).\n    criterion = nn.CrossEntropyLoss().to(rank)\n    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n\n    # Training Loop: Iterates through epochs and batches, performs forward and backward passes, and updates model parameters.\n    def train_epoch(epoch):\n        net.train()\n        train_sampler.set_epoch(epoch)\n        train_loss = 0\n        correct = 0\n        total = 0\n        start_time = time.time()\n        for batch_idx, (inputs, targets) in enumerate(trainloader):\n            inputs, targets = inputs.to(rank), targets.to(rank)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            if batch_idx % 10 == 0:\n                print(f'Rank {rank}, Batch: {batch_idx}, Loss: {train_loss/(batch_idx+1)}, Accuracy: {100.*correct/total}%')\n\n        end_time = time.time()\n        print(f'Rank {rank}: Training time for epoch {epoch}: {end_time - start_time} seconds')\n\n    # Training Execution: Runs training for 1 epoch.\n    for epoch in range(1):\n        train_epoch(epoch)\n\n    # Cleanup: Releases distributed training resources after completion.\n    cleanup()\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='PyTorch Distributed Training Example')\n    # args.world_size is passed as an argument, specifying the number of processes (world_size) for distributed training from the command line.\n    parser.add_argument('--world_size', type=int, default=1, help='Number of processes for distributed training')\n    args = parser.parse_args()\n    # spawn is a utility that facilitates launching multiple processes in a distributed manner.\n    mp.spawn(train, args=(args.world_size,), nprocs=args.world_size, join=True)\n</code></pre>"},{"location":"ai-lab/additional-guides/multiple-gpus-with-pytorch/#full-script","title":"Full script","text":"<pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torchvision\nimport torchvision.transforms as transforms\nimport time\nimport argparse\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n    torch.cuda.set_device(rank)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef train(rank, world_size):\n    # Setup: Initializes the distributed environment using setup(rank, world_size).\n    setup(rank, world_size)\n\n    # Data Loading: Prepares CIFAR-10 dataset with transformations for training.\n    print(f'Rank {rank}: Preparing data..')\n    transform = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n    # Distributed Sampler: Ensures data is divided among GPUs using DistributedSampler.\n    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=world_size, rank=rank)\n\n    # Data Loader: Creates a DataLoader that iterates through batches of data with distributed sampling and batching.\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False, num_workers=8, pin_memory=True, sampler=train_sampler)\n\n    # Model Initialization: Initializes ResNet-50 model (net) and distributes it across GPUs using DistributedDataParallel.\n    print(f'Rank {rank}: Building model..')\n    net = torchvision.models.resnet50().to(rank)\n    net = nn.parallel.DistributedDataParallel(net, device_ids=[rank])\n\n    # Loss and Optimizer: Defines cross-entropy loss (criterion) and SGD optimizer (optimizer).\n    criterion = nn.CrossEntropyLoss().to(rank)\n    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n\n    # Training Loop: Iterates through epochs and batches, performs forward and backward passes, and updates model parameters.\n    def train_epoch(epoch):\n        net.train()\n        train_sampler.set_epoch(epoch)\n        train_loss = 0\n        correct = 0\n        total = 0\n        start_time = time.time()\n        for batch_idx, (inputs, targets) in enumerate(trainloader):\n            inputs, targets = inputs.to(rank), targets.to(rank)\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            if batch_idx % 10 == 0:\n                print(f'Rank {rank}, Batch: {batch_idx}, Loss: {train_loss/(batch_idx+1)}, Accuracy: {100.*correct/total}%')\n\n        end_time = time.time()\n        print(f'Rank {rank}: Training time for epoch {epoch}: {end_time - start_time} seconds')\n\n    # Training Execution: Runs training for 1 epoch.\n    for epoch in range(1):\n        train_epoch(epoch)\n\n    # Cleanup: Releases distributed training resources after completion.\n    cleanup()\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='PyTorch Distributed Training Example')\n    # args.world_size is passed as an argument, specifying the number of processes (world_size) for distributed training from the command line.\n    parser.add_argument('--world_size', type=int, default=1, help='Number of processes for distributed training')\n    args = parser.parse_args()\n    # spawn is a utility that facilitates launching multiple processes in a distributed manner.\n    mp.spawn(train, args=(args.world_size,), nprocs=args.world_size, join=True)\n</code></pre>"},{"location":"ai-lab/additional-guides/multiple-gpus-with-pytorch/#running-the-script","title":"Running the Script","text":"<p>To execute the multi-GPU training script we will use a Bash script (submit_job.sh):</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=ddp_training\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=60G\n#SBATCH --time=02:00:00\n#SBATCH --output=ddp_training.out\n\n# Number of GPUs to allocate (adjust this value as needed, maximum 4 GPUs per job)\nnum_gpus=4\n\n# Set the number of tasks and GPUs accordingly\n#SBATCH --ntasks=$num_gpus\n#SBATCH --gres=gpu:$num_gpus\n\n# Execute the job using Singularity\nsrun singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python3 multi_gpu.py --world_size=$num_gpus\n</code></pre> <ul> <li><code>--job-name</code>: Specifies the name of the job.</li> <li><code>-partition</code>: Defines the partition or queue to submit the job to (l4 in this example).</li> <li><code>--cpus-per-task</code>: Specifies the number of CPUs allocated to each task.</li> <li><code>--mem</code>: Specifies the memory allocated to the job.</li> <li><code>--time</code>: Adjust these settings based on your specific resource requirements.</li> <li><code>num_gpus</code>: Modify this variable to specify the number of GPUs (--ntasks and --gres=gpu) allocated for your job. Note: Maximum 4 GPUs per job, and maximum 8 GPUs per user across all running jobs.</li> <li><code>srun singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python3 multi_gpu.py --world_size=$num_gpus</code>: Executes the job inside the specified Singularity container (<code>pytorch_24.09.sif</code>) with Python 3, running the <code>multi_gpu.py</code> script and passing <code>--world_size=$num_gpus</code> as an argument to specify the number of GPUs for distributed training.</li> </ul> <p>GPU Resource Limits</p> <p>To ensure fair access for all users, AI-LAB enforces two important limits:</p> <ul> <li>Maximum 4 GPUs per job: A single job can request no more than 4 GPUs (e.g., <code>--gres=gpu:4</code> or <code>-G 4</code>)</li> <li>Maximum 8 GPUs per user: Each user can run jobs using a total of up to 8 GPUs simultaneously across all their running jobs</li> </ul> <p>We strongly encourage inexperienced users to allocate only 1 GPU, as most workloads do not speed up automatically with more GPUs. For advanced users who know how to configure multi-GPU training correctly, up to 4 GPUs per job remain available.</p>"},{"location":"ai-lab/additional-guides/requeuing-and-checkpointing/","title":"Requeuing and checkpointing","text":"<p>On AI-LAB, jobs have a default time limit of 1 hour and a maximum runtime of 12 hours. Once this time limit is reached, your job will be canceled, and any unsaved data will be lost. To prevent data loss, it's important to implement checkpointing, which saves data at regular intervals. Additionally, you can set up automatic requeuing so that your job will restart automatically if it gets canceled, removing the need to manually resubmit it.</p> <p>This guide explains how to set up checkpointing in various frameworks like Python, PyTorch, and TensorFlow, as well as how to configure automatic requeuing for your jobs.</p> <p>Disclaimer</p> <p>Using checkpointing and requeuing is done at your own risk. This guide is intended as a reference, but saving data via checkpointing is entirely the responsibility of the user. There may be errors or inaccuracies within this guide. If you encounter any issues or discover mistakes, we encourage you to provide feedback so we can improve. You can submit your feedback here.</p>"},{"location":"ai-lab/additional-guides/requeuing-and-checkpointing/#checkpointing-methods","title":"Checkpointing methods","text":"<p>Checkpointing allows you to periodically save the state of your job so that it can be resumed later, even after an interruption. Different frameworks have different methods for implementing checkpointing. Below are examples for Python, PyTorch, and TensorFlow. </p> Python checkpointing <p>In Python, you can use the pickle module to periodically save and load the state of your job.</p> <p><pre><code>import pickle\nimport os\n\ndef save_checkpoint(data, filename):\n    \"\"\"Save the checkpoint data to a file.\"\"\"\n    with open(filename, 'wb') as f:\n        pickle.dump(data, f)\n\ndef load_checkpoint(filename):\n    \"\"\"Load the checkpoint data from a file.\"\"\"\n    with open(filename, 'rb') as f:\n        return pickle.load(f)\n\n# Check if there is a checkpoint file\nif os.path.exists('checkpoint.pkl'):\n    # If there is, load the checkpoint\n    data = load_checkpoint('checkpoint.pkl')\n    print(\"Resuming from checkpoint:\")\nelse:\n    # If there isn't, initialize data\n    data = {'counter': 0}\n\ntry:\n    # Simulate some long-running process\n    while True:\n        data['counter'] += 1\n        print(\"Current counter value:\", data['counter'])\n        # Save checkpoint every 5 iterations\n        if data['counter'] % 5 == 0:\n            save_checkpoint(data, 'checkpoint.pkl')\n        # Simulate some work\n        # Replace this with your actual process\n        import time\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    # Save checkpoint if the process is interrupted\n    save_checkpoint(data, 'checkpoint.pkl')\n    print(\"\\nCheckpoint saved. Exiting...\")\n</code></pre> </p> PyTorch checkpointing <p>PyTorch provides native support for saving and loading model and optimizer states during training. More information about PyTorch checkpointing can be found here. Here's an example that shows how to checkpoint during training of a simple neural network:</p> <pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\n# Define a simple feedforward neural network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(784, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Load MNIST dataset\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('data', train=True, download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.1307,), (0.3081,))\n                ])),\n    batch_size=64, shuffle=True)\n\n# Define the model\nmodel = SimpleNN()\n\n# Define the optimizer and loss function\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# Checkpoint directory\ncheckpoint_dir = 'checkpoints'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n##epoch number of steps\nepoch_steps = 20\n\n# Check if there are existing checkpoints\nif os.listdir(checkpoint_dir):\n    # If there are existing checkpoints, load the latest one\n    latest_checkpoint = max([int(file.split('.')[0]) for file in os.listdir(checkpoint_dir)])\n    checkpoint = torch.load(os.path.join(checkpoint_dir, f'{latest_checkpoint}.pt'))\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    start_epoch = latest_checkpoint + 1\nelse:\n    start_epoch = 0\n\n# Training loop\nfor epoch in range(start_epoch, epoch_steps):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        data = data.view(data.size(0), -1)\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch}: Loss {loss.item()}')\n\n    # Save checkpoint every epoch\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss\n        }, os.path.join(checkpoint_dir, f'{epoch}.pt'))\n</code></pre> <p></p> TensorFlow checkpointing <p>TensorFlow offers built-in functionality for saving model weights during training using the <code>ModelCheckpoint</code> callback. More information about TensorFlow checkpointing can be found here. Here's an example:</p> <pre><code>    import os\n    import sys\n    import os.path\n    import tensorflow as tf\n    from tensorflow import keras\n\n    #####Get an example dataset - we'll use the MNIST dataset first 1000 examples:\n    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n\n    train_labels = train_labels[:5000]\n    test_labels = test_labels[:5000]\n\n    train_images = train_images[:5000].reshape(-1, 28 * 28) / 255.0\n    test_images = test_images[:5000].reshape(-1, 28 * 28) / 255.0\n\n    ##epoch number of steps for each job:\n    epoch_steps=20\n\n    ####Define a simple sequential model:\n    def create_model():\n        model = tf.keras.models.Sequential([\n            keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(10)\n        ])\n\n        model.compile(optimizer='adam',\n                        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n                        metrics=[tf.metrics.SparseCategoricalAccuracy()])\n\n        return model\n\n\n    # Create a new model instance\n    model = create_model()\n\n    # Include the epoch in the file name (uses `str.format`)\n    checkpoint_path = \"checkpoints/{epoch:d}.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    # Create a callback that saves the model's weights every epoch (period=1)\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, \n        verbose=1, \n        save_weights_only=True,\n        period=1)\n\n    # Check if there are existing checkpoints\n    if os.path.exists(checkpoint_dir):\n        # If there are existing checkpoints, load the latest one\n        latest = tf.train.latest_checkpoint(checkpoint_dir)\n        # Load the previously saved weights, if there are any:\n        model.load_weights(latest)\n\n        # Re-evaluate the model\n        loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n        print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n\n        # Get the step number from the latest checkpoint\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir) \n        step = int(os.path.basename(ckpt.model_checkpoint_path).split('.')[0])\n        print('Continuing calculation from epoch step:' + str(step)) \n        # Set the initial epoch to the last recovered epoch\n        initialEpoch=step\n    else:\n        initialEpoch=0\n        # Save the weights for the initial epoch\n        model.save_weights(checkpoint_path.format(epoch=0))\n\n    # Train the model with the new callback\n    model.fit(train_images, \n            train_labels,\n            epochs=epoch_steps, \n            initial_epoch=initialEpoch,\n            callbacks=[cp_callback],\n            validation_data=(test_images,test_labels),\n            verbose=1)\n</code></pre> <p></p>"},{"location":"ai-lab/additional-guides/requeuing-and-checkpointing/#breakdown-of-the-key-components","title":"Breakdown of the key components:","text":"<p>First, the script checks if a checkpoint file named <code>checkpoint.pkl</code> exists using <code>os.path.exists()</code>. If the file exists, it loads the checkpoint data using <code>load_checkpoint</code> function and assigns it to data. If not, it initializes data with a dictionary containing a single key <code>counter</code> initialized to 0. </p> <p>Then, it enters an infinite loop (simulating a long-running process), where it increments the <code>counter</code> key of the data dictionary, prints the current counter value, and simulates some work (in this case, a 1-second delay using <code>time.sleep(1)</code>).</p> <p>Every 5 iterations (<code>if data['counter'] % 5 == 0)</code>, it saves the checkpoint by calling <code>save_checkpoint</code>. If the process is interrupted by a keyboard interrupt (Ctrl+C), it saves the current checkpoint and prints a message before exiting.</p>"},{"location":"ai-lab/additional-guides/requeuing-and-checkpointing/#breakdown-of-the-key-components_1","title":"Breakdown of the key components:","text":"<p>Checkpoint Directory Setup (line 39-41): Creating a directory for storing checkpoints.</p> <p>Checking for Existing Checkpoints (line 46-55): Checking for existing checkpoints and loading the latest one if available.</p> <p>Saving Checkpoints (line 69-75): Saving the model's state, optimizer's state, and current loss at the end of each epoch to a uniquely named file based on the epoch number.</p>"},{"location":"ai-lab/additional-guides/requeuing-and-checkpointing/#breakdown-of-the-key-components_2","title":"Breakdown of the key components:","text":"<p><code>checkpoint_path</code>: Specify the path where checkpoints will be saved. You can include dynamic elements such as epoch number in the file name to differentiate between checkpoints, like <code>checkpoints/{epoch:d}.ckpt</code></p> <p><code>cp_callback</code>: Create a ModelCheckpoint callback, which will save the model's weights at specified intervals during training. You can customize various parameters such as the file path, verbosity, and whether to save only the weights or the entire model.</p> <p><code>model.load_weights(latest)</code>: Before starting training, check if there are existing checkpoints. If so, load the latest one to resume training from the last saved state. This ensures continuity in training even if interrupted.</p>"},{"location":"ai-lab/additional-guides/requeuing-and-checkpointing/#requeing-jobs","title":"Requeing jobs","text":"<p>After implementing checkpointing in your script, you have the option to set up automatic job requeuing in case your job gets cancelled. This is done by modifying a bash script that will automatically requeue the job if it's terminated due to exceeding the time limit. You can find an example script, <code>requeue.sh</code>, on AI-LAB at <code>/ceph/course/claaudia/docs/requeue.sh</code>.</p> requeue.sh <pre><code>#!/bin/bash\n\n#SBATCH --job-name=requeue_example\n#SBATCH --time=00:01:00\n#SBATCH --signal=B:SIGTERM@30\n#SBATCH --gres=gpu:1\n#SBATCH --cpus-per-task=15\n#SBATCH --mem=24G\n\n#####################################################################################\n\n# tweak this to fit your needs\nmax_restarts=4\n\n# Fetch the current restarts value from the job context\nscontext=$(scontrol show job ${SLURM_JOB_ID})\nrestarts=$(echo ${scontext} | grep -o 'Restarts=[0-9]*' | cut -d= -f2)\n\n# If no restarts found, it's the first run, so set restarts to 0\niteration=${restarts:-0}\n\n# Dynamically set output and error filenames using job ID and iteration\noutfile=\"${SLURM_JOB_ID}_${iteration}.out\"\nerrfile=\"${SLURM_JOB_ID}_${iteration}.err\"\n\n# Print the filenames for debugging\necho \"Output file: ${outfile}\"\necho \"Error file: ${errfile}\"\n\n##  Define a term-handler function to be executed           ##\n##  when the job gets the SIGTERM (before timeout)          ##\n\nterm_handler()\n{\n    echo \"Executing term handler at $(date)\"\n    if [[ $restarts -lt $max_restarts ]]; then\n        # Requeue the job, allowing it to restart with incremented iteration\n        scontrol requeue ${SLURM_JOB_ID}\n        exit 0\n    else\n        echo \"Maximum restarts reached, exiting.\"\n        exit 1\n    fi\n}\n\n# Trap SIGTERM to execute the term_handler when the job gets terminated\ntrap 'term_handler' SIGTERM\n\n#######################################################################################\n\n# Use srun to dynamically specify the output and error files\nsrun --output=\"${outfile}\" --error=\"${errfile}\" singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python torch_bm.py\n</code></pre> <p>In this script, we will run a PyTorch script (located at <code>/ceph/course/claaudia/docs/torch_bm.py</code>) using the PyTorch container <code>/ceph/container/pytorch/pytorch_24.09.sif</code>. You can modify this to run any script or container you need. Key parameters to pay attention to are:</p> <ul> <li><code>#SBATCH --time=00:01:00</code>: This sets the time limit for your job. If your job exceeds this limit, it will be cancelled. If not specified, the default time limit is 1 hour (maximum 12 hours).</li> <li><code>#SBATCH --signal=B:SIGTERM@30</code>: This tells Slurm to send a SIGTERM signal 30 seconds before the job reaches the time limit, giving the job time to handle termination gracefully.</li> <li><code>max_restarts=4</code>: This defines the maximum number of times your job will be automatically requeued if it gets cancelled. In this example, the job will be requeued up to four times before it is finally terminated.</li> </ul>"},{"location":"ai-lab/additional-guides/run-a-bash-script/","title":"Run a bash script","text":"<p>In this guide, we will demonstrate how to submit a job to Slurm using a bash script. </p> <p>What is a bash script?</p> <p>A bash script is essentially a text file with a series of commands that you would normally type in the terminal. When executed, the script runs these commands in sequence. Bash scripts are used to automate repetitive tasks, manage system operations, and perform complex workflows.</p> <p>Let's create a bash script to submit a simple job that runs a Singularity container. This job will run a Python script inside the container.</p>"},{"location":"ai-lab/additional-guides/run-a-bash-script/#step-1-prepare-the-singularity-container","title":"Step 1: Prepare the Singularity Container","text":"<p>Ensure you have a Singularity image (.sif file) ready. For this example, let's use the <code>pytorch_24.09.sif</code> container image from <code>/ceph/container/pytorch</code>.</p>"},{"location":"ai-lab/additional-guides/run-a-bash-script/#step-2-create-the-python-script","title":"Step 2: Create the Python Script","text":"<p>Create a simple Python script named hello.py:</p> <pre><code>print(\"Hello from within the Singularity container!\")\n</code></pre>"},{"location":"ai-lab/additional-guides/run-a-bash-script/#step-3-create-the-bash-script","title":"Step 3: Create the Bash Script","text":"<p>Create a bash script named run_job.sh:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=singularity_test\n#SBATCH --output=result_%j.out\n#SBATCH --error=error_%j.err\n#SBATCH --time=00:10:00\n#SBATCH --ntasks=1\n#SBATCH --gres=gpu:1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem=1G\n\nsingularity exec /ceph/container/pytorch/pytorch_24.09.sif python3 hello.py\n</code></pre> <p>Explanation of SBATCH Options:</p> <ul> <li><code>--job-name</code>: Name of the job (Optional).</li> <li><code>--output</code>: File where standard output will be written, with %j replaced by the job ID (Required).</li> <li><code>--error</code>: File where standard error will be written, with %j replaced by the job ID (Optional).</li> <li><code>--time</code>: Maximum run time (hh:mm) (Optional).</li> <li><code>--ntasks</code>: Number of tasks (Optional).</li> <li><code>--gres=gpu:1</code>: Number of allocated GPUs (Optional).</li> <li><code>--cpus-per-task</code>: Number of CPUs per task (Optional).</li> <li><code>--mem</code>: Memory per node (Optional).</li> </ul>"},{"location":"ai-lab/additional-guides/run-a-bash-script/#step-4-submit-the-job","title":"Step 4: Submit the Job","text":"<p>To submit the job, use the sbatch command:</p> <pre><code>sbatch run_job.sh\n</code></pre> <p>After the job gets submitted, you should be able to find a file called something like <code>result_x.out</code> with <code>Hello from within the Singularity container!</code> in it.</p>"},{"location":"ai-lab/additional-guides/running-a-container-in-interactive-mode/","title":"Running a container in interactive mode","text":"<p>You can launch a shell within a Singularity container, allowing you to interact with the container's environment. Use the <code>shell</code> command with the desired image as follows</p> <pre><code>srun --gres=gpu:1 --pty singularity shell --nv /ceph/container/pytorch/pytorch_24.09.sif\n</code></pre> <p>The <code>--pty</code> creates a virtual interactive terminal for a command to run within.</p> <p>You now have shell access</p> <pre><code>Singularity&gt;\n</code></pre> <p>Lets try checking the Python version:</p> <pre><code>python3 --version\n</code></pre> <p>You can exit the interactive session with:</p> <pre><code>exit\n</code></pre>"},{"location":"ai-lab/additional-guides/setting-a-time-limit/","title":"Setting a time limit","text":"<p>Sometimes, jobs may get stuck or encounter unforeseen issues, causing them to run indefinitely. Setting a time limit ensures that such jobs are automatically terminated after a certain duration, preventing them from consuming resources unnecessarily.</p> <p>You can add a <code>--time</code> parameter to your Slurm command, e.g. <code>--time=08:00:00</code> to run a job for maximum 8 hours:</p> <p><pre><code>srun --time=08:00:00 hostname\n</code></pre> </p> Default and Maximum Job Time Limits <p> Every job submitted to AI-LAB has a default time limit of 1 hour if no time is specified. This default has been set to encourage efficient resource usage and prevent jobs from running unnecessarily long. The 1-hour default helps ensure fair access to resources for all users and reduces the likelihood of jobs getting stuck or consuming resources without active monitoring. However, you can request up to 12 hours maximum for longer computations by explicitly specifying the time limit. </p> Jobs can run no longer than 12 hours <p> The maximum time limit for any job on AI-LAB is 12 hours. This limit is set to prevent a single user from monopolizing the entire cluster indefinitely. We are trying to ensure that all users receive an equal share of available resources. </p>"},{"location":"ai-lab/additional-guides/old/download-container-images/","title":"Download container images","text":"<p>You can download a large range of container images by visiting NVIDIA GPU Cloud (NGC) and check whether NVIDIA provides a container image with the application you need.</p> <p></p> <p>As an example, this could be TensorFlow. You can search on NGC and find TensorFlow. Here you can choose the desired version from the \"Copy image path\" dropdown menu:</p> <p></p> <p>This copies a link to the container image which we will use in the following example.</p>"},{"location":"ai-lab/additional-guides/old/download-container-images/#setting-singularity_tmpdir-and-singularity_cachedir","title":"Setting <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code>:","text":"<p>Before downloading the container image, we need to set the <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code> environment variables, to speed up repeated operations. We will use these variables to a temporary directory (<code>$HOME/.singularity/tmp/</code> and <code>$HOME/.singularity/cache/</code>) inside your home directory. Singularity will use this directory for storing temporary files and cached data during container operations.</p> <pre><code>export SINGULARITY_TMPDIR=\"$HOME/.singularity/tmp/\"\nexport SINGULARITY_CACHEDIR=\"$HOME/.singularity/cache/\"\n</code></pre> <p>Then we need to create the directories defined by <code>SINGULARITY_CACHEDIR</code> and <code>SINGULARITY_TMPDIR</code>, if they don\u2019t already exist. The -p flag ensures that the command does not return an error if the directories are already in place.</p> <pre><code>mkdir -p $SINGULARITY_CACHEDIR $SINGULARITY_TMPDIR\n</code></pre>"},{"location":"ai-lab/additional-guides/old/download-container-images/#downloading-the-container-image","title":"Downloading the container image","text":"<p>We need to use Singularity to download the container image and in order to run Singularity, we must run it through the Slurm queueing system using the command <code>srun</code>. </p> <p>To download the container image to your directory paste the url to the container image like so:</p> <p><code>srun --mem 40G singularity pull docker://nvcr.io/nvidia/tensorflow:24.03-tf2-py3</code></p> <p>NOTE: The container image could take ~20 minutes to download. </p> <p>The above example consists of the following parts:</p> <ul> <li><code>srun</code>: the Slurm command which gets the following command executed on a compute node.</li> <li><code>mem</code>: a Slurm command that allows you allocate memory to your process, in this case 40GB of memory. A higher amount of memory than the default is needed specifically for this TensorFlow container image.</li> <li><code>singularity pull</code>: the Singularity command which downloads a specified container image.</li> <li><code>docker://nvcr.io/nvidia/tensorflow:24.03-tf2-py3</code>: this part of the command itself consists of two parts. <code>docker://</code> tells Singularity that we are downloading a Docker container image and Singularity automatically converts this to a Singularity container image upon download. <code>nvcr.io/nvidia/tensorflow:24.03-tf2-py3</code> is the container image label copied from the NGC webpage which identifies the particular container image and version that we want.</li> </ul> <p>Once the <code>singularity pull</code> command has completed, you should have a file called <code>tensorflow_24.03-tf2-py3.sif</code> in your user directory (use the command <code>ls</code> to see the files in your current directory).</p>"},{"location":"ai-lab/applications/imagemagick/","title":"Imagemagick","text":"<p>On AI-LAB, we have a ready-to-use ImageMagick container image. This means that you can quickly access ImageMagick's functionality within the AI-LAB environment without needing to install or configure the software yourself. By utilizing the container image, you can efficiently work with images in your projects, transforming them as needed to suit your applications or experiments.</p> <p>First, lets get the path to the ImageMagick container image from the AI-LAB container directory:</p> <pre><code>ls /ceph/container\n</code></pre> <p>To verify that everything is functioning as expected, let's use the \"mogrify\" tool to rotate some images. Begin by copying the following directory containing 100 cat images to your user directory:</p> <pre><code>scp /course/ailab-docs-files/cats ~\n</code></pre> <p>Next, create a folder to store the rotated images:</p> <pre><code>mkdir rotated_images\n</code></pre> <p>Finally, perform the image rotation by 90 degrees using the mogrify tool:</p> <pre><code>srun singularity exec /ceph/container/imagemagick_6.9.10-23.sif` mogrify -path rotated_images -rotate 90 cats/*.png\n</code></pre> <p>Note! The container image might be newer version at this time.</p>"},{"location":"ai-lab/applications/linux-text-editors/","title":"Linux text editors","text":""},{"location":"ai-lab/applications/linux-text-editors/#on-ai-lab-you-may-need-to-edit-files-frequently-whether-its-modifying-scripts-configuration-files-or-logs-two-popular-command-line-text-editors-are-nano-and-vim-this-guide-provides-an-introduction-to-both-editors-covering-essential-commands-and-workflows","title":"On AI-LAB, you may need to edit files frequently, whether it's modifying scripts, configuration files, or logs. Two popular command-line text editors are nano and vim. This guide provides an introduction to both editors, covering essential commands and workflows.","text":""},{"location":"ai-lab/applications/linux-text-editors/#nano-a-simple-text-editor","title":"Nano: A Simple Text Editor","text":"<p>Nano is a beginner-friendly text editor. It is easy to use, making it a good choice for new users.</p>"},{"location":"ai-lab/applications/linux-text-editors/#opening-a-file-with-nano","title":"Opening a File with Nano","text":"<p>To open or create a file, use:</p> <pre><code>nano &lt;filename&gt;\n</code></pre> <p>For example, to open <code>myfile.txt</code>:</p> <pre><code>nano myfile.txt\n</code></pre>"},{"location":"ai-lab/applications/linux-text-editors/#basic-commands-in-nano","title":"Basic Commands in Nano","text":"<p>Once inside Nano, use the following commands:</p> <ul> <li>Move the cursor: Use the arrow keys.</li> <li>Save the file: Press <code>Ctrl + O</code> (Write Out), then hit <code>Enter</code>.</li> <li>Exit Nano: Press <code>Ctrl + X</code>.</li> <li>Cut and Paste:<ul> <li>To cut: <code>Ctrl + K</code> cuts the current line.</li> <li>To paste: <code>Ctrl + U</code> pastes the cut text.</li> </ul> </li> <li>Search within the file: Press <code>Ctrl + W</code>, type the search term, and hit <code>Enter</code>.</li> </ul> <p>Tips for Nano</p> <ul> <li>The commands at the bottom of the Nano screen start with the <code>^</code> symbol, which stands for the <code>Ctrl</code> key.</li> <li>For more advanced editing, Nano has flags like syntax highlighting and can open files as read-only using the <code>-v</code> flag: <pre><code>nano -v myfile.txt\n</code></pre></li> </ul>"},{"location":"ai-lab/applications/linux-text-editors/#vim-a-powerful-text-editor","title":"Vim: A Powerful Text Editor","text":"<p>Vim is a more advanced editor with modes and extensive features. Though it has a steeper learning curve, it's incredibly powerful for experienced users.</p>"},{"location":"ai-lab/applications/linux-text-editors/#opening-a-file-with-vim","title":"Opening a File with Vim","text":"<p>To open or create a file in Vim, use:</p> <pre><code>vim &lt;filename&gt;\n</code></pre> <p>For example, to open <code>script.sh</code>:</p> <pre><code>vim script.sh\n</code></pre>"},{"location":"ai-lab/applications/linux-text-editors/#understanding-vim-modes","title":"Understanding Vim Modes","text":"<p>Vim has different modes, each designed for specific tasks:</p> <ul> <li>Normal Mode: Used for navigating and executing commands.</li> <li>Insert Mode: For typing and editing text.</li> <li>Visual Mode: For selecting and manipulating blocks of text.</li> <li>You start in Normal Mode by default. Press <code>i</code> to enter Insert Mode for text editing.</li> </ul>"},{"location":"ai-lab/applications/linux-text-editors/#basic-commands-in-vim","title":"Basic Commands in Vim","text":"Action Command Enter Insert Mode <code>i</code> Save the file <code>:w</code> Exit Vim <code>:q</code> Save and Exit <code>:wq</code> or <code>ZZ</code> Undo last change <code>u</code> Delete a line <code>dd</code> Copy a line <code>yy</code> Paste a line <code>p</code> Search <code>/</code> followed by search term and <code>Enter</code>"},{"location":"ai-lab/applications/linux-text-editors/#navigating-in-vim","title":"Navigating in Vim","text":"<ul> <li>Move the cursor: Use arrow keys or <code>h</code> (left), <code>j</code> (down), <code>k</code> (up), <code>l</code> (right).</li> <li>Jump to start/end of file: <code>gg</code> (start), <code>G</code> (end).</li> <li>Go to a specific line: <code>:&lt;line number&gt;</code>, then <code>Enter</code>.</li> </ul>"},{"location":"ai-lab/applications/linux-text-editors/#exiting-vim","title":"Exiting Vim","text":"<p>If you're stuck in Vim and want to exit:</p> <ul> <li>Force quit without saving: <code>:q!</code></li> <li>Save and quit: <code>:wq</code> or <code>ZZ</code>.</li> </ul> <p>Tips for Vim</p> <ul> <li>Vim has a built-in help system, accessed by typing <code>:help</code>.</li> <li>You can enable syntax highlighting with the command <code>:syntax</code> on.</li> </ul>"},{"location":"ai-lab/applications/linux-text-editors/#summary","title":"Summary","text":"Editor Easy-to-use Advanced Features Quick to Learn Nano Yes No Yes Vim No Yes No <p>Both editors are available on AI-LAB, so you can choose the one that fits your workflow and experience level. Nano is great for quick edits, while Vim offers advanced capabilities for power users.</p>"},{"location":"ai-lab/applications/pytorch/","title":"Pytorch","text":"<p>On AI-LAB, we have a ready-to-use PyTorch container image. This means that you can quickly access PyTorch's functionality within the AI-LAB environment without needing to install or configure the software yourself.</p> <p>First, lets get the path to the PyTorch container image from the AI-LAB container directory:</p> <pre><code>ls /ceph/container\n</code></pre> <p>You can run PyTorch scripts using Singularity to execute within the container. Below is an example of running a PyTorch script with 1 GPU allocated:</p> <pre><code>srun --gres=gpu:1 singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python3 your_script.py\n</code></pre> <p>Note! The container image might be newer version at this time.</p>"},{"location":"ai-lab/applications/pytorch/#checkpointing","title":"Checkpointing","text":"<p>Checkpointing is a technique used to ensure that your computational jobs can be resumed from a previously saved state in case of interruptions or failures. Checkpointing in PyTorch can be used to save the state of your model at various points, enabling you to resume training from a specific epoch in case of interruptions or to fine-tune models from previously saved states. This guide demonstrates checkpoint implementation in PyTorch.</p>"},{"location":"ai-lab/applications/tensorflow/","title":"Tensorflow","text":"<p>On AI-LAB, we have a ready-to-use TensorFlow container image. This allows you to quickly leverage TensorFlow's functionality within the AI-LAB environment without needing to install or configure the software yourself.</p> <p>First, lets get the path to the TensorFlow container image from the AI-LAB container directory:</p> <pre><code>ls /ceph/container\n</code></pre> <p>You can run TensorFlow scripts using Singularity to execute within the container. Below is an example of running a TensorFlow script with 1 GPU allocated:</p> <pre><code>srun --gres=gpu:1 singularity exec --nv /ceph/container/tensorflow/tensorflow_24.09.sif python3 your_script.py\n</code></pre> <p>Note! The container image might be newer version at this time.</p>"},{"location":"ai-lab/applications/tensorflow/#checkpointing","title":"Checkpointing","text":"<p>Checkpointing is a technique used to ensure that your computational jobs can be resumed from a previously saved state in case of interruptions or failures. TensorFlow provides native support for checkpointing during model training, allowing you to save the model's weights at specific intervals. This guide demonstrates how to use the <code>ModelCheckpoint</code> callback to checkpoint with TensorFlow. </p>"},{"location":"ai-lab/courses/ai-lab-workshop/","title":"Ai lab workshop","text":"<pre><code>                        \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557      \u2588\u2588\u2557      \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557                                                      \n                        \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2551      \u2588\u2588\u2551     \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557                                                     \n                        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d                                                     \n                        \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551     \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557                                                     \n                        \u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2551      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d                                                     \n                        \u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d      \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u255d                                                      \n\u2588\u2588\u2557    \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557  \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557  \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557      \u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2557  \u2588\u2588\u2557\n\u2588\u2588\u2551    \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2551 \u2588\u2588\u2554\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557    \u2588\u2588\u2554\u2588\u2588\u2557\u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2551  \u2588\u2588\u2551\n\u2588\u2588\u2551 \u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d    \u255a\u2550\u255d\u255a\u2550\u255d \u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\n\u2588\u2588\u2551\u2588\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2588\u2588\u2557 \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d           \u2588\u2588\u2554\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\n\u255a\u2588\u2588\u2588\u2554\u2588\u2588\u2588\u2554\u255d\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2551  \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551  \u2588\u2588\u2551\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551               \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557     \u2588\u2588\u2551\n \u255a\u2550\u2550\u255d\u255a\u2550\u2550\u255d  \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d               \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d     \u255a\u2550\u255d\n\n###############    High-Performance Computing for AAU students and teachers   ###############\n\n                                    by Frederik Petri\n                                        CLAAUDIA\n\n#############################################################################################\n</code></pre>"},{"location":"ai-lab/courses/ai-lab-workshop/#did-you-apply-for-access","title":"Did you apply for access?","text":"<p>If not, please go to https://forms.office.com/e/caEhCRmqVN and fill out the form :)</p>"},{"location":"ai-lab/courses/ai-lab-workshop/#what-is-ai-lab","title":"What is AI-LAB?","text":"<p>A GPU cluster available to students and teachers</p>"},{"location":"ai-lab/courses/ai-lab-workshop/#hardware","title":"Hardware","text":"<ul> <li>2 login nodes</li> <li>11 compute nodes each with 8 NVIDIA L4 GPUs</li> <li>Ceph file system</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#software","title":"Software","text":"<ul> <li>Linux</li> <li>Containerization for applications</li> <li>Slurm queue system</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#what-can-you-use-ai-lab-for","title":"What can you use AI-LAB for?","text":"<ul> <li>Access GPU resources for deep learning</li> <li>Enhance applied machine learning courses</li> <li>Collaborate on AI experiments and learning</li> <li>Semester project training and support</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#why-use-ai-lab","title":"Why use AI-LAB?","text":"<ul> <li>Easy to access</li> <li>Unlimited GPU resources</li> <li>Store course-specific materials </li> <li>Getting-started guides https://hpc.aau.dk/ai-lab/getting-started/</li> <li>CLAAUDIA support https://serviceportal.aau.dk/</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#other-hpc-options","title":"Other HPC options?","text":""},{"location":"ai-lab/courses/ai-lab-workshop/#ucloud","title":"UCloud","text":"<ul> <li>Access through webbrowser</li> <li>Great for interactive work</li> <li>Large software selection</li> <li>Can handle sensitive data</li> <li>Read more: https://hpc.aau.dk/ucloud/</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#other-hpc-options_1","title":"Other HPC options?","text":""},{"location":"ai-lab/courses/ai-lab-workshop/#ai-cloud","title":"AI Cloud","text":"<ul> <li>Large GPU cluster (AI-LABs big brother)</li> <li>Very limited access to students</li> <li>Need a strong justification</li> <li>Read more: https://hpc.aau.dk/ai-cloud/</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#terms-of-use","title":"Terms of use","text":"<ul> <li>Access is removed at August 1st</li> <li>1 hour default, 12 hour maximum limit on jobs</li> <li>Must not be used for confidential or sensitive data</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#lets-begin-using-ai-lab","title":"Lets begin using AI-LAB!","text":"<ol> <li>Log in via your local terminal using: <code>ssh -l user@student.aau.dk ailab-fe01.srv.aau.dk</code></li> <li>Enter <code>yes</code> if you get the following message: <code>Are you sure you want to continue connecting (yes/no/[fingerprint])?</code></li> <li>Enter your AAU password (it will not be visible)</li> </ol>"},{"location":"ai-lab/courses/ai-lab-workshop/#exercises","title":"Exercises","text":"<ul> <li>Log in to AI-LAB</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#file-management","title":"File management","text":"<ul> <li>Store files in your user directory <code>/ceph/home/student.aau.dk/user</code></li> <li>Shared files in <code>/ceph/container</code> and <code>/ceph/course</code></li> <li>Shared project directories in <code>/ceph/project</code></li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#nice-file-commands-to-know","title":"Nice file commands to know","text":"<ul> <li><code>ls [path]</code>: List files in directory</li> <li><code>cd [path]</code>: Change directory</li> <li><code>cp [source] [destination]</code>: Copy a file within AI-LAB</li> <li><code>cp -r [source] [destination]</code>: Copy a folder within AI-LAB</li> <li><code>mkdir [name]</code>: Make a directory</li> <li> <p><code>cat [filename]</code>: Print out file content in terminal</p> </li> <li> <p><code>~</code>: Shortcut path to your directory, e.g. <code>mkdir ~/stuff</code> creates a folder called <code>stuff</code> in your directory.</p> </li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#exercises_1","title":"Exercises","text":"<ul> <li>Create a directory called <code>workshop</code> in your home directory using the <code>mkdir</code> command</li> <li>Copy the file <code>/ceph/course/claaudia/docs/torch_bm.py</code> to the <code>workshop</code> folder using <code>cp</code> command</li> <li>Change directory to the <code>workshop</code> folder using <code>cd</code> command</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#create-or-edit-files","title":"Create or edit files","text":"<ul> <li><code>nano [filename]</code>: Open or create a file</li> <li>Use the arrow keys to move around (don't click with your mouse!)</li> <li>Save the file: Press <code>Ctrl + O</code>, rename the file if you want, then hit <code>Enter</code></li> <li>Exit Nano: Press <code>Ctrl + X</code></li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#exercises_2","title":"Exercises","text":"<ul> <li>Create a new file in the <code>workshop</code> folder called <code>run.sh</code> (job script) using <code>nano</code></li> <li>Enter this:</li> </ul> <pre><code>#!/bin/bash\necho \"Hello from AI-LAB!\"\n</code></pre> <ul> <li>Save it, and exit the file.</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#the-queue-system","title":"The queue system!","text":"<ul> <li>Slurm for job scheduling and resource allocation.</li> <li>Jobs are queued and executed when resources are available.</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#nice-commands-to-know","title":"Nice commands to know","text":"<ul> <li><code>sinfo</code>: Current status of the compute nodes.</li> <li><code>nodesummary</code>: Overview of allocated GPUs, CPUs, memory</li> <li><code>squeue</code>: Overview of the current job queue</li> <li><code>squeue --me</code>: Overview of your current job queue</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#how-to-submit-a-job","title":"How to submit a job?","text":"<ul> <li><code>srun [one line command]</code>: Runs a command interactively, taking over your terminal until the job finishes, e.g: <code>srun echo \"Hello from AI-LAB!\"</code></li> <li><code>sbatch [script]</code>: Runs a sequence of commands in the background (best for long term jobs)</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#exercises_3","title":"Exercises","text":"<ul> <li>Run the job script <code>run.sh</code> using the <code>sbatch</code> command</li> <li>Use <code>ls</code> to list the files in the <code>workhop</code> folder</li> <li>There should be an output file called something like <code>slurm-1234.out</code> in the folder</li> <li>Print out the content of the output file using the <code>cat</code> command</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#containers","title":"Containers","text":"<ul> <li>Containers bundle application code, libraries, and dependencies</li> <li>Easy to install and manage complex applications</li> <li>AI-LAB uses Singularity for container management</li> <li>Singularity container files (also called images), has <code>.sif</code> as extension</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#getting-containers","title":"Getting containers","text":""},{"location":"ai-lab/courses/ai-lab-workshop/#downloading-containers","title":"Downloading containers","text":"<ul> <li>https://catalog.ngc.nvidia.com/</li> <li>https://hub.docker.com/</li> <li>https://cloud.sylabs.io/library/</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#pre-downloaded-containers","title":"Pre-downloaded containers","text":"<ul> <li><code>ls /ceph/container</code></li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#customizing-containers","title":"Customizing containers","text":"<ul> <li>Add python packages via a virtual environment</li> <li>Build your own container image on your local computer</li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#using-containers","title":"Using containers","text":"<ul> <li><code>singularity exec [path/to/container] [action]</code>: tells Singularity to start a container and execute an action in that container instance, e.g:<ul> <li><code>srun singularity exec /ceph/container/pytorch/pytorch_24.07.sif python3 torch_bm.py</code></li> </ul> </li> </ul> <ul> <li>You need to add <code>--nv</code> and <code>--gres=gpu:1</code> to enable NVIDIA libraries and allocate a GPU to the job:<ul> <li>srun --gres=gpu:1 singularity exec --nv /ceph/container/pytorch/pytorch_24.07.sif python3 torch_bm.py</li> </ul> </li> </ul>"},{"location":"ai-lab/courses/ai-lab-workshop/#lets-put-is-all-together-in-a-job-script","title":"Lets put is all together in a job script","text":"<p>/ceph/course/claaudia/docs/run.sh: <pre><code>#!/bin/bash\n#SBATCH --job-name=torch_benchmark      # Name of the job\n#SBATCH --output=output_%j.log          # Output file name (%j will be replaced with the job ID)\n#SBATCH --error=error_%j.log            # Error file name (%j will be replaced with the job ID)\n#SBATCH --gres=gpu:1                    # Request 1 GPU\n#SBATCH --mem=16G                       # Request 16G Memory\n#SBATCH --cpus-per-task=15              # Request 15 CPUs\n\n# Run the command\nsingularity exec --nv /ceph/container/pytorch/pytorch_24.07.sif python3 torch_bm.py\n</code></pre></p>"},{"location":"ai-lab/courses/ai-lab-workshop/#the-final-exercises","title":"The final exercises!","text":"<p>Lets run the <code>torch_bm.py</code> script using a pre-made job script.</p> <ul> <li>Copy the job script <code>/ceph/course/claaudia/docs/run.sh</code> to the <code>workshop</code> folder using <code>cp /ceph/course/claaudia/docs/run.sh ~/workshop</code></li> <li>Use <code>cat run.sh</code> to check the content</li> <li>Run the job script using <code>sbatch run.sh</code></li> <li>Use <code>squeue --me</code> to check if your job is running, defined by the <code>R</code> below <code>ST</code></li> <li>Locate the <code>JOBID</code> and cancel your job using <code>scancel [JOBID]</code></li> </ul> <pre><code>################################################################################\n\n             \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557  \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557   \u2588\u2588\u2557\u2588\u2588\u2557  \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\n             \u255a\u2550\u2550\u2588\u2588\u2554\u2550\u2550\u255d\u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551\u2588\u2588\u2551 \u2588\u2588\u2554\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\n                \u2588\u2588\u2551   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\n                \u2588\u2588\u2551   \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2588\u2588\u2557 \u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\n                \u2588\u2588\u2551   \u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551  \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\n                \u255a\u2550\u255d   \u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u2550\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\n################### If you need any help, please visit: #######################\n\nhttps://serviceportal.aau.dk -&gt; IT -&gt; CLAAUDIA -&gt; Support for CLAAUDIA services\n\n################################################################################\n</code></pre>"},{"location":"ai-lab/courses/name-generator-exercises/part-1/","title":"Part 1","text":""},{"location":"ai-lab/courses/name-generator-exercises/part-1/#in-this-exercise-series-youll-work-with-a-recurrent-neural-network-rnn-to-generate-3-fictional-german-names-based-on-a-dataset-of-700-german-names-the-script-youll-interact-with-is-based-on-pytorch-and-demonstrates-how-ai-lab-can-be-used-for-sequence-prediction-tasks","title":"In this exercise series, you'll work with a Recurrent Neural Network (RNN) to generate 3 fictional German names based on a dataset of ~700 german names. The script you'll interact with is based on PyTorch and demonstrates how AI-LAB can be used for sequence prediction tasks.","text":"<ol> <li> <p>Log in to AI-LAB (Login guide)</p> </li> <li> <p>Copy the folder <code>/ceph/course/claaudia/generating-names-with-pytorch</code> to your user directory (Guide on how to copy a folder)</p> </li> <li> <p>Go into the copied directory <code>generating-names-with-pytorch</code> and open <code>name_generator.py</code> with nano (Nano guide) or vim (Vim guide) text editor.</p> </li> <li> <p>Add this line: <code>samples('German', 'GER')</code> at the bottom of the code, save it, and exit the file.</p> </li> <li> <p>(Optional) run <code>cat name_generator.py</code> to print out the code, and verify that <code>samples('German', 'GER')</code> is at the bottom.</p> </li> </ol> Solution <ol> <li> <p>Run the following command on a command-line interface on your local Windows (Windows PowerShell), macOS, or Linux computer <code>ssh -l user@student.aau.dk ailab-fe01.srv.aau.dk</code>. Replace user@student.aau.dk with your AAU email address.</p> <p>The first time you connect, you will get a message like:</p> <pre><code>The authenticity of host 'ailab-fe01.srv.aau.dk (172.21.131.1300)' can't be established.\nED25519 key fingerprint is SHA256:xosJtOSfQyyW16c6RtpN8tAi/91XHCR3GxM9/KJEogg.\nThis key is not known by any other names.\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\nPlease confirm by typing 'yes' to proceed with the connection.\n</code></pre> <p>Please confirm by typing <code>yes</code> to proceed with the connection.</p> </li> <li> <p>Enter <code>cp -r /ceph/course/claaudia/generating-names-with-pytorch ~/</code> to copy the directory to your user directory</p> </li> <li>Enter <code>cd generating-names-with-pytorch</code> to go into the directory</li> <li>Use <code>nano name_generator.py</code> to open the python file with nano text editor<ul> <li>Go down to the bottom of the script and enter <code>samples('German', 'GER')</code>.</li> <li>Press <code>CTRL+O</code> followed by <code>ENTER</code> to save the file, then press <code>CTRL+X</code> to exit the file.</li> </ul> </li> <li>Use <code>cat name_generator.py</code> and check that <code>samples('German', 'GER')</code> is now at the bottom of the code.</li> </ol>"},{"location":"ai-lab/courses/name-generator-exercises/part-2/","title":"Part 2","text":"<ol> <li> <p>Use <code>ls /ceph/container/pytorch</code> command to find an appropriate PyTorch container. Copy the path to the container. </p> </li> <li> <p>Edit <code>run.sh</code> with nano (Nano guide) or vim (Vim guide) text editor.</p> </li> <li> <p>Set the following parameters in the script (Guide to run a bash script)</p> <ul> <li>Set <code>#SBATCH --cpus-per-task=</code> to 15</li> <li>Set <code>#SBATCH --mem=</code> to 24G</li> <li>Set <code>#SBATCH --gres=gpu:1</code></li> <li>Add the container path you copied to <code>PATHTOCONTAINER=</code></li> <li>Add <code>name_generator.py</code> to <code>SCRIPT=</code></li> </ul> </li> <li> <p>Save and exit the file.</p> </li> <li> <p>Start <code>run.sh</code> using <code>sbatch</code> command</p> </li> <li> <p>Use <code>watch -n 1 squeue --me</code> to check your job process (approx. 3 minutes to processs)</p> </li> <li> <p>When the job done, press <code>CTRL+C</code> to exit <code>watch</code>-mode and check the content of <code>result_x.out</code> using  <code>cat</code> command. The <code>x</code> is the job id.</p> </li> </ol> Solution <ol> <li>Use <code>ls /ceph/container</code> to locate a PyTorch container image in the <code>/ceph/container</code> directory. Copy the path, e.g. <code>/ceph/container/pytorch/pytorch_24.07.sif</code>.</li> <li>Make sure your current directory is <code>user@student.aau.dk@ailab-fe01:~/generating-names-with-pytorch$</code>.<ul> <li>If not, go into the directory by using <code>cd generating-names-with-pytorch</code>.</li> </ul> </li> <li>Use <code>nano run.sh</code> to open the bash script with nano text editor<ul> <li>Set <code>#SBATCH --cpus-per-task=</code> to 15</li> <li>Set <code>#SBATCH --mem=</code> to 24G</li> <li>Set <code>#SBATCH --gres=gpu:1</code></li> <li>Add the container path you copied to <code>PATHTOCONTAINER=</code></li> <li>Add <code>name_generator.py</code> to <code>SCRIPT=</code></li> </ul> </li> <li>Press <code>CTRL+O</code> followed by <code>ENTER</code> to save the file, then press <code>CTRL+X</code> to exit the file.</li> <li>Use <code>sbatch run.sh</code> to start the job.</li> <li>Use <code>watch -n 1 squeue --me</code> to check your job process</li> <li>When the job done, press <code>CTRL+C</code> to exit <code>watch</code>-mode and check the content of <code>result_x.out</code> using  <code>cat</code> command </li> </ol>"},{"location":"ai-lab/for-lecturers/adding-a-course/","title":"Adding a course","text":"<p>You are invited to design your own course for AI-LAB. You can create your own pages within the documentation and upload course materials directly to the AI-LAB server.</p>"},{"location":"ai-lab/for-lecturers/adding-a-course/#how-to-add-a-course-to-the-documentation","title":"How to add a course to the documentation","text":"<p>Follow these steps to create a new course:</p> <ol> <li>To be able to contribute you will need a GitHub account.</li> <li>Start by forking the repository to your GitHub account from here: https://github.com/aau-claaudia/ailab-docs/fork.</li> <li>Go into your forked repository and in the <code>/docs/courses</code> directory, create a new folder named after your course. This folder will contain your <code>.md</code> files, which form the basis of your course content.</li> </ol> <p>Info</p> <ul> <li>We use Markdown format and Material for MkDocs for styling. </li> <li>The easiest way to get started with your page is by using this online editor: https://md.sigma2.no/new.</li> <li>You can also install Material for MkDocs by following this getting started guide.</li> <li>For design tips, refer to our page design guide.</li> <li>Your course series may include multiple files, e.g., <code>tensorflow-course-1.md</code>, <code>tensorflow-course-2.md</code>, etc.</li> </ul> <ol> <li>Once you have made the necessary changes, submit a pull request to the main repository.</li> <li>We will review your changes and, if everything is in order, merge your pull request.</li> </ol>"},{"location":"ai-lab/for-lecturers/adding-a-course/#adding-container-image-files-to-ai-lab","title":"Adding container image files to AI-LAB","text":"<p>You can add your own container image files to the <code>/ceph/container</code> directory on AI-LAB. Simply <code>cp</code> the container from your own directory to the <code>/ceph/container</code> or use <code>scp</code> if you want to transfer it from your local computer. Take a look at File management for more details. </p> <p>We also have guides on how to download container images and how to build your own container image.</p>"},{"location":"ai-lab/for-lecturers/adding-a-course/#adding-course-material-to-ai-lab","title":"Adding course material to AI-LAB","text":"<p>Similar to adding container image files, you can add files to the <code>/ceph/course</code> directory on AI-LAB. It could be datasets or scripts, but also container images. Please make a directory (<code>mkdir [name]</code>) that you can store your files in.</p>"},{"location":"ai-lab/for-lecturers/page-design-guide/","title":"Page design guide","text":"<p>This is a basic overview of which features you can use to design a MkDocs page. You can find more information at https://squidfunk.github.io/mkdocs-material/reference/.</p> Normal paragraph<pre><code>You write normal paragraph text just by typing like this. \n</code></pre> <p>Preview  You write normal paragraph text just by typing like this. </p> Headings<pre><code>You can create headings by placing a # before the text like so:. \n# Heading 1\n## Heading 2\n### Heading 3\n#### Heading 4\n</code></pre> <p>Preview </p> Inserting links<pre><code>You can insert links by:\n\nI want to insert a link [here](https://www.researcher.aau.dk/contact/claaudia)\n</code></pre> <p>Preview  I want to insert a link here</p> Code in paragrapgh<pre><code>You use backticks to `write code in text`.\n</code></pre> <p>Preview  You use backticks to <code>write code in text</code>.</p> Console codeblocks<pre><code> You can also create a console codeblock like so:\n\n ```console\n ssh -l xxxxxx@student.aau.dk ai-fe02.srv.aau.dk\n ```\n</code></pre> <p>Preview <pre><code>ssh -l xxxxxx@student.aau.dk ai-fe02.srv.aau.dk\n</code></pre></p> Python codeblocks<pre><code> You can also create a Python codeblock like so:\n\n ```py\n import tensorflow as tf\n for i in range(len(100)):\n    print(i)\n ```\n</code></pre> <p>Preview <pre><code>import tensorflow as tf\n\nfor i in range(len(100)):\n    print(i)\n</code></pre></p> Call-outs<pre><code>You can make call-outs/admonitions like so:\n\n!!! info \"This is the title\"\n    This is the content\n</code></pre> <p>Preview</p> <p>This is the title</p> <p>This is the content</p> Data tables<pre><code>You can also create data tables like this:\n\n| Method      | Description     |\n| ----------- | --------------- |\n| `GET`       | Fetch resource  |\n| `PUT`       | Update resource |\n| `DELETE`    | Delete resource |\n</code></pre> <p>Preview </p> Method Description <code>GET</code> Fetch resource <code>PUT</code> Update resource <code>DELETE</code> Delete resource Custom HTML/CSS<pre><code>&lt;div&gt;\n    &lt;p&gt;\n        You can paste your own custom HTML/CSS as you would in a normal .html file\n    &lt;/p&gt;\n&lt;/div&gt;\n</code></pre> <p>Preview </p> <p>         You can paste your own custom HTML/CSS as you would in a normal .html file     </p> Inserting images<pre><code>You can insert images from urls or by uploading images to \"/assets/img/\":\n\n![Image of CLAAUDIA Logo](../../assets/img/claaudia-logo.png)\n</code></pre> <p>Preview </p>"},{"location":"ai-lab/for-lecturers/page-design-guide/#heading-1","title":"Heading 1","text":""},{"location":"ai-lab/for-lecturers/page-design-guide/#heading-2","title":"Heading 2","text":""},{"location":"ai-lab/for-lecturers/page-design-guide/#heading-3","title":"Heading 3","text":""},{"location":"ai-lab/for-lecturers/page-design-guide/#heading-4","title":"Heading 4","text":""},{"location":"ai-lab/guides/","title":"Index","text":"<ul> <li>Adding Python packages</li> <li>Batch LLM Inference</li> <li>Build your own container</li> <li>Cancelling jobs</li> <li>Checking GPU utilization</li> <li>Checking the queue</li> <li>Checking the status of compute nodes</li> <li>Checkpointing</li> <li>CI/CD with GitHub Actions</li> <li>Creating shared project directories</li> <li>Download containers</li> <li>Essential Linux commands</li> <li>Getting access</li> <li>Login</li> <li>Requeuing jobs</li> <li>Running jobs using sbatch</li> <li>Running jobs using srun</li> <li>Specifying job options</li> <li>Transfer files between your local computer and AI-LAB</li> <li>Using containers</li> <li>Using pre-downloaded containers</li> </ul>"},{"location":"ai-lab/guides/additional-guides/","title":"Additional guides","text":""},{"location":"ai-lab/guides/additional-guides/#checkpointing","title":"Checkpointing","text":"<p>On AI-LAB, jobs have a default time limit of 1 hour and a maximum runtime of 12 hours. Once this time limit is reached, your job will be canceled, and any unsaved data will be lost. To prevent data loss, it's important to implement checkpointing, which saves data at regular intervals. Additionally, you can set up automatic requeuing so that your job will restart automatically if it gets canceled, removing the need to manually resubmit it.</p> Guide on checkpointing <p>This guide explains how to set up checkpointing in various frameworks like Python, PyTorch, and TensorFlow, as well as how to configure automatic requeuing for your jobs.</p> <p>Disclaimer</p> <p>Using checkpointing is done at your own risk. This guide is intended as a reference, but saving data via checkpointing is entirely the responsibility of the user. There may be errors or inaccuracies within this guide. If you encounter any issues or discover mistakes, we encourage you to provide feedback so we can improve. You can submit your feedback here.</p>"},{"location":"ai-lab/guides/additional-guides/#checkpointing-methods","title":"Checkpointing methods","text":"<p>Checkpointing allows you to periodically save the state of your job so that it can be resumed later, even after an interruption. Different frameworks have different methods for implementing checkpointing. Below are examples for Python, PyTorch, and TensorFlow. </p> Python checkpointing <p>In Python, you can use the pickle module to periodically save and load the state of your job.</p> <p><pre><code>import pickle\nimport os\n\ndef save_checkpoint(data, filename):\n    \"\"\"Save the checkpoint data to a file.\"\"\"\n    with open(filename, 'wb') as f:\n        pickle.dump(data, f)\n\ndef load_checkpoint(filename):\n    \"\"\"Load the checkpoint data from a file.\"\"\"\n    with open(filename, 'rb') as f:\n        return pickle.load(f)\n\n# Check if there is a checkpoint file\nif os.path.exists('checkpoint.pkl'):\n    # If there is, load the checkpoint\n    data = load_checkpoint('checkpoint.pkl')\n    print(\"Resuming from checkpoint:\")\nelse:\n    # If there isn't, initialize data\n    data = {'counter': 0}\n\ntry:\n    # Simulate some long-running process\n    while True:\n        data['counter'] += 1\n        print(\"Current counter value:\", data['counter'])\n        # Save checkpoint every 5 iterations\n        if data['counter'] % 5 == 0:\n            save_checkpoint(data, 'checkpoint.pkl')\n        # Simulate some work\n        # Replace this with your actual process\n        import time\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    # Save checkpoint if the process is interrupted\n    save_checkpoint(data, 'checkpoint.pkl')\n    print(\"\\nCheckpoint saved. Exiting...\")\n</code></pre> </p> PyTorch checkpointing <p>PyTorch provides native support for saving and loading model and optimizer states during training. More information about PyTorch checkpointing can be found here. Here's an example that shows how to checkpoint during training of a simple neural network:</p> <pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\n# Define a simple feedforward neural network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(784, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Load MNIST dataset\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('data', train=True, download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.1307,), (0.3081,))\n                ])),\n    batch_size=64, shuffle=True)\n\n# Define the model\nmodel = SimpleNN()\n\n# Define the optimizer and loss function\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# Checkpoint directory\ncheckpoint_dir = 'checkpoints'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n##epoch number of steps\nepoch_steps = 20\n\n# Check if there are existing checkpoints\nif os.listdir(checkpoint_dir):\n    # If there are existing checkpoints, load the latest one\n    latest_checkpoint = max([int(file.split('.')[0]) for file in os.listdir(checkpoint_dir)])\n    checkpoint = torch.load(os.path.join(checkpoint_dir, f'{latest_checkpoint}.pt'))\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    start_epoch = latest_checkpoint + 1\nelse:\n    start_epoch = 0\n\n# Training loop\nfor epoch in range(start_epoch, epoch_steps):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        data = data.view(data.size(0), -1)\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch}: Loss {loss.item()}')\n\n    # Save checkpoint every epoch\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss\n        }, os.path.join(checkpoint_dir, f'{epoch}.pt'))\n</code></pre> <p></p> TensorFlow checkpointing <p>TensorFlow offers built-in functionality for saving model weights during training using the <code>ModelCheckpoint</code> callback. More information about TensorFlow checkpointing can be found here. Here's an example:</p> <pre><code>    import os\n    import sys\n    import os.path\n    import tensorflow as tf\n    from tensorflow import keras\n\n    #####Get an example dataset - we'll use the MNIST dataset first 1000 examples:\n    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n\n    train_labels = train_labels[:5000]\n    test_labels = test_labels[:5000]\n\n    train_images = train_images[:5000].reshape(-1, 28 * 28) / 255.0\n    test_images = test_images[:5000].reshape(-1, 28 * 28) / 255.0\n\n    ##epoch number of steps for each job:\n    epoch_steps=20\n\n    ####Define a simple sequential model:\n    def create_model():\n        model = tf.keras.models.Sequential([\n            keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(10)\n        ])\n\n        model.compile(optimizer='adam',\n                        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n                        metrics=[tf.metrics.SparseCategoricalAccuracy()])\n\n        return model\n\n\n    # Create a new model instance\n    model = create_model()\n\n    # Include the epoch in the file name (uses `str.format`)\n    checkpoint_path = \"checkpoints/{epoch:d}.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    # Create a callback that saves the model's weights every epoch (period=1)\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, \n        verbose=1, \n        save_weights_only=True,\n        period=1)\n\n    # Check if there are existing checkpoints\n    if os.path.exists(checkpoint_dir):\n        # If there are existing checkpoints, load the latest one\n        latest = tf.train.latest_checkpoint(checkpoint_dir)\n        # Load the previously saved weights, if there are any:\n        model.load_weights(latest)\n\n        # Re-evaluate the model\n        loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n        print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n\n        # Get the step number from the latest checkpoint\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir) \n        step = int(os.path.basename(ckpt.model_checkpoint_path).split('.')[0])\n        print('Continuing calculation from epoch step:' + str(step)) \n        # Set the initial epoch to the last recovered epoch\n        initialEpoch=step\n    else:\n        initialEpoch=0\n        # Save the weights for the initial epoch\n        model.save_weights(checkpoint_path.format(epoch=0))\n\n    # Train the model with the new callback\n    model.fit(train_images, \n            train_labels,\n            epochs=epoch_steps, \n            initial_epoch=initialEpoch,\n            callbacks=[cp_callback],\n            validation_data=(test_images,test_labels),\n            verbose=1)\n</code></pre> <p></p>"},{"location":"ai-lab/guides/additional-guides/#breakdown-of-the-key-components","title":"Breakdown of the key components:","text":"<p>First, the script checks if a checkpoint file named <code>checkpoint.pkl</code> exists using <code>os.path.exists()</code>. If the file exists, it loads the checkpoint data using <code>load_checkpoint</code> function and assigns it to data. If not, it initializes data with a dictionary containing a single key <code>counter</code> initialized to 0. </p> <p>Then, it enters an infinite loop (simulating a long-running process), where it increments the <code>counter</code> key of the data dictionary, prints the current counter value, and simulates some work (in this case, a 1-second delay using <code>time.sleep(1)</code>).</p> <p>Every 5 iterations (<code>if data['counter'] % 5 == 0)</code>, it saves the checkpoint by calling <code>save_checkpoint</code>. If the process is interrupted by a keyboard interrupt (Ctrl+C), it saves the current checkpoint and prints a message before exiting.</p>"},{"location":"ai-lab/guides/additional-guides/#breakdown-of-the-key-components_1","title":"Breakdown of the key components:","text":"<p>Checkpoint Directory Setup (line 39-41): Creating a directory for storing checkpoints.</p> <p>Checking for Existing Checkpoints (line 46-55): Checking for existing checkpoints and loading the latest one if available.</p> <p>Saving Checkpoints (line 69-75): Saving the model's state, optimizer's state, and current loss at the end of each epoch to a uniquely named file based on the epoch number.</p>"},{"location":"ai-lab/guides/additional-guides/#breakdown-of-the-key-components_2","title":"Breakdown of the key components:","text":"<p><code>checkpoint_path</code>: Specify the path where checkpoints will be saved. You can include dynamic elements such as epoch number in the file name to differentiate between checkpoints, like <code>checkpoints/{epoch:d}.ckpt</code></p> <p><code>cp_callback</code>: Create a ModelCheckpoint callback, which will save the model's weights at specified intervals during training. You can customize various parameters such as the file path, verbosity, and whether to save only the weights or the entire model.</p> <p><code>model.load_weights(latest)</code>: Before starting training, check if there are existing checkpoints. If so, load the latest one to resume training from the last saved state. This ensures continuity in training even if interrupted.</p>"},{"location":"ai-lab/guides/additional-guides/#requeuing-jobs","title":"Requeuing jobs","text":"<p>After implementing checkpointing in your script, you have the option to set up automatic job requeuing in case your job gets cancelled. This is done by modifying a bash script that will automatically requeue the job if it's terminated due to exceeding the time limit. You can find an example script, <code>requeue.sh</code>, on AI-LAB at <code>/ceph/course/claaudia/docs/requeue.sh</code>.</p> Guide on requeing jobs <p>Disclaimer</p> <p>Using requeuing is done at your own risk. This guide is intended as a reference, but requeuing your jobs is entirely the responsibility of the user. There may be errors or inaccuracies within this guide. If you encounter any issues or discover mistakes, we encourage you to provide feedback so we can improve. You can submit your feedback here.</p> requeue.sh <pre><code>#!/bin/bash\n\n#SBATCH --job-name=requeue_example\n#SBATCH --time=00:01:00\n#SBATCH --signal=B:SIGTERM@30\n#SBATCH --gres=gpu:1\n#SBATCH --cpus-per-task=15\n#SBATCH --mem=24G\n\n#####################################################################################\n\n# tweak this to fit your needs\nmax_restarts=4\n\n# Fetch the current restarts value from the job context\nscontext=$(scontrol show job ${SLURM_JOB_ID})\nrestarts=$(echo ${scontext} | grep -o 'Restarts=[0-9]*' | cut -d= -f2)\n\n# If no restarts found, it's the first run, so set restarts to 0\niteration=${restarts:-0}\n\n# Dynamically set output and error filenames using job ID and iteration\noutfile=\"${SLURM_JOB_ID}_${iteration}.out\"\nerrfile=\"${SLURM_JOB_ID}_${iteration}.err\"\n\n# Print the filenames for debugging\necho \"Output file: ${outfile}\"\necho \"Error file: ${errfile}\"\n\n##  Define a term-handler function to be executed           ##\n##  when the job gets the SIGTERM (before timeout)          ##\n\nterm_handler()\n{\n    echo \"Executing term handler at $(date)\"\n    if [[ $restarts -lt $max_restarts ]]; then\n        # Requeue the job, allowing it to restart with incremented iteration\n        scontrol requeue ${SLURM_JOB_ID}\n        exit 0\n    else\n        echo \"Maximum restarts reached, exiting.\"\n        exit 1\n    fi\n}\n\n# Trap SIGTERM to execute the term_handler when the job gets terminated\ntrap 'term_handler' SIGTERM\n\n#######################################################################################\n\n# Use srun to dynamically specify the output and error files\nsrun --output=\"${outfile}\" --error=\"${errfile}\" singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python torch_bm.py\n</code></pre> <p>In this script, we will run a PyTorch script (located at <code>/ceph/course/claaudia/docs/torch_bm.py</code>) using the PyTorch container <code>/ceph/container/pytorch/pytorch_24.09.sif</code>. You can modify this to run any script or container you need. Key parameters to pay attention to are:</p> <ul> <li><code>#SBATCH --time=00:01:00</code>: This sets the time limit for your job. If your job exceeds this limit, it will be cancelled. If not specified, the default time limit is 1 hour (maximum 12 hours).</li> <li><code>#SBATCH --signal=B:SIGTERM@30</code>: This tells Slurm to send a SIGTERM signal 30 seconds before the job reaches the time limit, giving the job time to handle termination gracefully.</li> <li><code>max_restarts=4</code>: This defines the maximum number of times your job will be automatically requeued if it gets cancelled. In this example, the job will be requeued up to four times before it is finally terminated.</li> </ul>"},{"location":"ai-lab/guides/additional-guides/#cicd-with-github-actions","title":"CI/CD with GitHub Actions","text":"<p>Below is a step-by-step guide on how to set up a self-hosted GitHub Actions runner on AI-LAB. This allows you to run CI/CD jobs directly from GitHub on AI-LAB.</p> Guide on how to setup CI/CD with GitHub Actions on AI-LAB"},{"location":"ai-lab/guides/additional-guides/#1-create-a-self-hosted-runner-in-github","title":"1. Create a self-hosted runner in GitHub","text":"<ol> <li>Go to the repository in GitHub where you want to use the runner.</li> <li>Click \u201cSettings\u201d (at the top, depending on GitHub\u2019s UI).</li> <li>Select \u201cActions\u201d in the left menu, then choose \u201cRunners.\u201d</li> <li>Click \u201cNew self-hosted runner.\u201d</li> <li>Choose Linux as the OS and X64 for the architecture.</li> <li>GitHub will display commands you need to run on AI-LAB. </li> <li>Press \"Enter\" to all settings, to get the default setup.</li> <li>Once you run <code>./run.sh</code>, the runner will stay in the foreground and listen for new GitHub jobs. Stop it with Ctrl+C when you\u2019re done testing.</li> </ol>"},{"location":"ai-lab/guides/additional-guides/#2-create-a-github-actions-workflow","title":"2. Create a GitHub Actions workflow","text":"<ol> <li> <p>Create or edit a file called .github/workflows/ci.yaml in your repository with a minimal workflow:</p> <pre><code>name: AI-LAB test job\non:\n  push:\n    branches:\n      - main\njobs:\n  test-hpc:\n    runs-on: self-hosted\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v3\n      - name: AI-LAB hostname info\n        run: |\n          sbatch --output=hostname_output.txt --wrap=\"hostname\"\n</code></pre> </li> <li> <p>With the runner, running on AI-LAB, the job should start immediately. Once complete, you can check the output file using: </p> <pre><code>cat actions-runner/_work/ai-lab-data/ai-lab-data/hostname_output.txt\n</code></pre> </li> </ol>"},{"location":"ai-lab/guides/batch-llm-inference/","title":"Batch LLM Inference","text":"<p>This guide explains how to run batch LLM inference using vLLM on AI-LAB, covering:</p> <ul> <li>Setting up and running the vLLM container</li> <li>Submitting inference jobs via Slurm</li> </ul> <p>What is Batch LLM Inference?</p> <p>Batch LLM inference refers to processing multiple input prompts in a single inference pass rather than handling them individually. This approach enhances GPU utilization, increases throughput, and reduces overall latency, making it ideal for large-scale text processing tasks on a GPU cluster.</p> <p>What is vLLM?</p> <p>vLLM is an optimized inference engine for large language models, designed to improve performance and efficiency. Using vLLM on AI-LAB ensures efficient model execution, particularly when multiple users or jobs run concurrently.</p>"},{"location":"ai-lab/guides/batch-llm-inference/#obtaining-a-hugging-face-access-token","title":"Obtaining a Hugging Face Access Token","text":"<p>Many models on Hugging Face are restricted. To use them, you need an access token.</p> <ol> <li>Go to Hugging Face and log in or create an account.</li> <li> <p>Navigate to Hugging Face tokens and click Create new token.</p> <p></p> </li> <li> <p>Under Token Type, select <code>Read</code>, enter a Token Name, and click Create Token.</p> <p></p> </li> <li> <p>Copy the token value and click Done.</p> <p></p> </li> <li> <p>On AI-LAB, add the token to your <code>~/.bashrc</code> to ensure it is always available:</p> <pre><code>echo 'export HF_TOKEN=\"YOUR_TOKEN\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> </li> <li> <p>Replace <code>YOUR_TOKEN</code> with your actual token.</p> </li> <li> <p>Verify the token is set correctly:</p> <pre><code>echo $HF_TOKEN\n</code></pre> </li> </ol>"},{"location":"ai-lab/guides/batch-llm-inference/#running-vllm-with-slurm","title":"Running vLLM with Slurm","text":"<p>Now that access is set up, we can submit a job via Slurm. The example below demonstrates the basic usage of vLLM to generate text.</p>"},{"location":"ai-lab/guides/batch-llm-inference/#creating-a-python-script-for-vllm-inference","title":"Creating a Python Script for vLLM Inference","text":"<p>Create a new file called <code>basic.py</code> with the following code:</p> basic.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n# - Explicitly set the token before initializing LLM:\n\nfrom vllm import LLM, SamplingParams\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\n# Sample prompts.\nprompts = [\n    \"Hello, my name is\",\n    \"The president of the United States is\",\n    \"The capital of France is\",\n    \"The future of AI is\",\n]\n\n# Create a sampling params object.\nsampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n\n# Create an LLM instance.\nllm = LLM(model=\"facebook/opt-125m\")\n\n# Generate text.\noutputs = llm.generate(prompts, sampling_params)\n\n# Print results.\nfor output in outputs:\n    print(f\"Prompt: {output.prompt!r}, Generated text: {output.outputs[0].text!r}\")\n</code></pre> <p>This script initializes vLLM's engine using the facebook/opt-125m model and generates text based on the given prompts. For more details, refer to the vLLM documentation.</p>"},{"location":"ai-lab/guides/batch-llm-inference/#submitting-a-slurm-job","title":"Submitting a Slurm Job","text":"<p>A pre-built vLLM container is available on AI-LAB at <code>/ceph/container/vllm-openai_latest.sif</code>. This container includes vLLM and all necessary dependencies.</p> <p>Create a Slurm batch script <code>run_vllm.sh</code>:</p> run_vllm.sh<pre><code>#!/bin/bash\n#SBATCH --job-name=vllm_textgen\n#SBATCH --output=vllm_textgen_output.log\n#SBATCH --error=vllm_textgen_error.log\n#SBATCH --gres=gpu:1\n#SBATCH --mem=40G\n#SBATCH --time=04:00:00\n\nsingularity exec --nv /ceph/container/vllm-openai_latest.sif python3 basic.py\n</code></pre> <p>Submit the job using:</p> <pre><code>sbatch run_vllm.sh\n</code></pre> <p>The job should complete quickly (~2 minutes). Check the <code>vllm_textgen_output.log</code> file for results:</p> <pre><code>Prompt: 'Hello, my name is', Generated text: ' Joel, my dad is my friend and we are in a relationship. I am'\nPrompt: 'The president of the United States is', Generated text: ' speaking out against the release of some State Department documents which show the Russians were involved'\nPrompt: 'The capital of France is', Generated text: ' the most populous city in the world, with an annual population of nearly 3 million'\nPrompt: 'The future of AI is', Generated text: ' at stake\\nThe world is going to change in the next 20 years, and'\n</code></pre> <p>Restricted Model Access Error</p> <p>If you encounter an error such as:</p> <pre><code>Access to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list.\n</code></pre> <p>You need to request access on Hugging Face. Visit the model page, such as meta-llama/Llama-3.2-1B-Instruct, and click Agree and access repository.</p> <p></p>"},{"location":"ai-lab/guides/batch-llm-inference/#additional-vllm-examples","title":"Additional vLLM Examples","text":"<p>Below are additional examples demonstrating different vLLM use cases. More advanced examples can be found in the vLLM GitHub repository.</p> chat.py chat.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: dict):\n    # Pop arguments not used by LLM\n    max_tokens = args.pop(\"max_tokens\")\n    temperature = args.pop(\"temperature\")\n    top_p = args.pop(\"top_p\")\n    top_k = args.pop(\"top_k\")\n    chat_template_path = args.pop(\"chat_template_path\")\n\n    # Create an LLM\n    llm = LLM(**args)\n\n    # Create sampling params object\n    sampling_params = llm.get_default_sampling_params()\n    if max_tokens is not None:\n        sampling_params.max_tokens = max_tokens\n    if temperature is not None:\n        sampling_params.temperature = temperature\n    if top_p is not None:\n        sampling_params.top_p = top_p\n    if top_k is not None:\n        sampling_params.top_k = top_k\n\n    def print_outputs(outputs):\n        for output in outputs:\n            prompt = output.prompt\n            generated_text = output.outputs[0].text\n            print(f\"Prompt: {prompt!r}\")\n            print(f\"Generated text: {generated_text!r}\")\n        print(\"-\" * 80)\n\n    print(\"=\" * 80)\n\n    # In this script, we demonstrate how to pass input to the chat method:\n    conversation = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello\"\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"Hello! How can I assist you today?\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\":\n            \"Write an essay about the importance of higher education.\",\n        },\n    ]\n    outputs = llm.chat(conversation, sampling_params, use_tqdm=False)\n    print_outputs(outputs)\n\n    # You can run batch inference with llm.chat API\n    conversations = [conversation for _ in range(10)]\n\n    # We turn on tqdm progress bar to verify it's indeed running batch inference\n    outputs = llm.chat(conversations, sampling_params, use_tqdm=True)\n    print_outputs(outputs)\n\n    # A chat template can be optionally supplied.\n    # If not, the model will use its default chat template.\n    if chat_template_path is not None:\n        with open(chat_template_path) as f:\n            chat_template = f.read()\n\n        outputs = llm.chat(\n            conversations,\n            sampling_params,\n            use_tqdm=False,\n            chat_template=chat_template,\n        )\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    # Add engine args\n    engine_group = parser.add_argument_group(\"Engine arguments\")\n    EngineArgs.add_cli_args(engine_group)\n    engine_group.set_defaults(model=\"meta-llama/Llama-3.2-1B-Instruct\")\n    # Add sampling params\n    sampling_group = parser.add_argument_group(\"Sampling parameters\")\n    sampling_group.add_argument(\"--max-tokens\", type=int)\n    sampling_group.add_argument(\"--temperature\", type=float)\n    sampling_group.add_argument(\"--top-p\", type=float)\n    sampling_group.add_argument(\"--top-k\", type=int)\n    # Add example params\n    parser.add_argument(\"--chat-template-path\", type=str)\n    args: dict = vars(parser.parse_args())\n    main(args)\n</code></pre> classify.py classify.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom argparse import Namespace\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: Namespace):\n    # Sample prompts.\n    prompts = [\n        \"Hello, my name is\",\n        \"The president of the United States is\",\n        \"The capital of France is\",\n        \"The future of AI is\",\n    ]\n\n    # Create an LLM.\n    # You should pass task=\"classify\" for classification models\n    model = LLM(**vars(args))\n\n    # Generate logits. The output is a list of ClassificationRequestOutputs.\n    outputs = model.classify(prompts)\n\n    # Print the outputs.\n    for prompt, output in zip(prompts, outputs):\n        probs = output.outputs.probs\n        probs_trimmed = ((str(probs[:16])[:-1] +\n                        \", ...]\") if len(probs) &gt; 16 else probs)\n        print(f\"Prompt: {prompt!r} | \"\n            f\"Class Probabilities: {probs_trimmed} (size={len(probs)})\")\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    parser = EngineArgs.add_cli_args(parser)\n    # Set example specific arguments\n    parser.set_defaults(model=\"jason9693/Qwen2.5-1.5B-apeach\",\n                        task=\"classify\",\n                        enforce_eager=True)\n    args = parser.parse_args()\n    main(args)\n</code></pre> embed.py embed.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom argparse import Namespace\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: Namespace):\n    # Sample prompts.\n    prompts = [\n        \"Hello, my name is\",\n        \"The president of the United States is\",\n        \"The capital of France is\",\n        \"The future of AI is\",\n    ]\n\n    # Create an LLM.\n    # You should pass task=\"embed\" for embedding models\n    model = LLM(**vars(args))\n\n    # Generate embedding. The output is a list of EmbeddingRequestOutputs.\n    outputs = model.embed(prompts)\n\n    # Print the outputs.\n    for prompt, output in zip(prompts, outputs):\n        embeds = output.outputs.embedding\n        embeds_trimmed = ((str(embeds[:16])[:-1] +\n                        \", ...]\") if len(embeds) &gt; 16 else embeds)\n        print(f\"Prompt: {prompt!r} | \"\n            f\"Embeddings: {embeds_trimmed} (size={len(embeds)})\")\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    parser = EngineArgs.add_cli_args(parser)\n    # Set example specific arguments\n    parser.set_defaults(model=\"intfloat/e5-mistral-7b-instruct\",\n                        task=\"embed\",\n                        enforce_eager=True)\n    args = parser.parse_args()\n    main(args)\n</code></pre> generate.py generate.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: dict):\n    # Pop arguments not used by LLM\n    max_tokens = args.pop(\"max_tokens\")\n    temperature = args.pop(\"temperature\")\n    top_p = args.pop(\"top_p\")\n    top_k = args.pop(\"top_k\")\n\n    # Create an LLM\n    llm = LLM(**args)\n\n    # Create a sampling params object\n    sampling_params = llm.get_default_sampling_params()\n    if max_tokens is not None:\n        sampling_params.max_tokens = max_tokens\n    if temperature is not None:\n        sampling_params.temperature = temperature\n    if top_p is not None:\n        sampling_params.top_p = top_p\n    if top_k is not None:\n        sampling_params.top_k = top_k\n\n    # Generate texts from the prompts. The output is a list of RequestOutput\n    # objects that contain the prompt, generated text, and other information.\n    prompts = [\n        \"Hello, my name is\",\n        \"The president of the United States is\",\n        \"The capital of France is\",\n        \"The future of AI is\",\n    ]\n    outputs = llm.generate(prompts, sampling_params)\n    # Print the outputs.\n    for output in outputs:\n        prompt = output.prompt\n        generated_text = output.outputs[0].text\n        print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    # Add engine args\n    engine_group = parser.add_argument_group(\"Engine arguments\")\n    EngineArgs.add_cli_args(engine_group)\n    engine_group.set_defaults(model=\"meta-llama/Llama-3.2-1B-Instruct\")\n    # Add sampling params\n    sampling_group = parser.add_argument_group(\"Sampling parameters\")\n    sampling_group.add_argument(\"--max-tokens\", type=int)\n    sampling_group.add_argument(\"--temperature\", type=float)\n    sampling_group.add_argument(\"--top-p\", type=float)\n    sampling_group.add_argument(\"--top-k\", type=int)\n    args: dict = vars(parser.parse_args())\n    main(args)\n</code></pre> score.py score.py<pre><code># SPDX-License-Identifier: Apache-2.0\n# Modified by CLAAUDIA, ITS, AAU on 2025-03-04\n    # - Explicitly set the token before initializing LLM:\n\nfrom argparse import Namespace\nfrom vllm import LLM, EngineArgs\nfrom vllm.utils import FlexibleArgumentParser\nimport os\n\nos.environ[\"HUGGING_FACE_HUB_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n\ndef main(args: Namespace):\n    # Sample prompts.\n    text_1 = \"What is the capital of France?\"\n    texts_2 = [\n        \"The capital of Brazil is Brasilia.\",\n        \"The capital of France is Paris.\",\n    ]\n\n    # Create an LLM.\n    # You should pass task=\"score\" for cross-encoder models\n    model = LLM(**vars(args))\n\n    # Generate scores. The output is a list of ScoringRequestOutputs.\n    outputs = model.score(text_1, texts_2)\n\n    # Print the outputs.\n    for text_2, output in zip(texts_2, outputs):\n        score = output.outputs.score\n        print(f\"Pair: {[text_1, text_2]!r} | Score: {score}\")\n\n\nif __name__ == \"__main__\":\n    parser = FlexibleArgumentParser()\n    parser = EngineArgs.add_cli_args(parser)\n    # Set example specific arguments\n    parser.set_defaults(model=\"BAAI/bge-reranker-v2-m3\",\n                        task=\"score\",\n                        enforce_eager=True)\n    args = parser.parse_args()\n    main(args)\n</code></pre>"},{"location":"ai-lab/guides/batch-llm-inference/#batch-reasoning-with-deepseek-r1","title":"Batch Reasoning with DeepSeek R1","text":"<p>vLLM offers support for reasoning models like DeepSeek R1, which are designed to generate outputs containing both reasoning steps and final conclusions. This guide explains how to use the DeepSeek model with batch processing on. It includes setting up the vLLM server, running inference, and using guided decoding for structured outputs.</p>"},{"location":"ai-lab/guides/batch-llm-inference/#step-1-writing-the-inference-script","title":"Step 1: Writing the Inference Script","text":"<p>Create a Python script (<code>run_inference.py</code>) to interact with the vLLM server:</p> <pre><code>from openai import OpenAI\nfrom pydantic import BaseModel\n\n# Modify OpenAI's API key and API base to use vLLM's API server.\nopenai_api_key = \"EMPTY\"\nopenai_api_base = \"http://localhost:8000/v1\"\n\n# Initialize OpenAI client for vLLM\nclient = OpenAI(\n    api_key=openai_api_key,\n    base_url=openai_api_base,\n)\n\n# List available models\nmodels = client.models.list()\nmodel = models.data[0].id  # Assumes the first model is the correct one\n\n# Simple chat completion request\nprompt = \"What is the capital of France?\"\nresponse = client.chat.completions.create(\n    model=model,\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n    extra_body={\"guided_regex\": \"(Paris|London)\"},  # Example of guided decoding\n)\n\nprint(\"Reasoning:\", response.choices[0].message.reasoning_content)\nprint(\"Response:\", response.choices[0].message.content)\n\n# Guided decoding using JSON schema\nclass People(BaseModel):\n    name: str\n    age: int\n\njson_schema = People.model_json_schema()\n\nprompt = \"Generate a JSON with the name and age of one random person.\"\nresponse = client.chat.completions.create(\n    model=model,\n    messages=[{\"role\": \"user\", \"content\": prompt}],\n    extra_body={\"guided_json\": json_schema},\n)\n\nprint(\"Reasoning:\", response.choices[0].message.reasoning_content)\nprint(\"Response:\", response.choices[0].message.content)\n</code></pre>"},{"location":"ai-lab/guides/batch-llm-inference/#step-2-creating-the-slurm-job-script","title":"Step 2: Creating the Slurm Job Script","text":"<p>Create a Slurm batch script (<code>submit_vllm.sh</code>) to run the inference job:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=vllm_reasoning\n#SBATCH --gres=gpu:1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem=32G\n#SBATCH --time=01:00:00\n#SBATCH --output=vllm_output_%j.log\n#SBATCH --error=vllm_error_%j.log\n\n# Path to vLLM container\nVLLM_CONTAINER=\"/ceph/container/vllm-openai_latest.sif\"\n\n# Start the vLLM server in the background\nsingularity exec --nv $VLLM_CONTAINER vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B \\\n    --enable-reasoning --reasoning-parser deepseek_r1 &amp;\n\n# Get the PID of the server\nVLLM_PID=$!\n\n# Wait for server to be ready\necho \"Waiting for vLLM server to start...\"\nwhile ! curl -s http://localhost:8000/v1/models &gt;/dev/null; do\n    sleep 2  # Check every 2 seconds\ndone\n\n# Run inference script\nsingularity exec --nv $VLLM_CONTAINER python3 run_inference.py\n\n# Stop the server after inference is done\necho \"Stopping vLLM server...\"\nkill $VLLM_PID\n</code></pre>"},{"location":"ai-lab/guides/batch-llm-inference/#step-3-submitting-the-job","title":"Step 3: Submitting the Job","text":"<p>Run the following command to submit the job to Slurm:</p> <pre><code>sbatch submit_vllm.sh\n</code></pre>"},{"location":"ai-lab/guides/batch-llm-inference/#step-4-monitoring-and-debugging","title":"Step 4: Monitoring and Debugging","text":"<p>Check job status:</p> <pre><code>squeue --me\n</code></pre> <p>Check job logs:</p> <pre><code>tail -f vllm_output_&lt;job_id&gt;.log\n</code></pre> <p>If there are errors, inspect the error log:</p> <pre><code>tail -f vllm_error_&lt;job_id&gt;.log\n</code></pre> <p>This guide provides the foundation for running batch LLM inference using vLLM on AI-LAB. Explore the official vLLM documentation for further customization and optimizations.</p>"},{"location":"ai-lab/guides/checkpointing/","title":"Checkpointing","text":"<p>On AI-LAB, jobs have a default time limit of 1 hour and a maximum runtime of 12 hours. Once this time limit is reached, your job will be canceled, and any unsaved data will be lost. To prevent data loss, it's important to implement checkpointing, which saves data at regular intervals. Additionally, you can set up automatic requeuing so that your job will restart automatically if it gets canceled, removing the need to manually resubmit it.</p> <p>This guide explains how to set up checkpointing in various frameworks like Python, PyTorch, and TensorFlow, as well as how to configure automatic requeuing for your jobs.</p> <p>Disclaimer</p> <p>Using checkpointing is done at your own risk. This guide is intended as a reference, but saving data via checkpointing is entirely the responsibility of the user. There may be errors or inaccuracies within this guide. If you encounter any issues or discover mistakes, we encourage you to provide feedback so we can improve. You can submit your feedback here.</p>"},{"location":"ai-lab/guides/checkpointing/#checkpointing-methods","title":"Checkpointing methods","text":"<p>Checkpointing allows you to periodically save the state of your job so that it can be resumed later, even after an interruption. Different frameworks have different methods for implementing checkpointing. Below are examples for Python, PyTorch, and TensorFlow. </p> Python checkpointing <p>In Python, you can use the pickle module to periodically save and load the state of your job.</p> <p><pre><code>import pickle\nimport os\n\ndef save_checkpoint(data, filename):\n    \"\"\"Save the checkpoint data to a file.\"\"\"\n    with open(filename, 'wb') as f:\n        pickle.dump(data, f)\n\ndef load_checkpoint(filename):\n    \"\"\"Load the checkpoint data from a file.\"\"\"\n    with open(filename, 'rb') as f:\n        return pickle.load(f)\n\n# Check if there is a checkpoint file\nif os.path.exists('checkpoint.pkl'):\n    # If there is, load the checkpoint\n    data = load_checkpoint('checkpoint.pkl')\n    print(\"Resuming from checkpoint:\")\nelse:\n    # If there isn't, initialize data\n    data = {'counter': 0}\n\ntry:\n    # Simulate some long-running process\n    while True:\n        data['counter'] += 1\n        print(\"Current counter value:\", data['counter'])\n        # Save checkpoint every 5 iterations\n        if data['counter'] % 5 == 0:\n            save_checkpoint(data, 'checkpoint.pkl')\n        # Simulate some work\n        # Replace this with your actual process\n        import time\n        time.sleep(1)\nexcept KeyboardInterrupt:\n    # Save checkpoint if the process is interrupted\n    save_checkpoint(data, 'checkpoint.pkl')\n    print(\"\\nCheckpoint saved. Exiting...\")\n</code></pre> </p> PyTorch checkpointing <p>PyTorch provides native support for saving and loading model and optimizer states during training. More information about PyTorch checkpointing can be found here. Here's an example that shows how to checkpoint during training of a simple neural network:</p> <pre><code>import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\n# Define a simple feedforward neural network\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(784, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Load MNIST dataset\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('data', train=True, download=True,\n                transform=transforms.Compose([\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.1307,), (0.3081,))\n                ])),\n    batch_size=64, shuffle=True)\n\n# Define the model\nmodel = SimpleNN()\n\n# Define the optimizer and loss function\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\n# Checkpoint directory\ncheckpoint_dir = 'checkpoints'\nos.makedirs(checkpoint_dir, exist_ok=True)\n\n##epoch number of steps\nepoch_steps = 20\n\n# Check if there are existing checkpoints\nif os.listdir(checkpoint_dir):\n    # If there are existing checkpoints, load the latest one\n    latest_checkpoint = max([int(file.split('.')[0]) for file in os.listdir(checkpoint_dir)])\n    checkpoint = torch.load(os.path.join(checkpoint_dir, f'{latest_checkpoint}.pt'))\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    start_epoch = latest_checkpoint + 1\nelse:\n    start_epoch = 0\n\n# Training loop\nfor epoch in range(start_epoch, epoch_steps):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        optimizer.zero_grad()\n        data = data.view(data.size(0), -1)\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch}: Loss {loss.item()}')\n\n    # Save checkpoint every epoch\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss\n        }, os.path.join(checkpoint_dir, f'{epoch}.pt'))\n</code></pre> <p></p> TensorFlow checkpointing <p>TensorFlow offers built-in functionality for saving model weights during training using the <code>ModelCheckpoint</code> callback. More information about TensorFlow checkpointing can be found here. Here's an example:</p> <pre><code>    import os\n    import sys\n    import os.path\n    import tensorflow as tf\n    from tensorflow import keras\n\n    #####Get an example dataset - we'll use the MNIST dataset first 1000 examples:\n    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n\n    train_labels = train_labels[:5000]\n    test_labels = test_labels[:5000]\n\n    train_images = train_images[:5000].reshape(-1, 28 * 28) / 255.0\n    test_images = test_images[:5000].reshape(-1, 28 * 28) / 255.0\n\n    ##epoch number of steps for each job:\n    epoch_steps=20\n\n    ####Define a simple sequential model:\n    def create_model():\n        model = tf.keras.models.Sequential([\n            keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n            keras.layers.Dropout(0.2),\n            keras.layers.Dense(10)\n        ])\n\n        model.compile(optimizer='adam',\n                        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n                        metrics=[tf.metrics.SparseCategoricalAccuracy()])\n\n        return model\n\n\n    # Create a new model instance\n    model = create_model()\n\n    # Include the epoch in the file name (uses `str.format`)\n    checkpoint_path = \"checkpoints/{epoch:d}.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    # Create a callback that saves the model's weights every epoch (period=1)\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath=checkpoint_path, \n        verbose=1, \n        save_weights_only=True,\n        period=1)\n\n    # Check if there are existing checkpoints\n    if os.path.exists(checkpoint_dir):\n        # If there are existing checkpoints, load the latest one\n        latest = tf.train.latest_checkpoint(checkpoint_dir)\n        # Load the previously saved weights, if there are any:\n        model.load_weights(latest)\n\n        # Re-evaluate the model\n        loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n        print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n\n        # Get the step number from the latest checkpoint\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir) \n        step = int(os.path.basename(ckpt.model_checkpoint_path).split('.')[0])\n        print('Continuing calculation from epoch step:' + str(step)) \n        # Set the initial epoch to the last recovered epoch\n        initialEpoch=step\n    else:\n        initialEpoch=0\n        # Save the weights for the initial epoch\n        model.save_weights(checkpoint_path.format(epoch=0))\n\n    # Train the model with the new callback\n    model.fit(train_images, \n            train_labels,\n            epochs=epoch_steps, \n            initial_epoch=initialEpoch,\n            callbacks=[cp_callback],\n            validation_data=(test_images,test_labels),\n            verbose=1)\n</code></pre> <p></p>"},{"location":"ai-lab/guides/checkpointing/#breakdown-of-the-key-components","title":"Breakdown of the key components:","text":"<p>First, the script checks if a checkpoint file named <code>checkpoint.pkl</code> exists using <code>os.path.exists()</code>. If the file exists, it loads the checkpoint data using <code>load_checkpoint</code> function and assigns it to data. If not, it initializes data with a dictionary containing a single key <code>counter</code> initialized to 0. </p> <p>Then, it enters an infinite loop (simulating a long-running process), where it increments the <code>counter</code> key of the data dictionary, prints the current counter value, and simulates some work (in this case, a 1-second delay using <code>time.sleep(1)</code>).</p> <p>Every 5 iterations (<code>if data['counter'] % 5 == 0)</code>, it saves the checkpoint by calling <code>save_checkpoint</code>. If the process is interrupted by a keyboard interrupt (Ctrl+C), it saves the current checkpoint and prints a message before exiting.</p>"},{"location":"ai-lab/guides/checkpointing/#breakdown-of-the-key-components_1","title":"Breakdown of the key components:","text":"<p>Checkpoint Directory Setup (line 39-41): Creating a directory for storing checkpoints.</p> <p>Checking for Existing Checkpoints (line 46-55): Checking for existing checkpoints and loading the latest one if available.</p> <p>Saving Checkpoints (line 69-75): Saving the model's state, optimizer's state, and current loss at the end of each epoch to a uniquely named file based on the epoch number.</p>"},{"location":"ai-lab/guides/checkpointing/#breakdown-of-the-key-components_2","title":"Breakdown of the key components:","text":"<p><code>checkpoint_path</code>: Specify the path where checkpoints will be saved. You can include dynamic elements such as epoch number in the file name to differentiate between checkpoints, like <code>checkpoints/{epoch:d}.ckpt</code></p> <p><code>cp_callback</code>: Create a ModelCheckpoint callback, which will save the model's weights at specified intervals during training. You can customize various parameters such as the file path, verbosity, and whether to save only the weights or the entire model.</p> <p><code>model.load_weights(latest)</code>: Before starting training, check if there are existing checkpoints. If so, load the latest one to resume training from the last saved state. This ensures continuity in training even if interrupted.</p>"},{"location":"ai-lab/guides/ci-cd-with-github-actions/","title":"CI/CD with GitHub Actions","text":"<p>Below is a step-by-step guide on how to set up a self-hosted GitHub Actions runner on AI-LAB. This allows you to run CI/CD jobs directly from GitHub on AI-LAB.</p>"},{"location":"ai-lab/guides/ci-cd-with-github-actions/#1-create-a-self-hosted-runner-in-github","title":"1. Create a self-hosted runner in GitHub","text":"<ol> <li>Go to the repository in GitHub where you want to use the runner.</li> <li>Click \u201cSettings\u201d (at the top, depending on GitHub\u2019s UI).</li> <li>Select \u201cActions\u201d in the left menu, then choose \u201cRunners.\u201d</li> <li>Click \u201cNew self-hosted runner.\u201d</li> <li>Choose Linux as the OS and X64 for the architecture.</li> <li>GitHub will display commands you need to run on AI-LAB. </li> <li>Press \"Enter\" to all settings, to get the default setup.</li> <li>Once you run <code>./run.sh</code>, the runner will stay in the foreground and listen for new GitHub jobs. Stop it with Ctrl+C when you\u2019re done testing.</li> </ol>"},{"location":"ai-lab/guides/ci-cd-with-github-actions/#2-create-a-github-actions-workflow","title":"2. Create a GitHub Actions workflow","text":"<ol> <li> <p>Create or edit a file called .github/workflows/ci.yaml in your repository with a minimal workflow:</p> <pre><code>name: AI-LAB test job\non:\n    push:\n    branches:\n        - main\njobs:\n    test-hpc:\n    runs-on: self-hosted\n    steps:\n        - name: Check out repo\n        uses: actions/checkout@v3\n        - name: AI-LAB hostname info\n        run: |\n            sbatch --output=hostname_output.txt --wrap=\"hostname\"\n</code></pre> </li> <li> <p>With the runner, running on AI-LAB, the job should start immediately. Once complete, you can check the output file using: </p> <pre><code>cat actions-runner/_work/ai-lab-data/ai-lab-data/hostname_output.txt\n</code></pre> </li> </ol>"},{"location":"ai-lab/guides/file-handling/","title":"File Handling on AI-LAB","text":"<p>Now that you're logged into AI-LAB, it's time to learn how to navigate and manage your files. This guide will help you understand the file system structure and essential commands for working with files.</p>"},{"location":"ai-lab/guides/file-handling/#understanding-your-environment","title":"Understanding Your Environment","text":"<p>When you log into AI-LAB, you're placed in your user directory located at <code>/ceph/home/domain/user</code>. You can confirm your current location by typing <code>pwd</code>.</p> <p>This directory is your private storage space where you can keep all your files. It's stored on a network file system, so you can access your files from any compute node within the platform.</p>"},{"location":"ai-lab/guides/file-handling/#ai-lab-file-system-structure","title":"AI-LAB File System Structure","text":"<p>Here's how files are organized on AI-LAB:</p> <ul> <li> /ceph AI-LAB's file system <ul> <li> home user home directories <ul> <li> [domain] e.g student.aau.dk <ul> <li> [user] your user directory  </li> </ul> </li> </ul> </li> <li> project shared project directories </li> <li> course directory with course specific material </li> <li> container directory with ready-to-use applications </li> </ul> </li> </ul> <p>For a detailed overview of the AI-LAB storage system, click here.</p>"},{"location":"ai-lab/guides/file-handling/#essential-linux-commands","title":"Essential Linux Commands","text":"<p>AI-LAB runs on Ubuntu Linux, so you'll work primarily through a command-line interface. Don't worry if you're new to Linux - these essential commands will get you started.</p>"},{"location":"ai-lab/guides/file-handling/#navigation-commands","title":"Navigation Commands","text":"Command Description Example <code>pwd</code> Show current directory <code>pwd</code> <code>ls</code> List files and folders <code>ls -la</code> (detailed list) <code>cd</code> Change directory <code>cd /ceph/project</code>"},{"location":"ai-lab/guides/file-handling/#file-and-directory-management","title":"File and Directory Management","text":"Command Description Example <code>mkdir</code> Create directory <code>mkdir my_project</code> <code>rm</code> Remove file <code>rm old_file.txt</code> <code>rm -r</code> Remove directory <code>rm -r old_folder</code> <code>cp</code> Copy file <code>cp file.txt backup/</code> <code>cp -r</code> Copy directory <code>cp -r project/ backup/</code> <code>mv</code> Move/rename <code>mv old_name.txt new_name.txt</code> <code>cat</code> Display file content <code>cat script.py</code>"},{"location":"ai-lab/guides/file-handling/#text-editing-with-nano","title":"Text Editing with Nano","text":"<p>Nano is a beginner-friendly text editor perfect for creating and editing scripts:</p> <pre><code>nano my_script.py  # Create or edit a file\n</code></pre> <p>Nano Keyboard Shortcuts:</p> <ul> <li>Save: <code>Ctrl + O</code>, then <code>Enter</code></li> <li>Exit: <code>Ctrl + X</code></li> <li>Cut line: <code>Ctrl + K</code></li> <li>Paste: <code>Ctrl + U</code></li> <li>Search: <code>Ctrl + W</code></li> <li>Help: <code>Ctrl + G</code></li> </ul>"},{"location":"ai-lab/guides/file-handling/#transferring-files","title":"Transferring Files","text":"<p>You'll often need to move files between your local computer and AI-LAB. Here are the best methods for each operating system.</p> WindowsmacOS/Linux <p></p> <p>Recommended: WinSCP (Graphical Interface)</p> <ol> <li>Download and install WinSCP</li> <li>Open WinSCP and configure the connection:<ul> <li>Host name: <code>ailab-fe01.srv.aau.dk</code> or <code>ailab-fe02.srv.aau.dk</code></li> <li>User name: Your AAU email address</li> <li>Password: Your AAU password</li> </ul> </li> <li>Connect and you'll see a split-screen interface</li> <li>Drag and drop files between your computer (left) and AI-LAB (right)</li> </ol> <p></p> <p>Alternative: Command Line (PowerShell)</p> <pre><code># Upload file to AI-LAB\nscp myfile.txt user@student.aau.dk@ailab-fe01.srv.aau.dk:~/\n\n# Upload entire directory\nscp -r my_project/ user@student.aau.dk@ailab-fe01.srv.aau.dk:~/\n\n# Download file from AI-LAB\nscp user@student.aau.dk@ailab-fe01.srv.aau.dk:~/myfile.txt .\n\n# Download entire directory\nscp -r user@student.aau.dk@ailab-fe01.srv.aau.dk:~/my_project/ .\n</code></pre> <p></p> <p>Command Line with scp</p> <pre><code># Upload file to AI-LAB\nscp myfile.txt user@student.aau.dk@ailab-fe01.srv.aau.dk:~/\n\n# Upload entire directory\nscp -r my_project/ user@student.aau.dk@ailab-fe01.srv.aau.dk:~/\n\n# Download file from AI-LAB\nscp user@student.aau.dk@ailab-fe01.srv.aau.dk:~/myfile.txt .\n\n# Download entire directory\nscp -r user@student.aau.dk@ailab-fe01.srv.aau.dk:~/my_project/ .\n</code></pre> <p>File Transfer Tips</p> <ul> <li>Multiple files: Compress files into a <code>.zip</code> or <code>.tar.gz</code> archive first</li> <li>Hidden files: In WinSCP, enable \"Show hidden files\" in Options \u2192 Preferences \u2192 Panels</li> <li>Network issues: If transfers fail, try the other login node (<code>ailab-fe02</code>)</li> </ul>"},{"location":"ai-lab/guides/file-handling/#creating-shared-project-directories","title":"Creating Shared Project Directories","text":"<p>AI-LAB allows semester groups to collaborate by creating shared project directories in <code>/ceph/project</code>. This guide will help you set up a secure, group-only project directory.</p>"},{"location":"ai-lab/guides/file-handling/#who-can-create-shared-directories","title":"Who Can Create Shared Directories?","text":"<p>Semester Group Requirement</p> <p>You can only create private shared directories with users in your semester group. If you need to collaborate with users outside your semester group, you can create a public project directory (accessible to all AI-LAB users).</p>"},{"location":"ai-lab/guides/file-handling/#step-1-create-your-project-directory","title":"Step 1: Create Your Project Directory","text":"<p>Navigate to the project directory and create your project folder:</p> <pre><code>cd /ceph/project\nmkdir my_project  # Replace 'my_project' with your project name\n</code></pre>"},{"location":"ai-lab/guides/file-handling/#step-2-set-up-group-permissions","title":"Step 2: Set Up Group Permissions","text":""},{"location":"ai-lab/guides/file-handling/#check-your-group","title":"Check Your Group","text":"<p>First, find out which semester group you belong to:</p> <pre><code>groups\n</code></pre> <p>You'll see output like: <code>user@student.aau.dk xx-43-xx-9-01@student.aau.dk</code></p> <p>The semester group is typically the second entry (e.g., <code>xx-43-xx-9-01@student.aau.dk</code>).</p>"},{"location":"ai-lab/guides/file-handling/#set-group-ownership","title":"Set Group Ownership","text":"<p>Assign your project directory to your semester group:</p> <pre><code>chgrp xx-43-xx-9-01@student.aau.dk my_project  # Replace with your actual group\n</code></pre>"},{"location":"ai-lab/guides/file-handling/#set-directory-permissions","title":"Set Directory Permissions","text":"<p>Make the directory accessible only to you and your group members:</p> <pre><code>chmod 770 my_project\n</code></pre> <p>What <code>770</code> means: - 7 (owner): read, write, execute - 7 (group): read, write, execute - 0 (others): no access</p>"},{"location":"ai-lab/guides/file-handling/#enable-group-inheritance","title":"Enable Group Inheritance","text":"<p>Set the setgid bit so new files automatically belong to the group:</p> <pre><code>chmod g+s my_project\n</code></pre>"},{"location":"ai-lab/guides/file-handling/#step-3-verify-your-setup","title":"Step 3: Verify Your Setup","text":"<p>Check that everything is configured correctly:</p> <pre><code>ls -ld my_project\n</code></pre> <p>You should see output like: <pre><code>drwxrws--- 2 your_username xx-43-xx-9-01@student.aau.dk 4096 Sep 17 12:34 my_project\n</code></pre></p> <p>The <code>s</code> in the group permissions indicates the setgid bit is active.</p>"},{"location":"ai-lab/guides/file-handling/#step-4-collaboration-is-ready","title":"Step 4: Collaboration is Ready!","text":"<p>Now your project directory is set up for collaboration:</p> <p>\u2705 Group members can:</p> <ul> <li>Access the directory</li> <li>Read, write, and create files</li> <li>Edit files created by other group members</li> </ul> <p>\u274c Non-group members cannot:</p> <ul> <li>Access the directory</li> <li>See or modify any files</li> </ul>"},{"location":"ai-lab/guides/file-handling/#step-5-handle-file-upload-permissions-optional","title":"Step 5: Handle File Upload Permissions (optional)","text":"<p>When you upload files from your computer, they might not have the correct group permissions. Here's how to fix this:</p>"},{"location":"ai-lab/guides/file-handling/#option-1-manual-fix-quick","title":"Option 1: Manual Fix (Quick)","text":"<p>Fix permissions for uploaded files manually:</p> <pre><code>chmod -R g+rwX /ceph/project/my_project\n</code></pre>"},{"location":"ai-lab/guides/file-handling/#option-2-automatic-fix-recommended","title":"Option 2: Automatic Fix (Recommended)","text":"<p>Set up automatic permission fixing for ongoing collaboration:</p> <p>Create a permission fix script:</p> <pre><code>nano /ceph/project/my_project/fix_permissions.sh\n</code></pre> <p>Add this content: <pre><code>#!/bin/bash\nchmod -R g+rwX /ceph/project/my_project\n</code></pre></p> <p>Make it executable: <pre><code>chmod +x /ceph/project/my_project/fix_permissions.sh\n</code></pre></p> <p>Set up automatic execution: <pre><code>crontab -e\n</code></pre></p> <p>Add this line at the bottom: <pre><code>*/5 * * * * /ceph/project/my_project/fix_permissions.sh\n</code></pre></p> <p>This will automatically fix permissions every 5 minutes.</p>"},{"location":"ai-lab/guides/file-handling/#best-practices-for-collaboration","title":"Best Practices for Collaboration","text":"<ol> <li>Communicate with your group about who's working on what files</li> <li>Use descriptive filenames to avoid conflicts</li> <li>Create subdirectories for different parts of the project</li> <li>Regularly check permissions if files aren't accessible to group members</li> <li>Test access by having another group member try to access the directory</li> </ol>"},{"location":"ai-lab/guides/file-handling/#troubleshooting","title":"Troubleshooting","text":"<p>\"Permission denied\" when group members try to access files:</p> <ul> <li>Run the permission fix script: <code>chmod -R g+rwX /ceph/project/my_project</code></li> </ul> <p>Group members can't see the directory:</p> <ul> <li>Check group ownership: <code>ls -ld my_project</code></li> <li>Verify group membership: <code>groups</code></li> </ul> <p>Files uploaded via WinSCP aren't accessible:</p> <ul> <li>This is normal - use the permission fix script to resolve</li> </ul> <p>Now that you know the basics of file handling, lets proceed to learn how to run jobs on AI-LAB </p>"},{"location":"ai-lab/guides/getting-containers/","title":"Getting Containers for AI-LAB","text":"<p>Most applications on AI-LAB run inside containers - self-contained environments that include all the software and dependencies you need. AI-LAB uses Singularity to run containers.</p>"},{"location":"ai-lab/guides/getting-containers/#what-is-a-container","title":"What is a Container?","text":"<p>A container is like a pre-packaged software environment that includes:</p> <ul> <li>The application (Python, PyTorch, TensorFlow, etc.)</li> <li>All required libraries and dependencies</li> <li>System tools and configurations</li> <li>Everything needed to run your code</li> </ul> <p>Think of it as a complete, portable computer environment that works the same way every time.</p>"},{"location":"ai-lab/guides/getting-containers/#three-ways-to-get-containers","title":"Three Ways to Get Containers","text":"<ol> <li>Use pre-downloaded containers - Quickest option</li> <li>Download containers - For specific versions</li> <li>Build your own container - For custom environments</li> </ol>"},{"location":"ai-lab/guides/getting-containers/#which-method-should-you-choose","title":"Which Method Should You Choose?","text":"Method When to Use Time Required Difficulty Pre-downloaded Getting started, common frameworks Instant Easy Download Need specific version, latest updates 10-20 minutes Easy Build Custom requirements, specific packages 30+ minutes Advanced"},{"location":"ai-lab/guides/getting-containers/#1-pre-downloaded-containers","title":"1. Pre-downloaded Containers","text":"<p>The easiest way to get started is using containers that are already available on AI-LAB. These are stored in <code>/ceph/container</code> and are regularly updated.</p>"},{"location":"ai-lab/guides/getting-containers/#available-containers","title":"Available Containers","text":"<p>Check what's available:</p> <pre><code>ls /ceph/container\n</code></pre> <p>Common containers include:</p> <ul> <li>Python: Basic Python environment</li> <li>PyTorch: Deep learning with PyTorch</li> <li>TensorFlow: Deep learning with TensorFlow</li> <li>MATLAB: MATLAB computational environment</li> </ul>"},{"location":"ai-lab/guides/getting-containers/#using-pre-downloaded-containers","title":"Using Pre-downloaded Containers","text":"<p>You can use these containers directly by referencing their full path:</p> <pre><code># Example: Using PyTorch container\n/ceph/container/pytorch/pytorch_24.09.sif\n</code></pre>"},{"location":"ai-lab/guides/getting-containers/#finding-the-right-container","title":"Finding the Right Container","text":"<p>To see what's in each container directory:</p> <pre><code>ls /ceph/container/pytorch/    # See available PyTorch versions\nls /ceph/container/tensorflow/ # See available TensorFlow versions\n</code></pre>"},{"location":"ai-lab/guides/getting-containers/#2-download-containers","title":"2. Download Containers","text":"<p>If you need a specific version or container not available in the pre-downloaded collection, you can download containers from online repositories.</p>"},{"location":"ai-lab/guides/getting-containers/#popular-container-sources","title":"Popular Container Sources","text":"<ul> <li>NVIDIA NGC Catalog: Optimized containers for AI/ML</li> <li>Docker Hub: Large collection of community containers</li> </ul>"},{"location":"ai-lab/guides/getting-containers/#step-1-find-your-container","title":"Step 1: Find Your Container","text":"<p>NVIDIA NGC Catalog:</p> <ol> <li>Visit NGC Catalog</li> <li>Search for your framework (e.g., \"TensorFlow\", \"PyTorch\")</li> <li>Click \"Get Container\" to get the URL</li> <li>Copy the URL (e.g., <code>nvcr.io/nvidia/tensorflow:24.11-tf2-py3</code>)</li> </ol> <p></p> <p>Docker Hub:</p> <ol> <li>Visit Docker Hub</li> <li>Search for your container</li> <li>Click on \"Tags\" to see available versions</li> <li>Copy the URL (e.g., <code>tensorflow/tensorflow:nightly-jupyter</code>)</li> </ol> <p></p>"},{"location":"ai-lab/guides/getting-containers/#step-2-set-up-singularity-environment","title":"Step 2: Set Up Singularity Environment","text":"<p>Before downloading, configure Singularity for optimal performance:</p> <pre><code># Set up directories for Singularity\nexport SINGULARITY_TMPDIR=\"$HOME/.singularity/tmp/\"\nexport SINGULARITY_CACHEDIR=\"$HOME/.singularity/cache/\"\n\n# Create the directories\nmkdir -p $SINGULARITY_CACHEDIR $SINGULARITY_TMPDIR\n</code></pre>"},{"location":"ai-lab/guides/getting-containers/#step-3-download-the-container","title":"Step 3: Download the Container","text":"<p>Use <code>srun</code> to download the container (this may take 10-20 minutes):</p> <pre><code># Example: Download TensorFlow container\nsrun --mem 40G singularity pull docker://nvcr.io/nvidia/tensorflow:24.03-tf2-py3\n</code></pre> <p>Command explanation:</p> <ul> <li><code>srun --mem 40G</code>: Run on compute node with 40GB memory</li> <li><code>singularity pull</code>: Download and convert container</li> <li><code>docker://</code>: Indicates this is a Docker container URL</li> </ul>"},{"location":"ai-lab/guides/getting-containers/#step-4-use-your-downloaded-container","title":"Step 4: Use Your Downloaded Container","text":"<p>After download completes, you'll find a <code>.sif</code> file in your current directory:</p> <pre><code>ls *.sif  # List downloaded containers\n</code></pre> <p>Use it just like pre-downloaded containers:</p> <pre><code># Example usage\nsrun singularity exec --nv tensorflow_24.03-tf2-py3.sif python my_script.py\n</code></pre>"},{"location":"ai-lab/guides/getting-containers/#3-build-your-own-container-advanced","title":"3. Build Your Own Container (Advanced)","text":"<p>For specialized requirements or custom environments, you can build your own containers using Singularity definition files.</p>"},{"location":"ai-lab/guides/getting-containers/#step-1-create-a-definition-file","title":"Step 1: Create a Definition File","text":"<p>Create a Singularity definition file (<code>.def</code>) that describes your container:</p> <pre><code>nano my_container.def\n</code></pre> <p>Here's a simple example for a Python container:</p> my_container.def<pre><code>Bootstrap: docker\nFrom: ubuntu:20.04\n\n%post\n    # Update system\n    apt-get update\n    apt-get upgrade -y\n\n    # Install Python and pip\n    apt-get install -y python3 python3-pip\n\n    # Upgrade pip\n    pip install --no-cache-dir --upgrade pip\n\n    # Install Python packages\n    pip install --no-cache-dir numpy matplotlib torch\n\n%test\n    # Test that Python works\n    python3 --version\n    python3 -c \"import numpy, matplotlib, torch; print('All packages imported successfully')\"\n</code></pre> <p>Definition file sections: - <code>Bootstrap: docker</code>: Use Docker as the base - <code>From: ubuntu:20.04</code>: Base operating system - <code>%post</code>: Commands to run during build - <code>%test</code>: Commands to test the container</p>"},{"location":"ai-lab/guides/getting-containers/#step-2-set-up-environment","title":"Step 2: Set Up Environment","text":"<p>Configure Singularity for building:</p> <pre><code># Set up directories\nmkdir -p $HOME/.singularity/tmp\nmkdir -p $HOME/.singularity/cache\n\nexport SINGULARITY_TMPDIR=$HOME/.singularity/tmp\nexport SINGULARITY_CACHEDIR=$HOME/.singularity/cache\nexport TMPDIR=$HOME/.singularity/tmp\nexport TEMP=$HOME/.singularity/tmp\nexport TMP=$HOME/.singularity/tmp\n</code></pre>"},{"location":"ai-lab/guides/getting-containers/#step-3-build-the-container","title":"Step 3: Build the Container","text":"<p>Build your container using <code>srun</code>:</p> <pre><code>srun --mem=40G singularity build --fakeroot --tmpdir $SINGULARITY_TMPDIR my_container.sif my_container.def\n</code></pre> <p>This process may take 10-30 minutes depending on the complexity.</p>"},{"location":"ai-lab/guides/getting-containers/#step-4-test-your-container","title":"Step 4: Test Your Container","text":"<p>Test that your container works:</p> <pre><code># Test basic functionality\nsrun singularity exec my_container.sif python3 --version\n\n# Test package imports\nsrun singularity exec my_container.sif python3 -c \"import torch; print('PyTorch version:', torch.__version__)\"\n</code></pre>"},{"location":"ai-lab/guides/getting-containers/#step-5-use-your-container","title":"Step 5: Use Your Container","text":"<p>Use your custom container just like any other:</p> <pre><code>srun singularity exec --nv my_container.sif python3 my_script.py\n</code></pre> <p>Tips for Building Containers</p> <ul> <li>Start simple: Begin with basic containers and add complexity gradually</li> <li>Use <code>--no-cache-dir</code>: Prevents pip from storing package files</li> <li>Test thoroughly: Use the <code>%test</code> section to verify everything works</li> <li>Document your choices: Add comments explaining why you chose specific versions</li> </ul>"},{"location":"ai-lab/guides/getting-containers/#advanced-definition-file-options","title":"Advanced Definition File Options","text":"<p>For more complex containers, you can use additional sections:</p> <ul> <li><code>%environment</code>: Set environment variables</li> <li><code>%runscript</code>: Define what happens when the container runs</li> <li><code>%labels</code>: Add metadata to your container</li> <li><code>%help</code>: Add help text</li> </ul> <p>See the Singularity documentation for complete details.</p> <p>You are now ready to proceed to learn about using containers to run jobs </p>"},{"location":"ai-lab/guides/login/","title":"Logging into AI-LAB","text":"<p>This guide will help you connect to AI-LAB using SSH (Secure Shell). SSH is a secure way to access remote computers over a network.</p>"},{"location":"ai-lab/guides/login/#understanding-ai-lab-access","title":"Understanding AI-LAB Access","text":"<p>AI-LAB has two front-end nodes that act as entry points:</p> <ul> <li>ailab-fe01.srv.aau.dk</li> <li>ailab-fe02.srv.aau.dk</li> </ul> <p>You can connect to either node - they provide the same functionality.</p>"},{"location":"ai-lab/guides/login/#basic-ssh-connection","title":"Basic SSH Connection","text":""},{"location":"ai-lab/guides/login/#step-1-open-your-terminal","title":"Step 1: Open Your Terminal","text":"WindowsmacOSLinux <ul> <li>Open PowerShell (recommended)</li> </ul> <ul> <li>Open Terminal (found in Applications &gt; Utilities)</li> </ul> <ul> <li>Open your preferred terminal application</li> </ul>"},{"location":"ai-lab/guides/login/#step-2-connect-to-ai-lab","title":"Step 2: Connect to AI-LAB","text":"<p>Run one of these commands (replace <code>user@student.aau.dk</code> with your actual AAU email address):</p> <pre><code>ssh -l user@student.aau.dk ailab-fe01.srv.aau.dk\n</code></pre> <p>or</p> <pre><code>ssh -l user@student.aau.dk ailab-fe02.srv.aau.dk\n</code></pre>"},{"location":"ai-lab/guides/login/#step-3-first-time-connection","title":"Step 3: First-Time Connection","text":"<p>The first time you connect, you'll see a security message like this:</p> <pre><code>The authenticity of host 'ailab-fe01.srv.aau.dk (172.21.131.1300)' can't be established.\nED25519 key fingerprint is SHA256:xosJtOSfQyyW16c6RtpN8tAi/91XHCR3GxM9/KJEogg.\nThis key is not known by any other names.\nAre you sure you want to continue connecting (yes/no/[fingerprint])?\n</code></pre> <p>Type <code>yes</code> and press Enter to proceed. This adds AI-LAB to your list of trusted hosts.</p>"},{"location":"ai-lab/guides/login/#step-4-enter-your-password","title":"Step 4: Enter Your Password","text":"<p>When prompted, enter your AAU password. Important: You won't see any characters (like <code>***</code>) as you type - this is normal for security reasons.</p>"},{"location":"ai-lab/guides/login/#step-5-success","title":"Step 5: Success!","text":"<p>When you see a prompt like this, you're successfully logged in:</p> <pre><code>user@student.aau.dk@ailab-fe01:~$\n</code></pre> <p>This means you're now connected to AI-LAB and ready to start working!</p>"},{"location":"ai-lab/guides/login/#setting-up-ssh-shortcuts-recommended","title":"Setting Up SSH Shortcuts (Recommended)","text":"<p>Typing the full server addresses every time can be tedious. You can create shortcuts to make logging in much easier.</p>"},{"location":"ai-lab/guides/login/#step-1-create-or-update-ssh-config-file","title":"Step 1: Create or update SSH Config File","text":"WindowsmacOS/Linux <ul> <li>Navigate to <code>C:\\Users\\[YOUR_USERNAME]\\.ssh\\</code></li> <li>Create or update a file called <code>config</code> (no extension)</li> </ul> <ul> <li>Navigate to <code>~/.ssh/</code> in your terminal</li> <li>Create or update a file called <code>config</code>: <code>touch config</code></li> </ul>"},{"location":"ai-lab/guides/login/#step-2-add-ai-lab-shortcuts","title":"Step 2: Add AI-LAB Shortcuts","text":"<p>Open the config file in a text editor and add these shortcuts (replace <code>user@student.aau.dk</code> with your actual email):</p> ~/.ssh/config<pre><code># AI-LAB login nodes\nHost ailab-1\n    HostName ailab-fe01.srv.aau.dk\n    User user@student.aau.dk\n\nHost ailab-2\n    HostName ailab-fe02.srv.aau.dk\n    User user@student.aau.dk\n\n# AI-LAB via SSH Gateway (for off-campus access)\n# For this to work, you need to have set up AAU MFA (https://www.its.aau.dk/vejledninger/mfa)\nHost ailab-vpn\n    HostName ailab-fe01.srv.aau.dk\n    User user@student.aau.dk\n    ProxyJump user@student.aau.dk@sshgw.aau.dk\n</code></pre>"},{"location":"ai-lab/guides/login/#step-3-test-your-shortcuts","title":"Step 3: Test Your Shortcuts","text":"<p>Save the file and test your new shortcuts:</p> <pre><code>ssh ailab-1\nssh ailab-2\nssh ailab-vpn  # Connect via VPN (off-campus) # For this to work, you need to have set up AAU MFA (https://www.its.aau.dk/vejledninger/mfa)\n</code></pre> <p>Now you can log in with just <code>ssh ailab-1</code> instead of the full command!</p>"},{"location":"ai-lab/guides/login/#troubleshooting","title":"Troubleshooting","text":"Connection refused\" or \"Host unreachable <ul> <li>Check your network: Ensure you're connected to AAU Wi-Fi or VPN</li> <li>Try the other node: Switch between <code>ailab-1</code> and <code>ailab-2</code></li> </ul> Permission denied (publickey,password) <ul> <li>Check your email: Make sure you're using your correct AAU email address</li> <li>Verify password: Ensure you're entering your AAU password correctly</li> </ul> Windows-specific Issues <p>If SSH command is not recognized:</p> <ul> <li>Install OpenSSH for Windows</li> <li>Or use Windows Subsystem for Linux (WSL)</li> </ul> <p>If you can't create the .ssh folder:</p> <ul> <li>Open File Explorer and navigate to <code>C:\\Users\\[YOUR_USERNAME]\\</code></li> <li>Create a new folder named <code>.ssh</code> (with the dot)</li> <li>Create the <code>config</code> file inside this folder</li> </ul> Connection Timeouts <ul> <li>Check VPN: If off-campus, ensure VPN is connected and working</li> <li>Antivirus: Some Antivirus software block SSH - try disabling your Antivirus momentarily </li> </ul> <p>You are now ready to proceed to learn about file handling </p>"},{"location":"ai-lab/guides/monitoring/","title":"Monitoring Your Jobs on AI-LAB","text":"<p>This guide will help you monitor your jobs, check system resources, and troubleshoot issues on AI-LAB.</p>"},{"location":"ai-lab/guides/monitoring/#checking-the-job-queue","title":"Checking the Job Queue","text":"<p>The job queue shows all jobs currently running or waiting for resources.</p>"},{"location":"ai-lab/guides/monitoring/#view-all-jobs","title":"View All Jobs","text":"<pre><code>squeue\n</code></pre> <p>Example output: <pre><code>JOBID   PARTITION       NAME      USER    ST      TIME    NODES   NODELIST(REASON)\n42      gpu             interact  user1   R       6:45:14 1       ailab-l4-01\n43      gpu             training  user2   PD      0:00:00 1       (Priority)\n</code></pre></p>"},{"location":"ai-lab/guides/monitoring/#view-only-your-jobs","title":"View Only Your Jobs","text":"<pre><code>squeue --me\n</code></pre>"},{"location":"ai-lab/guides/monitoring/#understanding-the-output","title":"Understanding the Output","text":"Column Description Example <code>JOBID</code> Unique job identifier <code>42</code> <code>PARTITION</code> Queue partition <code>gpu</code> <code>NAME</code> Job name (set by user) <code>training</code> <code>USER</code> Username <code>user1</code> <code>ST</code> Job state <code>R</code> (running), <code>PD</code> (pending) <code>TIME</code> How long job has been running <code>6:45:14</code> <code>NODES</code> Number of nodes allocated <code>1</code> <code>NODELIST</code> Which node or reason for waiting <code>ailab-l4-01</code> or <code>(Priority)</code>"},{"location":"ai-lab/guides/monitoring/#common-job-states","title":"Common Job States","text":"<ul> <li><code>R</code> (Running): Job is currently executing</li> <li><code>PD</code> (Pending): Job is waiting for resources</li> <li><code>CG</code> (Completing): Job is finishing up</li> <li><code>CD</code> (Completed): Job finished successfully</li> <li><code>F</code> (Failed): Job failed with an error</li> </ul>"},{"location":"ai-lab/guides/monitoring/#checking-compute-node-status","title":"Checking Compute Node Status","text":"<p>Monitor compute nodes to see available resources and system health.</p>"},{"location":"ai-lab/guides/monitoring/#basic-node-information","title":"Basic Node Information","text":"<pre><code>sinfo\n</code></pre> <p>Example output: <pre><code>PARTITION       AVAIL      TIMELIMIT      NODES      STATE             NODELIST\nl4*                up       12:00:00         11       idle     ailab-l4-[01-11]\nvmware             up          10:00          4       idle        vmware[01-04]\n</code></pre></p>"},{"location":"ai-lab/guides/monitoring/#understanding-the-output_1","title":"Understanding the Output","text":"Column Description Example <code>PARTITION</code> Queue/partition name <code>l4*</code>, <code>vmware</code> <code>AVAIL</code> Partition availability <code>up</code> (available) <code>TIMELIMIT</code> Maximum job time <code>12:00:00</code> (12 hours max, 1 hour default) <code>NODES</code> Number of nodes <code>11</code> <code>STATE</code> Node status <code>idle</code>, <code>mix</code>, <code>allocated</code> <code>NODELIST</code> Specific nodes <code>ailab-l4-[01-11]</code>"},{"location":"ai-lab/guides/monitoring/#node-states","title":"Node States","text":"<ul> <li><code>idle</code>: Node is completely free and available</li> <li><code>mix</code>: Node is partially used (some resources available)</li> <li><code>allocated</code>: Node is fully occupied</li> <li><code>down</code>: Node is offline or having issues</li> </ul>"},{"location":"ai-lab/guides/monitoring/#detailed-node-information","title":"Detailed Node Information","text":"<p>Get detailed information about a specific node:</p> <pre><code>scontrol show node ailab-l4-04\n</code></pre> <p>This shows: - CPU allocation and total cores - Memory usage - GPU information - Node features and capabilities</p>"},{"location":"ai-lab/guides/monitoring/#user-friendly-node-summary","title":"User-Friendly Node Summary","text":"<p>For a more intuitive view of system resources:</p> <pre><code>nodesummary\n</code></pre> <p></p> <p>This tool provides:</p> <ul> <li>Visual overview of all nodes</li> <li>Resource utilization (CPU, GPU, memory)</li> <li>Easy-to-read status for each node</li> <li>Quick assessment of system availability</li> </ul>"},{"location":"ai-lab/guides/monitoring/#monitoring-gpu-utilization","title":"Monitoring GPU Utilization","text":"<p>Monitoring GPU usage helps you optimize your jobs and ensure you're getting the most out of the allocated resources.</p>"},{"location":"ai-lab/guides/monitoring/#step-1-start-your-gpu-job","title":"Step 1: Start Your GPU Job","text":"<pre><code># Start a GPU job (example with PyTorch)\nsrun --gres=gpu:1 --mem=24G --cpus-per-task=15 --time=01:00:00 \\\n     singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif \\\n     python3 my_training_script.py\n</code></pre>"},{"location":"ai-lab/guides/monitoring/#step-2-find-your-job-id","title":"Step 2: Find Your Job ID","text":"<p>In another terminal session:</p> <pre><code>squeue --me\n</code></pre> <p>Note your job ID (e.g., <code>1978</code>).</p>"},{"location":"ai-lab/guides/monitoring/#step-3-connect-to-your-running-job","title":"Step 3: Connect to Your Running Job","text":"<pre><code>srun --jobid 1978 --interactive --pty /bin/bash\n</code></pre>"},{"location":"ai-lab/guides/monitoring/#step-4-monitor-gpu-usage","title":"Step 4: Monitor GPU Usage","text":"<p>Inside your job's interactive session:</p> <pre><code># Use the provided GPU monitoring script\npython3 /ceph/course/claaudia/docs/gpu_util.py\n\n# Or use nvidia-smi directly\nnvidia-smi\n</code></pre>"},{"location":"ai-lab/guides/monitoring/#understanding-gpu-metrics","title":"Understanding GPU Metrics","text":"<p>Key metrics to watch:</p> <ul> <li>GPU-Util: Percentage of GPU being used (aim for 70-100% during training)</li> <li>Memory-Usage: How much GPU memory your job is using</li> <li>Temperature: GPU temperature (should stay below 80\u00b0C)</li> <li> <p>Power: Power consumption (indicates workload intensity)</p> <pre><code>+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA L4                      Off |   00000000:01:00.0 Off |                    0 |\n| N/A   44C    P0             36W /   72W |     245MiB /  23034MiB |     90%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  NVIDIA L4                      Off |   00000000:02:00.0 Off |                    0 |\n| N/A   38C    P8             16W /   72W |       4MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   2  NVIDIA L4                      Off |   00000000:41:00.0 Off |                    0 |\n| N/A   41C    P8             16W /   72W |       1MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n...\n\n+------------------------------------------------------------------------------+\n|  GPU    PID     USER    GPU MEM  %CPU  %MEM      TIME  COMMAND               |\n|    0 232843   user@+     236MiB   100   0.1  01:00:20  /usr/bin/python3 tor  |\n+------------------------------------------------------------------------------+\n</code></pre> <p>The most important parameter to notice here is the <code>GPU-Util</code> metric. Here, you can see that the first GPU is operating at 90% GPU utilization. This indicates excellent utilization of the GPU.</p> <p>You can locate which GPU(s) that belongs to your job, by finding your username below <code>USER</code> and the GPU number under <code>GPU</code>. In this case <code>user@+</code> are utilizing GPU number <code>0</code> in the NVIDIA-SMI list.</p> <pre><code>+------------------------------------------------------------------------------+\n|  GPU    PID     USER    GPU MEM  %CPU  %MEM      TIME  COMMAND               |\n|    0 232843   user@+     236MiB   100   0.1  01:00:20  /usr/bin/python3 tor  |\n+------------------------------------------------------------------------------+\n</code></pre> <p>High Utilization (70-100%)</p> <p>For many GPU-accelerated applications like deep learning training or scientific simulations, a high GPU utilization (often around 70-100%) during compute-intensive tasks is considered good. It indicates that the GPU is efficiently processing tasks without significant idle time.</p> <p>Low to Moderate Utilization (10-40%)</p> <p>In some cases, especially when the workload is less intensive or the application is idle waiting for data or other resources, the GPU utilization might be lower (e.g., 10-40%). This doesn't necessarily mean the GPU is underutilized or performing poorly; it could indicate a natural variation in workload or efficient scheduling of tasks.</p> </li> </ul> <p> Congratulations! </p> <p>You've mastered the fundamentals of AI-LAB! If you experience any errors or have feedback, please let us know!.</p>"},{"location":"ai-lab/guides/prerequisites/","title":"Prerequisites","text":"<p>Before you can start using AI-LAB, you need to complete a few essential steps. This guide will walk you through everything you need to prepare for your first AI-LAB session.</p>"},{"location":"ai-lab/guides/prerequisites/#what-is-ai-lab","title":"What is AI-LAB?","text":"<p>AI-LAB is a high-performance computing platform designed specifically for students at Aalborg University. It provides access to powerful GPUs and computing resources for:</p> <ul> <li>Training machine learning models</li> <li>Running deep learning experiments</li> <li>Processing large datasets</li> <li>Conducting research simulations</li> </ul>"},{"location":"ai-lab/guides/prerequisites/#step-1-get-your-user-account","title":"Step 1: Get Your User Account","text":"<p>First, you need to request access to AI-LAB:</p> <ol> <li>Request an account: Fill out the AI-LAB account request form</li> <li>Wait for approval: You'll receive confirmation when your account is ready</li> </ol> <p>Account Requirements</p> <ul> <li>You must be a current student at Aalborg University</li> <li>Your account will be linked to your AAU email address</li> </ul>"},{"location":"ai-lab/guides/prerequisites/#step-2-network-connection","title":"Step 2: Network Connection","text":"<p>AI-LAB is only accessible from the AAU network. More on that topic in the login guide.</p>"},{"location":"ai-lab/guides/prerequisites/#step-3-review-policies","title":"Step 3: Review Policies","text":"<p>Before using AI-LAB, please familiarize yourself with our policies:</p> <ul> <li>Terms and Conditions: Legal terms for using AI-LAB</li> <li>Fair Usage Policy: Guidelines for responsible resource usage</li> </ul>"},{"location":"ai-lab/guides/prerequisites/#key-points-to-remember","title":"Key Points to Remember:","text":"<ul> <li>AI-LAB is for educational and research purposes only</li> <li>No sensitive or confidential data is allowed (use UCloud for sensitive data)</li> <li>GPU resources are shared - be considerate of other users</li> <li>Jobs have time limits - default 1 hour, maximum 12 hours - plan your work accordingly</li> </ul>"},{"location":"ai-lab/guides/prerequisites/#step-4-basic-requirements","title":"Step 4: Basic Requirements","text":""},{"location":"ai-lab/guides/prerequisites/#technical-skills","title":"Technical Skills","text":"<p>While AI-LAB is designed to be user-friendly, some basic knowledge is helpful:</p> <ul> <li>Command line basics: You'll work primarily through a terminal interface</li> <li>Linux fundamentals: AI-LAB runs on Ubuntu Linux</li> <li>File management: Understanding directories, file permissions, and basic commands</li> </ul>"},{"location":"ai-lab/guides/prerequisites/#software-requirements","title":"Software Requirements","text":"<ul> <li>SSH client: Built into most operating systems</li> <li>File transfer tool: For moving files between your computer and AI-LAB<ul> <li>Windows: WinSCP or PuTTY</li> <li>macOS/Linux: Built-in <code>scp</code> command</li> </ul> </li> </ul>"},{"location":"ai-lab/guides/prerequisites/#whats-next","title":"What's Next?","text":"<p> Ready to proceed?</p> <p>With these preparations complete, you're ready to start your AI-LAB journey! Let's log in </p>"},{"location":"ai-lab/guides/requeuing-jobs/","title":"Requeuing jobs","text":"<p>After implementing checkpointing in your script, you have the option to set up automatic job requeuing in case your job gets cancelled. This is done by modifying a bash script that will automatically requeue the job if it's terminated due to exceeding the time limit. You can find an example script, <code>requeue.sh</code>, on AI-LAB at <code>/ceph/course/claaudia/docs/requeue.sh</code>.</p> <p>Disclaimer</p> <p>Using requeuing is done at your own risk. This guide is intended as a reference, but requeuing your jobs is entirely the responsibility of the user. There may be errors or inaccuracies within this guide. If you encounter any issues or discover mistakes, we encourage you to provide feedback so we can improve. You can submit your feedback here.</p> requeue.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=requeue_example\n#SBATCH --time=00:01:00\n#SBATCH --signal=B:SIGTERM@30\n#SBATCH --gres=gpu:1\n#SBATCH --cpus-per-task=15\n#SBATCH --mem=24G\n\n#####################################################################################\n\n# tweak this to fit your needs\nmax_restarts=4\n\n# Fetch the current restarts value from the job context\nscontext=$(scontrol show job ${SLURM_JOB_ID})\nrestarts=$(echo ${scontext} | grep -o 'Restarts=[0-9]*' | cut -d= -f2)\n\n# If no restarts found, it's the first run, so set restarts to 0\niteration=${restarts:-0}\n\n# Dynamically set output and error filenames using job ID and iteration\noutfile=\"${SLURM_JOB_ID}_${iteration}.out\"\nerrfile=\"${SLURM_JOB_ID}_${iteration}.err\"\n\n# Print the filenames for debugging\necho \"Output file: ${outfile}\"\necho \"Error file: ${errfile}\"\n\n##  Define a term-handler function to be executed           ##\n##  when the job gets the SIGTERM (before timeout)          ##\n\nterm_handler()\n{\n    echo \"Executing term handler at $(date)\"\n    if [[ $restarts -lt $max_restarts ]]; then\n        # Requeue the job, allowing it to restart with incremented iteration\n        scontrol requeue ${SLURM_JOB_ID}\n        exit 0\n    else\n        echo \"Maximum restarts reached, exiting.\"\n        exit 1\n    fi\n}\n\n# Trap SIGTERM to execute the term_handler when the job gets terminated\ntrap 'term_handler' SIGTERM\n\n#######################################################################################\n\n# Use srun to dynamically specify the output and error files\nsrun --output=\"${outfile}\" --error=\"${errfile}\" singularity exec --nv /ceph/container/pytorch/pytorch_24.09.sif python torch_bm.py\n</code></pre> <p>In this script, we will run a PyTorch script (located at <code>/ceph/course/claaudia/docs/torch_bm.py</code>) using the PyTorch container <code>/ceph/container/pytorch/pytorch_24.09.sif</code>. You can modify this to run any script or container you need. Key parameters to pay attention to are:</p> <ul> <li><code>#SBATCH --time=00:01:00</code>: This sets the time limit for your job. If your job exceeds this limit, it will be cancelled. If not specified, the default time limit is 1 hour (maximum 12 hours).</li> <li><code>#SBATCH --signal=B:SIGTERM@30</code>: This tells Slurm to send a SIGTERM signal 30 seconds before the job reaches the time limit, giving the job time to handle termination gracefully.</li> <li><code>max_restarts=4</code>: This defines the maximum number of times your job will be automatically requeued if it gets cancelled. In this example, the job will be requeued up to four times before it is finally terminated.</li> </ul>"},{"location":"ai-lab/guides/running-jobs/","title":"Running Jobs on AI-LAB","text":"<p>This guide will teach you how to run computational tasks on AI-LAB using the Slurm job scheduler. Slurm manages all the computing resources and ensures fair access for all users.</p>"},{"location":"ai-lab/guides/running-jobs/#understanding-slurm","title":"Understanding Slurm","text":"<p>Slurm is a job scheduling system that:</p> <ul> <li>Manages resources: Allocates CPUs, GPUs, and memory to your jobs</li> <li>Queues jobs: Organizes jobs when resources are busy</li> <li>Ensures fairness: Prevents any single user from monopolizing resources</li> </ul>"},{"location":"ai-lab/guides/running-jobs/#two-ways-to-run-jobs","title":"Two Ways to Run Jobs","text":"<p>AI-LAB offers two methods for running jobs:</p> <ol> <li>srun - Interactive jobs for testing and debugging</li> <li>sbatch - Batch jobs for longer computations</li> </ol>"},{"location":"ai-lab/guides/running-jobs/#when-to-use-each-method","title":"When to Use Each Method","text":"Method Best For Duration Interaction <code>srun</code> Testing, debugging, quick tasks Short (&lt; 1 hour) Interactive <code>sbatch</code> Training models, long computations Long (&gt; 1 hours) Non-interactive"},{"location":"ai-lab/guides/running-jobs/#using-srun-interactive-jobs","title":"Using srun (Interactive Jobs)","text":"<p><code>srun</code> runs commands interactively on a compute node. Your terminal connects directly to the compute node, making it perfect for testing and debugging.</p>"},{"location":"ai-lab/guides/running-jobs/#basic-srun-example","title":"Basic srun Example","text":"<p>Let's start with a simple test:</p> <pre><code>srun hostname\n</code></pre> <p>This command will:</p> <ol> <li>Request a compute node</li> <li>Run the <code>hostname</code> command on that node</li> <li>Display the result</li> <li>Return you to the front-end node</li> </ol>"},{"location":"ai-lab/guides/running-jobs/#what-youll-see","title":"What You'll See","text":"<p>When you run an srun command, you might see:</p> <pre><code>srun: job 12345 queued and waiting for resources\nsrun: job 12345 has been allocated resources\nailab-l4-01\n</code></pre> <p>This shows:</p> <ul> <li>Your job ID (12345)</li> <li>The job was queued (waiting for resources)</li> <li>Resources were allocated</li> <li>The hostname of the compute node (ailab-l4-01)</li> </ul>"},{"location":"ai-lab/guides/running-jobs/#when-to-use-srun","title":"When to Use srun","text":"<p>\u2705 Good for:</p> <ul> <li>Testing commands and scripts</li> <li>Debugging code</li> <li>Quick computations</li> <li>Interactive exploration</li> </ul> <p>\u274c Not ideal for:</p> <ul> <li>Long-running jobs (hours/days)</li> <li>Jobs that need to run without you being connected</li> <li>Production model training</li> </ul>"},{"location":"ai-lab/guides/running-jobs/#using-sbatch-batch-jobs","title":"Using sbatch (Batch Jobs)","text":"<p><code>sbatch</code> is perfect for longer-running jobs. You create a script with your commands, submit it to the queue, and Slurm runs it when resources are available.</p>"},{"location":"ai-lab/guides/running-jobs/#creating-a-job-script","title":"Creating a Job Script","text":"<p>Let's create a simple job script:</p> <pre><code>nano my_job.sh\n</code></pre> <p>Add this content:</p> my_job.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=my_test_job  # Name of your job\n#SBATCH --output=my_job.out     # Output file\n#SBATCH --error=my_job.err      # Error file\n\n# Your commands go here\nhostname\necho \"Hello from AI-LAB!\"\ndate\n</code></pre>"},{"location":"ai-lab/guides/running-jobs/#understanding-the-script","title":"Understanding the Script","text":"<ul> <li><code>#!/bin/bash</code>: Tells the system to use bash shell</li> <li><code>#SBATCH</code> lines: Slurm directives that configure your job</li> <li>Commands below: What you want to run</li> </ul>"},{"location":"ai-lab/guides/running-jobs/#submitting-the-job","title":"Submitting the Job","text":"<pre><code>sbatch my_job.sh\n</code></pre> <p>You'll see: <pre><code>Submitted batch job 12345\n</code></pre></p>"},{"location":"ai-lab/guides/running-jobs/#what-happens-next","title":"What Happens Next","text":"<ol> <li>Job is queued: Slurm adds your job to the queue</li> <li>Resources allocated: When available, Slurm assigns compute resources</li> <li>Job runs: Your script executes on the compute node</li> <li>Output saved: Results are written to your specified output file</li> </ol>"},{"location":"ai-lab/guides/running-jobs/#checking-results","title":"Checking Results","text":"<p>Once the job completes, check the output:</p> <pre><code>cat my_job.out    # View the output\ncat my_job.err    # View any errors (if empty, no errors occurred)\n</code></pre>"},{"location":"ai-lab/guides/running-jobs/#when-to-use-sbatch","title":"When to Use sbatch","text":"<p>\u2705 Perfect for:</p> <ul> <li>Training machine learning models</li> <li>Long data processing tasks</li> <li>Jobs that take hours or days</li> <li>Running jobs overnight or while you're away</li> </ul> <p>\u274c Not needed for:</p> <ul> <li>Quick tests or debugging</li> <li>Interactive exploration</li> <li>Commands that finish in minutes</li> </ul>"},{"location":"ai-lab/guides/running-jobs/#specifying-job-resources","title":"Specifying Job Resources","text":"<p>Most jobs need specific resources like GPUs, memory, or time limits. You specify these using Slurm options.</p>"},{"location":"ai-lab/guides/running-jobs/#common-resource-options","title":"Common Resource Options","text":"Option Description Example Notes <code>--mem</code> Memory allocation <code>--mem=24G</code> Max 24GB per GPU <code>--cpus-per-task</code> CPU cores <code>--cpus-per-task=15</code> Max 15 CPUs per GPU <code>--gres</code> GPUs <code>--gres=gpu:1</code> Max 4 GPUs per job, max 8 GPUs per user <code>--time</code> Time limit <code>--time=01:00:00</code> 1 hour (HH:MM:SS)"},{"location":"ai-lab/guides/running-jobs/#resource-guidelines","title":"Resource Guidelines","text":"<p>Memory: Request enough memory for your data and model</p> <ul> <li>Small models: <code>--mem=8G</code></li> <li>Large models: <code>--mem=24G</code></li> </ul> <p>CPUs: More CPUs can speed up data loading and preprocessing</p> <ul> <li>Basic: <code>--cpus-per-task=4</code></li> <li>Intensive: <code>--cpus-per-task=15</code></li> </ul> <p>GPUs: Essential for deep learning</p> <ul> <li>Single GPU: <code>--gres=gpu:1</code> (recommended for most users)</li> <li>Multiple GPUs: <code>--gres=gpu:2</code> to <code>--gres=gpu:4</code> (only if your code supports it)</li> </ul> <p>GPU Resource Limits</p> <p>To ensure fair access for all users, AI-LAB enforces two important limits:</p> <ul> <li>Maximum 4 GPUs per job: A single job can request no more than 4 GPUs (e.g., <code>--gres=gpu:4</code> or <code>-G 4</code>)</li> <li>Maximum 8 GPUs per user: Each user can run jobs using a total of up to 8 GPUs simultaneously across all their running jobs</li> </ul> <p>We strongly encourage inexperienced users to allocate only 1 GPU, as most workloads do not speed up automatically with more GPUs. For advanced users who know how to configure multi-GPU training correctly, up to 4 GPUs per job remain available.</p> <p>Time: Set realistic time limits</p> <ul> <li>Quick tests: <code>--time=00:30:00</code> (30 minutes)</li> <li>Training: <code>--time=04:00:00</code> (4 hours)</li> <li>Default: 1 hour (if not specified)</li> <li>Maximum: 12 hours</li> </ul> <p>Multi-GPU Usage</p> <p>You can request multiple GPUs with <code>--gres=gpu:2</code> (up to 4), but only if your code actually uses them. Allocating unused GPUs violates our Fair Usage Policy.</p>"},{"location":"ai-lab/guides/running-jobs/#using-options-with-srun","title":"Using Options with srun","text":"<p>Add options directly to your srun command:</p> <pre><code>srun --mem=24G --cpus-per-task=15 --gres=gpu:1 --time=01:00:00 hostname\n</code></pre>"},{"location":"ai-lab/guides/running-jobs/#using-options-with-sbatch","title":"Using Options with sbatch","text":"<p>Add options as <code>#SBATCH</code> directives in your script:</p> my_job.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=my_training_job\n#SBATCH --output=training.out\n#SBATCH --error=training.err\n#SBATCH --mem=24G\n#SBATCH --cpus-per-task=15\n#SBATCH --gres=gpu:1\n#SBATCH --time=04:00:00\n\n# Your training commands here\npython train_model.py\n</code></pre> <p>Now that you know how to run jobs on AI-LAB, let's delve into how to get applications/containers </p>"},{"location":"ai-lab/guides/using-containers/","title":"Using Containers to Run Jobs","text":"<p>Now that you know how to get containers, let's learn how to use them to run your computational tasks on AI-LAB.</p>"},{"location":"ai-lab/guides/using-containers/#basic-container-usage","title":"Basic Container Usage","text":"<p>To run commands inside a container, you use <code>singularity exec</code> with either <code>srun</code> or <code>sbatch</code>.</p>"},{"location":"ai-lab/guides/using-containers/#running-a-simple-command","title":"Running a Simple Command","text":"<p>Let's start with a basic example using a Python container:</p> <pre><code>srun --mem=24G --cpus-per-task=15 --gres=gpu:1 --time=01:00:00 singularity exec --nv /ceph/container/python/python_3.10.sif python3 -c \"print('Hello from AI-LAB!')\"\n</code></pre> <p>Command breakdown:</p> <ul> <li><code>srun</code>: Run on a compute node with specified resources</li> <li><code>singularity exec</code>: Execute a command inside a container</li> <li><code>--nv</code>: Enable NVIDIA GPU drivers (required for GPU jobs)</li> <li><code>/ceph/container/python/python_3.10.sif</code>: Path to the container</li> <li><code>python3 -c \"print('Hello from AI-LAB!')\"</code>: Command to run</li> </ul>"},{"location":"ai-lab/guides/using-containers/#using-containers-with-sbatch","title":"Using Containers with sbatch","text":"<p>For longer jobs, create a batch script:</p> my_job.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=my_python_job\n#SBATCH --output=my_job.out\n#SBATCH --error=my_job.err\n#SBATCH --mem=24G\n#SBATCH --cpus-per-task=15\n#SBATCH --gres=gpu:1\n#SBATCH --time=01:00:00\n\n# Run Python script in container\nsingularity exec --nv /ceph/container/python/python_3.10.sif python3 my_script.py\n</code></pre> <p>Submit the job:</p> <pre><code>sbatch my_job.sh\n</code></pre> <p>Check the results:</p> <pre><code>cat my_job.out  # View output\ncat my_job.err  # View errors (if any)\n</code></pre>"},{"location":"ai-lab/guides/using-containers/#adding-python-packages","title":"Adding Python Packages","text":"<p>Sometimes you need additional Python packages that aren't included in the container. The best way to handle this is by creating a virtual environment.</p>"},{"location":"ai-lab/guides/using-containers/#quick-setup-guide","title":"Quick Setup Guide","text":"<p>Here's the simplest way to add packages to your container:</p>"},{"location":"ai-lab/guides/using-containers/#step-1-create-virtual-environment","title":"Step 1: Create Virtual Environment","text":"<p>Create a virtual environment in your current directory:</p> <pre><code># Create virtual environment\nsrun singularity exec /ceph/container/pytorch/pytorch_25.08.sif python -m venv --system-site-packages my_venv\n</code></pre> <p>Explanation</p> <p><code>srun</code>: Runs your command on a compute node via Slurm  <code>singularity exec</code>: Executes a command inside the container  <code>/ceph/container/pytorch/pytorch_25.08.sif</code>: The PyTorch container image (you can change the version if needed)  <code>python -m venv</code>: Creates a Python virtual environment  <code>--system-site-packages</code>: Lets your venv see the preinstalled PyTorch packages from the container  <code>~/my_venv</code>: Location of your virtual environment \u2014 this folder will appear in your home directory</p>"},{"location":"ai-lab/guides/using-containers/#step-2-install-additional-packages","title":"Step 2: Install Additional Packages","text":"<p>Install packages in your virtual environment, e.g. numpy pandas matplotlib: </p> <pre><code># Install packages (example: openpyxl)\nsrun singularity exec --nv \\\n     -B ~/my_venv:/scratch/my_venv \\\n     -B $HOME/.singularity:/scratch/singularity \\\n     /ceph/container/pytorch/pytorch_25.08.sif \\\n     /bin/bash -c \"export TMPDIR=/scratch/singularity/tmp &amp;&amp; \\\n                   source /scratch/my_venv/bin/activate &amp;&amp; \\\n                   pip install --no-cache-dir numpy pandas matplotlib\"\n</code></pre> <p>Explanation</p> <p><code>--nv</code>: Enables GPU access (NVIDIA) inside the container  <code>-B ~/my_venv:/scratch/my_venv</code>: \u201cBinds\u201d your local folder <code>~/my_venv</code> into <code>/scratch/my_venv</code> inside the container \u2014 this is where the container can find your environment  <code>-B $HOME/.singularity:/scratch/singularity</code>: Temporary folder for pip\u2019s build files  <code>/bin/bash -c \"...\"</code>: Tells Singularity to open a shell and run multiple commands  <code>source /scratch/my_venv/bin/activate</code>: Activates your virtual environment inside the container  <code>pip install --no-cache-dir openpyxl</code>: Installs your desired package (replace openpyxl with any other)</p>"},{"location":"ai-lab/guides/using-containers/#step-3-verify-packages","title":"Step 3: Verify packages","text":"<p>To verify that your packages installed correctly:</p> <pre><code>srun singularity exec --nv \\\n    -B ~/my_venv:/scratch/my_venv \\\n    /ceph/container/pytorch/pytorch_25.08.sif \\\n    /bin/bash -c \"source /scratch/my_venv/bin/activate &amp;&amp; pip list\"\n</code></pre>"},{"location":"ai-lab/guides/using-containers/#step-4-use-your-virtual-environment","title":"Step 4: Use Your Virtual Environment","text":"<p>Run scripts with your additional packages:</p> <pre><code># Run script with virtual environment\nsrun singularity exec --nv \\\n     -B ~/my_venv:/scratch/my_venv \\\n     /ceph/container/pytorch/pytorch_25.08.sif \\\n     /bin/bash -c \"source /scratch/my_venv/bin/activate &amp;&amp; python my_script.py\"\n</code></pre>"},{"location":"ai-lab/guides/using-containers/#virtual-environment-tips","title":"Virtual Environment Tips","text":"<ul> <li>Use absolute paths when working in shared project directories</li> <li>Always activate the environment before running Python scripts</li> <li>Use <code>--no-cache-dir</code> to save disk space</li> <li>Mount directories with <code>-B</code> to access your virtual environment inside the container</li> </ul>"},{"location":"ai-lab/guides/using-containers/#cancelling-jobs","title":"Cancelling Jobs","text":"<p>Sometimes you need to cancel jobs that are running too long, stuck, or have incorrect parameters.</p>"},{"location":"ai-lab/guides/using-containers/#check-your-jobs-first","title":"Check Your Jobs First","text":"<p>Before cancelling, see what jobs you have running:</p> <pre><code>squeue --me\n</code></pre> <p>This shows all your jobs with their IDs and status.</p>"},{"location":"ai-lab/guides/using-containers/#cancel-a-specific-job","title":"Cancel a Specific Job","text":"<p>To cancel a single job, use its job ID:</p> <pre><code>scancel 12345  # Replace 12345 with your actual job ID\n</code></pre>"},{"location":"ai-lab/guides/using-containers/#cancel-all-your-jobs","title":"Cancel All Your Jobs","text":"<p>To cancel all your jobs at once:</p> <pre><code>scancel --user=$USER\n</code></pre>"},{"location":"ai-lab/guides/using-containers/#common-scenarios","title":"Common Scenarios","text":"<p>Job is stuck or running too long: <pre><code>squeue --me  # Find the job ID\nscancel 12345  # Cancel it\n</code></pre></p> <p>Wrong parameters in batch script: <pre><code>scancel 12345  # Cancel the job\nnano my_job.sh  # Edit the script\nsbatch my_job.sh  # Resubmit with correct parameters\n</code></pre></p> <p>Emergency - cancel everything: <pre><code>scancel --user=$USER  # Cancel all your jobs\n</code></pre></p> <p>Now that you know how to run jobs using containers, let's delve into the last part about monitoring on AI-LAB </p>"},{"location":"ai-lab/guides/video-onboarding-guide/","title":"Video Onboarding Guide","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#full-onboarding-guide","title":"Full onboarding guide","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#01-what-is-ai-lab","title":"01 What is AI-LAB","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#02-how-to-access","title":"02 How to access","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#03-preperations","title":"03 Preperations","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#04-how-to-login","title":"04 How to login","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#05-file-management","title":"05 File management","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#06-running-jobs","title":"06 Running jobs","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#07-containers","title":"07 Containers","text":""},{"location":"ai-lab/guides/video-onboarding-guide/#08-monitoring","title":"08 Monitoring","text":""},{"location":"ai-lab/workshop/1-Introduction-to-ai-lab/","title":"\ud83c\udf93 Welcome to AI-LAB Workshop \ud83c\udf93","text":"<p>This workshop introduces you to the AI-LAB computing platform \u2014 a GPU-powered system for AI and deep learning.</p> <p>Presenter - Frederik Petri Svenningsen Data Scientist, CLAAUDIA \u2013 research data services</p>"},{"location":"ai-lab/workshop/1-Introduction-to-ai-lab/#accessing-ai-lab","title":"Accessing AI-LAB","text":"<p>Before you can log in, you\u2019ll need to complete this application form.</p>"},{"location":"ai-lab/workshop/1-Introduction-to-ai-lab/#workshop-overview","title":"Workshop overview","text":"<p>You\u2019ll learn to:</p> <ul> <li>Log in to AI-LAB securely</li> <li>Navigate the Linux environment</li> <li>Run and monitor jobs using Slurm</li> <li>Use containers for AI workloads</li> <li>Manage resources efficiently</li> </ul> <p>Next: What is AI-LAB \u2192</p>"},{"location":"ai-lab/workshop/10-two-ways-of-running-jobs/","title":"Two ways of running jobs","text":"<p>You can run compute tasks in two main ways on AI-LAB: interactive (srun) or batch (sbatch).</p>"},{"location":"ai-lab/workshop/10-two-ways-of-running-jobs/#1-interactive-job-srun","title":"1\ufe0f\u20e3 Interactive Job \u2013 srun","text":"<p>Runs immediately in your terminal session.</p> <pre><code>srun -u echo \"Hello from compute node\"\n</code></pre> <p>Use for quick tests or debugging.</p> <p><code>-u</code> forces srun to print outputs immediately</p>"},{"location":"ai-lab/workshop/10-two-ways-of-running-jobs/#2-batch-job-sbatch","title":"2\ufe0f\u20e3 Batch Job \u2013 sbatch","text":"<p>Submit a script to run in the background.</p> run.sh<pre><code>#!/bin/bash\necho \"Hello from compute node\"\n</code></pre> <p>Submit it:</p> <pre><code>sbatch run.sh\n</code></pre> <p>Next: Exercise 1 \u2192</p>"},{"location":"ai-lab/workshop/11-exercise-1/","title":"Exercise 1: Run a simple job with srun","text":"<ol> <li> <p>Download workshop files by running this command:</p> <pre><code>ailab --workshop\n</code></pre> </li> <li> <p>Change directory (<code>cd</code>) to <code>workshop</code></p> Hint <pre><code>cd ~/workshop\n</code></pre> </li> <li> <p>Run the script <code>simple_script.py</code> with <code>python3</code> using <code>srun -u</code></p> Hint <pre><code>srun -u python3 simple_script.py\n</code></pre> </li> <li> <p>...and you should get:</p> </li> </ol> <pre><code>...\nSecond 29...\nSecond 30...\nDone after 30 seconds!\n</code></pre> <p>Next: Creating an sbatch Script \u2192</p>"},{"location":"ai-lab/workshop/12-creating-a-sbatch-script/","title":"Creating an sbatch script","text":"<p>Batch scripts tell Slurm what to run and which resources to use.</p>"},{"location":"ai-lab/workshop/12-creating-a-sbatch-script/#creating-a-script","title":"\u270f\ufe0f Creating a script","text":"<p>Create your script using micro or your preferred editor:</p> <pre><code>micro run.sh\n</code></pre> run.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=myjob       \n#SBATCH --time=0:10:00 \n#SBATCH --output=myjob.log\n\necho \"Hello from compute node\"\nsleep 60\necho \"Done sleeping\"\n</code></pre> <p>Save and exit (<code>Ctrl+S</code>, Enter, <code>Ctrl+Q</code>).</p>"},{"location":"ai-lab/workshop/12-creating-a-sbatch-script/#submit-your-script","title":"\ud83d\ude80 Submit your script","text":"<p>Submit the batch script to Slurm:</p> <pre><code>sbatch run.sh\n</code></pre> <p>This command sends your script to the Slurm scheduler, which will run it when resources become available.</p>"},{"location":"ai-lab/workshop/12-creating-a-sbatch-script/#check-the-output","title":"\ud83d\udcc4 Check the output","text":"<p>Once your job completes, check the output file:</p> <pre><code>cat myjob.log\n</code></pre> <p>Next: Exercise 2 \u2192</p>"},{"location":"ai-lab/workshop/13-exercise-2/","title":"Exercise 2: Create and submit a batch script","text":"<p>Practice creating and submitting batch scripts.</p> <ol> <li> <p>Use <code>micro</code> text editor (or any other if you're an experienced Linux user) to open the script <code>run.sh</code> that already exist in the workshop directory.</p> Hint <pre><code>micro run.sh\n</code></pre> </li> <li> <p>In the bottom of the script, add:</p> <pre><code>python3 simple_script.py\n</code></pre> </li> <li> <p>Save it by hitting <code>CTRL + S</code> and then <code>CTRL + Q</code> to exit nano.</p> </li> <li> <p>Submit the job using <code>sbatch</code></p> Hint <pre><code>sbatch run.sh\n</code></pre> </li> <li> <p>Check the job status using <code>squeue --me</code></p> Hint: Make it update every second <pre><code>watch -n1 squeue --me\n</code></pre> </li> <li> <p>Once completed, check the results by printing out the output file using <code>cat</code> command</p> Hint <pre><code>cat myjob.log\n</code></pre> </li> </ol> <p>Next: Allocating Resources \u2192</p>"},{"location":"ai-lab/workshop/14-allocating-resources/","title":"Allocating resources","text":"<p>When running jobs, you can request specific resources like memory, CPUs, and GPUs.</p>"},{"location":"ai-lab/workshop/14-allocating-resources/#system-memory","title":"\ud83d\udcbe System memory","text":"<pre><code>--mem=40G\n</code></pre>"},{"location":"ai-lab/workshop/14-allocating-resources/#cpus","title":"\u2699\ufe0f CPUs","text":"<pre><code>--cpus-per-task=15\n</code></pre>"},{"location":"ai-lab/workshop/14-allocating-resources/#gpus","title":"\ud83c\udfae GPUs","text":"<pre><code>--gres=gpu:1\n</code></pre> <p>GPU Resource Limits</p> <p>To ensure fair access for all users, AI-LAB enforces two important limits:</p> <ul> <li>Maximum 4 GPUs per job: A single job can request no more than 4 GPUs (e.g., <code>--gres=gpu:4</code>)</li> <li>Maximum 8 GPUs per user: Each user can run jobs using a total of up to 8 GPUs simultaneously across all their running jobs</li> </ul> <p>We strongly encourage inexperienced users to allocate only 1 GPU, as most workloads do not speed up automatically with more GPUs.</p>"},{"location":"ai-lab/workshop/14-allocating-resources/#example-allocating-resources-with-srun","title":"\ud83d\ude80 Example: Allocating resources with srun","text":"<pre><code>srun --cpus-per-task=4 --mem=8G --gres=gpu:1 python3 my_script.py\n</code></pre>"},{"location":"ai-lab/workshop/14-allocating-resources/#example-allocating-resources-with-sbatch","title":"\ud83d\udcdd Example: Allocating resources with sbatch","text":"<p>In a batch script, add resource requests using <code>#SBATCH</code> directives:</p> run.sh<pre><code>#!/bin/bash\n#SBATCH --gres=gpu:1         # Request 1 GPU\n#SBATCH --cpus-per-task=4    # Request 4 CPUs\n#SBATCH --mem=8G             # Request 8 GB memory\n\npython3 my_script.py\n</code></pre> <p>Next: Containers \u2192</p>"},{"location":"ai-lab/workshop/15-containers/","title":"Containers on AI-LAB","text":"<p>AI-LAB uses Singularity containers to run applications safely and reproducibly.</p>"},{"location":"ai-lab/workshop/15-containers/#what-are-containers","title":"\ud83d\udce6 What are containers?","text":"<p>Containers bundle:</p> <ul> <li>Application code</li> <li>Libraries and dependencies</li> <li>Configuration files</li> </ul> <p>They ensure your code runs the same everywhere.</p>"},{"location":"ai-lab/workshop/15-containers/#why-containers","title":"\ud83d\udce2 Why containers?","text":"<ul> <li>Designed for HPC environments</li> <li>Runs without admin privileges</li> <li>Uses <code>.sif</code> container files</li> </ul> <p>Next: Getting Containers \u2192</p>"},{"location":"ai-lab/workshop/16-getting-containers/","title":"Getting containers on AI-LAB","text":"<p>You can use preinstalled containers, download them, or create your own.</p>"},{"location":"ai-lab/workshop/16-getting-containers/#pre-downloaded-containers","title":"\ud83c\udfd7\ufe0f Pre-downloaded containers","text":"<p>Stored in:</p> <pre><code>/ceph/container\n</code></pre> <p>List available containers:</p> <pre><code>ailab --list-containers\n</code></pre>"},{"location":"ai-lab/workshop/16-getting-containers/#download-from-ngc-or-docker-hub","title":"\ud83c\udf10 Download from NGC or Docker Hub","text":"<p>Follow this AI-LAB guide for downloading containers from:</p> <ul> <li>NVIDIA NGC</li> <li>Docker Hub</li> </ul>"},{"location":"ai-lab/workshop/16-getting-containers/#build-your-own","title":"\ud83e\uddf1 Build your own","text":"<p>Create a <code>.def</code> file and build your container using Singularity. See AI-LAB\u2019s guide for how to create your own container.</p> <p>Next: Using Containers \u2192</p>"},{"location":"ai-lab/workshop/17-using-containers/","title":"Using containers on AI-LAB","text":"<p>Let's run a simple Python script inside a Singularity container with GPU support.</p>"},{"location":"ai-lab/workshop/17-using-containers/#example-running-a-container-with-srun","title":"\ud83d\ude80 Example: Running a container with srun","text":"<pre><code>srun singularity exec --nv /ceph/container/pytorch/pytorch_25.04.sif python3 gpu_stress.py\n</code></pre>"},{"location":"ai-lab/workshop/17-using-containers/#example-running-a-container-with-sbatch","title":"\ud83d\udcdd Example: Running a container with sbatch","text":"<p>In a batch script, add resource requests using <code>#SBATCH</code> directives:</p> run.sh<pre><code>#!/bin/bash\n\nsingularity exec --nv /ceph/container/pytorch/pytorch_25.04.sif python3 gpu_stress.py\n</code></pre>"},{"location":"ai-lab/workshop/17-using-containers/#understanding-the-singularity-command","title":"\ud83d\udcd6 Understanding the Singularity command","text":"<p>Let's break down what each part does:</p> <ul> <li><code>singularity exec</code>: Tells Singularity to execute something inside the container.</li> <li><code>--nv</code>: Tells Singularity to include NVIDIA libraries. Always use this flag when running GPU-accelerated code so your container can access the GPU.</li> <li><code>/ceph/container/pytorch/pytorch_25.04.sif</code>: The path to your container file. This is a pre-downloaded PyTorch container stored on AI-LAB.</li> <li><code>python3 gpu_stress.py</code>: The command to run inside the container. This executes your Python script using Python 3 from within the container environment.</li> </ul> <p>Next: Exercise 3 \u2192</p>"},{"location":"ai-lab/workshop/18-exercise-3/","title":"Exercise 3: Running a GPU script with containers and resources","text":"<p>Let's try running a Python GPU script inside a PyTorch container with resources allocated.</p> <ol> <li> <p>Inside the workshop directory, you will also find a file called <code>run_container.sh</code></p> </li> <li> <p>Check the file content using <code>cat run_container.sh</code></p> </li> <li> <p>Submit the job using <code>sbatch</code></p> Hint <pre><code>sbatch run_container.sh\n</code></pre> </li> <li> <p>Check the job status using <code>squeue --me</code> and find the JOBID.</p> Hint: How to find the JOBID <p>Here, <code>162841</code> is the JOBID <pre><code>     JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n    162841        l4    myjob ry90cd@i  R      10:25      1 ailab-l4-11\n</code></pre></p> </li> <li> <p>Check the GPU utilization be running the following command:</p> <pre><code>ailab --gpu-util 162841\n</code></pre> <p>Replace <code>162841</code> with your JOBID</p> Hint: Understanding GPU Metrics <p>Key metrics to watch:</p> <p>GPU-Util: Percentage of GPU being used (aim for 70-100% during training) Memory-Usage: How much GPU memory your job is using Temperature: GPU temperature (should stay below 80\u00b0C) Power: Power consumption (indicates workload intensity)</p> <pre><code>+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA L4                      Off |   00000000:01:00.0 Off |                    0 |\n| N/A   44C    P0             36W /   72W |     245MiB /  23034MiB |     90%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  NVIDIA L4                      Off |   00000000:02:00.0 Off |                    0 |\n| N/A   38C    P8             16W /   72W |       4MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   2  NVIDIA L4                      Off |   00000000:41:00.0 Off |                    0 |\n| N/A   41C    P8             16W /   72W |       1MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n...\n\n+------------------------------------------------------------------------------+\n|  GPU    PID     USER    GPU MEM  %CPU  %MEM      TIME  COMMAND               |\n|    0 232843   user@+     236MiB   100   0.1  01:00:20  /usr/bin/python3 tor  |\n+------------------------------------------------------------------------------+\n</code></pre> <p>The most important parameter to notice here is the GPU-Util metric. Here, you can see that the first GPU is operating at 90% GPU utilization. This indicates excellent utilization of the GPU.</p> <p>You can locate which GPU(s) that belongs to your job, by finding your username below USER and the GPU number under GPU. In this case user@+ are utilizing GPU number 0 in the NVIDIA-SMI list.</p> <pre><code>+------------------------------------------------------------------------------+\n|  GPU    PID     USER    GPU MEM  %CPU  %MEM      TIME  COMMAND               |\n|    0 232843   user@+     236MiB   100   0.1  01:00:20  /usr/bin/python3 tor  |\n+------------------------------------------------------------------------------+\n</code></pre> </li> <li> <p>Once completed, cancel all your jobs by using <code>scancel -u $USER</code></p> </li> </ol> <p>Next: Final pointers \u2192</p>"},{"location":"ai-lab/workshop/19-final-pointers/","title":"Final pointers","text":"<p>Congratulations \u2014 you\u2019ve reached the end of the AI-LAB workshop! \ud83c\udf89</p>"},{"location":"ai-lab/workshop/19-final-pointers/#key-reminders","title":"\u2705 Key reminders","text":"<ul> <li>Do not store confidential or sensitive data (type 2 or 3)</li> <li>Jobs must not exceed 12 hours</li> <li>Read the Fair Usage Policy</li> <li>Access resets each August 1st</li> <li>Expect 4 annual maintenance windows</li> </ul>"},{"location":"ai-lab/workshop/19-final-pointers/#need-help","title":"\ud83c\udd98 Need help?","text":"<p>Visit the AAU Service Portal: https://serviceportal.aau.dk</p>"},{"location":"ai-lab/workshop/19-final-pointers/#coming-soon","title":"\ud83d\ude80 Coming soon","text":"<ul> <li>VS Code integration on compute nodes</li> <li>Web-based AI-LAB interface</li> </ul> <p>\ud83c\udf93 Thank you for participating!</p>"},{"location":"ai-lab/workshop/2-what-is-ai-lab/","title":"What is AI-LAB?","text":""},{"location":"ai-lab/workshop/2-what-is-ai-lab/#ai-lab-is-a-gpu-powered-mini-supercomputer-that-lets-students-run-ai-experiments-deep-learning-projects-and-simulations-without-needing-their-own-advanced-hardware","title":"AI-LAB is a GPU-powered mini-supercomputer that lets students run AI experiments, deep-learning projects, and simulations without needing their own advanced hardware.","text":""},{"location":"ai-lab/workshop/2-what-is-ai-lab/#what-you-can-do","title":"\ud83d\udcbb What You Can Do","text":"<p>AI-LAB allows you to:</p> <ul> <li>Train deep learning models on GPU hardware</li> <li>Run AI experiments and simulations</li> <li>Collaborate with classmates or research groups</li> <li>Access powerful resources without owning a GPU</li> </ul>"},{"location":"ai-lab/workshop/2-what-is-ai-lab/#why-use-ai-lab","title":"\ud83d\udd27 Why Use AI-LAB?","text":"<ul> <li>Centralized system: no setup needed</li> <li>Preinstalled environments (PyTorch, TensorFlow, etc.)</li> <li>Fair resource sharing through Slurm</li> <li>Remote access from anywhere</li> </ul>"},{"location":"ai-lab/workshop/2-what-is-ai-lab/#example-use-cases","title":"\ud83e\udde0 Example Use Cases","text":"<ul> <li>Deep learning projects for courses</li> <li>Research prototypes</li> <li>Data processing or simulation workloads</li> </ul> <p>Next: AI-LAB Under the Hood \u2192</p>"},{"location":"ai-lab/workshop/3-ai-lab-under-the-hood/","title":"AI-LAB under the hood","text":"<p>AI-LAB combines specialized hardware and software to deliver high-performance computing for AI workloads.</p> <pre><code>flowchart LR\n  subgraph id1[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Compute nodes&lt;/p&gt;]\n  direction TB\n  A[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\"  width='25' height='25' &gt;ailab-l4-[01-11]&lt;/span&gt;\"]\n  end\n\n  subgraph id2[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 16px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 10px;\"&gt;AI-LAB&lt;/p&gt;]\n  direction TB\n  subgraph id3[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;Front-end nodes&lt;/p&gt;]\n    direction TB\n    G[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;ailab-fe[01-02]&lt;/span&gt;\"]\n    end\n  id3 --&gt; id1 \n\n  subgraph id4[&lt;p style=\"font-family: Barlow, sans-serif; font-weight: 800; font-size: 12px; text-transform: uppercase; color: #221a52; letter-spacing: 1px; margin: 5px;\"&gt;File storage&lt;/p&gt;]\n    direction TB\n    E[\"&lt;span&gt;&lt;img src=\"/assets/img/server.svg\" width='25' height='25'&gt;Ceph&lt;/span&gt;\"]\n    end\n\n  id1 &amp; id3 &lt;--&gt; id4\n  end\n\n  F[&lt;span&gt;&lt;img src=\"/assets/img/person.svg\" width='25' height='25'&gt;User&lt;/span&gt;]-- SSH --&gt; id3\n</code></pre>"},{"location":"ai-lab/workshop/3-ai-lab-under-the-hood/#hardware-overview","title":"\ud83d\udda5\ufe0f Hardware Overview","text":"Component Description Login Nodes 2 nodes for connecting and submitting jobs Compute Nodes 11 powerful machines with GPUs GPUs NVIDIA L4 GPUs (8 per node, 24 GB memory each) Storage Central networked storage via Ceph"},{"location":"ai-lab/workshop/3-ai-lab-under-the-hood/#software-stack","title":"\u2699\ufe0f Software Stack","text":"Layer Tool Purpose Scheduler Slurm Manages compute resources and queues Containers Singularity Isolates applications and dependencies <p>Next: The AI-LAB Workflow \u2192</p>"},{"location":"ai-lab/workshop/4-the-ai-lab-workflow/","title":"The AI-LAB workflow","text":"<p>AI-LAB follows a simple 4-step workflow for running AI experiments efficiently.</p>"},{"location":"ai-lab/workshop/4-the-ai-lab-workflow/#workflow-overview","title":"\ud83d\udd04 Workflow Overview","text":"<ol> <li>Log in from your local computer</li> <li>Upload your code and data</li> <li>Run compute jobs on the GPUs using Slurm</li> <li>View or download your results</li> </ol> <p>Next: Logging into AI-LAB \u2192</p>"},{"location":"ai-lab/workshop/5-logging-into-ai-lab/","title":"Logging into AI-LAB","text":"<p>You connect to AI-LAB using SSH (Secure Shell).</p>"},{"location":"ai-lab/workshop/5-logging-into-ai-lab/#login-nodes","title":"\ud83d\udcbb Login Nodes","text":"<p>There are two frontend nodes:</p> <ul> <li><code>ailab-fe01.srv.aau.dk</code></li> <li><code>ailab-fe02.srv.aau.dk</code></li> </ul> <p>Use either when logging in.</p>"},{"location":"ai-lab/workshop/5-logging-into-ai-lab/#logging-in","title":"\ud83d\udd10 Logging In","text":"<p>Open your terminal (Windows users should use PowerShell) and run:</p> <pre><code>ssh user@student.aau.dk@ailab-fe01.srv.aau.dk\n</code></pre> <p>Replace <code>user@student.aau.dk</code> with your actual AAU email address.</p> <p>The first time you connect, type <code>yes</code> to trust the server fingerprint. Then enter your AAU password (no stars are shown while typing).</p> <p>Having login issues? Check out the troubleshooting guide for solutions.</p> <p>Next: File Handling on AI-LAB \u2192</p>"},{"location":"ai-lab/workshop/6-file-handling-on-ai-lab/","title":"File handling on AI-LAB","text":"<p>All your files are stored in network-mounted directories shared across the system.</p>"},{"location":"ai-lab/workshop/6-file-handling-on-ai-lab/#default-user-directory","title":"\ud83d\udcc2 Default User Directory","text":"<p>Your personal home directory:</p> <pre><code>/ceph/home/[domain]/[user]\n</code></pre>"},{"location":"ai-lab/workshop/6-file-handling-on-ai-lab/#shared-spaces","title":"\ud83d\udc68\u200d\ud83d\udc66\u200d\ud83d\udc66 Shared Spaces","text":"Path Purpose <code>/ceph/project</code> Shared project folders <code>/ceph/course</code> Course-related materials <code>/ceph/container</code> Ready-to-use containers <p>Private project folders can be created among semestergroup members \u2014 follow this guide.</p> <p>Next: Essential Linux Commands \u2192</p>"},{"location":"ai-lab/workshop/7-essential-linux-commands/","title":"Essential Linux commands","text":"<p>AI-LAB runs on Linux \u2014 here are the basics you\u2019ll need.</p>"},{"location":"ai-lab/workshop/7-essential-linux-commands/#navigating-directories","title":"\ud83d\udcc1 Navigating Directories","text":"<pre><code>pwd            # Show current directory\nls             # List files\ncd foldername  # Change directory\n</code></pre>"},{"location":"ai-lab/workshop/7-essential-linux-commands/#managing-files","title":"\ud83d\udcc4 Managing Files","text":"<pre><code>cp file1 file2     # Copy file\nmv file1 folder/   # Move or rename file\nrm file1           # Delete file\nmkdir newfolder    # Create a folder\ncat file.txt       # Display file contents\n</code></pre>"},{"location":"ai-lab/workshop/7-essential-linux-commands/#editing-files","title":"\u270f\ufe0f Editing Files","text":"<p>Use the micro editor:</p> <pre><code>micro myscript.sh\n</code></pre> <ul> <li>Save: <code>Ctrl + S</code> then Enter</li> <li>Exit: <code>Ctrl + Q</code></li> </ul> <p>Next: Transferring Files \u2192</p>"},{"location":"ai-lab/workshop/8-transferring-files/","title":"Transferring files","text":"<p>Use scp (secure copy) to upload and download files between your local computer and AI-LAB.</p>"},{"location":"ai-lab/workshop/8-transferring-files/#uploading-files","title":"\ud83d\udce4 Uploading Files","text":"<pre><code>scp -r myfile.txt user@student.aau.dk@ailab-fe01.srv.aau.dk:~\n</code></pre>"},{"location":"ai-lab/workshop/8-transferring-files/#downloading-files","title":"\ud83d\udce5 Downloading Files","text":"<pre><code>scp -r user@student.aau.dk@ailab-fe01.srv.aau.dk:~/myfile.txt .\n</code></pre> <ul> <li><code>-r</code> copies directories recursively</li> <li><code>~</code> means your home directory on AI-LAB</li> </ul>"},{"location":"ai-lab/workshop/8-transferring-files/#file-managers-recommended","title":"\ud83d\udcbb File managers (recommended)","text":"<p>For Windows users, we recommend WinSCP. </p> <p>For Linux, macOS, or Windows (cross-platform), we recommend Double Commander.</p> <p>Next: Slurm \u2192</p>"},{"location":"ai-lab/workshop/9-slurm/","title":"Slurm","text":"<p>Slurm is the job scheduler that manages compute resources on AI-LAB.</p>"},{"location":"ai-lab/workshop/9-slurm/#what-slurm-does","title":"\ud83e\udde0 What Slurm Does","text":"<ul> <li>Allocates CPUs, GPUs, and memory to jobs</li> <li>Queues jobs when resources are busy</li> <li>Ensures fairness among users</li> </ul>"},{"location":"ai-lab/workshop/9-slurm/#useful-commands","title":"\ud83d\udd0d Useful Commands","text":"<pre><code>squeue          # View all jobs\nsqueue --me     # View your jobs\nsinfo           # Show node status\nnodesummary     # Display resource allocations\n</code></pre> <p>Next: Two Ways of Running Jobs \u2192</p>"},{"location":"external-hpc/","title":"External HPC Facilites","text":"<p>In addition to the HPC platforms that we provide locally at AAU, users can gain access to several powerful platforms made available through national and european cooperation. We encourage all users to reach out for these resources - especially if they have large or continuous long-stretched resource needs. </p>"},{"location":"external-hpc/#consider-applying-for-ressources-on-an-external-hpc-facility-if","title":"Consider applying for ressources on an external HPC facility if:","text":"<ul> <li> <p>You have a concrete research project which requires HPC-ressources.</p> </li> <li> <p>You need more compute time time, than you can acquire in our local platform portfolio.</p> </li> <li> <p>You need a specific resource type that is not available in our local platform portfolio.</p> </li> </ul>"},{"location":"external-hpc/#resource-providers","title":"Resource providers","text":""},{"location":"external-hpc/#deic-hpc-ressources","title":"DeiC HPC ressources","text":"<ul> <li> National resource pool</li> <li> Available via applications to DeiC calls (abbr. Danish e-infrastructure Consortium).</li> <li>Learn more  DeiC HPC resources.</li> </ul> <p>Open calls for DeiC's National HPC ressources</p> <p>Call \"H2-2026\" is open from the 13th of January 2026, and will close 10th of March 2026.</p> <p>The platforms in question are: UCloud, Sophia, GenomeDK, Computerrome 2 and LUMI.</p> <ul> <li> <p>Find more information on CLAAUDIA's page dedicated to this  DeiC HPC resources.</p> </li> <li> <p>Find the official call page  DeiC \"H2-2026\".</p> </li> </ul>"},{"location":"external-hpc/#eurohpc-resources","title":"EuroHPC resources","text":"<ul> <li> European resource pool </li> <li> Available via applications to EuroHPC calls.</li> <li>Learn more  EuroHPC resources</li> </ul> <p>Open calls for EuroHPC ressources</p> <p>Calls open and close on a continuous basis - learn more on our EuroHPC section</p>"},{"location":"external-hpc/#questions","title":"Questions","text":"<p>If you have any questions regarding these applications - get in touch with the CLAAUDIA team via serviceportal.aau.dk.</p>"},{"location":"external-hpc/deic-resources/","title":"DeiC's National Resources","text":"<p>DeiC is the overarching national body responsible for coordinating national HPC efforts on across all the danish universities. Among other things, they are responsible for distributing compute time on national HPC facilities.</p> <ul> <li> <p>DeiC grants a portion of it's resources to the danish universities, for the purpose of providing direct access for their researchers. These are the local resources to the national HPC facilities.</p> </li> <li> <p>Another portion is reserved for a larger national resource pool, from which researchers can apply twice a year.</p> </li> </ul> <p>Call open: Possible to apply for national resources</p> <p>Call \"H2-2026\" is open from the 13th of January 2026, and will close 10th of March 2026. </p> <p>The platforms in question are: UCloud, Sophia, GenomeDK, Computerrome 2 and LUMI.</p> <p>Find the official call page  DeiC \"H2-2026\".</p> <p>Which HPC platforms can be applied to?</p> <p>The national HPC facilities are those in which DeiC has a stake and are provided to all universities via the national and local resource pools.</p> <ul> <li>DeiC Interactive HPC: UCloud</li> <li>DeiC Throughput HPC: Computerome, GenomeDK, Sophia</li> <li>LUMI Capability HPC: LUMI</li> </ul>"},{"location":"external-hpc/deic-resources/#applications-to-the-national-resource-pool","title":"Applications to the national resource pool","text":"<p>Objective: To allow researchers to apply for medium-large sized resource grants</p> <p>Opens: January/July</p> <p>Deadline: March / September</p> <p>Grant decision: June / December</p> <p>Proces:</p> <p>In the beginning of the year a new call is made available and researchers have a 3-month window in which they can apply. When the window ends there is a period, where a scientific committee evaluates the applications that have been submitted based on predefined criteria. After this proces has been completed, applicants receive a response on the decision - 6 months after the call opened. This cycle repeats twice a year.</p> <p>How to apply:</p> <p>The national application calls are always announced on DeiC's website - look for the call text (pdf), to learn about available resources, the proces, etc. Applications are submitted through the e-grant service (structured as an application form with a series of questions). It's possible to get an overview of these questions by logging in to the platform, or viewing see DeiC's guide on using the service). Further it can also be useful to read the section \"Assessment criteria\" of the official process description.</p> <p>Questions regarding national HPC grants</p> <p>If you have questions about an application to a national grant - reach out to CLAAUDIA via serviceportal.aau.dk.</p> <p>If you have questions regarding an existing national grant - reach out to DeiC's HPC back office through their service desk.</p>"},{"location":"external-hpc/deic-resources/#applications-to-the-local-resource-pool","title":"Applications to the local resource pool","text":"<p>Objective: Testing purposes - but grants are also handed out in modest amounts for regular project work</p> <p>Deadline: None (continuous handouts)</p> <p>Grant decision: Typically same day</p> <p>Proces:</p> <p>In the beginning of every year CLAAUDIA receives an amount of resources to hand out to researchers, who wish to use one of the national platforms. Overall our objective is to make the most of these resources - we aim to strike a balance between maximum utilisation, whilst retaining general availability for our users throughout the year.</p> <p>How to apply:</p> <ul> <li>UCloud: See our \"How to acess\" page for UCloud.</li> <li>Computerome, GenomeDK, Sophia: Fill out the application form.</li> <li>LUMI: Fill out the application form.</li> </ul> <p>Questions regarding the local pool for national HPC facilities</p> <p>Reach out to CLAAUDIA via serviceportal.aau.dk.</p>"},{"location":"external-hpc/eurohpc-resources/","title":"EuroHPC resources","text":"<p>EuroHPC is the body responsible for coordinating HPC efforts on the european level. There is a number of calls from which HPC-resources can be acquired. The following is a brief summary of the official page for EuroHPC access calls.</p>"},{"location":"external-hpc/eurohpc-resources/#which-hpc-platforms-can-be-applied-to","title":"Which HPC platforms can be applied to?","text":"<p>Find an overview of the HPC facilities accessible with EuroHPC resources on EuroHPC page \"Our Supercomputers\".</p> <p>EPICURE</p> <p>Together with a EuroHPC grant it is also possible to apply for HPC expert assistance from EPICURE. This is in-depth support from an expert user, who will sit down with you and help port your application to the HPC facility, help you with code refactoring, benchmarking and optimization in order to improve performance and enable scaling across multiple nodes.</p>"},{"location":"external-hpc/eurohpc-resources/#applicatons-to-eurohpc","title":"Applicatons to EuroHPC","text":"<p>There are multiple calls throughout the year. Find them in the table below:</p> Access call Objective Deadline Grant decision Benchmark access For testing your software on the facility and benchmarking it to estimate how many resources you need. Every month 2-3 weeks Development access For testing your software on the facility and benchmarking it to estimate how many resources you need. Every month 2-3 weeks Regular access Regular project work handouts Late march / late september 4 months Extreme Scale For very large resource needs. 2 times each year 6 months AI for Science and Collaborative EU projects Intended for projects that focus on AI/ML - especially foundation models and generative AI Every two months 1 month <p>Assistance with writing applications to EuroHPC</p> <p>The Danish National Competency Centre for HPC provides support for researchers interested in submitting applications to EuroHPC. Their guidance includes selecting an HPC facility that fits your objectives together with an appropriate resource type. They give detailed advice before submitting applications to EuroHPC. </p> <p>If you are interested in this oppurtunity - reach out to them here </p>"},{"location":"external-hpc/lumi/","title":"LUMI","text":"<p>LUMI is a supercomputer located in Kajaani, Finland and ranks among the world's Top 10 supercomputers according to the Top 500 list. The true power of the system lies in it's oppurtunity to scale jobs massively, but we also want to encourage our users to experiment with the system, and to think of it as an extension of the compute capacity available to them as researchers at AAU.</p> <p>Call open: Possible to apply for national resources</p> <p>Call \"H2-2026\" is open from the 13th of January 2026, and will close 10th of March 2026.</p> <ul> <li> <p>Find more information on CLAAUDIA's page dedicated to this  DeiC HPC resources.</p> </li> <li> <p>Find the official call page  DeiC \"H2-2026\".</p> </li> </ul>"},{"location":"external-hpc/lumi/#access","title":"Access","text":"<p>The system is funded by EuroHPC and the LUMI consortium which Denmark is a member of. For this reason CLAAUDIA can provide AAU-users with direct access to the system. </p>"},{"location":"external-hpc/lumi/#recommendations-for-acquiring-compute-time-on-lumi","title":"Recommendations for acquiring compute time on LUMI","text":"<p>Acquiring LUMI-resources should always be a two step proces:</p> <ol> <li> <p>Acquire resources for testing out the system: </p> <p>It is always good to do a test run on the system prior to reaching out for a larger grant. Being able to demonstrate that you are able to utilise the system effectivly, and that your project fits the system, will greatly help your chances of being awarded the resources. Further acquiring too large a resource, which is left unused, might make this resource unavailable to others who might have been able to put it to good use.</p> <p>Make use of one of the following:</p> <ul> <li> <p>AAU's local resource pool: Fill out our application form.</p> </li> <li> <p>EuroHPC: Read more on our page dedicated to this option.</p> </li> </ul> </li> <li> <p>Acquire resources for actual project work: </p> <p>When you have demonstrated that your applicaiton is fit for the system, you can reach out for a larger grant.</p> <p>Make use of one of the following:</p> <ul> <li> <p>AAU's local resource pool: Fill out our application form. Suitable for modest/large grants, depending on our budget.</p> </li> <li> <p>DeiC's national resource pool: Read more on our page dedicated to this option.</p> </li> <li> <p>EuroHPC: Read more on our page dedicated to this option.</p> </li> </ul> </li> </ol> <p>LUMI's resource cutter</p> <p>In order to ensure consistency in the availability of resources, LUMI has imposed a resource cutting mechanism that affects projects that run for more than 6 months (ie. projects with a shorter lifespan are not affected). If 40 % of the allocated resources have not been consumed within 6 months, an amount up to 40 % is cut from the total allocation. To clarify:</p> <ul> <li> <p>If the project has consumed 39 % of the total allocation after 6 months, 1 % is cut.</p> </li> <li> <p>If the project has consumed 45 % of the total allocation after 6 months, nothing is cut.</p> </li> <li> <p>If the project's lifespan is 6 months or shorter, nothing is cut.</p> </li> </ul>"},{"location":"external-hpc/lumi/#user-support","title":"User support","text":"<p>User support for the system is provided jointly by CLAAUDIA and the LUMI User Support Team (LUST).</p> <p>With a EuroHPC grant it is possible to apply for in-depth, HPC-expert assistance from the Epicure project.</p>"},{"location":"external-hpc/lumi/#software","title":"Software","text":"<p>LUMI utilises two main software components:</p> <ul> <li>Slurm queueing system for distributing ressources.</li> <li>Singularity container framework for containerising software.</li> </ul> <p>Users familiar with AI Cloud or AI-LAB will find that operating the system a familiar experience.</p>"},{"location":"external-hpc/lumi/#hardware","title":"Hardware","text":""},{"location":"external-hpc/lumi/#compute-nodes","title":"Compute nodes","text":"<p>LUMI consists of multiple compute partitions. Two of the main ones are:</p> Partition Number of nodes Purpose Node configuration LUMI-C 2978 Scaleable, demanding CPU operations 128 cores AMD EPYC with different RAM capacities 256, 512 and 1024 GB LUMI-G 2048 Scaleable, demanding GPU operations 4 x AMD MI250x GPU's (128 GB GPU-RAM each) <p>The table above is intended for the purpose of providing a rough overview of the hardware.  A more complete overview can be found in the official LUMI documentation</p> <p>A note on AMD GPU hardware</p> <p>The AMD ROCM ecosystem has matured a lot in the recent years, and in most cases Nvidia-supported code can be ported to an AMD-system with only minor tweaks.</p>"},{"location":"external-hpc/lumi/#network","title":"Network","text":"<p>All compute nodes are equipped with an high-speed interconnect which ensures high transfer speeds between compute nodes and storage partitions.</p> <ul> <li>Bandwidth measurements between storage and compute nodes</li> </ul>"},{"location":"external-hpc/lumi/#storage","title":"Storage","text":"<p>LUMI also several different storage partitions serving different purposes. Users should note that these have different storage quotas, and different billing rates, ie. the allocated storage units <code>TB/hrs</code> are spent at different rates, depending on the storage partition is being used.</p> <ul> <li>Recommendations on using the storage partitions</li> </ul>"},{"location":"external-hpc/lumi/#using-the-system","title":"Using the system","text":""},{"location":"external-hpc/lumi/#before-logging-in","title":"Before logging in","text":"<p>Assuming that you have decided to make use of AAU's local resource pool, follow the instructions in the letter of approval, sent out following your resource application. This involves completing AAU's identity verification procedure and uploading an SSH key to the system.</p>"},{"location":"external-hpc/lumi/#log-in-to-the-system","title":"Log in to the system","text":"<p>Log in according to official instructions. Please know that after uploading your SSH-key, you may need to wait ~20 minutes for the server to synchronise.</p>"},{"location":"external-hpc/lumi/#looking-around","title":"Looking around","text":"<p>Optionally <code>git clone</code> our LUMI-starter-pack: <pre><code>git clone https://github.com/aau-claaudia/lumi-starter-pack.git\n</code></pre></p> <p>LUMI's operating system CrayOS is a variant of Linux, and the system can thus be navigated using regular GNU/Linux commands.</p> <p>LUMI uses Modules to manage software environments. Loading modules essentially just alters the <code>$PATH</code> variable, allowing you to access additional software and/or versions. Learn about using modules here.</p> <p>Each time the user logs in to the system, the <code>lumi-tools</code>-module is automatically loaded, giving you access to commands like <code>lumi-workspaces</code>, <code>lumi-allocations</code>, <code>lumi-check-quota</code>, which will allow you to inspect your project and it's resource consumption.</p>"},{"location":"external-hpc/lumi/#transfer-your-files","title":"Transfer your files","text":"<p>Transfer your files according to the official instructions. We recommend Rsync for it's ability to continue a transfer if gets interrupted.</p> <p>Storage units are spent continously</p> <p>Please be mindful of the fact that storage units are spent continuously. There's no need to constantly move files around, but we ask you to be mindful of your storage quota, and to get in touch with us if you are nearing the limits of your quota. We will likely be able to help you find more resources.</p>"},{"location":"external-hpc/lumi/#prepare-software-environment","title":"Prepare software environment","text":"<p>We recommend creating Singularity images using the tool Cotainr, which has been designed with LUMI in mind, eg. it has the flag <code>--system=lumi-g</code> to help you collect the correct modules.</p> <p>You can also find pre-built container images in: <code>/appl/local/containers/sif-images</code></p>"},{"location":"external-hpc/lumi/#run-your-first-job","title":"Run your first job","text":"<p>It is generally recommended to launch your jobs with batch-scripts. We provide the following example, which you can use as a basis for your own batch scripts.</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=torch_bm\n#SBATCH --account=project_415001489\n#SBATCH --partition=small-g\n#SBATCH --gpus=1\n#SBATCH --cpus-per-task=15\n#SBATCH --time=01:00:00\n#SBATCH --output=out.%x_%j\n#SBATCH --error=err.%x_%j\n\n# Directories\nPROJECT=\"/project/$SLURM_JOB_ACCOUNT\"\nSCRATCH=\"/scratch/$SLURM_JOB_ACCOUNT\"\nFLASH=\"/flash/$SLURM_JOB_ACCOUNT\"\nmkdir -p $PROJECT $SCRATCH $FLASH\n\n# Container image (here we are targetting one that comes preinstalled on the system)\nlumi_images=\"/appl/local/containers/sif-images\"\nlumi_pytorch_base=\"$lumi_images/lumi-pytorch-rocm-6.2.3-python-3.12-pytorch-v2.5.1.sif\"\n\nCONTAINER=\"$lumi_pytorch_base\"\n\n# Script\nSCRIPT=\"$PROJECT_DIR/torch_bm.py\"\n\n# The command to execute on the node(s)\nsrun --chdir=\"$PROJECT_DIR\" singularity exec --bind=\"$PROJECT_DIR,$SCRATCH_DIR,$FLASH_DIR\" $CONTAINER bash -c \"\\$WITH_CONDA; python3 $SCRIPT\"\n</code></pre> <p>Consider making the following adjustments:</p> <ul> <li>Decide on a good naming convention for your runs. Pass this to <code>--job-name</code>.</li> <li>Find your project account number using the command <code>lumi-workspaces</code>. Pass this to the <code>--account</code> parameter.</li> <li>Run the job on an appropriate compute partition:<ul> <li>View the partitions with the command: <code>sinfo -o \"%25P %5D %l\"</code></li> <li>Read about the compute hardware in the official documentation.</li> </ul> </li> <li>Replace the paths to your <code>CONTAINER</code> and <code>SCRIPT</code>.</li> </ul> <p>Finally run this batch-script with <code>sbatch torch_bm.sh</code> (or whatever you called the file).</p>"},{"location":"external-hpc/lumi/#monitor-the-job","title":"Monitor the job","text":"<p>Confirm that it is running with:  <pre><code>squeue --me\n</code></pre> If you are running a GPU-demanding job; find the <code>jobid</code> from the <code>squeue</code> command and run the following to monitor the GPU-activity: <pre><code>srun --jobid=7100665 rocmi-smi\n</code></pre></p>"},{"location":"removed-for-now/definition-library/","title":"Definition library","text":""},{"location":"removed-for-now/definition-library/#computing-definitions","title":"Computing definitions","text":"HPC (High Performance Computing) <p>High-performance computing (HPC) involves the use of powerful computing resources to perform computationally demanding tasks that are beyond the capability of traditional computing systems. HPC is used to process large datasets, perform simulations, and run resource-intensive applications, such as modelling climate patterns, simulating molecular behaviour, analysing genetic data, designing and testing products and structures, simulating fluid dynamics, optimizing manufacturing processes, identifying trends, and making predictions. HPC allows processing and analysis of complex data, leading to faster discoveries, more efficient processes, and better decision-making.</p> Cloud computing <p>All the HPC systems presented on the HPC Matchmaker are systems accessible in the cloud. Cloud computing refers to on-demand delivery and access to computing resources -like applications, servers, or storage - via the Internet. This way the user can access the resources through their local machine from any location, which results in high accessibility and convenience of use. In the context of data analysis, cloud services allow users to perform high-demanding computational tasks in a relatively short time.</p> Parallel processing <p>Parallel processing is the technique of dividing a single task into smaller parts that can be executed simultaneously on multiple processors or computing systems. It is often used in HPC to speed up computations and increase efficiency. The hardware component crucial for enabling parallel processing is GPU.</p> Virtual machine (VM) <p>A virtual machine (VM) is a software environment that emulates a physical computer, including hardware components such as a CPU, memory, and storage. VMs are commonly used in HPC to create isolated environments for running scientific applications, providing users with the flexibility to customize and configure the environment to their specific needs without interfering with other users or applications running on the same hardware.</p>"},{"location":"removed-for-now/definition-library/#hardware-components-definitions","title":"Hardware components definitions","text":"Central Processing Unit (CPU) <p>The Central Processing Unit - CPU - is the primary component of a computer that performs arithmetic, logic, and input/output operations. It is often referred to as the 'brain' of the computer. HPC systems typically use multiple CPUs or multicore processors to perform large-scale calculations in parallel, allowing for much faster processing of data and computation than can be achieved with a single CPU.</p> Graphics Processing Unit (GPU) <p>The GPU (Graphics Processing Unit) is a specialized processor optimized for parallelizable tasks, such as image processing, scientific simulations, and machine learning. Unlike a CPU, which is optimized for single-threaded performance, a GPU can perform many computations simultaneously, making it ideal for the large-scale data processing needed in HPC. GPUs can be used alone or with CPUs to accelerate specific calculations, and many HPC systems have numerous GPUs to achieve maximum computational power.</p> HPC Memory <p>Memory in high-performance computing plays a great role in providing fast and temporary storage of data to support data-intensive tasks. Memory stores the currently processed data in the system, which is especially important for simultaneous tasks run in parallel, where holding extensive and large data sets it's crucial and very important.</p> HPC Storage <p>While storage on a regular local machine means long-term saving the data in the local drive for easy and fast access to it, the storage systems in HPC are slightly different. Since high-performance computing allows performing multiple tasks in parallel, the role of storage is to provide a vast I/O (input/output) to be able to scale out with the compute and enable the CPUs to 'work', while not overloading with data.</p>"},{"location":"removed-for-now/definition-library/#computing-infrastructure-definitions","title":"Computing infrastructure definitions","text":"Cluster <p>A cluster is a group of computers that are connected to work as a single system. It is often used in HPC to distribute workloads across multiple systems to increase performance and processing power.</p> Node <p>In the context of a cluster, a node is a single computer within the cluster that performs computations and communicates with other nodes in the cluster.</p> Front-end node <p>The front-end node is used for logging into the platform, accessing your files, and starting jobs on the compute nodes. The front-end node is a relatively small server which is not meant for performing heavy computations; only light-weight operations such as transferring files to and from AI-LAB and defining and launching job scripts.</p>"},{"location":"removed-for-now/definition-library/#system-environment-definitions","title":"System environment definitions","text":"Command-line <p>The command-line is a text-based interface used to interact with a computer system or program. Users enter commands and parameters to execute operations, typically without the use of a graphical user interface.</p> Graphical User Interface (GUI) <p>GUI (Graphical User Interface) is a type of user interface that uses visual representations of controls and elements to interact with a computer program or system. It allows users to interact with software in a more intuitive and user-friendly way compared to command-line interfaces.</p> Linux <p>All HPC resources available through Aalborg University use Linux. Linux is a popular open-source operating system based on the Unix operating system. It is widely used in HPC environments due to its flexibility, performance, and ability to be customized for specific use cases.</p> Slurm <p>Slurm is a management and job-scheduling queue system, which is used for Linux clusters. It requires users to specify commands and resources needed to run the job. Then, Slurm prioritizes the job according to prompted tasks and the resource availability, and adds the job to the queue, among other user's requests. Slurm is utilized in AI Cloud HPC.</p> Containerisation <p>Containerisation refers to the process of creating isolated software environments that contain all the necessary dependencies and configurations needed to run an application. Containers provide a lightweight and portable solution for deploying applications across different HPC systems without the need to modify the underlying operating system. This makes it easier to share and reproduce software environments and enables more efficient use of HPC resources by allowing multiple applications to run on the same node without interfering with each other.</p>"},{"location":"removed-for-now/definition-library/#data-classification-definitions","title":"Data classification definitions","text":"Data Classification Model <p>There are certain limitations to each of the HPC resources available through Aalborg University regarding the data levels which can be managed on them. Data Classification Model consist of predefined categories of data which determine how the data should be accessed and treated by those who handle it.</p> Data level 0: Public information <p>Information which is in the public domain, and where disclosure is not harmful to AAU.</p> Data level 1: internal information <p>The information which only users with a purely work-related need may and can have access to, and where a breach of confidentiality will have no or a low impact on AAU, private individuals, or partner(s).</p> Data level 2: confidential information <p>The information which only users with a purely work-related need may and can have access to, and where a breach of confidentiality will have semi-serious impacts for AAU, private individuals, or partner(s).</p> Data level 3: sensitive information <p>This is information which, by virtue of its personal, technical, commercial, or competitive nature and sensitivity, must be protected against unintentional access and disclosure.</p>"},{"location":"strato/","title":"Strato","text":"Researchers Indicates if the platform is accessible for researchers (e.g., PhD students, postdocs, faculty) for research purposes. Students Indicates if the platform is accessible to students for educational purposes (e.g., coursework, projects, thesis). Sensitive Data Whether the platform supports processing and storing sensitive or confidential data CPU processing Indicates if the platform supports computational tasks that only require CPU resources. GPU processing Indicates if the platform supports computational tasks that require GPU resources for acceleration (e.g., deep learning). Unlimited compute Whether the platform allows unrestricted compute usage, without limitations on the amount of usage time. Terminal interface The method used to access the platform. Pre-installed apps Indicates if the platform comes with pre-installed applications or frameworks for convenience (e.g., Ansys, PyTorch, TensorFlow). Collaboration friendly Indicates if the platform supports collaborative work (e.g., sharing resources, co-editing, team projects). Working interactively Indicates if the platform supports interactive workflows where users can interact with running processes (e.g., Jupyter notebooks). Possible to add GUI Whether it is possible to run graphical user interfaces (GUIs) on the platform (e.g., remote desktops, JupyterLab). Not for storage This platform is not designed for long term storage of research data."},{"location":"strato/#introduction","title":"Introduction","text":"<p>Strato is a cluster of hardware that is virtualised to create instances that essentially function as a regular computer environment. Strato Instances are virtual machines, that can be launched by the user when they need it. When the instance has been created, it can be accessed from a terminal application on the user's local computer. </p>"},{"location":"strato/#getting-started","title":"Getting Started","text":"<p>How to access</p> <p>Learn how to access Strato</p> <p>Guides for Strato</p> <p>Learn the basics on how to use Strato</p> <p>Terms and Conditions</p> <p>Get an overview of the Terms and Conditions for Strato</p>"},{"location":"strato/#key-features","title":"Key FeaturesCustomizable Virtual MachinesScalable Computing PowerCPU &amp; GPU Support","text":"<p>Adjust CPU, RAM, and storage to match research needs, providing flexibility for diverse workloads.</p> <p>Effortlessly scale resources up or down for optimal performance and cost-efficiency during intensive computations.</p> <p>Leverage powerful CPU and GPU resources for simulations, machine learning, and complex model training.</p>"},{"location":"strato/#common-use-cases","title":"Common Use Cases","text":"<p>IoT and smart system control</p> <p>Blockchain and distributed systems</p> <p>Data processing and analytics</p> <p>Internet and network technologies</p> <p>Server and client application hosting</p> <p>Simulation and modeling tasks</p> <p>Machine learning model training</p> <p>Parallel computing and optimization</p> <p>Natural language processing</p>"},{"location":"strato/#important-information","title":"Important Information","text":"<p>Not for confidential or sensitive data</p> <p>With Strato you are only allowed to work with public or internal information according to AAU\u2019s data classification model (classified as levels 0 and 1, respectively).</p> <p>If you would like to work with confidential or sensitive data (classified as levels 2 and 3), then we support another HPC platform called UCloud.</p> <p>Review the terms and conditions</p> <p>Before getting started, take a few moments to review the terms and conditions of using Strato, and don't hesitate to reach out to our support team if you have any questions or concerns.</p>"},{"location":"strato/faq/","title":"Faq","text":"I cannot connect to my Strato instance via SSH (e.g., 'Permission denied (publickey)' or 'Connection timed out'). What should I do? When I launch an instance, I keep getting an error: 'No fixed IP addresses available for network.' Why is this happening? How can I request or enable GPU instances (e.g., A10, A40, T4) in Strato for my project or research? Is it possible to increase or reassign quotas (more vCPUs, RAM, or storage) either across projects or for a single project? How do I switch my existing instance from a public network to an internal (campus) network without reinstalling everything? My instance is stuck in 'BUILD' or 'ERROR' status and never completes. How can I fix this or see why it fails? I need large compute resources (many cores) or large storage (e.g., 50 TB) for HPC or big-data tasks. What do I do? Attaching a new volume caused me to lose access to my instance, or I can\u2019t see my data. How should I manage volumes? I want to host a public-facing website or API (e.g., Flask, Jupyter) on my Strato instance. How do I open specific ports and configure firewall rules? I have a new project or group of students and want them added to Strato. How do I fill out the request form or add multiple users to one project? I\u2019m trying to run a GUI application (MATLAB, Gedit, COMSOL, etc.) on my Strato instance\u2014how do I enable remote display (X11 forwarding, VNC, etc.)? How can I extend my project\u2019s end date or keep my instance running longer if I haven\u2019t finished my work? I accidentally deleted my default security group rules or messed up my SSH key pairs. Can you help me restore them so I can log in again? Which flavor do I pick or how do I set up a multi-core server for large memory usage? And how do I upgrade an existing instance to more cores or RAM? I\u2019m trying to close or reassign an old/unneeded project (or free up resources) in Strato\u2014what\u2019s the correct procedure?"},{"location":"strato/how-to-access/","title":"How to access","text":"<ol> <li>Go to Strato web interface: Strato servers are managed via the Strato web interface, to log go to the Strato web interface go to with your favourite browser.</li> <li>Authenticate: Ensure the Authenticate Using is set to WAYF and click Connect. You will be redirected to signon.aau.dk/... </li> <li>Log in: You must login with your Aalborg University credentials, click LOGIN and now you should be redirected to the cloud dashboard.</li> <li>SSH key: To access your server you will need to use an SSH key, and you can follow the step-by-step instructions in the Getting started guide.</li> </ol>"},{"location":"strato/how-to-access/#strato-projects-apply-for-additional-quota","title":"Strato Projects: Apply for additional quota","text":"<p>Strato Projects allow users to apply for additional quota to access additional processing capacity.\u00a0</p> <p>GPU resources are limited and users are expected to follow a strict policy of deleting all GPU instances when not actively using the GPU. New instances can be very quickly created from existing volumes (boot disks). </p> <p>Strato Projects are only available to all researchers. Each project requires the completion of a project request form.</p> <p>Not for confidential or sensitive data</p> <p>With Strato you are only allowed to work with data classified as level 1 according to AAU\u2019s data classification model.</p> <p>If you would like to work with confidential or sensitive data (classified as levels 2 and 3), then we support another HPC platform called UCloud.</p> <p>There are no back-ups</p> <p>It is important that you keep your data backed-up outside of the platform. Data is not backed up on any of our HPC platforms, while the data is kept safe through security copies, all copies are simultaneously updated when you make changes, and all changes are permanent.</p> <p>Review the terms and conditions</p> <p>Before getting started, take a few moments to review the terms and conditions of using Strato, and don't hesitate to reach out to our support team if you have any questions or concerns.</p> <p>GPU Limitations - Multi-GPU instances must be benchmarked</p> <p>The GPU cards on Strato are not connected with high-speed interconnects. This means that unless you know exactly how to separate your processes across the GPU cards, there is no performance benefit to launching virtual machines with multiple GPU cards.</p> <p>If you are going to use a machine with multiple GPUs you must benchmark the performance of your code by resizing between single and multiple GPU flavours and comparing the performance.</p> <p>Access and complete the project request form for Strato Projects</p>"},{"location":"strato/service-windows/","title":"Service windows","text":"<p>Four times a year, all of our platforms are subject to service windows where changes and security upgrades are implemented. During these, we reserve an entire day for maintainance of the systems.</p> <p>It should be expected that the platforms are offline for the entire day from 00:01 until 23:59 - but they may come online by the end of the days, as the work is finished.</p>"},{"location":"strato/service-windows/#schedule","title":"Schedule","text":"<p>A service window will take place on the following dates:</p> <p>AI Cloud, Strato, UCloud VM's &amp; UCloud Kubernetes</p> 2025 2026 2027 2028 11/02 10/02 09/02 08/02 13/05 12/05 11/05 09/05 16/09 15/09 14/09 12/09 02/12 01/12 30/11 28/11 <p>AI-LAB</p> 2025 2026 2027 2028 13/02 12/02 11/02 10/02 15/05 14/05 13/05 11/05 18/09 17/09 16/09 14/09 04/12 03/12 02/12 30/11 <p>TAAURUS</p> 2026 2027 2028 2029 03/02 - - - - - - - - - - - - - - - <p>Sign up for notifications on serviceinfo.dk</p> <p>Click this link to go to serviceinfo.dk. Then select Aalborg University, and under the tab Subscribe (or Abonn\u00e9r), select CLAAUDIA. Select email, SMS or calendar, according to your preferences:</p> <p> Go to ServiceInfo.dk</p>"},{"location":"strato/service-windows/#platform-specific-information","title":"Platform specific information","text":""},{"location":"strato/service-windows/#strato-and-ucloud-virtual-machines","title":"Strato and UCloud virtual machines","text":"<p>Be sure to save your work no later than the end of the day before the service window begins, as all virtual machines will be automatically shut down during the service window and any unsaved data will be lost.</p> <p>Usage Management Process </p> <p>1. Servers will NOT restart automatically after service windows     - All servers in the AAU availability zone will be shut down during service windows and will not restart automatically, unless they have been registered for automatic restart before the service window.      - You can easily restart your servers manually after the service window.</p> <p>2. Automatic server resizing after 48 hours of inactivity     - Servers that remain shut down for more than 48 hours will be automatically resized to the smallest CPU configuration.     - You will receive a notification when your instance has been resized.</p> <p>3. Automatic server deletion after 30 days of inactivity     - Servers that remain shut down for 30 days will be permanently deleted, but their volumes will be preserved.     - You will be notified in advance about any affected instances.</p> <p>4. Unused volume cleanup     - Volumes not attached to any server for 30 days will be deleted.     - A notification will be sent before deletion.</p> <p>All virtual machines should be removed when not in use.  Basic rule: keep your volumes, delete your unused VMs, and only run a VM with the size you really need right now. Please consult the page 'Delete and restart an instance from the volume' for instructions on how to do this.</p> <p>Apply for automatic restart of your Strato server</p> <p>Note: The deadline for requesting inclusion in the automatic restart list has now passed for the service window on the 2nd december.</p> <p>You could request automatic restarts for your server if all of the following conditions were met:</p> <ul> <li>The server is part of a Strato Project</li> <li>You can provide a valid motivation for needing automatic restart</li> <li>The server is in one of these availability zones:<ul> <li>AAU</li> <li>AAU-T4</li> <li>AAU-A10</li> <li>AAU-A40</li> </ul> </li> </ul> <p>Servers running in personal project spaces (such as default quota projects, e.g. <code>GK83DJ@aau.dk</code>) cannot be included. If you want to move your project, you can find instructions on how to apply for a Strato Project</p> <p>The application form for inclusion in the automatic restart list closed on November 25th: Strato service window: Automatic server restart inclusion form</p> <p>Link to Strato's web-interface: strato-new.claaudia.aau.dk</p>"},{"location":"strato/service-windows/#ai-cloud","title":"AI Cloud","text":"<p>In the days leading up to the service window, a reservation will be put in place for the entire cluster. The entirety of the cluster will therefore be unavailable for that day, but may come back online by the end of the day.</p> <p>You can still submit jobs in the days leading up to the service window. Since the <code>batch</code> and <code>prioritized</code> partitions have time limits of 12 hours and 6 days respectively, you will only be able to launch new jobs if you add the <code>--time</code> parameter to your Slurm command. If you do not set this parameter, and there are 5 days until the day of the service window, your job will not start until after the service window. You will thus need to calculate how much time there is left, and then submit the job with this parameter added. </p> <p>To submit a job that runs for 1 day and 8 hours, you can simply add <code>--time=1-08:00:00</code> to your Slurm command. </p> <p>Additionally you can read about our recommendations for using checkpointing to work with time limits.</p>"},{"location":"strato/service-windows/#ai-lab","title":"AI-LAB","text":"<p>In the days leading up to the service window, a time limit will be imposed, which will prevent you from launching jobs with end dates that surpass the date of the service window. </p> <p>In this period, you will only be able to launch new jobs, if you add the <code>--time</code> parameter to your Slurm command. If the time parameter is not included, Slurm assumes you ask for the default maximum time for the partition. You will thus have to calculate how much time you have before the service window, and then submit a job with this parameter added. </p> <p>To submit a job that runs for 12 hours, you should add: <code>--time=12:00:00</code>. Not setting the <code>--time</code> parameter will place your job in the queue, where it will wait until the service window has been completed.</p> <p>IMPORTANT: You can still run jobs in the days leading up to the service window</p> <p>If you have any questions, please open a case with us on serviceportal.aau.dk</p>"},{"location":"strato/service-windows/#ucloud-aauk8s","title":"UCloud (AAU/K8s)","text":"<p>The UCloud (AAU/K8s) cluster will be unavailable for the entire duration of the service window and may become available again by the end of the day. While it may be technically possible to start jobs on the day of the service window, please note that any running jobs will be terminated as part of the scheduled maintenance activities performed by the administrators. We recommend planning your work accordingly to avoid interruptions.</p>"},{"location":"strato/terms-and-conditions/","title":"Terms and Conditions","text":""},{"location":"strato/terms-and-conditions/#high-performance-computing-systems-at-aau-are-subjects-limited-by-the-ever-changing-availability-of-the-resources-dependant-on-the-users-thus-having-resources-granted-does-not-consequently-mean-that-it-is-possible-to-use-them-right-away-learn-about-the-guidelines-and-rules-to-ensure-a-smooth-and-efficient-computing-experience","title":"High-Performance Computing systems at AAU are subjects limited by the ever-changing availability of the resources, dependant on the users. Thus, having resources granted does not consequently mean that it is possible to use them right away. Learn about the guidelines and rules to ensure a smooth and efficient computing experience.","text":"<p>General principles and definitions of terms</p> <p>As a general principle, the HPC resources are intended to provide additional computational power to AAU researchers and staff.</p> <ul> <li>We refers to CLAAUDIA and or any other part of the Information Technology Services (ITS) department that is responsible for the provision, maintenance or support of HPC RESOURCES at Aalborg University.</li> <li>You refers to you the user, which may be an individual or other legal person.</li> <li>HPC refers to High Performance Computing resources</li> </ul> <p>What are the systems not intended for?</p> <ul> <li>They are not designed for long term storage of research data.</li> <li>They are not designed for production.</li> <li>They are not intended to host long term shared research projects.</li> </ul> <p>We offer custom solutions If you are in need of larger research project solutions, production virtual machines, or long term storage, please submit a request CLAAUDIA support team.</p>"},{"location":"strato/terms-and-conditions/#1-access-and-responsibility","title":"1. Access and Responsibility","text":"<p>The use of HPC RESOURCES requires that you are employed at AAU. You are responsible for any actions taken on these systems including the responsibility for ensuring that access is restricted to the appropriate individuals. Users are responsible for ensuring that their activities align with the guidelines and best practices outlined in the respective documentation of each platform.</p> <p>Only users authorized via the CLAAUDIA application form may have administrative access to the applied resources.</p>"},{"location":"strato/terms-and-conditions/#2-fair-and-sustainable-use-of-platforms","title":"2. Fair and Sustainable Use of Platforms","text":"<p>Responsibility for following guidelines</p> <p>It is imperative to follow the guidelines for virtual machine usage and resource allocation in AI Cloud, and to always prioritize consideration for fellow researchers when using these resources.</p>"},{"location":"strato/terms-and-conditions/#21-strato","title":"2.1. Strato","text":"<p>Active virtual machines prevent other users from accessing those resources. A virtual machine should only be kept running while it is in current and active use. Active use requires that the machine will be used for research purposes within the coming 48 hours. The setup of each virtual machine is stored on a block device volume, which can be used to new virtual machines \u201cfrom volumes\u201d at a later stage. All virtual machines that are not in use must be deleted. </p> <p>See this guide</p>"},{"location":"strato/terms-and-conditions/#22-ai-cloud","title":"2.2. AI Cloud","text":"<p>Users should be considerate of fellow researchers when allocating jobs in AI Cloud. Jobs should only run if they are actively utilising the computation resources that have been allocated to them. I.e. Interactive jobs should only be used very briefly for development purposes, and no job should allocate any GPU resources that are not used by the job. Users should test their applications for effective utilisation of GPU resources before starting any resource-heavy jobs.</p>"},{"location":"strato/terms-and-conditions/#3-gdpr-compliance-and-data-responsibility","title":"3. GDPR Compliance and Data Responsibility","text":"<p>Adherence to GDPR</p> <p>You must adhere to the General Data Protection Act (GDPR) regulations, e.g. gain consent when needed - links are available below in sections 3.1. and 3.2.. You are personally responsible for any data stored on any of the HPC RESOURCES.</p>"},{"location":"strato/terms-and-conditions/#31-gdpr-compliance-for-aau-employees","title":"3.1. GDPR compliance for AAU employees","text":"<p>If you are interested in using HPC RESOURCES in your research work as an AAU employee, you need to go to the GDPR website and complete and submit a notification of your data collection.</p> <p>You can find more information at AAU's website for GDPR related info for employees.</p>"},{"location":"strato/terms-and-conditions/#4-confidentiality-and-sensitivity-of-data","title":"4. Confidentiality and Sensitivity of Data","text":"<p>AI Cloud and virtual machines on Strato or UCloud must not be used to store confidential and/or sensitive data.</p> <p>UCloud projects with sensitive data</p> <p>Please read the procedure for working with sensitive data on UCloud that has been agreed upon with the Department of Grants and Contracts. </p>"},{"location":"strato/terms-and-conditions/#5-deletion-of-accounts-and-data","title":"5. Deletion of Accounts and Data","text":"<p>With regards to data stored on any of the HPC RESOURCES, it will automatically be deleted if the user is no longer registered as an active student or staff member.</p>"},{"location":"strato/terms-and-conditions/#51-deletion-of-strato-and-ai-cloud-student-accounts-and-data-extraction-responsibilities","title":"5.1. Deletion of Strato and AI Cloud Student Accounts and Data Extraction Responsibilities","text":"<p>All Strato and AI Cloud student accounts will be deleted at the end of each semester (01 February, and 01 August). Students are responsible for the extraction or saving of all data that is of value to them prior to these dates.</p>"},{"location":"strato/terms-and-conditions/#52-extract-or-delete-inactive-data","title":"5.2 Extract or delete inactive data","text":"<p>Once you\u2019ve finished processing your data, please make sure to either extract it or delete it\u2014\u201cfinished data\u201d means anything you\u2019re no longer actively working on. HPC platforms aren\u2019t meant for long-term storage, so when you\u2019re done, move your data to a dedicated storage solution like Datadeposit.</p>"},{"location":"strato/terms-and-conditions/#6-prohibited-usage-and-consequences","title":"6. Prohibited Usage and Consequences","text":"<p>HPC RESOURCES may not, under any circumstances, be used for any purpose outside the scope of staff research, teaching or administrative functions. Any misuse of the HPC RESOURCES will result in an immediate and permanent ban of the use of any HPC RESOURCES. Criminal or unlawful activity will be reported to the appropriate authorities.</p>"},{"location":"strato/terms-and-conditions/#7-service-windows","title":"7. Service Windows","text":"<p>What is a service window?</p> <p>A service window is a scheduled time when maintenance work is done on AAU's HPC systems that disrupt normal use. This maintenance can make the system temporarily unavailable or some resources unusable. AAU informs users in advance so they can plan their work around it. Once it's done, the system returns to normal and users can resume their work.</p> <ul> <li>Scheduled service windows: Four entire days each year are reserved for security updates. </li> <li>Planned service windows: Occur when sub-system maintenance is required between the existing scheduled service windows.</li> <li>Emergency service windows: All systems may be subject to emergency service windows. In the case of an accute emergency, all users will be informed of the nature and expected duration of the window.</li> </ul>"},{"location":"strato/terms-and-conditions/#71-scheduled-service-windows-for-strato-and-ai-cloud","title":"7.1. Scheduled service windows for Strato and AI Cloud","text":"<p>Four entire days each year are reserved for security updates. This may require that all hosts are restarted. Users should expect that all virtual machines will be shut off during this service window and the job queue will be cleared.</p> <p>Proposed schedule of service windows (these dates are subjects to change):</p> <p>2024 17/09, 03/12</p> <p>2025 11/02, 13/05, 16/09, 02/12</p> <p>2026 10/02, 12/05, 15/09, 01/12</p> <p>2027 09/02, 11/05, 14/09, 30/11</p> <p>2028 08/02, 09/05, 12/09, 28/11</p> <p>Check ServiceInfo.dk to learn more about current service windows</p>"},{"location":"strato/terms-and-conditions/#72-right-to-maintenance-and-modification-of-systems","title":"7.2. Right to maintenance and modification of systems","text":"<p>We reserve the right to periodically shut off entire systems for maintenance or security purposes. These systems require maintenance and updates at regular intervals, and we commit, where possible, to provide a minimum of two calendar weeks warning before any shut down period commences.</p> <p>We reserve the right to modify, redesign, disable or remove any of the existing services. Where possible, users will be notified of major modifications to the existing systems a minimum of three calendar months before these changes are implemented. Updates, upgrades and shutdown periods are not considered major modifications.</p>"},{"location":"strato/terms-and-conditions/#73-communication-policy-around-service-windows","title":"7.3. Communication policy around service windows","text":"Scheduled IT disruptionsPlanned IT disruptionsEmergency communication timeframes <ol> <li> <p>Service window date reminder email</p> <ul> <li>Sent to all users of Strato, AI Cloud</li> <li>Dispatched 6-8 weeks before service window</li> </ul> </li> <li> <p>Orientation email about service window</p> <ul> <li>Sent to the internal CLAAUDIA and ITS management list</li> <li>Dispatched 2 weeks before service window</li> </ul> </li> <li> <p>Notice of service window pre arranged on ServiceInfo.dk</p> <ul> <li>Put on 1 week before the service window.</li> </ul> </li> <li> <p>Orientation email to system owner forum, key stakeholders or research group leaders</p> <ul> <li>Dispatched 2 weeks before service window.</li> </ul> </li> <li> <p>Orientation email to all users</p> <ul> <li>Dispatched 1 week before service window.</li> </ul> </li> <li> <p>Completion of planned work changed on ServiceInfo.dk</p> <ul> <li>Changed on first working day after the service window.</li> </ul> </li> </ol> <ol> <li> <p>Service window date reminder email</p> <ul> <li>Sent to all users of Strato, AI Cloud</li> <li>Dispatched 6-8 weeks before service window</li> </ul> </li> <li> <p>Orientation email about service window</p> <ul> <li>Sent to the internal CLAAUDIA and ITS management list</li> <li>Dispatched 4 weeks before service window</li> </ul> </li> <li> <p>Notice of service window pre arranged on ServiceInfo.dk</p> <ul> <li>Put on 2-3 weeks before the service window</li> </ul> </li> <li> <p>Orientation email to system owner forum, key stakeholders or research group leaders</p> <ul> <li>Dispatched 3 weeks before service window.</li> </ul> </li> <li> <p>Orientation email to all users</p> <ul> <li>Dispatched 2 weeks before service window.</li> </ul> </li> <li> <p>Completion of planned work changed on ServiceInfo.dk</p> <ul> <li>Changed on first working day after the service window.</li> </ul> </li> </ol> <ol> <li> <p>After 1st hour</p> <ul> <li>Out of order notice posted on ServiceInfo.dk.</li> </ul> </li> <li> <p>Unresolved problems at end of day</p> <ul> <li>Update on status - even if no change has occurred.</li> </ul> </li> <li> <p>After problem resolution</p> <ul> <li>The issue will be marked as resolved on ServiceInfo.dk</li> </ul> </li> </ol>"},{"location":"strato/terms-and-conditions/#8-loan-of-physical-equipment","title":"8. Loan of physical equipment","text":""},{"location":"strato/terms-and-conditions/#81-responsibility-and-liability-for-physical-equipment-loaned-by-aau","title":"8.1. Responsibility and Liability for Physical Equipment Loaned by AAU","text":"<p>With regards to physical equipment, you are solely responsible for damage to or loss of the equipment during the loan period. In the event of damage, AAU determines whether the equipment shall be repaired or replaced. If AAU determines that it is not viable to repair the equipment or if the equipment is lost, you shall compensate AAU for the value of the equipment.</p> <p>If AAU determines that the equipment can be repaired, you shall pay for the repair.</p>"},{"location":"strato/terms-and-conditions/#82-ethical-use-and-legal-responsibility-for-physical-kits-with-cameras","title":"8.2. Ethical Use and Legal Responsibility for Physical Kits with Cameras","text":"<p>Physical kits are delivered with a camera. Please act ethically and refrain from using them in places where other people may consider it unpleasant or annoying. You are responsible for acting according to the legislation of the country in which you use the equipment and the Danish legal and ethical rules.</p>"},{"location":"strato/terms-and-conditions/#9-updates-to-terms-and-conditions","title":"9. Updates to Terms and Conditions","text":"<p>We reserve the right to make periodic changes to these terms and conditions, and commit to inform users of the changes made.</p>"},{"location":"strato/terms-and-conditions/#appendix","title":"Appendix","text":""},{"location":"strato/terms-and-conditions/#procedure-for-working-with-sensitive-data-on-ucloud-projects","title":"Procedure for working with sensitive data on UCloud projects","text":"<p>CLAAUDIA, Aalborg University</p> <p>2023-10-10</p> <p>v1.0</p> <p>As a user on the UCloud platform you have a workspace called \"My workspace\".</p> <p>It is also possible to apply for a separate \"Project\" workspace on the UCloud platform. Projects on UCloud allow for collaboration with separate storage, compute resources and management of user rights and responsibilities on the UCloud platform.</p> <p>The project environment is required for the following types of work on UCloud:</p> <ol> <li> <p>For employed researchers at AAU (VIP)</p> <p>a.  Sensitive data: All work on the UCloud platform that involves     research data in classification levels 2. a 2.  All users</p> <p>a.  GPU access on UCloud: All access to GPU resources on UCloud     require a project.</p> <p>b.  Additional compute resources that are allocated out of the AAU     pool of UCloud resources.</p> </li> </ol> <p>UCloud users at AAU must be familiar with the details of the following codes of conduct and policies:</p> <ol> <li> <p>The Danish Code of Conduct for Research     Integrity</p> </li> <li> <p>The AAU Policy for Research Data     Management</p> </li> <li> <p>The AAU policies with regards to     GDPR     (Available in English for     researchers     (VIP) and     teachers     (VIP);     Only in Danish for administration (TAP)     employees)</p> </li> <li> <p>The AAU data management     recommendations</p> </li> </ol> <p>These policies cover the general rules all researchers (and TAP staff for point 3.) should abide by with regards to what kind of data may be kept, for how long, whether data can be re-used or recycled, and how long it should be archived for, etc.</p> <p>Sensitive data: Registration of research projects at Grants and Contracts</p> <p>For researchers at AAU, working with sensitive personal data requires that you register your research project with \"Grants and Contracts\" by completing the digital form that matches your role in relation to the data, for example Data Controller or Data processor.</p> <p>Data processing agreement between AAU and the EScience center at SDU</p> <p>For AAU users, data analysis and processing may then take place on the UCloud platform according to the data processing agreement between AAU and EScience center at SDU.</p> <p>Steps required to working with projects on the UCloud platform</p> <ol> <li> <p>Identify the data classification of your data by reviewing the AAU     data classification     model.</p> </li> <li> <p>If you are a researcher, and working with personally identifiable information, you must register a research project with Grants and Contracts     using the relevant registration     form.</p> <p>a.  Once you have registered your research activity at Grants and     Contracts, you will get a receipt that contains a \"WorkZone case     number\" (To be included in your UCloud project application).</p> </li> </ol> <ol> <li> <p>All applicants for projects on UCloud must complete the CLAAUDIA     application form for DeiC Interactive HPC resources.</p> </li> <li> <p>Once approved, you will receive a UCloud project     number, and you must apply for a project in the UCloud     Interface,     including the resources that you had approved in the CLAAUDIA     application. (You can apply for additional resources later if     needed.)</p> <p>a.  As project applicant you will be the Principal Investigator for     the project, and you should be aware of your roles and     responsibilities.</p> <p>b. The project must use the same project title as provided in the CLAAUDIA application, and both the DeiC project number and the Grants and Contracts reference number should be included:</p> <pre><code>i. The DeiC project number should be entered in the \"DeiC Interactive HPC project number\" field.\nii. The WorkZone case number should be entered in the \"WorkZone reference number\" field.\n</code></pre> <p>c.  Once your project is approved, you will get access to project     storage (Drive(s)) on UCloud that is separate from your \"My     Workspace\" storage. No sensitive data may be stored in the \"My     workspace\" drives.</p> </li> <li> <p>Adding data to the UCloud platform:</p> <p>a.  Any data added to the project should be in a project folder and     this must be marked according to the level of data sensitivity,     as described in the AAU data classification     model.</p> <pre><code>i.  On the UCloud platform the corresponding classifications are\n    as follows:\n\n    - AAU Level 1  \u2192 UCloud: Inherit\n    - AAU Level 2  \u2192 UCloud: Private/Confidential\n    - AAU Level 3  \u2192 UCloud: Sensitive (Only permitted to be added to your registered \n    and approved project folder.) Sensitive data may **NOT** be added to My Workspace.\n    - AAU Level 4  \u2192 Not allowed\n</code></pre> </li> <li> <p>Collaboration on UCloud within projects: Fellow AAU persons</p> <p>a.  Only persons named in the project registered with Grants and     Contracts may be added to the UCloud project.</p> </li> <li> <p>Collaboration on UCloud within projects: Persons from outside     AAU</p> <p>a.  The collaborator's employer must have a Data Processing     agreement with SDU (SDU are hosting UCloud), or</p> <pre><code>i.  Where there is an agreement of shared data responsibility\n    (Agreement on Joint data controlling), that states that it\n    is agreed to use DeiC/SDU as the data processor, then it is\n    sufficient that AAU has an existing data processing\n    agreement with DeiC/SDU. In these cases AAU will be\n    responsible for the data processing agreement with DeiC/SDU.\n</code></pre> <p>b.  If this is not the case, you cannot invite the collaborator     inside the project folder in UCloud.</p> <p>c.  No person(s) that are not included in the data processing     agreement or the agreement on joint data controlling may be     invited to the project.</p> </li> <li> <p>UCloud project members and roles should be set appropriately.</p> <p>a.  Project \"admins\" can see all member files by activating the     \"show member files\" option. The Principal Investigator is     responsible for ensuring that all roles and     responsibilities     are properly assigned.</p> </li> <li> <p>Read and write privileges on UCloud</p> <p>a.  If collaborators are only allowed read or write to specific     parts of the data / dataset, you will need to follow the     following steps:</p> <pre><code>i.  Within the project, you will need to create a new \"Drive\".\n    (As drives are the only level to which you can specify read\n    and write permissions.)\n\n    1.  Only project \"admins\" can create new drives within a\n        project.\n\nii. Name the drive and then click the \"...\" button to modify the\n    permissions. Then choose the permissions (None / Read /\n    Write).\n</code></pre> </li> <li> <p>Permitted applications and uses</p> <p>a. Only the SDU/K8 provider is permitted for working with data classifications 2 and 3.</p> <p>b. The AAU/K8 and AAU virtual machine providers are only permitted to be used for data classified as level 1.</p> </li> <li> <p>On completion the project\u00a0</p> <p>a.  All data on the UCloud platform should be deleted.</p> <p>b.  The project should then be archived with a final date that     corresponds with the GDPR notification with 'Grants and     Contracts'.</p> <p>c.  All files in trash folders should be permanently deleted.</p> <p>d.  All complete data sets and metadata should be stored in a data     repository in accordance with The AAU Policy for Research Data     Management.     As of 2023-January, AAU     DataDeposit     as a local archiving solution, while a national solution is     under development.</p> </li> </ol>"},{"location":"strato/usage-management/","title":"Usage Management","text":"<p>Effective from 16th September 2025</p> <p>Note: Usage management as described on this page is only applicable to the AAU Availability Zone. </p> <pre><code>graph TD\n    A(\"Server shut down\") --&gt; B(\"\u23f1\ufe0f 48 hours&lt;br/&gt;elapsed\")\n    B --&gt; C(\"\ud83d\udcc9 Auto-resize&lt;br/&gt;to smallest CPU\")\n    C --&gt; D(\"\u23f1\ufe0f 30 days&lt;br/&gt;elapsed\")\n    D --&gt; E(\"\ud83d\uddd1\ufe0f Auto-delete server&lt;br/&gt;(volumes kept)\")\n    E --&gt; F(\"\u23f1\ufe0f 30 days&lt;br/&gt;elapsed\")\n    F --&gt; G(\"\ud83d\uddd1\ufe0f Delete unused&lt;br/&gt;volumes\")\n\n    %% Define classes for colors\n    classDef event fill:#e6f3ff,stroke:#1d70b8,color:#0b0c0c,font-size:14px;\n    classDef action fill:#fff2f2,stroke:#d4351c,color:#0b0c0c,font-size:14px;\n\n    %% Assign classes\n    class A,B,D,F event;\n    class C,E,G action;</code></pre> How this affects you <ul> <li>Server shut down: Usage management is triggered when a server is shut down. This can happen either manually or automatically during the service window.</li> <li>After 48 hours: If a VM remains shut down for 48 hours, it is automatically resized to the smallest CPU size. This frees up resources for active research. You can easily resize your server again when needed.</li> <li>After 30 days: If a VM stays shut down for an additional 30 days, it is automatically deleted. However, its attached volumes are retained to keep your data safe.</li> <li>Unused volumes: Volumes that are not attached to any VM for 30 days are deleted.</li> </ul> Tips <ul> <li>Want to keep your server running after service windows? If your server is part of a dedicated research project, register the VM for auto-restart before the service window begins.</li> <li>Want to keep your server active? Simply start it up whenever you need it.</li> <li>Back up your data regularly: Strato is not a storage platform and does not maintain backups. We recommend backing up your data elsewhere.</li> <li>Resize manually when needed: You can resize your server up or down based on your current needs. This helps free up resources and ensures they are available when you need them.</li> </ul>"},{"location":"strato/advanced-guides/attaching-a-volume-for-additional-storage/","title":"Attaching a volume for additional storage","text":"<p>If you need additional storage, you can attach a volume to a running instance, make a filesystem and then mount the new filesystem on the attached volume.</p> <p>Be aware that each user has 10 TB of storage by default.</p> <p>Guide:</p> <ol> <li>Go to Volumes/Volumes and then click \"+ Create Volume\". Give it a name to make it easier to locate and a size. Make sure to leave \"Volume Source\" and \"Type\" at their default values.</li> <li>Find the instance you wish to attach the newly created volume to under Compute/Instances and under \"Actions\" for the relevant instance (must be a running instance) select \"Attach Volume\". Select the volume you have just created.</li> <li>You should see a popup message with the name of new device, e.g. \"/dev/vdb\", \"/dev/vdc\" etc. You can also click on the instance name to to get info on e.g. the attached volumes and their naming.</li> <li>SSH to the instance and create a new filesystem for the newly attached device/volume with e.g. (this overwrites any existing data. Only do this the first time you attach this volume; not when re-attaching later after a reboot or similar.)    <pre><code>$ sudo mkfs.ext4  /dev/vdb\n</code></pre></li> <li>Make a mount point in e.g. your home dir:    <pre><code>mkdir ~/vol1\n</code></pre></li> <li>Mount    <pre><code>$ sudo mount /dev/vdb ~/vol1\n</code></pre></li> <li>Change owner and group of directory to default user:    <pre><code>$ sudo chown -R $USER:$USER ./test\n</code></pre></li> <li>Verify that the volume has been mounted as expected:    <pre><code>$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\nudev            7.9G     0  7.9G   0% /dev\n................................................\n/dev/vdb        976M  2.6M  907M   1% /home/ubuntu/vol1\n</code></pre></li> </ol>"},{"location":"strato/advanced-guides/attaching-a-volume-for-additional-storage/#mounting-the-volume-permanently","title":"Mounting the volume permanently","text":"<p>You may want to configure your above mount permanently, so it automatically gets mounted if you reboot your instance, for example. In order to do this, follow steps 1-5 above. Then proceed as follows:</p> <ol> <li>Edit the file system mounting table    <pre><code>$ sudo nano /etc/fstab\n</code></pre> Do not alter or remove any of the existing contents in this file. This can render your instance unusable.</li> <li>Add the following on a new line at the bottom of this file:    <pre><code>/dev/vdb    /home/ubuntu/vol1    ext4    defaults    0 0\n</code></pre></li> <li>The long whitespaces above must be tab characters</li> <li>This assumes that your volume is attached as \"/dev/vdb\". If it is attached as another device (see step 3 above), type this device name instead.</li> <li> <p>This assumes that you have created your mount point at \"~/vol1\". If you have created it somewhere else (see step 5 above), type the full path to it instead of \"/home/ubuntu/vol1\".</p> </li> <li> <p>Press CTRL-X in the nano text editor, type \"y\" for yes and hit ENTER to exit the editor and save the file.</p> </li> <li>Now mount your newly configured volume with the following command (causes mount to mount all file systems mentioned in \"etc/fstab\"):    <pre><code>$ sudo mount -a\n</code></pre></li> <li>Verify that the volume has been mounted as expected:     <pre><code>$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\nudev            7.9G     0  7.9G   0% /dev\n................................................\n/dev/vdb        976M  2.6M  907M   1% /home/ubuntu/vol1\n</code></pre></li> </ol>"},{"location":"strato/advanced-guides/check-ownership-guide/","title":"How to Check Ownership of a Volume or Server on Strato","text":"<p>This guide walks you through verifying whether you are the owner of a volume or instance (server) on Strato.</p>"},{"location":"strato/advanced-guides/check-ownership-guide/#finding-your-user-id-and-project-id","title":"Finding your User ID and Project ID","text":"<ul> <li>You can use the Identity &gt; Projects section to confirm your current project ID.</li> <li>You can use the Identity &gt; Users section to confirm your user ID.</li> <li>You need to check that you select the correct project from the project dropdown menu in the top-left corner of the Strato landing page.</li> </ul>"},{"location":"strato/advanced-guides/check-ownership-guide/#checking-server-instance-ownership","title":"Checking Server (Instance) Ownership","text":""},{"location":"strato/advanced-guides/check-ownership-guide/#1-log-in-to-the-strato-web-interface","title":"1. Log in to the Strato web interface.","text":"<ol> <li>Navigate to the Strato web interface</li> <li>Log in with your AAU (WAYF) credentials.</li> </ol>"},{"location":"strato/advanced-guides/check-ownership-guide/#2-navigate-to-your-list-of-instances-servers","title":"2. Navigate to your list of instances (servers)","text":"<ol> <li>Go to Project &gt; Compute &gt; Instances.</li> </ol>"},{"location":"strato/advanced-guides/check-ownership-guide/#3-find-the-instance","title":"3. Find the instance","text":"<ol> <li>Find the instance you want to check in the list.</li> </ol>"},{"location":"strato/advanced-guides/check-ownership-guide/#4-open-the-instance-details-page","title":"4. Open the instance details page","text":"<ol> <li>Click the instance name to open its details page.</li> </ol>"},{"location":"strato/advanced-guides/check-ownership-guide/#5-under-the-overview-tab-check","title":"5. Under the \"Overview\" tab, check:","text":"<ol> <li>Project ID</li> <li>User ID</li> <li>Launched by</li> </ol> <p>If your User and Project ID matches the metadata, you are the owner.</p>"},{"location":"strato/advanced-guides/check-ownership-guide/#checking-volume-ownership","title":"Checking Volume Ownership","text":"<p>It is unfortunately not possible to check the user ownership of a volume, but it is possible to check the project ownership.</p> <p>If you are in doubt about the ownership of the volume you can either:</p> <ol> <li>Complete a volume transfer from within the project yourself.</li> <li>Create a ticket in ServicePortal for us to investigate the volume, please include<ol> <li>Volume ID</li> <li>Project ID</li> <li>Your User ID</li> </ol> </li> </ol>"},{"location":"strato/advanced-guides/check-ownership-guide/#1-log-in-to-the-strato-web-interface_1","title":"1. Log in to the Strato web interface.","text":"<ol> <li>Navigate to the Strato web interface</li> <li>Log in with your AAU (WAYF) credentials.</li> </ol>"},{"location":"strato/advanced-guides/check-ownership-guide/#2-open-the-volumes-list","title":"2. Open the volumes list","text":"<ol> <li>Navigate to Project &gt; Volumes &gt; Volumes.</li> </ol> <p>Note: It is a good idea to name your volumes appropriately before deleting any compute instances that they are attached to. Click the Edit Volume button to edit the volume name.</p>"},{"location":"strato/advanced-guides/check-ownership-guide/#3-find-the-volume-you-want-to-transfer","title":"3. Find the volume you want to transfer","text":"<ol> <li>In the volume list, locate the volume in question.</li> </ol> <p>If you have not named the volume appropriately, you can check the Attached To column to get the name of the instance it is attached to.</p>"},{"location":"strato/advanced-guides/check-ownership-guide/#4-click-the-volume-name-to-view-detailed-metadata-which-includes","title":"4. Click the volume name to view detailed metadata, which includes:","text":"<ol> <li>Name</li> <li>ID</li> <li>Project ID</li> <li>Attachments, to identify any server attachments that are registered for the volume.</li> </ol> <p>If your User and Project ID matches the metadata, you are the owner.</p>"},{"location":"strato/advanced-guides/command-line-interface-access/","title":"Command line interface access","text":"<p>For advanced users it is possible to manage the cloud instances from the command line interface.</p> <p>THE GUIDE IS TESTED ON UBUNTU 18.04 For CLI access, the OpenStackClient (OSC) must be installed. USE PIP The package in apt does not work for SAML2 Authentication.</p>"},{"location":"strato/advanced-guides/command-line-interface-access/#linux","title":"Linux","text":"<pre><code>$ sudo apt install python3-openstackclient\n# or\n$ pip install python-openstackclient\n# If pip is not installed run\n$ sudo apt install python-pip\n</code></pre>"},{"location":"strato/advanced-guides/command-line-interface-access/#mac","title":"Mac","text":"<pre><code>curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython get-pip.py\npip install python-openstackclient\n</code></pre>"},{"location":"strato/advanced-guides/command-line-interface-access/#get-token","title":"Get token","text":"<p>From a internet browser, login to this openstack wayf auth and inspect the Response Headers and find the X-Subject-Token. How to find the Response Headers varies from browser to browser. To find the Response Headers checkout this guide https://www.dev2qa.com/how-to-view-http-headers-cookies-in-google-chrome-firefox-internet-explorer/ which covers the most common browsers.</p> <p></p> <p>After you have found the X-Subject-Token, login to strato-new as normal. In the upper right corner, find and click your AAU ID (XXZZXX@aau.dk), and then \"OpenStack RC File\". Open or save the file. Start a terminal, and export the following variables (you need to locate a few values from the \"OpenStack RC File\"):</p> <pre><code>export OS_AUTH_TYPE=token\nexport OS_IDENTITY_API_VERSION=3\nexport OS_AUTH_URL=https://strato-new.claaudia.aau.dk:5000\nexport OS_PROJECT_ID=&lt;project ID as given in the OpenStack RC File&gt;\nexport OS_PROJECT_NAME=&lt;your name as given in the Openstack RC File&gt;\nexport OS_TOKEN=&lt;value of **X-Subject-Token**&gt;\n</code></pre> <p>If successful, you can now test your setup like</p> <pre><code>openstack server list\n$ openstack server list\n+--------------------------------------+--------+--------+------------------------------+--------------------------+-----------+\n| ID                                   | Name   | Status | Networks                     | Image                    | Flavor    |\n+--------------------------------------+--------+--------+------------------------------+--------------------------+-----------+\n| cdaa335b-6b7f-44e0-9903-7d6b0a9dd06e | matlab | ACTIVE | Campus Network 01=10.92.0.55 | N/A (booted from volume) | gp.medium |\n+--------------------------------------+--------+--------+------------------------------+--------------------------+-----------+\n</code></pre> <p>To get more information about your instance you can do e.g.</p> <pre><code>$ openstack server show cdaa335b-6b7f-44e0-9903-7d6b0a9dd06e\n+-----------------------------+------------------------------------------------------------------+\n| Field                       | Value                                                            |\n+-----------------------------+------------------------------------------------------------------+\n| OS-DCF:diskConfig           | MANUAL                                                           |\n| OS-EXT-AZ:availability_zone | AAU                                                              |\n| OS-EXT-STS:power_state      | Running                                                          |\n| OS-EXT-STS:task_state       | None                                                             |\n| OS-EXT-STS:vm_state         | active                                                           |\n| OS-SRV-USG:launched_at      | 2022-01-17T10:17:53.000000                                       |\n| OS-SRV-USG:terminated_at    | None                                                             |\n| accessIPv4                  |                                                                  |\n| accessIPv6                  |                                                                  |\n| addresses                   | Campus Network 01=10.92.0.55                                     |\n| config_drive                |                                                                  |\n| created                     | 2022-01-13T12:53:35Z                                             |\n| flavor                      | gp.medium (0313b9b4-fbc3-44d9-81d1-9e5e925d1a97)                 |\n| hostId                      | e62666d97723e316fb8cc43a508156253a5e8684ae5c97525f36a94c         |\n| id                          | cdaa335b-6b7f-44e0-9903-7d6b0a9dd06e                             |\n| image                       | N/A (booted from volume)                                         |\n| key_name                    | stratonew                                                        |\n| name                        | matlab                                                           |\n| progress                    | 0                                                                |\n| project_id                  | 19d0e041fb364580abc26539180dd0e1                                 |\n| properties                  |                                                                  |\n| security_groups             | name='default'                                                   |\n| status                      | ACTIVE                                                           |\n| updated                     | 2022-01-17T10:19:56Z                                             |\n| user_id                     | a42a435578323b3d7edd853e98fc643cbb4dd82ef8d5160c30be720f218b121f |\n| volumes_attached            | id='88a77439-439a-4647-a069-f5ec7035239d'                        |\n+-----------------------------+------------------------------------------------------------------+\n</code></pre> <p>Information that can be obtained from the Horizon web interface can also be accessed via the CLI, like quota:</p> <pre><code>$ openstack quota show --max-width 79\n+-----------------------+-----------------------------------------------------+\n| Field                 | Value                                               |\n+-----------------------+-----------------------------------------------------+\n| backup-gigabytes      | 1000                                                |\n| backups               | 10                                                  |\n| cores                 | 64                                                  |\n| fixed-ips             | -1                                                  |\n| floating-ips          | 50                                                  |\n| gigabytes             | 10000                                               |\n| gigabytes_RBD         | -1                                                  |\n| gigabytes___DEFAULT__ | -1                                                  |\n| groups                | 10                                                  |\n| injected-file-size    | 10240                                               |\n| injected-files        | 5                                                   |\n| injected-path-size    | 255                                                 |\n| instances             | 5                                                   |\n| key-pairs             | 100                                                 |\n| location              | Munch({'cloud': '', 'region_name': '', 'zone':      |\n|                       | None, 'project': Munch({'id':                       |\n|                       | '19d0e041fb364580abc26539180dd0e1', 'name':         |\n|                       | 'XU43DZ@aau.dk', 'domain_id': None, 'domain_name':  |\n|                       | None})})                                            |\n| networks              | 100                                                 |\n| per-volume-gigabytes  | -1                                                  |\n| ports                 | 500                                                 |\n| project               | 19d0e041fb364580abc26539180dd0e1                    |\n| project_name          | XU43DZ@aau.dk                                       |\n| properties            | 128                                                 |\n| ram                   | 512000                                              |\n| rbac_policies         | 10                                                  |\n| routers               | 10                                                  |\n| secgroup-rules        | 100                                                 |\n| secgroups             | 10                                                  |\n| server-group-members  | 10                                                  |\n| server-groups         | 10                                                  |\n| snapshots             | 5                                                   |\n| snapshots_RBD         | -1                                                  |\n| snapshots___DEFAULT__ | -1                                                  |\n| subnet_pools          | -1                                                  |\n| subnets               | 100                                                 |\n| volumes               | 10                                                  |\n| volumes_RBD           | -1                                                  |\n| volumes___DEFAULT__   | -1                                                  |\n+-----------------------+-----------------------------------------------------+\n</code></pre> <p>Flavors:</p> <pre><code>$ openstack flavor list\n+--------------------------------------+--------------+--------+------+-----------+-------+-----------+\n| ID                                   | Name         |    RAM | Disk | Ephemeral | VCPUs | Is Public |\n+--------------------------------------+--------------+--------+------+-----------+-------+-----------+\n| 0238fdc1-2525-4669-be22-a545341c8301 | cpu.small    |  16384 |  100 |         0 |     8 | True      |\n| 0313b9b4-fbc3-44d9-81d1-9e5e925d1a97 | gp.medium    |  32768 |  100 |         0 |     8 | True      |\n| 076618de-18c3-4539-b77c-fa4e09fd0755 | cpu.xlarge   | 131072 |  100 |         0 |    64 | True      |\n| 386615e0-efa8-488f-a7ec-4e643eaa1df1 | cpu.large    |  65536 |  100 |         0 |    32 | True      |\n| 5ae3ddeb-6a25-409e-ac18-9a27dde53dcf | m1.xlarge    |  16384 |  160 |         0 |     8 | True      |\n| 755ffd3f-1329-48aa-a7cf-6974981a8dab | gp.small     |  16384 |  100 |         0 |     4 | True      |\n| 7cb367d4-9715-411c-867f-a1b90d0e98ae | gp.large     |  65536 |  100 |         0 |    16 | True      |\n| 928a50d7-d05b-4b7d-9396-71f7afb94e46 | gpu.t4-large |  41000 |  100 |         0 |    10 | True      |\n| a2246ad5-7f9b-414b-9f92-6bda0021508d | mem.xlarge   | 262144 |  100 |         0 |    32 | True      |\n| abb9477b-955c-45fa-bfaf-b53ebc8b2cb7 | mem.small    |  32768 |  100 |         0 |     4 | True      |\n| cc48e798-6bf2-4df9-8705-5f3a3b558f1d | mem.medium   |  65536 |  100 |         0 |     8 | True      |\n| dd498df0-a489-48da-a5fd-44959b1ae34c | mem.large    | 131072 |  100 |         0 |    16 | True      |\n| e986e579-45e1-4542-a99e-5fc1518adc8a | cpu.medium   |  32768 |  100 |         0 |     3 | True      |\n+--------------------------------------+--------------+--------+------+-----------+-------+-----------+\n</code></pre> <p>Images:</p> <pre><code>$ openstack image list\n+--------------------------------------+------------------------------+--------+\n| ID                                   | Name                         | Status |\n+--------------------------------------+------------------------------+--------+\n| 4321a635-97c6-4c82-a000-71b381f4e0ce | CentOS 8                     | active |\n| 6a77c780-37ea-4b73-afe8-c730e19524cb | FreeBSD 12.1                 | active |\n| a561c93f-adb4-46e8-8d31-bb34c3430e78 | Ubuntu 18.04 (Bionic Beaver) | active |\n| dd18a9d1-6d53-423f-9511-bf075c4c9ce7 | Ubuntu 20.04 (Focal Fossa)   | active |\n| 9cb0e0e5-715d-4cdb-bca2-d239a451e3b6 | cirros-0.5.1-x86_64          | active |\n+--------------------------------------+------------------------------+--------+\n</code></pre> <p>For more information on how to use the cli check out the OpenStack CLI documentation or the Python OpenStack Client</p>"},{"location":"strato/advanced-guides/custom-security-groups/","title":"Custom security groups","text":"<p>Each instance has an internal fixed cloud IP address, but can also have a floating public IP address. An internal cloud IP addresses is used for communication between instances, and a floating public IP address is used for communication with networks outside the cloud, including the Internet.</p>"},{"location":"strato/advanced-guides/custom-security-groups/#ssh-rule","title":"SSH rule","text":"<p>Most images is reached by SSH, which require port 22 open.</p> <ol> <li>Navigate to network</li> <li>Click the sub menu Security Groups</li> <li>Click Manage Rules on the default Security group</li> <li>Add a rule</li> <li>Choose SSH from dropdown menu.</li> </ol> <p></p>"},{"location":"strato/advanced-guides/custom-security-groups/#custom-rule","title":"Custom rule","text":"<p>Some services require different ports open. To achieve this, the user must create a custom security rule and add it the instance</p> <ol> <li>Navigate to network</li> <li>click the sub menu Security Groups</li> <li>Create new Security group</li> <li>Enter name &amp; description</li> <li>Add a rule with a custom port </li> </ol>"},{"location":"strato/advanced-guides/custom-security-groups/#key-pair","title":"Key-pair","text":"<p>Openstack authenticates per default Linux instances with a ssh key-pair. If you have to access the machine with SSH, the key-pair must be set.  </p> <ol> <li>Navigate to Compute</li> <li>Click on the sub menu Key Pairs</li> <li>Add new Key Pair</li> <li>Fill out name</li> <li>Save the public key locally </li> </ol>"},{"location":"strato/advanced-guides/custom-security-groups/#ssh-access-to-instance","title":"SSH access to instance","text":"<p>You will have root-admin access to every instance you create and can therefore install additional software, tweak the instance or simply use it as is. Default username is ubuntu for all instances. There is no default password. Use SSH keys for safety, otherwise you muse create a user, and set a secure password your self.</p> <p><code>bash ssh ubuntu@130.226.98.xx -i yourPersonalKey.pem</code></p> <p></p>"},{"location":"strato/advanced-guides/persistent-terminal-sessions/","title":"Persistant terminal sessions","text":"<p>Every time you log in to a Strato instance, you are landed in a session. Connecting to the same instance in a different window, will land you in a new sesison. Applications launched in \"Session A\" will be detectable from within \"Session B\", but most often you will not be able to interact with them.</p> <p>In many cases it can be desireable to be able to launch an application, put it away, and attach to the same session - perhaps many days later. For this purpose we can use of either <code>tmux</code> or <code>screen</code>. Both come preinstalled on most Linux distributions.</p> <p>In the following we will show you the most basic features.</p>"},{"location":"strato/advanced-guides/persistent-terminal-sessions/#tmux","title":"Tmux","text":"<p>Create a new session: <pre><code>tmux new\n</code></pre></p> <p></p> <p>At the bottom of the window, you will see a green pane. This indicates you have entered a Tmux sesison.</p> <p>Now detach from the session using: Ctrl+B , D . Please note that this is: Ctrl+B and then D .</p> <p>List open sessions (if there are any): <pre><code>tmux ls\n</code></pre> </p> <p>The session, we have just detached from is called <code>0</code>.</p> <p>Attach to it using: <pre><code>tmux attach -t 0\n</code></pre></p> <p>We could also have killed it using: <pre><code>tmux kill-session -t \n</code></pre></p> <p>These commands should be enough to get you started!</p>"},{"location":"strato/advanced-guides/persistent-terminal-sessions/#screen","title":"Screen","text":"<p>Start a new screen: <pre><code>screen\n</code></pre></p> <p>Accept the terms by pressing <code>Enter</code>. </p> <p>You should now be standing inside a new Screen session.</p> <p>Detach from the current session using : Ctrl+A , D  (please note that this is Ctrl+A and then D ).</p> <p>You should now be in your login session again.</p> <p>List the open <code>screen</code>-sessions with:</p> <p><pre><code>screen -ls\n</code></pre> This outputs something like:</p> <pre><code>There is a screen on:\n    1463.pts-0.screen-test  (09/09/21 09:48:48) (Detached)\n1 Socket in /run/screen/S-ubuntu.\n</code></pre> <p>Here 1463 is our session identifier.</p> <p>Attach to the sesion with: <pre><code>screen -r 1463\n</code></pre></p> <p>A session can be killed with:</p> <pre><code>screen -XS 1463 kill\n</code></pre> <p>These commands should be enough to get you started.</p>"},{"location":"strato/advanced-guides/transfer-volume/","title":"Guide: Transferring volumes using the Strato interface","text":"<p>This guide explains how to transfer a volume to another user using the Strato web interface. You can also use this method to change the ownership of a volume within a project by transferring it to another person or yourself within the same project.</p>"},{"location":"strato/advanced-guides/transfer-volume/#1-log-in-to-strato","title":"1. Log in to Strato","text":"<ol> <li>Open your web browser and navigate to your Strato interface.</li> <li>Log in with your WAYF credentials.</li> </ol>"},{"location":"strato/advanced-guides/transfer-volume/#2-select-the-right-project","title":"2. Select the right project","text":"<ol> <li>Select the project where the volume is owned in the top ribbon.</li> </ol>"},{"location":"strato/advanced-guides/transfer-volume/#3-navigate-to-volumes","title":"3. Navigate to volumes","text":"<ol> <li>In the left sidebar, navigate to Volumes &gt; Volumes and you will now see a list of all the volumes in the project.</li> </ol>"},{"location":"strato/advanced-guides/transfer-volume/#4-select-the-volume","title":"4. Select the volume","text":"<ol> <li>Locate the volume you want to transfer.</li> <li>Ensure the volume is available (not attached to any instance). <p>Note: It is a good idea to name your volumes appropriately before deleting any compute instances that they are attached to. Click the Edit Volume button to edit the volume name.</p> </li> <li>Click the Create Transfer button in the Actions column for that volume.</li> </ol> <p></p>"},{"location":"strato/advanced-guides/transfer-volume/#5-create-the-transfer","title":"5. Create the transfer","text":"<ol> <li>Enter a Name for the transfer (optional).</li> <li>Click Create Volume Transfer.</li> </ol> <p>A Transfer ID and Authorization Key will be displayed. Copy these details and share them securely with the recipient.</p>"},{"location":"strato/advanced-guides/transfer-volume/#6-accept-the-transfer-recipient","title":"6. Accept the transfer (Recipient)","text":"<ol> <li>The recipient logs in to the Strato interface.</li> <li>Go to Volumes &gt; Volumes.</li> <li>Click Accept Transfer.</li> <li>Enter the Transfer ID and Authorization Key provided.</li> <li>Click Accept Volume Transfer.</li> </ol> <p>The volume will now appear in the recipient's project.</p>"},{"location":"strato/advanced-guides/transfer-volume/#notes","title":"Notes","text":"<ul> <li>The volume must be detached from the server before transfer.</li> <li>After transfer, all access to the volume is moved to the recipient.</li> </ul>"},{"location":"strato/application-guides/Isaac-sim/","title":"Installation guide for Isaac-sim on Strato","text":""},{"location":"strato/application-guides/Isaac-sim/#general","title":"General:","text":"<ul> <li>Software for mechanical simulation</li> <li>Recommended to use GPU virtual machines and docker</li> <li>It is a software package that requires docker and is currently tested for the \"CUDA Ubuntu 22.04\" image.</li> </ul>"},{"location":"strato/application-guides/Isaac-sim/#notes","title":"Notes","text":"<ul> <li>The NVIDIA driver installation requires a specific Linux kernel, which is available on the \"CUDA Ubuntu 22.04\" image.</li> <li>Isaac-Sim is compatible with a specific NVIDIA installation, which is not part of the standard Strato image set, so it requires removing the existing NVIDIA installation from the \"CUDA Ubuntu 22.04\" image.</li> <li>On UCloud, the product is called Virtual Machine \"CUDA 22.04\"</li> <li>X-forwarding (particularly the activation of a display) has been affected by which network a virtual machine is started on - i.e. a public or local network in the Strato platform. I can't explain why, but there are several items that must be modified in the <code>/etc/ssh/sshd_config</code> file location if starting from a \"campus network\" IP address, which are not necessary when launching from a public IP.</li> </ul>"},{"location":"strato/application-guides/Isaac-sim/#create-an-instance-on-strato-or-on-ucloud-if-you-have-access-to-virtual-machine-resources","title":"Create an instance on Strato (or on UCloud, if you have access to virtual machine resources)","text":"<p>For both Strato and UCloud you will need to prepare an SSH key. You can follow the getting started guide for Strato to create an SSH key, and to ensure that you also enable access to the instance via SSH port 22.</p> <p>On both platforms there is an option to enter the public part of you SSH key when launching an instance (on Strato) or job (on UCloud).</p>"},{"location":"strato/application-guides/Isaac-sim/#connect-to-your-instance-from-the-terminal-powershell-for-windows-using-ssh","title":"Connect to your instance from the terminal (powershell for Windows) using SSH","text":"<p>It is a good idea include the X11 forwarding flag <code>-X</code> in your connection command.</p> <p>Isaac-sim also allows traffic for different services via certain ports, and you might want to include port forwarding for some of those services from the beginning.</p> <p>According to ChatGPT, Isaac Sim typically runs Omniverse Kit-based applications with a WebSocket or HTTP server. The default Ports for Isaac Sim are: * Default WebSocket ports: 3000, 8211 * Default Streaming (WebRTC) port: 3000 * Default HTTP-based UI port: 8080 * If using Jupyter Lab: 8888</p> <p>Some examples of the connection command for your virtual machine are as follows, you can leave out port exposures that you don't need by removing, for example, <code>-L 8888:localhost:8888</code> if you do not need Jupyter Lab notebook exposure.</p>"},{"location":"strato/application-guides/Isaac-sim/#ucloud-connection-command","title":"UCloud connection command","text":"<pre><code>ssh -i ~/.ssh/ucloud_key ucloud@130.225.38.??? -L 3000:localhost:3000 -L 8080:localhost:8080 -L 8888:localhost:8888 -X\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#strato-connection-command","title":"Strato connection command","text":"<pre><code>ssh -i ~/.ssh/strato_key ubuntu@130.225.37.??? -L 3000:localhost:3000 -L 8080:localhost:8080 -L 8888:localhost:8888 -X\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#update-apt-before-purging-the-nvidia-drivers","title":"Update apt before purging the NVIDIA drivers","text":"<p>Begin by updating the APT packaging index, so that you have an updated list of sources to download applications from.</p> <p>It is very important that you do not <code>sudo apt upgrade</code>, as this will alter the kernel.</p> <pre><code>sudo apt update\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#purge-the-server-for-any-nvidia-drivers","title":"Purge the server for any NVIDIA drivers","text":"<p>The NVIDIA drivers pre-installed on the image will be incompatible with the installation you need for Isaac Sim. These need to be removed before continuing.</p> <pre><code>sudo apt-get remove --purge nvidia-* -y\n</code></pre> <pre><code>sudo apt autoremove &amp;&amp; sudo apt autoclean\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#install-x-server","title":"Install x server","text":"<p>To ensure that X11 works properly for forwarding the visual interface you will need to install a few additional packages.</p> <pre><code>sudo apt install -y \\\n    xserver-xorg x11-utils x11-xserver-utils xinit\\\n    pkg-config vulkan-tools build-essential\\\n    xdg-utils mesa-utils xvfb\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#install-the-nvidia-drivers-for-running-the-docker-container","title":"Install the NVIDIA drivers for running the docker container","text":"<p>It is possible to try to run either one of two sets of drivers, 550.127.05 is the latest driver available from XFree86, but if you want to install the one recommended on NVIDIA's website you can install 535.129.03. Both are compatible with the kernel of the \"CUDA Ubuntu 22.04\" image.</p>"},{"location":"strato/application-guides/Isaac-sim/#55012705-driver-latest","title":"550.127.05 driver (Latest)","text":"<pre><code>wget https://us.download.nvidia.com/XFree86/Linux-x86_64/550.127.05/NVIDIA-Linux-x86_64-550.127.05.run\nchmod +x NVIDIA-Linux-x86_64-550.127.05.run\nsudo ./NVIDIA-Linux-x86_64-550.127.05.run\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#53512903-driver","title":"535.129.03 driver","text":"<p><pre><code># wget https://us.download.nvidia.com/XFree86/Linux-x86_64/535.129.03/NVIDIA-Linux-x86_64-535.129.03.run\n# chmod +x NVIDIA-Linux-x86_64-535.129.03.run\n# sudo ./NVIDIA-Linux-x86_64-535.129.03.run\n</code></pre> You will be presented with a few options during the installation, where I have had success by just selecting [YES] in each case.</p> <ul> <li>Install 32 bit components [YES]</li> <li>Build DKMS tarball [YES]</li> <li>Rebuild intraframs [YES]</li> </ul>"},{"location":"strato/application-guides/Isaac-sim/#install-docker","title":"Install docker","text":"<p>You then need to install docker - there are some additional docker instructions if you launch this virtual machine on a \"Campus Network\"</p> <p><pre><code># Docker installation using the convenience script\ncurl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n</code></pre> Allow the installation to complete, adn then run the post installation commands:</p> <p><pre><code># Post-install steps for Docker\nsudo groupadd docker\nsudo usermod -aG docker $USER\nnewgrp docker\n</code></pre> Once complete, your user will be able to run docker without a <code>sudo</code> pre-text. Now run a <code>hello world</code> to test your installation.</p> <pre><code># Verify Docker\ndocker run hello-world\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#install-the-nvidia-container-toolkit","title":"Install the NVIDIA Container Toolkit","text":"<p>Next you will need to install the NVIDIA container toolkit. </p> <p>It is important that this is run after purging nad reinstalling the NVIDIA drivers, as a compatible container toolkit will be automatically installed.</p> <pre><code># Configure the repository\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n    &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list \\\n    &amp;&amp; \\\n    sudo apt-get update\n\n# Install the NVIDIA Container Toolkit packages\nsudo apt-get install -y nvidia-container-toolkit\nsudo systemctl restart docker\n</code></pre> <p>Configure the NVIDIA runtime to docker.</p> <pre><code># Configure the container runtime\nsudo nvidia-ctk runtime configure --runtime=docker\nsudo systemctl restart docker\n</code></pre> <p>Run <code>nvidia-smi</code> from within docker to see that all GPUs are visible from within the docker environment.</p> <pre><code># Verify NVIDIA Container Toolkit\ndocker run --rm --runtime=nvidia --gpus all ubuntu nvidia-smi\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#fetch-and-run-the-isaac-sim-container-in-docker","title":"Fetch and run the Isaac-Sim container in Docker","text":"<p>Starting by the following lines to start the container from the link</p>"},{"location":"strato/application-guides/Isaac-sim/#running-isaac-sim-headless-on-strato","title":"Running Isaac-sim headless on Strato:","text":"<p>You will need to allow TCP and UDP traffic by modifying the security groups on Strato</p> <pre><code>docker run --name isaac-sim --entrypoint bash -it --runtime=nvidia --gpus all -e \"ACCEPT_EULA=Y\" --rm --network=host \\\n    -e \"PRIVACY_CONSENT=Y\" \\\n    -v ~/docker/isaac-sim/cache/kit:/isaac-sim/kit/cache:rw \\\n    -v ~/docker/isaac-sim/cache/ov:/root/.cache/ov:rw \\\n    -v ~/docker/isaac-sim/cache/pip:/root/.cache/pip:rw \\\n    -v ~/docker/isaac-sim/cache/glcache:/root/.cache/nvidia/GLCache:rw \\\n    -v ~/docker/isaac-sim/cache/computecache:/root/.nv/ComputeCache:rw \\\n    -v ~/docker/isaac-sim/logs:/root/.nvidia-omniverse/logs:rw \\\n    -v ~/docker/isaac-sim/data:/root/.local/share/ov/data:rw \\\n    -v ~/docker/isaac-sim/documents:/root/Documents:rw \\\n    nvcr.io/nvidia/isaac-sim:4.5.0\n</code></pre> <p>Then run Isaac Sim headless and wait for the terminal to show \"Isaac Sim Full Streaming App is loaded\"</p> <pre><code>./runheadless.sh -v\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#install-the-webrtc-streaming-client-on-your-local-machine","title":"Install the WebRTC Streaming Client on your local machine","text":"<p>Now open a new terminal on your local machine (SKIP if you have downloaded the Isaac Sim WebRTC Streaming Client) if not, this is how to do it</p> <p>Go to this link: https://docs.isaacsim.omniverse.nvidia.com/latest/installation/download.html#isaac-sim-latest-release</p> <p>Download the Isaac Sim WebRTC Streaming Client for linux, and put it in a folder called \"\"IsaacSim\" on your local machine home directory</p> <p>Now start Isaac Sim WebRTC Streaming Client in the directory where you downloaded it.</p> <pre><code>./IsaacSim/isaacsim-webrtc-streaming-client-1.0.6-linux-x64.AppImage\n</code></pre> <p>Insert the ip addresse of the openstack instance and open the GUI</p> <p>Now you should have Isaac Sim up and running</p>"},{"location":"strato/application-guides/Isaac-sim/#strato-campus-network-additional-instructions","title":"Strato Campus Network Additional instructions","text":""},{"location":"strato/application-guides/Isaac-sim/#strato-campus-network-virtual-machines-docker-port-modifications-to-ensure-that-the-ip-ranges-needed-for-docker-are-modified","title":"Strato Campus Network virtual machines: Docker port modifications to ensure that the ip ranges needed for docker are modified.","text":"<p>As per the AAU docker guidelines in Danish, or English</p> <p>Edit <code>/etc/docker/daemon.json</code> to include</p> <pre><code>{\n\"bip\": \"10.14.0.1/16\",\n\"ipv6\": false\n}\n</code></pre> <pre><code># reboot the virtual machine\nsudo reboot\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#modify-some-lines-in-the-sshd_config-file","title":"Modify some lines in the sshd_config file","text":"<p>If you are launching the instance on the Strato platform, and use the one of the local \"Campus\" network options. You will need to check that on the server the following is included in <code>/etc/ssh/sshd_config</code>:</p> <pre><code>AllowTcpForwarding yes\nX11Forwarding yes\nX11DisplayOffset 10\nX11UseLocalhost yes\n</code></pre> <p>It is then a good idea to restart the SSH server service. <pre><code>sudo systemctl restart sshd\n</code></pre></p> <p>Thereafter you should be able to activate a display point.</p> <pre><code>xauth generate $DISPLAY . trusted\n\nexport XAUTHORITY=$HOME/.Xauthority\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#alternate-running-options","title":"Alternate running options","text":"<pre><code>sudo nvidia-xconfig\nsudo reboot\n\nsudo systemctl restart docker\n\ndocker run --privileged --gpus=all -e ACCEPT_EULA=Y   -e DISPLAY=$DISPLAY   -v /tmp/.X11-unix:/tmp/.X11-unix   -p 3000:3000 -p 8080:8080 -p 8888:8888   --network=host   --name isaac-sim   -it nvcr.io/nvidia/isaac-sim:4.5.0\n</code></pre> <pre><code>docker run --name isaac-sim --entrypoint bash -it --runtime=nvidia --gpus all -e \"ACCEPT_EULA=Y\" --rm --network=host \\\n    -e \"PRIVACY_CONSENT=Y\" \\\n    -p 3000:3000 -p 8080:8080 -p 8888:8888 \\\n    -e \"HEADLESS=1\" \\\n    -v ~/docker/isaac-sim/cache/kit:/isaac-sim/kit/cache:rw \\\n    -v ~/docker/isaac-sim/cache/ov:/root/.cache/ov:rw \\\n    -v ~/docker/isaac-sim/cache/pip:/root/.cache/pip:rw \\\n    -v ~/docker/isaac-sim/cache/glcache:/root/.cache/nvidia/GLCache:rw \\\n    -v ~/docker/isaac-sim/cache/computecache:/root/.nv/ComputeCache:rw \\\n    -v ~/docker/isaac-sim/logs:/root/.nvidia-omniverse/logs:rw \\\n    -v ~/docker/isaac-sim/data:/root/.local/share/ov/data:rw \\\n    -v ~/docker/isaac-sim/documents:/root/Documents:rw \\\n    nvcr.io/nvidia/isaac-sim:4.5.0\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#reboot-instance","title":"Reboot instance","text":"<p>Run a reboot to ensure that the X forwarding features are available.</p> <pre><code>sudo reboot\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#reconnect-to-your-server-after-reboot","title":"Reconnect to your server after reboot","text":"<p>From the terminal either run the UCloud or Ubuntu (for Strato) connection command.</p>"},{"location":"strato/application-guides/Isaac-sim/#ucloud","title":"UCloud","text":"<pre><code>ssh -i ~/.ssh/ucloud_key ucloud@130.225.38.??? -L 3000:localhost:3000 -L 8080:localhost:8080 -L 8888:localhost:8888 -X\n</code></pre>"},{"location":"strato/application-guides/Isaac-sim/#strato","title":"Strato","text":"<pre><code>ssh -i ~/.ssh/strato_key ubuntu@130.225.37.??? -L 3000:localhost:3000 -L 8080:localhost:8080 -L 8888:localhost:8888 -X\n</code></pre>"},{"location":"strato/application-guides/docker/","title":"Docker","text":"<p>In the following we will be guiding you throught the process of installing Docker on a Strato Instance.</p>"},{"location":"strato/application-guides/docker/#installing-docker","title":"Installing Docker","text":"<p>Begin by fetching the appropriate GPG key. This is used by the APT package manager to verify the integrity of the software we want to install. <pre><code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n</code></pre></p> <p>Add the Docker repository to the list of sources in the APT packaging index. <pre><code>echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre></p> <p>After this has been done, we will update the APT packaging index. <pre><code>sudo apt update\n</code></pre></p> <p>Install Docker CE (Community Edition), Docker CE CLI (Command Line Interface) and containerd.io (a container runtime dependency). <pre><code>sudo apt install docker-ce docker-ce-cli containerd.io\n</code></pre> If this went well, we should now have installed Docker successfully. Let's verify that, by checking if Docker is running: <pre><code>sudo systemctl --no-pager status docker\n</code></pre></p>"},{"location":"strato/application-guides/docker/#change-the-privileges","title":"Change the privileges","text":"<p>By default the <code>docker</code> commands can only be run by the root user, and we will thus need to take two steps to allow the current user to execute <code>docker</code> commands. </p> <p>Create a new group called <code>docker</code> and add the current user to this group: <pre><code>sudo usermod -aG docker ${USER} &amp;&amp; newgrp docker\n</code></pre></p> <p>Optionally you can run a Docker command (eg. <code>docker ps</code>) to verify that all the steps were completed correctly.</p>"},{"location":"strato/application-guides/jupyter-notebook/","title":"Jupyter Notebook","text":"<p>In the following we will be guiding you throught the process of setting up Jupyter Notebooks on a Strato Instance.</p> <p>Info</p> <p>Jupyter Notebookes are also available on DeiC Interactive HPC (also known as UCloud). This requires no setup and ships with a GUI out of the box. Read more about this possibility in the official platform documentation.</p>"},{"location":"strato/application-guides/jupyter-notebook/#installing-jupyter","title":"Installing Jupyter","text":"<p>Jupyter can be installed either using Pip or Conda (also known as Anaconda). You will find instructions for both, but it is wise to only chose one of these methods.</p>"},{"location":"strato/application-guides/jupyter-notebook/#using-conda","title":"Using Conda","text":"<p>We recommend following the official installation instructions for installing Miniconda (a lightweight Conda distribution).</p> <p>Info</p> <p>It's also possible to launch an instance that has Miniconda preinstalled. You can find this image in the list of source images (look for Miniconda Ubuntu 22.04) - refer back to the section Launch Instance to learn about this list. </p> <p>Install Jupyter with conda <pre><code>conda install -c conda-forge jupyter\n</code></pre></p>"},{"location":"strato/application-guides/jupyter-notebook/#using-pip","title":"Using Pip","text":"<p>Update the apt package index: <pre><code>sudo apt update\n</code></pre></p> <p>Then install Pip: <pre><code>sudo apt install python3-pip python3-dev\n</code></pre></p> <p>Jupyter Notebook can now be installed with Pip: <pre><code>pip3 install jupyter\n</code></pre></p> <p>Finally set Jupyter to the path where pip installed it: <pre><code>export PATH=\"$PATH:$HOME/.local/bin/\"\n</code></pre></p>"},{"location":"strato/application-guides/jupyter-notebook/#launch-jupyter-notebook","title":"Launch Jupyter Notebook","text":"<p>By adding a few details to our initial SSH-command, you can launch a Jupyter Notebook on your Strato instance and access it in a web browser running on your local computer. <pre><code>ssh -i ~/.ssh/my_ssh_key -L 8888:localhost:8888 &lt;user&gt;@&lt;instance_ip&gt;\n</code></pre></p> <p>This establishes port-forwarding from your instance to the localhost of your computer. If you did not do this when you logged in to your instance, simply log out and log back in with these details added.</p> <p>Launch the Jupyter Notebook from your instance with: <pre><code>jupyter notebook --port=8888\n</code></pre></p> <p>This will generate a substantial number of lines. Find the line that has a link that looks something like this: <pre><code>http://localhost:8888/tree?token=b9fc44a51db685da273a2cd2kl25ac299f346ce8445bfa262382c\n</code></pre></p> <p>Now copy this link and paste it in to your web browser of choice. </p> <p>This should land you inside the notebook and everything should feel familiar.</p>"},{"location":"strato/application-guides/matlab/","title":"Matlab","text":"<p>In the following we will be guiding you throught the process of installing Matlab on a Strato Instance.</p> <p>Info</p> <p>Matlab is also available on DeiC Interactive HPC (also known as UCloud). This requires no setup and ships with a GUI out of the box. Read more about this possibility in the official platform documentation.</p>"},{"location":"strato/application-guides/matlab/#installing-matlab","title":"Installing Matlab","text":"<p>Begin by updating the APT packaging index, so we have an updated list of sources to download applications from: <pre><code>sudo apt update\n</code></pre></p> <p>Before going further, we will need to install an unzip tool and some additional libraries recommended by Mathworks. <pre><code>sudo apt install unzip libx11-dev xorg-dev xvfb libgdk-pixbuf-2.0-0\n</code></pre></p> <p>Download the Matlab Package Manager (MPM) from Mathworks and make it executable: <pre><code>sudo wget -P /usr/local/bin/ https://www.mathworks.com/mpm/glnxa64/mpm &amp;&amp; sudo chmod +x /usr/local/bin/mpm\n</code></pre></p> <p>Install Matlab using MPM. Note that here we will be installing a version from late 2024 - check Mathworks website for a newer release. <pre><code>mpm install MATLAB --release=R2024b --destination=$HOME/.local/matlab/\n</code></pre></p> <p>To be able to launch Matlab when we type <code>matlab</code> - we will need to add the directory where the matlab executable is found to our <code>$PATH</code> variable. We can make this addition permanent by writing to the file <code>.bashrc</code>, which is read every time a new shell session starts. <pre><code>echo 'export PATH=$HOME/.local/matlab/bin:$PATH' &gt;&gt; $HOME/.bashrc\n</code></pre></p> <p>We source the <code>.bashrc</code>-file, to apply these changes to the current session. <pre><code>source $HOME/.bashrc\n</code></pre></p>"},{"location":"strato/application-guides/matlab/#installing-aditional-toolboxes","title":"Installing aditional toolboxes","text":"<p>Additional matlab toolboxes can be installed in the following manner: <pre><code>mpm install --release=R2024b --destination=$HOME/matlab --products Signal_Processing_Toolbox Communications_Toolbox\n</code></pre> For a full list of available toolboxes check out mpm's documentation for input files. If you cannot find a toolbox you need, it might be unavailable for the Matlab release and/or platform, read about mpm's limitations.</p>"},{"location":"strato/application-guides/matlab/#running-matlab","title":"Running Matlab","text":"<p>In the following example, we will be running Matlab on the Strato instance, but rendering the application's graphics in the webbrowser of your local computer. In order for your local computer to receive the datastream from the server, we will need to add a small detail to our SSH command. <pre><code>ssh -i ~/.ssh/my_ssh_key -L 8888:localhost:8888 &lt;user&gt;@&lt;instance_ip&gt;\n</code></pre></p> <p>This establishes a connection between your Strato instance and a network adress on your computer (<code>localhost</code>). If you did not do this when you logged in to your instance, simply log out and log back in with these details added.</p> <p>Now let's proceed with the install. We will install <code>pip</code> along with some dependencies.</p> <pre><code>sudo apt install python3-pip python3-dev python3-venv\n</code></pre> <p>On modern Linux distributions, you will not be able to install Pip modules system wide - they must be installed in a virtual environment. Let's create one with: <pre><code>python3 -m venv $HOME/.local/matlab-venv\n</code></pre></p> <p>Finally we can activate the virtual environment before installing: <pre><code>source $HOME/.local/matlab-venv/bin/activate\n</code></pre></p> <p>The virtual environment is not loaded by default, when you log in to the instance. You will have to either run <code>source</code> command (shown above), or run this command, to add the source command to your .bashrc file (this file is sourced on login). <pre><code>echo \"source $HOME/.local/matlab-venv/bin/activate\" &gt;&gt; .bashrc\n</code></pre></p> <p>With the virtual environment activated, you can now install the Jupyter Kernel with: <pre><code>pip install jupyter jupyter-matlab-proxy\n</code></pre></p> <p>Now launch Jupyter with: <pre><code>jupyter lab --port=8888\n</code></pre></p> <p>This will output a great many lines. Towards the end of the output, you will find a line that looks something like this: <pre><code>http://localhost:8888/tree?token=b9fc44a5ic1dl685da73a2acad22uu5ac299f3d46icae8445bfa262382c\n</code></pre></p> <p>This URL has the port number we specified earlier and a special security token. Copy this link and paste it into your web browser. You can now choose to either run Matlab as an application inside your browser or as a Jupyter Notebook.</p> <p></p>"},{"location":"strato/application-guides/matlab/#activate-license","title":"Activate license","text":"<p>If you chose \"Open Matlab\" you will be met with a registration window. Enter your AAU-email.</p> <p>Wait for the license to be acquired. This may take a few minutes.</p> <p></p> <p>After this step, you should be inside the application and everything should feel familiar.</p> <p></p>"},{"location":"strato/application-guides/strato-applications/","title":"Strato applications","text":"<p>All Strato instances are essentially Linux computers with headless interfaces. They are in many ways very similar to regular desktop computers as they have a file system, network and computing capability, and they can run virtually any application - provided it can run on Linux. This is the most efficient way of distributing computing ressources and should be sufficient in most cases.</p>"},{"location":"strato/application-guides/strato-applications/#command-line-interfaces","title":"Command Line Interfaces","text":"<p>For many users, operating a computer from the command line will be a new experience. At first they may not know what to do with it. and they may be tempted to install applications, that more or less turn their instance into a remote desktop. Although this may be possible, it might not necessarily be a good idea. Installing desktop capabilities will require a large number additional libraries to be installed, whereby critical system libraries are replaced, leaving you with a very non-standard instance that may be prone to errors, is difficult to troubleshoot and potentially has security risks.</p> <p>Info</p> <p>A great ressource for learning how to use the Linux command line is: linuxjourney.com</p>"},{"location":"strato/application-guides/strato-applications/#graphical-user-interfaces","title":"Graphical User Interfaces","text":"<p>In some cases however, you might need a graphical user interface (also known as a GUI) to do the work you need. These could be situations where your software does not have a headless interface or where it simply does not make sense to have one.</p> <p>In the following we will suggest a few simple solutions for working with GUI applications on Strato.</p> <p>Info</p> <p>If you find that the prospect of learning to navigate the command line will be too difficult, you may consider one of our other HPC options:</p> <ul> <li>A more suitable alternative could be DeiC Interactive HPC (also known as UCloud), which as the name indicates is built for GUI-reliant interactive HPC operations.</li> <li>Read about our other computing services. </li> </ul>"},{"location":"strato/application-guides/strato-applications/#port-forwarding","title":"Port forwarding","text":"<p>This is likely the prefereable choice for most users.</p> <p>Many applications have dedicated server versions that can be run on a remote server and accessed through a web browser on your local computer.</p> <p>Before you go ahead and run the application, you should consider two things:</p> <ol> <li> <p>Find out what port is being used to expose the application. This configuration will vary frome one application to another, but in many cases you will find that certain applications use a default port. You should be able to find this in the documentation for the application. In many cases you should also be able to specify a different port, should the default port conflict with one that's being used.</p> </li> <li> <p>Establish port forwarding between the Strato instance and your local computer. We do this by adding an additional parameter to our SSH command: <code>-L &lt;local_port&gt;:localhost:&lt;remote_port&gt;</code>. Assuming that the port in question is <code>8888</code> the full command would be: <pre><code>ssh -i ~/.ssh/&lt;my_private_key&gt; -L 8888:localhost:8888 ubuntu@10.92.x.xxx\n</code></pre></p> </li> </ol> <p>Now you should be able to run your application in a web browser!</p> <p>We use Jupyter Notebook as an example</p> <p>Assuming that we logged in with the <code>-L</code> parameter added to our ssh command and installed Jupyter, we can launch it with <pre><code>jupyter notebook\n</code></pre></p> <p>Now find a web browser on your local computer. In Jupyter's case a URL will be outputted after executing the application. Normally it would be sufficient to go to: <pre><code>localhost:8888\n</code></pre></p> <p>You should now have a fully functional Jupyter Notebook environment from within your browser!</p> <p></p>"},{"location":"strato/application-guides/strato-applications/#x11-forwarding","title":"X11 forwarding","text":"<p>This approach can be good for rendering less demanding applications, plots, images, etc. In most cases rendering complete desktop software will simply be to heavy, and you will experience a considerable amount of lag.</p> <p>X11 is an display server technology commonly used in Linux, and is not always supported out of the box on other operating systems. Setup will therefore depend on your operating system. In recent years there have been advances with regards to support for X11 Forwarding, and the required setup of your system has become relatively easy.</p> WindowsmacOSLinux desktops <ul> <li>Ensure that you are using an appropriate terminal emulator. We recomend using Powershell. Both Powershell and OpenSSH come preinstalled with all currently supported versions of Windows.</li> <li>Ensure that your version of OpenSSH is greater than <code>8.1p1</code>. Check the version with: <pre><code>PS C:\\ ssh -V\nOpenSSH_for_Windows_8.1p1, LibreSSL 3.0.2\n</code></pre> If your version that is lower than 8.1p1 your version is supported. If your version is lower, you should consider updating your system.</li> </ul> <ul> <li>Ensure that you have Xquartz installed on your system. If this is not the case it can be downloaded from the official XQuartz webpage.</li> </ul> <ul> <li>Check which display server you are running on your local computer. Open a terminal application and run the command: <pre><code>echo $XDG_SESSION_TYPE\n</code></pre><ul> <li>If this outputs <code>X11</code>, you need not do anything.</li> <li>If this outputs <code>wayland</code>, you might want to install Waypie or consider switching to X11 temporarily.</li> </ul> </li> </ul> <p>Now you should be ready to use the feature. We do this by verifying by adding <code>-X</code> to our initial ssh command:</p> <p><pre><code>ssh -i ~/.ssh/&lt;my_private_key&gt; -X ubuntu@10.92.x.xxx\n</code></pre> If you did not log in to the instance with the <code>-X</code> flag, simply log out and log back in.</p> <p>This will create a file in the home diretory of your Strato instance called <code>.Xauthority</code>. You can use <code>ls -al $HOME</code> to view the files in your user directory. If you find one, and the last modified date column corresponds to the time you logged in to the server, you can assume that everything went well.</p> <p>Example</p> <p>Now that you have logged in to your instance with <code>ssh -X</code> image windows will now get rendered on your computer.</p> <p>Assuming that I have the following R code <pre><code>x &lt;- rnorm(100)\ny &lt;- rnorm(100)\nplot(x, y)\n</code></pre></p> <p>As soon as the <code>plot(x, y)</code> is run, this window will open:</p> <p></p>"},{"location":"strato/best-practice-guides/create-smaller-volumes/","title":"Create smaller volumes","text":"<p>When you create a new instance, it will inherit the volume size from the flavour (1TB). To create a custom volume the user must first create a volume and then launch this volume as an instance.</p> <ol> <li>Navigate to the Volume tab.</li> <li>Click the Create Volume button.</li> <li>Set Volume Name.</li> <li>Set Volume Source from image.</li> <li>Set Set custom size.</li> <li>Click launch instance as volume.</li> <li>Set name for instance</li> <li>Select Boot source Volume.</li> <li>Select flavour and launch instance</li> </ol> <p></p>"},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/","title":"Delete and restart an instance from the volume","text":"<p>wThis is essentially a 3 step process.</p> <ol> <li>Rename the volume attached to your instance / server.</li> <li>Delete your instance</li> <li>Start a new instance and choose a volume rather than an image as the \"Source\".</li> </ol>"},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/#method-1-how-to-shut-off-delete-and-reinstate-an-instance-from-a-volume","title":"Method 1: How to Shut off, delete and reinstate an instance from a volume","text":""},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/#preparation-and-deletion-of-an-instance","title":"Preparation and deletion of an instance","text":"<ol> <li>Browse to the <code>&gt;Compute &gt;&gt;Instances</code> section, and on the relevant instance click the instance name.<ol> <li>Make a note of the volume number.</li> <li>Copy and paste the volume number somewhere you can find it for future reference.</li> </ol> </li> <li>Browse to the <code>&gt;Volumes &gt;&gt;Volumes</code> section and rename the volume noted in 1.2 to a name you can identify later. (For example, RStudio server volume)</li> <li>Browse to the <code>&gt;Compute &gt;&gt;Instances</code> section, and on the relevant instance click the dropdown-menu,<ol> <li>Select <code>Shut Off Instance</code>, to make sure that all operations are properly shut down before deleting.</li> </ol> </li> <li>Browse to the <code>&gt;Compute &gt;&gt;Instances</code> section, and on the relevant instance click the dropdown-menu,<ol> <li>Select Delete Instance. This will delete the instance.</li> </ol> </li> <li>Browse to <code>&gt;Volumes &gt;&gt;Volumes</code> and check that the volume is still there.</li> </ol>"},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/#re-launching-the-instance","title":"Re-launching the instance:","text":"<ol> <li>Browse to the <code>&gt;Volumes &gt;&gt;Volumes</code> section.<ol> <li>Find the volume noted in point 3, and then click the dropdown menu button at Edit Volume:</li> </ol> </li> <li>Select Launch as Instance.</li> <li>Choose the most relevant / appropriate flavour. You here have the option of changing flavours.</li> <li>NB when you select the <code>&gt;Source &gt;&gt;Boot source</code>, you must select Volume. <ol> <li>You will need to click the up arrow alongside the volume noted in point 3 to use it as the boot source.</li> <li>Follow all other instance setup instructions as noted in the Quick guide for the network settings, keypairs etc., and launch the instance.</li> </ol> </li> <li>Check that the instance has launched and note the new IP address.</li> <li>Access your volume via the terminal (ssh ubuntu@\u2026. ), here you will need to use the new IP address.</li> <li>Your machine should run as before, but with the flavour most recently selected.</li> </ol> <p>NOTE: Windows users may need to update PuTTy settings.</p>"},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/#method-2-how-to-shut-off-delete-and-reinstate-an-instance-where-delete-volume-on-instance-delete-is-activated-set-to-yes","title":"Method 2: How to Shut off, delete and reinstate an instance where \u201cDelete volume on Instance delete\u201d is activated (set to yes).","text":"<p>Warning: This method is experimental and includes a possible failsafe to prevent automatic deletion of volume, so proceed with caution: We have tested this to work, but we cannot guarantee that it will prevent the deletion of the volume. At present, creating a snapshot of a volume prevents the automatic deletion of the volume when the instance is deleted. A snapshot is NOT a copy or image of a disk, and thus depends on the disk still existing. If you are in doubt about whether you have activated this setting, you should be able to use the following process to delete your instances safely:</p>"},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/#preparation-and-deletion-of-an-instance_1","title":"Preparation and deletion of an instance","text":"<ol> <li>Browse to the <code>&gt;Compute &gt;&gt;Instances</code> section, and on the relevant instance click the instance name.</li> <li>Make a note of the volume number.</li> <li>Copy and paste the volume number somewhere you can find it for future reference.</li> <li>Browse to the <code>&gt;Volumes &gt;&gt;Volumes</code> section and rename the instance noted in 1.2 to a name you can identify later. (For example RStudio server volume)</li> <li>Browse to the <code>&gt;Compute &gt;&gt;Instances</code> section, and on the relevant instance click the dropdown-menu,</li> <li>Select Shut Off Instance, to make sure that all operations are properly shut down before deleting.</li> <li>Browse to <code>&gt;Volumes &gt;&gt;Volumes</code>, and for the relevant volume:</li> <li>Click the dropdown-box and select Create snapshot.</li> <li>Choose an appropriate name. (For example Temporary snapshot of RStudio server volume), and create the snapshot</li> <li>Check that the snapshot is listed in the <code>&gt;Volumes &gt;&gt;Snapshots</code> section.</li> <li>Browse to the <code>&gt;Compute &gt;&gt;Instances</code> section, and on the relevant instance click the dropdown-menu,</li> <li>Select Delete Instance. This will delete the instance, you can now go ahead and delete the snapshot.</li> <li>Browse to <code>&gt;Volumes &gt;&gt;Volumes</code> and check that the volume is still there.</li> <li>Browse to <code>&gt;Volumes &gt;&gt;Snapshots</code> and click the dropdown box alongside the relevant snapshot, then click the Delete snapshot option to delete the snapshot.</li> </ol>"},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/#re-launching-the-instance_1","title":"Re-launching the instance:","text":"<ol> <li>Browse to the <code>&gt;Volumes &gt;&gt;Volumes</code> section.</li> <li>Find the volume noted in point 3, and then click the dropdown menu button at Edit Volume:</li> <li>Select Launch as Instance.</li> <li>Choose the most relevant / appropriate flavour. You have the option of changing flavours.</li> <li>NB when you select the <code>&gt;Source &gt;&gt;Boot</code> source, you must select Volume. </li> <li>You will need to click the up arrow alongside the volume noted in point 3 to use it as the boot source.</li> <li>Follow all other instance setup instructions as noted in the Quick guide for the network settings, keypairs etc., and launch the instance.</li> <li>Check that the instance has launched and note the new IP address.</li> <li>Access your volume via the terminal (ssh ubuntu@\u2026. ), here you will need to use the new IP address.</li> <li>Your machine should run as before, but with the flavour most recently selected.</li> </ol> <p>NOTE: Windows users may need to update PuTTy settings.</p>"},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/#additional-benefits","title":"Additional Benefits:","text":"<ul> <li>This solves the current inability to resize an instance.</li> <li>Every time you need to make changes to the installation on the volume, you can spin up a machine that is the perfect size for the task.</li> <li>This mitigates the problems encountered when trying to shelve a GPU instance. (Launching a new instance from a volume does not require that the identical physical device is attached to the instance, as is the case when trying to shelve an instance).</li> <li>You will get an idea of how many volumes you have allocated to your user and can clean up your storage.</li> </ul>"},{"location":"strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/#note-on-volume-sizes","title":"Note on volume sizes","text":"<p>Volumes can always be extended later (but not reduced in size) so any image or snapshot creation intended for sharing or as templates should be set to the minimum viable size.</p>"},{"location":"strato/best-practice-guides/how-to-minimize-the-risk-of-malware/","title":"How to Minimize the Risk of Malware","text":"<p>By adhering to these best practices, you can significantly reduce the risk of malware infections and strengthen the overall security posture of your STATO environment</p>"},{"location":"strato/best-practice-guides/how-to-minimize-the-risk-of-malware/#1-use-trusted-repositories","title":"1. Use trusted repositories","text":"<ul> <li> <p>Stick to official sources: Always install software from your Linux distribution\u2019s official repositories (e.g., APT for Ubuntu/Debian, YUM/DNF for CentOS/RHEL). These repositories are regularly vetted and maintained by trusted developers, ensuring a higher level of security.</p> </li> <li> <p>Verify external sources: If you need to use third-party repositories or download packages from external sources, ensure they are well-known, trusted, and verified. Always check for digital signatures and authenticity.</p> </li> </ul>"},{"location":"strato/best-practice-guides/how-to-minimize-the-risk-of-malware/#2-opt-for-minimalist-installation","title":"2. Opt for minimalist installation","text":"<ul> <li>Install only essential packages: Limit the installation to only the software necessary for your server\u2019s intended purpose. A minimalist approach reduces the potential attack surface by limiting the number of installed packages that could be compromised.</li> </ul>"},{"location":"strato/best-practice-guides/how-to-minimize-the-risk-of-malware/#3-keep-the-operating-system-and-packages-up-to-date","title":"3. Keep the operating system and packages up-to-date","text":"<ul> <li>Timely kernel and software updates: Regularly update the Linux kernel and all installed packages to ensure that security vulnerabilities are promptly patched. Consider automating this process where possible to minimize delays.</li> </ul>"},{"location":"strato/best-practice-guides/how-to-minimize-the-risk-of-malware/#4-implement-strong-access-controls","title":"4. Implement strong access controls","text":"<ul> <li>Enforce Strong SSH Keys: Mandate the use of strong, unique SSH keys for server access. Avoid using weak or default passwords.</li> </ul>"},{"location":"strato/best-practice-guides/resize-your-server/","title":"Resize your server","text":""},{"location":"strato/best-practice-guides/resize-your-server/#resize-your-strato-server","title":"Resize your Strato server","text":"<p>This guide shows you how to change the size of your Strato server to a smaller or larger flavor (vCPUs and GPUs).</p>"},{"location":"strato/best-practice-guides/resize-your-server/#1-log-in-to-the-strato-portal","title":"1. Log in to the Strato portal","text":"<ol> <li>Open your browser and go to the Strato portal.</li> <li>Log in with your Strato username and password.</li> </ol>"},{"location":"strato/best-practice-guides/resize-your-server/#2-go-to-the-correct-project","title":"2. Go to the correct project","text":"<ol> <li>In the top bar navigation, locate and select the project that the server belongs to.    Strato servers are organized by project, so you must be in the correct project to see the relevant servers.</li> </ol>"},{"location":"strato/best-practice-guides/resize-your-server/#3-open-the-server-overview","title":"3. Open the server overview","text":"<ol> <li>In the main navigation, go to the Compute section and open the Instances page that lists your servers.</li> <li>Find the server you want to resize in the list.</li> </ol>"},{"location":"strato/best-practice-guides/resize-your-server/#4-open-the-resizechange-flavor-dialog","title":"4. Open the resize/change flavor dialog","text":"<ol> <li>Click the three\u2011dot menu on the far right of the server row.</li> <li>In the server context menu, click Resize instance.</li> </ol>"},{"location":"strato/best-practice-guides/resize-your-server/#5-choose-the-new-size-flavor","title":"5. Choose the new size (flavor)","text":"<p>In the resize dialog you will see a list of available flavors (predefined combinations of vCPUs, RAM, and possibly disk and GPUs).</p> <ul> <li>Review current size:</li> <li>Note the current vCPUs, RAM, and disk so you can compare.</li> <li>Select a new flavor:</li> <li>Pick a flavor that meets your performance needs.</li> <li>Make sure it fits within your quota and budget limits.</li> </ul> <p>Tip: Before resizing your server, make sure your project has a high enough quota for the new flavor (vCPUs, RAM, GPU). If not, you may need to request a quota increase through the Strato application form.</p>"},{"location":"strato/best-practice-guides/resize-your-server/#6-confirm-the-resize-operation","title":"6. Confirm the resize operation","text":"<ol> <li>After selecting the new flavor, click Resize.</li> <li>The dialog window will close. </li> <li>Back on the server page, in the upper\u2011right corner, click Confirm Resize/Migrate to apply the change.</li> </ol>"},{"location":"strato/best-practice-guides/resize-your-server/#7-wait-for-the-operation-to-complete","title":"7. Wait for the operation to complete","text":"<p>The server status will change while Strato applies the new size.</p> <ul> <li>Wait until the status returns to Running/Active.</li> <li>The time required depends on the size change and backend load.</li> </ul>"},{"location":"strato/best-practice-guides/resize-your-server/#8-verify-the-new-size","title":"8. Verify the new size","text":"<p>After the resize is complete:</p> <ol> <li>Check the server detail page:</li> <li>Confirm the vCPUs, RAM, and (if relevant) GPUs now match the selected flavor.</li> <li>(Optional) Log in to the server:</li> <li>On Linux, check resources with <code>lscpu</code> and <code>free -h</code>.</li> <li>On Windows, use Task Manager or System Information.</li> </ol>"},{"location":"strato/best-practice-guides/stop-pause-and-delete-instances/","title":"Stop, pause & delete instances","text":"<p>Instances in the Strato CLAAUDIA Compute cloud can have a range of States:</p> <ul> <li>Active: Instance is active, you can connect to it.</li> <li>Shelved (CPU only): Shelving is useful if you have a CPU only instance (i.e. no GPU) that you are not using, but would like retain in your list of servers. For example, you can stop an instance at the end of a work week, and resume work again at the start of the next week. All associated data and resources are kept; however, anything still in memory is not retained. It is, however, better practice to delete the instance and then later start a new instance from the volume with compute resources needed at that time.</li> <li>Paused: In this state, the server state is preserved in RAM, but operations have been stopped and will resume when instructed. This state will keep allocated resources from being used by others.</li> <li>Suspended: Instance state has been stored on disk, including the contents of its RAM. This state will keep allocated resources from being used by others.</li> <li>Shutoff: This is like powering off a server. This state will keep allocated resources from being used by others.</li> <li>Resized: Allows you to select a new instance flavor, after which the instance will be taken down and then come back up with the new computational resources available to it. On Linux you can check with commands such as <code>lscpu</code> and <code>lsmem</code> or <code>cat /proc/cpuinfo</code> and <code>cat /proc/meminfo</code>. This state will keep allocated resources from being used by others.</li> </ul>"},{"location":"strato/best-practice-guides/stop-pause-and-delete-instances/#delete-an-instance","title":"Delete an instance","text":"<p>To delete an instance using the Horizon web interface you must be logged in. For an instance to be deleted, it should first be shut down. Navigate to the launch instance menu using the horizon web interface.</p> <ol> <li>Navigate to the project tab</li> <li>Click the Compute sub-tab</li> <li>Click on Instances</li> <li>Mark the checkbox of the instance you wish to delete.</li> <li>Press Delete Instances on the right side of the webpage.</li> <li>Press Delete Instances in the confirmation dialog.</li> </ol> <p></p> <p>Deleting an instance will not delete the attached volume, unless specifically set to during creation.</p>"},{"location":"strato/best-practice-guides/stop-pause-and-delete-instances/#shelve-an-instance-cpu-only","title":"Shelve an instance (CPU only)","text":"<p>It is possible to shelve an instance, but we do not recommend this practice. </p> <p>Any attempt to shelve or unshelve with a GPU flavour will end in an error state.</p> <p>If you know you are not going to use a CPU only instance for a while, for example the next couple of days or even longer, it is encouraged to release the resources to make them available to other users running instances on Strato.</p> <ol> <li>Navigate to the project tab.</li> <li>Click the Compute sub-tab.</li> <li>Click on Instances.</li> <li>In the row of the instance you wish to shelve, press the dropdown menu in the right-most column, Actions.</li> <li>Select Shelve Instance from the dropdown.</li> </ol> <p>This will first shut down the instance nicely, save it to disk and subsequently release its resources. In order to use your instance again at a later point, repeat the above steps and this time select Unshelve Instance from the dropdown menu. Although other states such as Paused, Suspended, and Shutoff also make the instance unavailable, shelving an instance is the only approach that actually releases the resources and makes them available to other users and instances.</p>"},{"location":"strato/getting-started/","title":"Before you begin","text":"<p>Before diving into Strato, ensure you have the necessary tools and knowledge for the best experience. Here's a brief overview:</p> <p>Request access</p> <p>If you haven't done so yet, please visit how to access to learn how to get approved for using Strato.</p>"},{"location":"strato/getting-started/#preperations","title":"Preperations","text":"<ul> <li>Ensure you are connected to the AAU network (including VPN)</li> <li>For Windows users, use Windows PowerShell to follow our guides effectively. Alternatively, try installing OpenSSH or a Linux subsystem</li> </ul> <p>Please review our Terms and Conditions, especially noting the following points:</p> <ul> <li>Strato is not intended for working with confidential or sensitive data</li> <li>Strato is not designed for long term storage of research data.</li> <li>Strato is not designed for production.</li> <li>Strato is not intended to host long term shared research projects.</li> </ul> <p>With these preparations in place, lets get started </p>"},{"location":"strato/getting-started/access-instance/","title":"Access instance","text":"<p>All Strato instances are run on the AAU-network. Before you attempt to access your instance, please make sure that you are connected to the AAU-network - either by being physically on university grounds, being connected to the AAU VPN-service or establishing the connection through the SSH-gateway. </p> <p>Strato requires your key file to be in the OpenSSH-format, and if you have managed to create the key pair according to the previous section, it's safe to assume that you have OpenSSH installed on your machine. </p> <p>The following will work on most modern computers, but for Windows users we specifically recomend using either Powershell (comes preinstalled on all Windows computers), MobaXterm or PuTTY. Do not rely on the console built in the OpenStack dashboard.</p>"},{"location":"strato/getting-started/access-instance/#access-your-instance","title":"Access your instance","text":"<p>Open the appropriate terminal application for your system and enter the SSH command. </p> <p>The command structure is:</p> <pre><code>ssh -i ~/.ssh/&lt;my_private_key&gt; ubuntu@10.92.0.zzz\n</code></pre> <ul> <li><code>ssh</code> is a call for establishing an SSH-connection. </li> <li><code>-i</code> is an additional argument for specifying an identity file (private key).</li> <li><code>~/.ssh/yourPersonalKey</code> is the typical location of your private key (identity file). Don't forget to swap this out for the actual location of your SSH-key.</li> <li><code>ubuntu@10.92.10.zzz</code> specifies which user you want to log in as, and the IP adress of the instance you want to connect to (can be found in the OpenStack dashboard; Compute &gt; Instances )</li> </ul> <p>The command should look something like this:</p> <pre><code>ssh -i ~/.ssh/my_ssh_key ubuntu@10.92.1.99\n</code></pre> <p>You should now have accessed your instance!</p>"},{"location":"strato/getting-started/access-instance/#additional-information","title":"Additional information","text":"<p>Usernames for other distribution images</p> <p>The default user name for Ubuntu-instances is always \"ubuntu\". If you decide to try out a different distribution image, this would change. </p> <p>Connecting via AAU's SSH-gateway</p> <p>If you do not have access to the VPN, it is also possible to connect to your instance by using AAU's SSH gateway as a jump host. This way your connection gets established through the gateway without redirecting the rest of your network traffic. Note that this will ask you for multifactor authentication. </p> <p><pre><code>ssh -J &lt;aau_username&gt;@sshgw.aau.dk -i  ~/.ssh/my_ssh_key ubuntu@10.92.1.99\n</code></pre> Where you switch out  for your actual username, like so: <pre><code>ssh -J kf41yf@dep.aau.dk@sshgw.aau.dk -i  ~/.ssh/my_ssh_key ubuntu@10.92.1.99\n</code></pre> <p>File permissions</p> <p>It is possible, you might be faced with an error message telling you \"Permissions are too open\". In order to solve this you need to modify the file permissions: <pre><code>chmod 600 ~/.ssh/my_ssh_key\n</code></pre> </p>"},{"location":"strato/getting-started/launch-instance/","title":"Launch instance","text":"<p>Strato instances are launched in an Openstack dashboard which can be accessed at: strato-new.claaudia.aau.dk.</p> <ul> <li>Ensure the field \"Authenticate using\" is set to \"WAYF\" and click Sign in. </li> <li>You will be redirected to \"signon.aau.dk/\" where you must login with your regular AAU credentials. Enter them and click Sign in.</li> </ul> <p>When you have done this, you should have reached the OpenStack dashboard!</p> <p></p>"},{"location":"strato/getting-started/launch-instance/#initial-openstack-setup","title":"Initial Openstack setup","text":"<p>The default way of accessing Strato instances is done with SSH. This a commonly used protocol in cloud computing. Before launching your first Strato instance, we need to make a couple of configurations in the OpenStack platform. </p>"},{"location":"strato/getting-started/launch-instance/#ssh-rule","title":"SSH rule","text":"<p>Strato configures port access with Security groups. Each group can have multiple rules to permit access. Follow these steps to add port 22 (standard for SSH) to the default security group.</p> <ol> <li>Navigate to Network -&gt; Security Groups</li> <li>Click Manage Rules on the default Security group</li> <li>Click Add Rule</li> <li>Choose SSH from dropdown menu.</li> <li>Click Add</li> </ol> <p></p>"},{"location":"strato/getting-started/launch-instance/#create-ssh-key-pair","title":"Create SSH key pair","text":"<p>Authenticating with SSH requires you to have an SSH key pair. This key pair consists of a public key (stored on the remote device) and a private key (stored only on your local device). </p> <p>For security reasons your SSH-key must be encrypted with a password, and therefore this needs to be done on your local computer. In the following we will create a key pair using the OpenSSH-standard compatible with Strato.</p> <p>The following will work on most modern terminal emulators. For Windows users we recomend using the preinstalled application Powershell.</p> <ul> <li>Open your terminal application.</li> <li>Enter <code>cd ~/.ssh</code> to navigate to the conventional directory for SSH-keys.<ul> <li>If the directory doesn't exist already, you can create it with: <ul> <li><code>mkdir ~/.ssh</code> MacOS/Linux</li> <li><code>md ~/.ssh</code> on Windows</li> </ul> </li> <li>Don't forget to enter the directory afterwards, with <code>cd ~/.ssh</code></li> <li>Type <code>ls</code> to list the files in the current directory. This is just so you can keep track of what changes.</li> </ul> </li> <li>Enter <code>ssh-keygen</code> to initiate the key generation.</li> <li>When faced with the prompt \"Enter file in which to save the key...\" you can set an optional name for your keyfile.</li> <li>Then you will asked to set a password. For security reasons, we strongly recommend setting a password for your keys. See AAU IT Security's recommendations for passwords.</li> <li>You should now have two files that weren't there before. Typing <code>ls</code> will reveal two new files: \"id_rsa\" and \"id_rsa.pub\" (if you chose your own file name this will have replaced the \"id_rsa\" part).</li> </ul>"},{"location":"strato/getting-started/launch-instance/#upload-key-pair-to-openstack","title":"Upload key pair to OpenStack","text":"<p>Now that we have created our key pair, we need to upload the public key to Strato </p> <ul> <li>Navigate to Compute -&gt; Key Pairs</li> <li>Click Import Public Key. This will open a dialog box.</li> <li>Under Key Pair Name type in the name you gave the key, when you created it.</li> <li>Under Key Type select SSH. </li> <li>Under Load Public Key from a file click Browse and navigate to the location of your keyfile.<ul> <li>On Mac OS and Linux the directory <code>~/.ssh</code> is hidden and might not be visible in your file manager.<ul> <li>MacOS Finder press \"cmd + shift + .\" to show hidden files.</li> <li>Ubuntu/Gnome (using Nautilus file manager) press \"ctrl + h\" to show hidden files.</li> </ul> </li> </ul> </li> <li>Select your public key file (ends in .pub) and click Ok.</li> </ul>"},{"location":"strato/getting-started/launch-instance/#launch-ubuntu-instance","title":"Launch Ubuntu instance","text":"<p>To launch the Ubuntu instance navigate to the \"launch instance\" menu using the webinterface.</p> <ol> <li>Navigate to Compute -&gt; Images</li> <li>Press Launch on the right side of the image you wish to Launch.</li> </ol> <p></p> <p>In the \"Launch instance\" menu you can choose the settings for the instance. In this excercise we will apply the following:</p> <ul> <li>Details: Choose a name for your instance.</li> <li>Source: Choose Ubuntu 22.04.</li> <li>Flavour: Choose \"AAU.CPU-1-4\" to create the smallest possible instance. </li> <li>Networks: Select \"Campus Network 01\" or \"Campus Network 02\". If you are interested in having an instance that is globally accessible for e.g. hosting a webservice, copying data from another university etc., then select \"AAU Public\". Make sure you understand the security risks.<ul> <li>Only associate one of the two networks to your instance. If you associate both; it will not work without considerable additional effort not documented here.</li> </ul> </li> <li>Security groups: Ensure that the default security group we edited earlier is applied (should be default). </li> <li>Key-pair: Ensure that the key-pair created earlier is applied (should be default).</li> </ul> <p></p> <p>Congratulations!</p> <p>You have launched your first instance. Now consult the \"Access instance\"-section to learn how to access your instance!</p> <p>Reminder: Strato is a pool of ressources shared between all users. If you do not plan on using the instance, you have just created, please delete it, so other users can make use of the ressources. Consult the page \"Shutting down\" for instructions on how to do this.</p>"},{"location":"strato/getting-started/shutting-down/","title":"Shutting down","text":"<p>Strato is a service made available to all AAU-users. The platform consists of shared hardware, and this only works if the users use the platform as intended. This is why we ask you to consider whether the ressources you have reserved for your instance, are being put to use at the moment. If not, you might be occupying ressources, that another user could benefit from.</p> <p>We therefore ask you to read through our Terms and Conditions to help make this assessment.</p>"},{"location":"strato/getting-started/shutting-down/#shelve-instance","title":"Shelve instance","text":"<p>When you shelve your instance, you retain all of the data and software you might have installed on your instance, but you free up ressources for others to use.</p> <ol> <li>Navigate to the project tab</li> <li>Click the Compute sub-tab</li> <li>Click on Instances</li> <li>Find the instance and the Action roll down.</li> <li>Select \"Shelve instance\". After a bit of time, the Status should be \"Shelved Offloaded\"</li> <li>When you need the instance again - select \"Unshelve instance\" under the Actions roll-down.</li> </ol> <p></p>"},{"location":"strato/getting-started/shutting-down/#delete-instance","title":"Delete instance","text":"<p>If you are done using your instance, then you can delete it. </p> <ol> <li>Navigate to the project tab</li> <li>Click the Compute sub-tab</li> <li>Click on Instances</li> <li>Mark the checkbox of the instance you wish to delete.</li> <li>Press Delete Instances on the right side of the webpage.</li> <li>press Delete Instances in the confirmation dialog.</li> </ol> <p></p>"},{"location":"strato/getting-started/transfer-files/","title":"Transfer files","text":"<p>In the following, we will demonstrate three ways of transfering files from your local computer to your Strato instance.</p>"},{"location":"strato/getting-started/transfer-files/#scp","title":"SCP","text":"<p>SCP (Secure file copy) is a method for transfering files via SSH-connections. The command <code>scp</code> is available for all operating systems. </p> <p>The general command structure is as follows:</p> <pre><code>scp -i &lt;my_ssh_key&gt; -r &lt;directory_to_be_sent&gt; &lt;remote_location&gt;\n</code></pre> <p>In order to send a folder called \"my_datafiles\" to the home directory of my instance, you could type:</p> <pre><code>scp -i ~/.ssh/my_ssh_key -r my_datafiles ubuntu@10.92.1.99:~/\n</code></pre> <ul> <li><code>scp</code> specifies we will be using the scp protocol.</li> <li><code>-i</code> is an additional argument for specifying an identity file (private key).</li> <li><code>~/.ssh/my_ssh_key</code> is the conventional location of your private key.</li> <li><code>-r</code> specifies that we want to send recursively (ie. a folder and all it's content). If you are only sending a single file, you can leave this out.</li> <li><code>ubuntu</code> is the default username of our Ubuntu instance.</li> <li><code>10.92.1.99</code> is the IP adress of your instance.</li> <li><code>:~/</code> is where you want your files copied to on the remote location (<code>~/</code> is the home directory).</li> </ul>"},{"location":"strato/getting-started/transfer-files/#rsync","title":"Rsync","text":"<p>For larger file transfers it can be benefitial to use Rsync which has a few extra features. Rsync comes preinstalled on MacOS and Linux, but is unavailable for Windows.</p> <p>The basic command structure for transfering files over SSH is: <pre><code>rsync -e \"ssh -i &lt;my_ssh_key&gt;\" &lt;file_location&gt; &lt;receiver_location&gt;\n</code></pre></p> <p>The command structure is essentially the same as for SCP. To send a folder called \"my_datafiles\", with some additional Rsync features applied, you could type: <pre><code>rsync -e \"ssh -i ~/.ssh/my_ssh_key\" -vazPr my_datafiles ubuntu@10.92.1.99:~/\n</code></pre></p> <p>The <code>-vazPr</code> part specifies a series of options, we can apply to our transfer:</p> <ul> <li><code>-v</code> Tells us about the status of our transfer.</li> <li><code>-a</code> Archives the files during transfer.</li> <li><code>z</code> Compresses the files during transfer. Can make the transfer more efficient</li> <li><code>-P</code> Displays a progress bar of the transfer</li> <li><code>-r</code> specifies the transfer should be recursive (ie. we want the folder and all it's content).</li> </ul>"},{"location":"strato/getting-started/transfer-files/#winscp","title":"WinSCP","text":"<p>If you are a Windows user, we recommend you use WinSCP to transfer the files. WinSCP is available for download in the AAU Software Center.</p> <ul> <li>Opening the application should give you this window: </li> </ul> <p></p> <ul> <li> <p>Choose SCP as the \"File protocol\"</p> </li> <li> <p>In the field \"Host name\" type in the IP-adress of your instance.</p> </li> <li> <p>For the SSH-protocol the standard \"Port number\" is 22.</p> </li> <li> <p>The field \"User name\" is a standard username that gets assigned to your instance. A list of standard usernames can be found here.   </p> </li> <li> <p>By standard the field \"Password\" can be left empty.</p> </li> <li> <p>Then click the \"Advanced Button\", and you will be faced with this window:</p> </li> </ul> <p></p> <ul> <li>Navigate to SSH -&gt; Authentication and browse to the location of your SSH-key. Select the key and press \"Open\". </li> </ul> <p></p> <ul> <li> <p>If you have navigated to the correct location and still can not see your SSH-key, please select \"Show all files\" as shown in the image above. Note that WinSCP only supports SSH-keys in the PuTTY-format (.pkk). If you have not already converted your key to this format, WinSCP will offer to do this for you, when you select the key in .pem-format.</p> </li> <li> <p>Press \"Ok\" in the \"Advanced\" window to apply these settings.</p> </li> <li> <p>You should now be back at this window. Press login.</p> </li> </ul> <p></p> <ul> <li>The first time you login you will be welcomed by a warning message, asking wether you do in fact want to connect to this adress. If you can confirm this is what you are trying to do, you can press \"Yes\".</li> </ul> <p></p> <ul> <li>You should now have a two-pane window, split vertically. On the left side you will have your local computer, and on the right side you will have the remote computer. To transfer files between them you can simply drag and drop. </li> </ul> <p></p>"},{"location":"taaurus/","title":"TAAURUS","text":"SUND Indicates that the platform is only for the Faculty of Medicine (SUND) researchers. Researchers Indicates if the platform is accessible for researchers (e.g., PhD students, postdocs, faculty) for research purposes. Students Indicates if the platform is accessible to students for educational purposes (e.g., coursework, projects, thesis). Sensitive Data Whether the platform supports processing and storing sensitive or confidential data CPU processing Indicates if the platform supports computational tasks that only require CPU resources. GPU processing Indicates if the platform supports computational tasks that require GPU resources for acceleration (e.g., deep learning). Remote Desktop The method used to access the platform via Remote Desktop Protocol (RDP). Pre-installed apps Indicates if the platform comes with pre-installed applications or frameworks for convenience (e.g., R, Python, MATLAB, Stata). Collaboration friendly Indicates if the platform supports collaborative work (e.g., sharing resources, co-editing, team projects). Working interactively Indicates if the platform supports interactive workflows where users can interact with running processes (e.g., Jupyter notebooks). Secure Storage Whether the platform provides secure, encrypted storage for sensitive research data. Compliance Platform designed for compliance with GDPR, ISO 27001, and other security standards."},{"location":"taaurus/#introduction","title":"Introduction","text":"<p>TAAURUS is a secure, flexible, and scalable platform that supports research and innovation in environments with high requirements for data processing and information security. The platform combines user-friendliness, quality, and compliance in one integrated solution, which can be adapted to different research projects and workflows. </p> <p>TAAURUS provides a solid and future-proof infrastructure that can be expanded and adapted as needs for data, users, and capacity grow \u2014 without compromising security or system operations. The platform is specifically designed for researchers working with sensitive data who require secure processing and storage. </p>"},{"location":"taaurus/#getting-started","title":"Getting Started","text":"<p>How to apply</p> <p>Learn how to apply for access to TAAURUS</p> <p>How to login</p> <p>Learn how to login to TAAURUS</p> <p>Navigating TAAURUS</p> <p>Learn the basics of using the TAAURUS platform</p>"},{"location":"taaurus/#key-features","title":"Key FeaturesSecure Data ProcessingHigh-Performance GPU ComputingPre-installed Software Suite","text":"<p>TAAURUS provides a secure environment for processing sensitive research data with encrypted storage and secure data transfer capabilities.</p> <p>Access to powerful NVIDIA L40S GPUs through SLURM job scheduling for AI/ML workloads, machine learning, and high-performance computing tasks.</p> <p>Comprehensive software environment including R, Python, MATLAB, Stata, SPSS, and specialized tools for statistical analysis and data processing.</p>"},{"location":"taaurus/#common-use-cases","title":"Common Use Cases","text":"<p>Sensitive data analysis</p> <p>GPU-accelerated computing</p> <p>Machine learning and AI research</p> <p>Statistical analysis and modeling</p> <p>Compliance-focused research</p> <p>Collaborative research projects</p> <p>High-performance simulations</p> <p>Secure data processing</p> <p>AI model development</p>"},{"location":"taaurus/how-to-access/","title":"How to access","text":""},{"location":"taaurus/how-to-access/#who-can-get-access","title":"Who can get access?","text":"<p>At this time, access to TAAURUS is available to researchers affiliated with the Faculty of Medicine (SUND) at Aalborg University.</p> <p>If you are unsure whether you are eligible, please contact CLAAUDIA via the AAU Service Portal.</p>"},{"location":"taaurus/how-to-access/#overview-of-the-application-process","title":"Overview of the application process","text":"<p>Working on TAAURUS requires a two\u2011part application. You must complete Part 1 before submitting Part 2.</p>"},{"location":"taaurus/how-to-access/#part-1-plan-your-research-project","title":"Part 1 \u2013 Plan your research project","text":"<p>Use this form to describe your project and compute needs.</p> <p>A long with this you should:</p> <ul> <li>Initiate GDPR registration for the project</li> <li>Initiate the relevant ethical approvals</li> <li> <p>Start a data management plan (DMP)</p> <p>For writing a Data Management Plan (DMP), we recommend using DeiC DMP, but other DMP tools are also acceptable. At CLAAUDIA, we support the use of DeiC DMP and can guide you in using the system. We also offer consulting and guidance on how to write a DMP.</p> </li> </ul> <p>Timing of approvals</p> <p>These items do not need to be fully approved to submit Part 1, but they must be approved before you submit Part 2.</p> <p>After Part 1 is submitted, you can proceed to Part 2 once the items above have been approved.</p>"},{"location":"taaurus/how-to-access/#part-2-create-your-taaurus-project","title":"Part 2 \u2013 Create your TAAURUS project","text":"<p>Use this form to request creation of the actual project on TAAURUS. This step can only be completed when Part 1 is submitted and your GDPR/ethics/DMP work has been initiated. The form must be submitted by the project\u2019s Principal Investigator (PI).</p>"},{"location":"taaurus/how-to-access/#processing-of-your-request","title":"Processing of your request","text":"<p>You will receive an email with a link to your project request on AAU Service Portal when your request has been approved.</p> <p>If you have questions during the process, contact CLAAUDIA via the AAU Service Portal.</p>"},{"location":"taaurus/how-to-access/#after-approval-next-steps","title":"After approval: next steps","text":"<p>Once your project is active, you are ready to start using TAAURUS. To get started, we recommend that you begin by reading the TAAURUS guides.</p>"},{"location":"taaurus/service-windows/","title":"Service windows","text":"<p>Four times a year, all of our platforms are subject to service windows where changes and security upgrades are implemented. During these, we reserve an entire day for maintainance of the systems.</p> <p>It should be expected that the platforms are offline for the entire day from 00:01 until 23:59 - but they may come online by the end of the days, as the work is finished.</p>"},{"location":"taaurus/service-windows/#schedule","title":"Schedule","text":"<p>A service window will take place on the following dates:</p> <p>AI Cloud, Strato, UCloud VM's &amp; UCloud Kubernetes</p> 2025 2026 2027 2028 11/02 10/02 09/02 08/02 13/05 12/05 11/05 09/05 16/09 15/09 14/09 12/09 02/12 01/12 30/11 28/11 <p>AI-LAB</p> 2025 2026 2027 2028 13/02 12/02 11/02 10/02 15/05 14/05 13/05 11/05 18/09 17/09 16/09 14/09 04/12 03/12 02/12 30/11 <p>TAAURUS</p> 2026 2027 2028 2029 03/02 - - - - - - - - - - - - - - - <p>Sign up for notifications on serviceinfo.dk</p> <p>Click this link to go to serviceinfo.dk. Then select Aalborg University, and under the tab Subscribe (or Abonn\u00e9r), select CLAAUDIA. Select email, SMS or calendar, according to your preferences:</p> <p> Go to ServiceInfo.dk</p>"},{"location":"taaurus/service-windows/#platform-specific-information","title":"Platform specific information","text":""},{"location":"taaurus/service-windows/#strato-and-ucloud-virtual-machines","title":"Strato and UCloud virtual machines","text":"<p>Be sure to save your work no later than the end of the day before the service window begins, as all virtual machines will be automatically shut down during the service window and any unsaved data will be lost.</p> <p>Usage Management Process </p> <p>1. Servers will NOT restart automatically after service windows     - All servers in the AAU availability zone will be shut down during service windows and will not restart automatically, unless they have been registered for automatic restart before the service window.      - You can easily restart your servers manually after the service window.</p> <p>2. Automatic server resizing after 48 hours of inactivity     - Servers that remain shut down for more than 48 hours will be automatically resized to the smallest CPU configuration.     - You will receive a notification when your instance has been resized.</p> <p>3. Automatic server deletion after 30 days of inactivity     - Servers that remain shut down for 30 days will be permanently deleted, but their volumes will be preserved.     - You will be notified in advance about any affected instances.</p> <p>4. Unused volume cleanup     - Volumes not attached to any server for 30 days will be deleted.     - A notification will be sent before deletion.</p> <p>All virtual machines should be removed when not in use.  Basic rule: keep your volumes, delete your unused VMs, and only run a VM with the size you really need right now. Please consult the page 'Delete and restart an instance from the volume' for instructions on how to do this.</p> <p>Apply for automatic restart of your Strato server</p> <p>Note: The deadline for requesting inclusion in the automatic restart list has now passed for the service window on the 2nd december.</p> <p>You could request automatic restarts for your server if all of the following conditions were met:</p> <ul> <li>The server is part of a Strato Project</li> <li>You can provide a valid motivation for needing automatic restart</li> <li>The server is in one of these availability zones:<ul> <li>AAU</li> <li>AAU-T4</li> <li>AAU-A10</li> <li>AAU-A40</li> </ul> </li> </ul> <p>Servers running in personal project spaces (such as default quota projects, e.g. <code>GK83DJ@aau.dk</code>) cannot be included. If you want to move your project, you can find instructions on how to apply for a Strato Project</p> <p>The application form for inclusion in the automatic restart list closed on November 25th: Strato service window: Automatic server restart inclusion form</p> <p>Link to Strato's web-interface: strato-new.claaudia.aau.dk</p>"},{"location":"taaurus/service-windows/#ai-cloud","title":"AI Cloud","text":"<p>In the days leading up to the service window, a reservation will be put in place for the entire cluster. The entirety of the cluster will therefore be unavailable for that day, but may come back online by the end of the day.</p> <p>You can still submit jobs in the days leading up to the service window. Since the <code>batch</code> and <code>prioritized</code> partitions have time limits of 12 hours and 6 days respectively, you will only be able to launch new jobs if you add the <code>--time</code> parameter to your Slurm command. If you do not set this parameter, and there are 5 days until the day of the service window, your job will not start until after the service window. You will thus need to calculate how much time there is left, and then submit the job with this parameter added. </p> <p>To submit a job that runs for 1 day and 8 hours, you can simply add <code>--time=1-08:00:00</code> to your Slurm command. </p> <p>Additionally you can read about our recommendations for using checkpointing to work with time limits.</p>"},{"location":"taaurus/service-windows/#ai-lab","title":"AI-LAB","text":"<p>In the days leading up to the service window, a time limit will be imposed, which will prevent you from launching jobs with end dates that surpass the date of the service window. </p> <p>In this period, you will only be able to launch new jobs, if you add the <code>--time</code> parameter to your Slurm command. If the time parameter is not included, Slurm assumes you ask for the default maximum time for the partition. You will thus have to calculate how much time you have before the service window, and then submit a job with this parameter added. </p> <p>To submit a job that runs for 12 hours, you should add: <code>--time=12:00:00</code>. Not setting the <code>--time</code> parameter will place your job in the queue, where it will wait until the service window has been completed.</p> <p>IMPORTANT: You can still run jobs in the days leading up to the service window</p> <p>If you have any questions, please open a case with us on serviceportal.aau.dk</p>"},{"location":"taaurus/service-windows/#ucloud-aauk8s","title":"UCloud (AAU/K8s)","text":"<p>The UCloud (AAU/K8s) cluster will be unavailable for the entire duration of the service window and may become available again by the end of the day. While it may be technically possible to start jobs on the day of the service window, please note that any running jobs will be terminated as part of the scheduled maintenance activities performed by the administrators. We recommend planning your work accordingly to avoid interruptions.</p>"},{"location":"taaurus/system-overview/","title":"System overview","text":"<p>Comming soon</p>"},{"location":"taaurus/terms-and-conditions/","title":"Terms and conditions","text":"<p>Comming soon</p>"},{"location":"taaurus/guides/before-running-jobs/","title":"Before you run GPU jobs","text":"<p>TAURUS has a high\u2011performance GPU cluster for machine learning, AI training, and graphics workloads. It consists of two compute nodes, each with 8 NVIDIA L40S GPUs. You access the cluster from the TAURUS desktop using a terminal, where you submit jobs and check their status. Jobs are queued and run by Slurm (the system that schedules and manages resources). For consistent and reproducible software environments, workloads can run inside Singularity containers.</p>"},{"location":"taaurus/guides/before-running-jobs/#open-the-terminal","title":"Open the terminal","text":"<p>Go to Menu in the top left corner, search for mate terminal, and click the application to start it.</p> <p></p> Improve terminal readability <p>The default terminal theme can be low contrast. To switch to a darker, higher\u2011contrast scheme:</p> <ol> <li>Go to Edit \u2192 Profile Preferences.</li> </ol> <p></p> <ol> <li>Open the Colors tab and uncheck Use colors from system theme.</li> <li>Select a dark built\u2011in scheme (e.g., \"White on black\"), then close the dialog.</li> </ol> <p></p> Nice-to-know Linux commands <p>Don\u2019t worry if you\u2019re new to Linux\u2014these essentials will get you started.</p>"},{"location":"taaurus/guides/before-running-jobs/#navigation","title":"Navigation","text":"Command Description Example <code>pwd</code> Show current directory <code>pwd</code> <code>ls</code> List files and folders <code>ls -la</code> (detailed list) <code>cd</code> Change directory <code>cd /media/project</code>"},{"location":"taaurus/guides/before-running-jobs/#files-and-folders","title":"Files and folders","text":"Command Description Example <code>mkdir</code> Create directory <code>mkdir my_project</code> <code>rm</code> Remove file <code>rm old_file.txt</code> <code>rm -r</code> Remove directory <code>rm -r old_folder</code> <code>cp</code> Copy file <code>cp file.txt backup/</code> <code>cp -r</code> Copy directory <code>cp -r project/ backup/</code> <code>mv</code> Move/rename <code>mv old_name.txt new_name.txt</code> <code>cat</code> Display file content <code>cat script.py</code>"},{"location":"taaurus/guides/before-running-jobs/#quick-editing-with-nano","title":"Quick editing with nano","text":"<pre><code>nano my_script.py  # Create or edit a file\n</code></pre> <p>Shortcuts:</p> <ul> <li>Save: <code>Ctrl + O</code>, then <code>Enter</code></li> <li>Exit: <code>Ctrl + X</code></li> <li>Cut line: <code>Ctrl + K</code></li> <li>Paste: <code>Ctrl + U</code></li> <li>Search: <code>Ctrl + W</code></li> <li>Help: <code>Ctrl + G</code></li> </ul>"},{"location":"taaurus/guides/before-running-jobs/#know-your-directories","title":"Know your directories","text":""},{"location":"taaurus/guides/before-running-jobs/#personal-user-directory","title":"Personal user directory","text":"<p>When you open the terminal, you start in your personal home directory (e.g., <code>/home/domain.aau.dk/user</code>). You can use this location for private or temporary files, but be aware that it is not backed up and does not provide access to the GPU cluster.</p>"},{"location":"taaurus/guides/before-running-jobs/#shared-project-directory","title":"Shared project directory","text":"<p>To work with project data and use the GPU cluster, switch to your project directory under <code>/media</code>. In the examples below, the project is named <code>project</code>\u2014replace this with your actual project name.</p> What is my project directory called? <p>Show available projects with:</p> <pre><code>ls /media\n</code></pre> <p>Change to your project directory:</p> <pre><code>cd /media/project\n</code></pre> <p>Inside your project directory you will find three pre\u2011made folders:</p> <ol> <li><code>/media/project/data</code> \u2013 store datasets and large inputs</li> <li><code>/media/project/work</code> \u2013 keep scripts, notebooks, and code here</li> <li><code>/media/project/export</code> \u2013 place files here that you plan to export out</li> </ol>"},{"location":"taaurus/guides/before-running-jobs/#next-steps","title":"Next steps","text":"<p>When ready, continue to: Running Jobs</p>"},{"location":"taaurus/guides/getting-containers/","title":"Getting containers on TAAURUS","text":"<p>To run most applications on the TAAURUS GPU cluster you need to do it inside containers - self-contained environments that include all the software and dependencies you need. TAAURUS uses Singularity to run containers.</p>"},{"location":"taaurus/guides/getting-containers/#what-is-a-container","title":"What is a container?","text":"<p>A container is like a pre-packaged software environment that includes:</p> <ul> <li>The application (Python, PyTorch, TensorFlow, etc.)</li> <li>All required libraries and dependencies</li> </ul> <p>Think of it as a complete, portable computer environment that works the same way every time.</p>"},{"location":"taaurus/guides/getting-containers/#methods-to-obtain-containers","title":"Methods to obtain containers","text":"<ol> <li>Use pre-downloaded containers on TAAURUS - Quickest option </li> <li>Download containers locally or on AI Cloud - For specific versions</li> <li>Build your own container locally or on AI Cloud - For custom environments</li> </ol> 1. Pre-downloaded containers <p>The easiest way to get started is using containers that are already available on TAAURUS. These are stored in <code>/pack/Singularity</code> and are regularly updated.</p> 2. Download or build containers locally <p>This guide will show you how to use an application called Podman on your local computer to build containers, transfer it to TAAURUS, and convert it into a Singularity image.</p> <p>Why Use Podman to Build Containers Locally?</p> <p>Building Singularity containers directly on TAAURUS requires an internet connection which is blocked on TAAURUS. To overcome this, you can use an application called Podman to build containers locally on your own machine. Podman is a container management tool similar to Docker. Once created, the container can be transferred to TAAURUS and converted into a Singularity image.</p> 3. Download or build containers (via AI Cloud) <p>Network access from TAAURUS compute nodes is restricted, so you cannot pull or build containers directly on TAAURUS. The easiest way to get specific or custom containers is to use AAU\u2019s HPC platform AI Cloud, which has a similar setup (Slurm + Singularity) and allows internet access for pulling/building images. AI Cloud also provides the same GPU type (NVIDIA L40S), making it an ideal testing environment before running the container on TAAURUS.</p> <p>You are now ready to proceed to learn about using containers to run jobs </p>"},{"location":"taaurus/guides/getting-containers/#available-containers","title":"Available Containers","text":"<p>Check what's available:</p> <pre><code>ls /pack/Singularity\n</code></pre>"},{"location":"taaurus/guides/getting-containers/#using-pre-downloaded-containers","title":"Using pre-downloaded containers","text":"<p>You can use these containers by first copying them to your projects work directory:</p> <pre><code># Example: Using PyTorch container\ncp /pack/Singularity/pytorch/pytorch_25.05.sif /media/test05/work\n</code></pre> <p>Remember to replace <code>test05</code> with your projects name.</p>"},{"location":"taaurus/guides/getting-containers/#install-podman-on-your-local-machine","title":"Install Podman on your local machine","text":"<p>Before starting, you'll need to install Podman on your local machine to build containers. Podman is available for Windows, macOS, and Linux, and the installation process varies slightly depending on your operating system.</p> WindowsmacOSLinux <ol> <li> <p>Begin by downloading the Podman Windows installer (.exe). Make sure to choose version 4.1 or later for compatibility with the features discussed in this guide.</p> </li> <li> <p>Run the installer and follow the prompts to complete the installation. A system restart may be required.</p> </li> <li> <p>Once installed, open PowerShell and initialize your first Podman machine with the following command:</p> <pre><code>podman machine init\n</code></pre> </li> </ol> <p>Automatic WSL Installation</p> <p>If Windows Subsystem for Linux (WSL) is not already installed, Podman will prompt you to install it automatically during the <code>podman machine init</code> process. Accepting this will install WSL and restart your system. After logging back in, the machine creation will continue. If you prefer, you can install WSL manually before running <code>podman machine init</code>.</p> <p>To start the Podman machine, run:</p> <pre><code>podman machine start\n</code></pre> <p>This starts a virtual machine where containers can be build.</p> <ol> <li> <p>You can either download the latest Podman installer from the Podman GitHub releases or use Homebrew (recommended for macOS users) to install Podman:</p> <pre><code>brew install podman\n</code></pre> </li> <li> <p>Once installed, initialize your first machine:</p> <pre><code>podman machine init\n</code></pre> </li> <li> <p>Start the machine:</p> <pre><code>podman machine start\n</code></pre> <p>This starts a virtual machine where containers can be build.</p> </li> </ol> <p>On most Linux distributions, Podman is available through the package manager. Follow the instructions for your specific distribution below.</p> <ol> <li> <p>Update your system: It's always good practice to update your system before installing new software.</p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade   # Debian-based distros (Ubuntu, etc.)\nsudo dnf update                       # Fedora-based distros\n</code></pre> </li> <li> <p>Install Podman:</p> <ul> <li> <p>Debian-based distributions (Ubuntu, Debian, etc.):</p> <pre><code>sudo apt install podman -y\n</code></pre> </li> <li> <p>Fedora-based distributions (Fedora, CentOS, RHEL): Podman may already be installed on Fedora. If not:</p> <pre><code>sudo dnf install podman -y\n</code></pre> </li> <li> <p>Arch Linux:</p> <pre><code>sudo pacman -S podman\n</code></pre> </li> <li> <p>Other distributions: Refer to the official Podman installation guide for installation instructions for other Linux distributions.</p> </li> </ul> </li> <li> <p>After installation, verify that Podman is installed correctly by checking the version:</p> <pre><code>podman --version\n</code></pre> <p>You should see the installed version of Podman. If successful, you are ready to proceed.</p> </li> </ol>"},{"location":"taaurus/guides/getting-containers/#download-or-build-a-container-with-podman","title":"Download or build a container with Podman","text":"Option A: Downloading a Container with PodmanOption B: Building a Container with Podman <p>If you don\u2019t need to build your own container, Podman can also download (\u201cpull\u201d) existing containers from public registries such as Docker Hub or NVIDIA NGC.</p> <p>Example: Download a container from Docker Hub</p> <p>To download an official Python container:</p> <pre><code>podman pull docker.io/library/python:3.10-slim\n</code></pre> <p>You can list the downloaded containers with: <pre><code>podman images\n</code></pre></p> <p>Save the downloaded image as a TAR file:</p> <p>Regardless of whether the image came from Docker Hub or NGC, export it for transfer to TAAURUS:</p> <pre><code>podman save -o python-slim.tar docker.io/library/python:3.10-slim\n</code></pre> <p>This will create a file named python-slim.tar.</p> <p>To create a container, you first need to define what the container will look like and how it will behave. This is done using a special text file called a Dockerfile. A Dockerfile is essentially a set of instructions that tell Podman how to create the container, such as what software to include and what commands to run when the container starts.</p> <p>When creating a Dockerfile, it's important that the file has no extension (like <code>.txt</code> or <code>.doc</code>). The file should simply be named Dockerfile. This is because tools like Podman specifically look for a file named <code>Dockerfile</code> to understand how to build the container.</p> <p>Here\u2019s an example of a simple Dockerfile for a Python-based container:</p> Dockerfile<pre><code># Use an official Python image as the base\nFROM python:3.9-slim\n\n# Install necessary Python libraries\nRUN pip install --no-cache-dir numpy scipy\n\n# Set the command to run when the container starts\nCMD [\"python3\"]\n</code></pre> <p>What does this Dockerfile do? <code>FROM python:3.9-slim</code>: This tells Podman to start from an existing container image, in this case, a lightweight version of Python 3.9. It provides a base to build your custom container.</p> <p><code>RUN pip install --no-cache-dir numpy scipy</code>: This command installs the Python libraries <code>numpy</code> and <code>scipy</code> inside the container.</p> <p><code>CMD [\"python3\"]</code>: This sets the default action when the container runs\u2014in this case, it starts the Python interpreter.</p> <p>Next, save the Dockerfile in an empty folder on your computer. It's important to create an empty folder to save the Dockerfile in because when you build a container with Podman, it includes all the files from the current directory in the container image by default.</p> <p>In the directory where your Dockerfile is located, run:</p> <pre><code>podman build -t my-python-app .\n</code></pre> <p>INFO: It may require a lot of space</p> <p>Building the container may take up a lot of space on your local computer. A simple PyTorch container can take up approx. 20GB of space.</p> <p>Replace <code>my-python-app</code> with the name you want for your container image.</p>"},{"location":"taaurus/guides/getting-containers/#saving-and-exporting-the-container","title":"Saving and Exporting the Container","text":"<p>Once your container is built, export it as a TAR file so that it can be transferred to the Slurm cluster:</p> <pre><code>podman save -o my-python-app.tar my-python-app\n</code></pre> <p>This will create a file named <code>my-python-app.tar</code>.</p>"},{"location":"taaurus/guides/getting-containers/#transferring-the-container-to-taaurus","title":"Transferring the Container to TAAURUS","text":"<p>Follow our import guide to transfer the container to TAAURUS.</p>"},{"location":"taaurus/guides/getting-containers/#converting-the-container-to-singularity","title":"Converting the Container to Singularity","text":"<p>Environment Variables Set by Default</p> <p>The <code>SINGULARITY_TMPDIR</code> and <code>SINGULARITY_CACHEDIR</code> environment variables are set as default on TAAURUS, so you don't need to set them manually. These variables are configured to use temporary directories (<code>/media/project/work/.singularity/tmp/</code> and <code>/media/project/work/.singularity/cache/</code>) to speed up repeated operations.</p> <p>Now, convert the Podman image into a Singularity image:</p> <pre><code>singularity build my-python-app.sif docker-archive://my-python-app.tar\n</code></pre> <p>This will convert the container into a Singularity Image File (.sif) that can be used in the cluster.</p>"},{"location":"taaurus/guides/getting-containers/#test-running-the-singularity-container-optional","title":"Test running the Singularity Container (optional)","text":"<p>Submit a job to Slurm using the newly converted Singularity image:</p> <pre><code>srun --gres=gpu:1 singularity exec my-python-app.sif python3 --version\n</code></pre>"},{"location":"taaurus/guides/getting-containers/#workflow","title":"Workflow","text":"<ol> <li>Get access to AI Cloud: see How to access AI Cloud</li> <li>Log in to AI Cloud: see Log in guide</li> <li>Get the container by either:<ol> <li>Pull container images on AI Cloud: see Pulling container images from the internet</li> <li>Build your own container image on AI Cloud: see Building your own container image</li> </ol> </li> <li>Export the resulting <code>.sif</code> from AI Cloud: see Transfer files between a server and a local computer</li> <li>Import it into TAAURUS: see Import &amp; export of data</li> </ol>"},{"location":"taaurus/guides/import-export-of-data/","title":"Import &amp; Export of Data","text":""},{"location":"taaurus/guides/import-export-of-data/#importing-data","title":"Importing data","text":"<p>Temporary import solution</p> <p>Currently, to import data to/from your TAAURUS project, you need to submit a service request.</p> <p>Important: The service request must be submitted by the Principal Investigator (PI) of the project.</p> <p>Submit a service request at: https://serviceportal.aau.dk/</p> <p>Please describe in your service request:</p> <ul> <li>What should be imported</li> <li>How much data (size/volume)</li> <li>Where the data comes from (source location)</li> </ul>"},{"location":"taaurus/guides/import-export-of-data/#exporting-data","title":"Exporting data","text":"<p>To export data from your TAAURUS project, you can use the SP Exporter application. Follow these steps:</p>"},{"location":"taaurus/guides/import-export-of-data/#step-1-open-sp-exporter","title":"Step 1: Open SP Exporter","text":"<ol> <li>Click the Menu button in the top-left corner of your remote desktop.</li> <li>In the search bar, type <code>sp-exporter</code>.</li> <li>Select sp-exporter from the search results to launch the application.</li> </ol>"},{"location":"taaurus/guides/import-export-of-data/#step-2-create-a-new-export","title":"Step 2: Create a new export","text":"<ol> <li>Once SP Exporter opens, you'll see the main window with an Exports section on the left.</li> <li>Click the Add export button to start creating a new export.</li> </ol>"},{"location":"taaurus/guides/import-export-of-data/#step-3-select-file-to-export","title":"Step 3: Select file to export","text":"<ol> <li>In the export dialog, click the Add file: button (marked with a plus icon).</li> <li>A file picker dialog will open. Navigate to the location of the file you want to export. The project directory is located at the bottom of the file navigation.</li> <li>Select the desired file from the file picker.</li> <li>Click Open to confirm your selection.</li> </ol> <p>Exporting multiple files or folders</p> <p>SP Exporter only allows you to select a single file at a time. To export multiple files or entire folders, you need to compress them first using the file manager:</p> <ol> <li>Open the file manager (not the file picker dialog) and navigate to the files or folders you want to export.</li> <li>Select the files or folders you need.</li> <li>Right-click on your selection.</li> <li>Choose Compress from the context menu (this will create a ZIP, RAR, or similar archive file).</li> <li>Then, in SP Exporter, use the file picker to select the compressed archive file you just created.</li> </ol>"},{"location":"taaurus/guides/import-export-of-data/#step-4-add-a-comment-and-export","title":"Step 4: Add a comment and export","text":"<ol> <li>After selecting your file, you'll see it listed in the export dialog.</li> <li>Optionally, add a comment in the Comment: field to describe what you're exporting (e.g., \"This file contains logs from gpu test\").</li> <li>Review the file path shown in the title bar to ensure you're exporting the correct file.</li> <li>Click the Export button to submit your export request.</li> </ol>"},{"location":"taaurus/guides/import-export-of-data/#step-5-view-export-status","title":"Step 5: View export status","text":"<p>After submitting an export, you can view its details in the SP Exporter window:</p> <ul> <li>Date: When the export was created</li> <li>ID: Unique identifier for the export</li> <li>Approved: Approval status (shown as an orange dot if pending)</li> <li>Description: The comment you provided</li> <li>Files: List of files included in the export</li> </ul> <p></p> <p>Export approval</p> <p>Exports require approval before they are processed. Check the approval status in the export details. Once approved, you'll be able to download your exported data.</p>"},{"location":"taaurus/guides/import-export-of-data/#step-6-pi-approval","title":"Step 6: PI Approval","text":"<p>Before an export can be downloaded, it must be approved by the Principal Investigator (PI) of the project. The PI can approve exports using SP Exporter:</p> <ol> <li>Open SP Exporter on the TAAURUS remote desktop.</li> <li>In the Approve section, you'll see pending export requests with their details (Date, ID, User, Files).</li> <li>Review the export request details to ensure it's appropriate.</li> <li>Click the Approve button to approve the export request.</li> </ol> <p>Once approved, the export will be processed and made available for download.</p> <p></p>"},{"location":"taaurus/guides/import-export-of-data/#step-7-downloading-approved-exports","title":"Step 7: Downloading Approved Exports","text":"<p>After your export has been approved by the PI, you can download it from your local computer:</p> <ol> <li>Connect to the AAU network - You must be connected to the AAU network (either on-campus or via VPN).</li> <li>Open your web browser and navigate to: <code>export.taaurus.aau.dk</code> and login with your AAU credentials.</li> <li>You'll see a directory listing with your approved export files (ZIP archives).</li> <li>Click on the export file you want to download (e.g., <code>@its.aau.dk_20f12b63-d5dd-4f33-8b48-df7ed62c0c61.zip</code>).</li> <li>The file will download to your computer.</li> </ol> <p></p>"},{"location":"taaurus/guides/login/","title":"Logging into TAAURUS","text":"<p>This guide will help you connect to TAAURUS using Remote Desktop Protocol (RDP).</p>"},{"location":"taaurus/guides/login/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to TAAURUS platform</li> <li>Remote Desktop Protocol (RDP) client installed (see the guides below)</li> <li>AAU email</li> <li>Microsoft Authenticator app for 2FA authentication (see MFA Setup Requirements below)</li> <li>AAU network connection<ul> <li>If off campus please follow these instructions to set up VPN at AAU</li> </ul> </li> <li>MFA setup<ul> <li>If you haven't set up MFA yet, please follow this setup guide</li> <li> <p>Make sure to choose the notification method (push notifications) during setup, not the code method.</p> <p>Changing from Code Method to Notification Method</p> <p>If you already have MFA set up but are using the code method, you need to change it to the notification method:</p> <ol> <li>Open a new incognito/private browser window</li> <li>Go to https://aka.ms/mfasetup and log in</li> <li>Change \"Default sign-in method\" to \"App based authentication - notification\"</li> <li>Click \"Confirm\"</li> </ol> <p>This will enable push notifications in your Microsoft Authenticator app, which is required for TAAURUS login.</p> </li> </ul> </li> </ul> WindowsmacOSLinux"},{"location":"taaurus/guides/login/#step-1-connecting-from-windows","title":"Step 1: Connecting from Windows","text":"<p>On your local Windows PC:</p> <ol> <li>Open the Start menu and search for Remote Desktop Connection</li> <li>Select Remote Desktop Connection from the results<ul> <li>Danish users: Look for \"Forbindelse til Fjernskrivebord\"</li> </ul> </li> </ol>"},{"location":"taaurus/guides/login/#step-2-enter-server-details","title":"Step 2: Enter Server Details","text":"<ol> <li>In the Remote Desktop Connection window, enter the server address: <pre><code>sp-test05.srv.aau.dk\n</code></pre></li> <li>Click Show Options to access Advanced settings in the tab</li> </ol>"},{"location":"taaurus/guides/login/#step-3-configure-gateway-settings","title":"Step 3: Configure Gateway Settings","text":"<ol> <li>Go to the Advanced tab</li> <li>Click Settings... under \"Connect from anywhere\"</li> <li>In the Connection settings dialog:<ul> <li>Enter <code>rdgw.taaurus.aau.dk</code> in the Server name field</li> <li>Select Ask for password from the Logon method dropdown</li> <li>Uncheck \"Use these RD Gateway server settings\"</li> </ul> </li> <li>Click OK to save settings</li> <li>Click Connect to initiate the connection</li> </ol>"},{"location":"taaurus/guides/login/#step-4-authentication-process","title":"Step 4: Authentication Process","text":"<p>You will go through a multi-step authentication process:</p>"},{"location":"taaurus/guides/login/#first-authentication","title":"First Authentication","text":"<ul> <li>A Windows Security popup will appear</li> <li>Click More choices and then Use a different account</li> <li>Enter your AAU email address (You need to use the 6-digit email, like <code>xx11yy@domain.aau.dk</code>) and password</li> <li>Click OK</li> </ul>"},{"location":"taaurus/guides/login/#second-authentication-2fa","title":"Second Authentication (2FA)","text":"<ul> <li>You will be prompted to authenticate using your Microsoft Authenticator app<ul> <li>If you need help setting up AAU MFA please follow these instructions</li> </ul> </li> <li>Open the app and approve the login request</li> </ul>"},{"location":"taaurus/guides/login/#final-authentication","title":"Final Authentication","text":"<ul> <li>You may need to authenticate once more with your AAU email (You need to use the 6-digit email, like <code>xx11yy@domain.aau.dk</code>) and password</li> </ul>"},{"location":"taaurus/guides/login/#step-5-success","title":"Step 5: Success!","text":"<p>Once authenticated, you will be connected to the TAAURUS remote desktop environment. You should see the desktop interface of the TAAURUS server.</p> <p></p>"},{"location":"taaurus/guides/login/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues during the login process:</p> <ol> <li>Connection fails: Check that you are connected to AAU network and try again</li> <li>Authentication errors: Verify your AAU credentials and MFA setup</li> <li>Gateway issues: Ensure you've correctly configured the RD Gateway settings</li> <li>Still having problems: Contact CLAAUDIA support at serviceportal.aau.dk</li> </ol>"},{"location":"taaurus/guides/login/#step-1-connecting-from-macos","title":"Step 1: Connecting from macOS","text":"<p>TAAURUS provides access through a Windows Remote Desktop environment, which means all operating systems must connect using the Remote Desktop Protocol (RDP).</p> <p>Because only Windows includes an RDP client by default, macOS users must install one before connecting.</p>"},{"location":"taaurus/guides/login/#install-microsoft-remote-desktop","title":"Install Microsoft Remote Desktop","text":"<ol> <li>Open the Software Center</li> <li>Search for Windows App</li> <li>Install the application</li> </ol>"},{"location":"taaurus/guides/login/#step-2-configure-the-connection","title":"Step 2: Configure the connection","text":"<ol> <li> <p>Open Microsoft Remote Desktop </p> </li> <li> <p>Open Settings in top menu (\u2318 ,)</p> </li> <li>Add Gateway in \"Gateways\", use gateway name:     <code>rdgw.taaurus.aau.dk</code> </li> <li>Click Connections -&gt; Add PC (\u2318 N) use the server address for your project, fx <code>sp-test05.srv.aau.dk</code> </li> </ol> <p>Save the connection and double-click it to connect.   </p>"},{"location":"taaurus/guides/login/#step-3-authentication-process","title":"Step 3: Authentication Process","text":"<p>You will be prompted to log in with your AAU email (You need to use the 6-digit email, like <code>xx11yy@domain.aau.dk</code>) and password, followed by approval in Microsoft Authenticator.   </p>"},{"location":"taaurus/guides/login/#step-4-final-authentication","title":"Step 4: Final Authentication","text":"<ul> <li>You may need to authenticate once more with your AAU email (You need to use the 6-digit email, like <code>xx11yy@domain.aau.dk</code>) and password</li> </ul>"},{"location":"taaurus/guides/login/#step-5-success_1","title":"Step 5: Success!","text":"<p>Once authenticated, you will be connected to the TAAURUS remote desktop environment. You should see the desktop interface of the TAAURUS server.</p> <p></p>"},{"location":"taaurus/guides/login/#troubleshooting_1","title":"Troubleshooting","text":"<p>If you encounter any issues during the login process:</p> <ol> <li>Connection fails: Check that you are connected to AAU network and try again</li> <li>Authentication errors: Verify your AAU credentials and MFA setup</li> <li>Gateway issues: Ensure you've correctly configured the RD Gateway settings</li> <li>Still having problems: Contact CLAAUDIA support at serviceportal.aau.dk</li> </ol>"},{"location":"taaurus/guides/login/#connecting-from-linux","title":"Connecting from Linux","text":"<p>TAAURUS provides access through a Windows Remote Desktop environment, which means all operating systems must connect using the Remote Desktop Protocol (RDP).</p> <p>Because only Windows includes an RDP client by default, Linux users must install one before connecting.</p> <p>Linux desktop environments use a display server to handle windows, input, and graphics. The two most common ones are:</p> <ul> <li>X11 (X.Org) \u2013 Older, very widely supported</li> <li>Wayland \u2013 Newer, more secure, and default on many modern distributions</li> </ul> <p>To check which one you are running, open a terminal and run:</p> <pre><code>echo $XDG_SESSION_TYPE\n</code></pre> <ul> <li>Output <code>x11</code> \u2192 follow X11 instructions</li> <li>Output <code>wayland</code> \u2192 follow Wayland instructions</li> </ul>"},{"location":"taaurus/guides/login/#step-1-install-freerdp","title":"Step 1: Install FreeRDP","text":"<p>FreeRDP is an open-source Remote Desktop (RDP) client for Linux.</p>"},{"location":"taaurus/guides/login/#for-x11","title":"For X11","text":"<pre><code>sudo apt install freerdp2-x11\n</code></pre> <p>This installs the <code>xfreerdp</code> command.</p>"},{"location":"taaurus/guides/login/#for-wayland","title":"For Wayland","text":"<pre><code>sudo apt install freerdp2-wayland\n</code></pre> <p>This installs the <code>wlfreerdp</code> command  </p>"},{"location":"taaurus/guides/login/#step-2-connect-to-taaurus","title":"Step 2: Connect to TAAURUS","text":"<p>Use the command that matches your display server.</p>"},{"location":"taaurus/guides/login/#wayland","title":"Wayland","text":"<pre><code>wlfreerdp /v:SERVER-NAME /f /u:AAU-EMAIL /g:rdgw.taaurus.aau.dk\n</code></pre>"},{"location":"taaurus/guides/login/#x11","title":"X11","text":"<pre><code>xfreerdp /v:SERVER-NAME /f /u:AAU-EMAIL /g:rdgw.taaurus.aau.dk\n</code></pre> <p>Replace <code>SERVER-NAME</code> with your TAAURUS projects server name. </p> <p>Replace <code>AAU-EMAIL</code> with your AAU Email. You need to use the 6-digit email, like <code>xx11yy@domain.aau.dk</code>.</p> <p>Parameter explanation:</p> <pre><code>- `/v:` \u2013 Target TAAURUS server\n- `/f` \u2013 Fullscreen mode\n- `/u:` \u2013 Your AAU username (email format)\n- `/g:` \u2013 RD Gateway used for secure access\n</code></pre> <p>When prompted: 1. Enter your AAU password. 2. Approve the login in Microsoft Authenticator</p> <p>You may be asked to authenticate more than once \u2014 this is expected.</p>"},{"location":"taaurus/guides/login/#known-notes-limitations","title":"Known Notes &amp; Limitations","text":"<ul> <li>MFA must be set up with Microsoft Authenticator push notifications</li> <li>VPN may be required if you are off campus</li> <li>Clipboard and drive redirection may behave differently than on Windows/macOS</li> <li>This setup is not guaranteed to work on all Linux distributions</li> </ul>"},{"location":"taaurus/guides/login/#need-help","title":"Need Help?","text":"<p>If this does not work for you, please submit a support ticket and include: - Your Linux distribution - Whether you use X11 or Wayland - The full command you tried - Any error output from the terminal</p> <p>\ud83d\udc49 Submit a ticket via the AAU Service Portal: https://serviceportal.aau.dk/serviceportal?id=sc_cat_item&amp;sys_id=a05e2fb4c3434610f0f3041ad00131d0</p>"},{"location":"taaurus/guides/login/#next-steps","title":"Next Steps","text":"<p>Now that you're logged in, you're ready to explore the TAAURUS platform. Continue to learn about navigating TAAURUS, available applications, and the file system.</p>"},{"location":"taaurus/guides/monitoring/","title":"Monitoring your jobs on TAAURUS","text":"<p>This guide will help you monitor your jobs, check system resources, and troubleshoot issues on TAAURUS.</p>"},{"location":"taaurus/guides/monitoring/#checking-the-job-queue","title":"Checking the Job Queue","text":"<p>The job queue shows all jobs currently running or waiting for resources.</p>"},{"location":"taaurus/guides/monitoring/#view-all-jobs","title":"View All Jobs","text":"<pre><code>squeue\n</code></pre> <p>Example output: <pre><code>JOBID   PARTITION       NAME      USER    ST      TIME    NODES   NODELIST(REASON)\n42      l40s            interact  user1   R       6:45:14 1       sp-l40s-01\n43      l40s            training  user2   PD      0:00:00 1       (Priority)\n</code></pre></p>"},{"location":"taaurus/guides/monitoring/#view-only-your-jobs","title":"View Only Your Jobs","text":"<pre><code>squeue --me\n</code></pre>"},{"location":"taaurus/guides/monitoring/#understanding-the-output","title":"Understanding the Output","text":"Column Description Example <code>JOBID</code> Unique job identifier <code>42</code> <code>PARTITION</code> Queue partition <code>l40s</code> <code>NAME</code> Job name (set by user) <code>training</code> <code>USER</code> Username <code>user1</code> <code>ST</code> Job state <code>R</code> (running), <code>PD</code> (pending) <code>TIME</code> How long job has been running <code>6:45:14</code> <code>NODES</code> Number of nodes allocated <code>1</code> <code>NODELIST</code> Which node or reason for waiting <code>sp-l40s-01</code> or <code>(Priority)</code>"},{"location":"taaurus/guides/monitoring/#common-job-states","title":"Common Job States","text":"<ul> <li><code>R</code> (Running): Job is currently executing</li> <li><code>PD</code> (Pending): Job is waiting for resources</li> <li><code>CG</code> (Completing): Job is finishing up</li> <li><code>CD</code> (Completed): Job finished successfully</li> <li><code>F</code> (Failed): Job failed with an error</li> </ul>"},{"location":"taaurus/guides/monitoring/#checking-compute-node-status","title":"Checking Compute Node Status","text":"<p>Monitor compute nodes to see available resources and system health.</p>"},{"location":"taaurus/guides/monitoring/#basic-node-information","title":"Basic Node Information","text":"<pre><code>sinfo\n</code></pre> <p>Example output: <pre><code>PARTITION       AVAIL      TIMELIMIT      NODES      STATE             NODELIST\nl40s*              up       12:00:00         2       idle       sp-l40s-[01-02]\n</code></pre></p>"},{"location":"taaurus/guides/monitoring/#understanding-the-output_1","title":"Understanding the Output","text":"Column Description Example <code>PARTITION</code> Queue/partition name <code>l40s*</code> <code>AVAIL</code> Partition availability <code>up</code> (available) <code>TIMELIMIT</code> Maximum job time <code>12:00:00</code> (12 hours max, 1 hour default) <code>NODES</code> Number of nodes <code>11</code> <code>STATE</code> Node status <code>idle</code>, <code>mix</code>, <code>allocated</code> <code>NODELIST</code> Specific nodes <code>sp-l40s-[01-02]</code>"},{"location":"taaurus/guides/monitoring/#node-states","title":"Node States","text":"<ul> <li><code>idle</code>: Node is completely free and available</li> <li><code>mix</code>: Node is partially used (some resources available)</li> <li><code>allocated</code>: Node is fully occupied</li> <li><code>down</code>: Node is offline or having issues</li> </ul>"},{"location":"taaurus/guides/monitoring/#detailed-node-information","title":"Detailed Node Information","text":"<p>Get detailed information about a specific node:</p> <pre><code>scontrol show node sp-l40s-01\n</code></pre> <p>This shows: - CPU allocation and total cores - Memory usage - GPU information - Node features and capabilities</p>"},{"location":"taaurus/guides/monitoring/#monitoring-gpu-utilization","title":"Monitoring GPU Utilization","text":"<p>Monitoring GPU usage helps you optimize your jobs and ensure you're getting the most out of the allocated resources.</p>"},{"location":"taaurus/guides/monitoring/#step-1-start-your-gpu-job","title":"Step 1: Start Your GPU Job","text":"<pre><code># Start a GPU job (example with PyTorch)\nsrun --gres=gpu:1 --mem=24G --cpus-per-task=15 --time=01:00:00 \\\n     singularity exec --nv /media/project/work/pytorch_25.05.sif \\\n     python3 my_training_script.py\n</code></pre>"},{"location":"taaurus/guides/monitoring/#step-2-find-your-job-id","title":"Step 2: Find Your Job ID","text":"<p>In another terminal session:</p> <pre><code>squeue --me\n</code></pre> <p>Note your job ID (e.g., <code>1978</code>).</p>"},{"location":"taaurus/guides/monitoring/#step-3-connect-to-your-running-job","title":"Step 3: Connect to Your Running Job","text":"<pre><code>srun --jobid 1978 --interactive --pty /bin/bash\n</code></pre>"},{"location":"taaurus/guides/monitoring/#step-4-monitor-gpu-usage","title":"Step 4: Monitor GPU Usage","text":"<p>Inside your job's interactive session:</p> <pre><code>nvidia-smi\n</code></pre>"},{"location":"taaurus/guides/monitoring/#understanding-gpu-metrics","title":"Understanding GPU Metrics","text":"<p>Key metrics to watch:</p> <ul> <li>GPU-Util: Percentage of GPU being used (aim for 70-100% during training)</li> <li>Memory-Usage: How much GPU memory your job is using</li> <li>Temperature: GPU temperature (should stay below 80\u00b0C)</li> <li>Power: Power consumption (indicates workload intensity)</li> </ul> <pre><code>+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA L40s                    Off |   00000000:01:00.0 Off |                    0 |\n| N/A   44C    P0             36W /   72W |     245MiB /  23034MiB |     90%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  NVIDIA L40s                    Off |   00000000:02:00.0 Off |                    0 |\n| N/A   38C    P8             16W /   72W |       4MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   2  NVIDIA L40s                    Off |   00000000:41:00.0 Off |                    0 |\n| N/A   41C    P8             16W /   72W |       1MiB /  23034MiB |      0%      Default |\n|                                         |                        |                  N/A |\n...\n</code></pre> <p>High Utilization (70-100%)</p> <p>For many GPU-accelerated applications like deep learning training or scientific simulations, a high GPU utilization (often around 70-100%) during compute-intensive tasks is considered good. It indicates that the GPU is efficiently processing tasks without significant idle time.</p> <p>Low to Moderate Utilization (10-40%)</p> <p>In some cases, especially when the workload is less intensive or the application is idle waiting for data or other resources, the GPU utilization might be lower (e.g., 10-40%). This doesn't necessarily mean the GPU is underutilized or performing poorly; it could indicate a natural variation in workload or efficient scheduling of tasks.</p> <p> Congratulations! </p> <p>You've mastered the fundamentals of TAAURUS GPU cluster! If you experience any errors or have feedback, please let us know!.</p>"},{"location":"taaurus/guides/navigating-taaurus/","title":"Navigating TAAURUS","text":"<p>This guide will help you navigate the platform, understand the available applications, and work with the file system effectively.</p>"},{"location":"taaurus/guides/navigating-taaurus/#desktop-overview","title":"Desktop Overview","text":"<p>When you first log into TAAURUS, you'll see a Windows desktop environment with several key components:</p> <ul> <li>Desktop Icons: Shortcuts to commonly used applications</li> <li>Taskbar: Quick access to running applications and system functions</li> <li>Start Menu: Access to all installed software and system tools</li> <li>File Explorer: Navigate and manage your files and folders</li> </ul> <p></p>"},{"location":"taaurus/guides/navigating-taaurus/#available-applications","title":"Available Applications","text":"<p>TAAURUS comes pre-installed with applications for research and high-performance computing:</p>"},{"location":"taaurus/guides/navigating-taaurus/#scientific-and-statistical-software","title":"Scientific and Statistical Software","text":"<ul> <li>R and RStudio</li> <li>Python and Anaconda</li> <li>MATLAB</li> <li>Stata</li> </ul>"},{"location":"taaurus/guides/navigating-taaurus/#medical-and-imaging-software","title":"Medical and Imaging Software","text":"<ul> <li>DICOMscope: Medical imaging viewer for DICOM files</li> <li>Weasis: Advanced medical image viewer</li> </ul>"},{"location":"taaurus/guides/navigating-taaurus/#office-applications","title":"Office Applications","text":"<ul> <li>LibreOffice Calc: Spreadsheet application for data analysis</li> <li>LibreOffice Writer: Word processing for documentation and reports</li> <li>PDF Reader: Atril Document Viewer for viewing research documents</li> <li>Pluma: Simple text editor</li> </ul>"},{"location":"taaurus/guides/navigating-taaurus/#terminal","title":"Terminal","text":"<ul> <li>MATE Terminal</li> </ul>"},{"location":"taaurus/guides/navigating-taaurus/#file-system-navigation","title":"File System Navigation","text":""},{"location":"taaurus/guides/navigating-taaurus/#project-specific-storage","title":"Project-Specific Storage","text":"<p>TAAURUS provides dedicated, secure storage for each project located in <code>/media/project</code>:</p> <pre><code>/media/project/\n\u251c\u2500\u2500 data/          # Your project's dataset\n\u251c\u2500\u2500 work/          # Scripts and other project relevant files\n\u2514\u2500\u2500 export/        # Files and folders ready for exporting\n</code></pre> <p>File Management Best Practices</p> <p>Project Organization: Keep all project files in your dedicated storage area. Do not use your own storage (<code>/home/domain.aau.dk/user</code>)</p>"},{"location":"taaurus/guides/navigating-taaurus/#working-with-applications","title":"Working with Applications","text":""},{"location":"taaurus/guides/navigating-taaurus/#starting-applications","title":"Starting Applications","text":""},{"location":"taaurus/guides/navigating-taaurus/#from-start-menu","title":"From Start Menu","text":"<ol> <li>Click the Start button</li> <li>Browse or search for your application</li> <li>Click to launch</li> </ol>"},{"location":"taaurus/guides/running-jobs/","title":"Running jobs on TAAURUS","text":"<p>This guide will teach you how to run computational tasks on TAAURUS using the Slurm job scheduler. Slurm manages all the computing resources and ensures fair access for all users.</p>"},{"location":"taaurus/guides/running-jobs/#understanding-slurm","title":"Understanding Slurm","text":"<p>Slurm is a job scheduling system that:</p> <ul> <li>Manages resources: Allocates CPUs, GPUs, and memory to your jobs</li> <li>Queues jobs: Organizes jobs when resources are busy</li> <li>Ensures fairness: Prevents any single user from monopolizing resources</li> </ul>"},{"location":"taaurus/guides/running-jobs/#two-ways-to-run-jobs","title":"Two Ways to Run Jobs","text":"<p>Slurm offers two methods for running jobs:</p> <ol> <li>srun - Interactive jobs for testing and debugging</li> <li>sbatch - Batch jobs for longer computations</li> </ol>"},{"location":"taaurus/guides/running-jobs/#when-to-use-each-method","title":"When to Use Each Method","text":"Method Best For Duration Interaction <code>srun</code> Testing, debugging, quick tasks Short (&lt; 1 hour) Interactive <code>sbatch</code> Training models, long computations Long (&gt; 1 hours) Non-interactive"},{"location":"taaurus/guides/running-jobs/#using-srun-interactive-jobs","title":"Using srun (Interactive Jobs)","text":"<p><code>srun</code> runs commands interactively on a compute node. Your terminal connects directly to the compute node, making it perfect for testing and debugging.</p>"},{"location":"taaurus/guides/running-jobs/#basic-srun-example","title":"Basic srun Example","text":"<p>Let's start with a simple test:</p> <pre><code>srun hostname\n</code></pre> <p>This command will:</p> <ol> <li>Request a compute node</li> <li>Run the <code>hostname</code> command on that node</li> <li>Display the result</li> <li>Return you to the front-end node</li> </ol>"},{"location":"taaurus/guides/running-jobs/#what-youll-see","title":"What You'll See","text":"<p>When you run an srun command, you might see:</p> <pre><code>sp-l40s-01\n</code></pre> <p>This shows the hostname of one of the compute nodes (in this case <code>sp-l40s-01</code>)</p>"},{"location":"taaurus/guides/running-jobs/#when-to-use-srun","title":"When to Use srun","text":"<p>\u2705 Good for:</p> <ul> <li>Testing commands and scripts</li> <li>Debugging code</li> <li>Quick computations</li> <li>Interactive exploration</li> </ul> <p>\u274c Not ideal for:</p> <ul> <li>Long-running jobs (hours/days)</li> <li>Jobs that need to run without you being connected</li> <li>Production model training</li> </ul>"},{"location":"taaurus/guides/running-jobs/#using-sbatch-batch-jobs","title":"Using sbatch (Batch Jobs)","text":"<p><code>sbatch</code> is perfect for longer-running jobs. You create a script with your commands, submit it to the queue, and Slurm runs it when resources are available.</p>"},{"location":"taaurus/guides/running-jobs/#creating-a-job-script","title":"Creating a Job Script","text":"<p>Let's create a simple job script:</p> <pre><code>nano my_job.sh\n</code></pre> <p>Add this content:</p> my_job.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=my_test_job  # Name of your job\n#SBATCH --output=my_job.out     # Output file\n#SBATCH --error=my_job.err      # Error file\n\n# Your commands go here\nhostname\necho \"Hello from TAAURUS!\"\ndate\n</code></pre>"},{"location":"taaurus/guides/running-jobs/#understanding-the-script","title":"Understanding the Script","text":"<ul> <li><code>#!/bin/bash</code>: Tells the system to use bash shell</li> <li><code>#SBATCH</code> lines: Slurm directives that configure your job</li> <li>Commands below: What you want to run</li> </ul>"},{"location":"taaurus/guides/running-jobs/#submitting-the-job","title":"Submitting the Job","text":"<pre><code>sbatch my_job.sh\n</code></pre> <p>You'll see: <pre><code>Submitted batch job 12345\n</code></pre></p>"},{"location":"taaurus/guides/running-jobs/#what-happens-next","title":"What Happens Next","text":"<ol> <li>Job is queued: Slurm adds your job to the queue</li> <li>Resources allocated: When available, Slurm assigns compute resources</li> <li>Job runs: Your script executes on the compute node</li> <li>Output saved: Results are written to your specified output file</li> </ol>"},{"location":"taaurus/guides/running-jobs/#checking-results","title":"Checking Results","text":"<p>Once the job completes, check the output:</p> <pre><code>cat my_job.out    # View the output\ncat my_job.err    # View any errors (if empty, no errors occurred)\n</code></pre>"},{"location":"taaurus/guides/running-jobs/#when-to-use-sbatch","title":"When to Use sbatch","text":"<p>\u2705 Perfect for most jobs:</p> <ul> <li>Training machine learning models</li> <li>Long data processing tasks</li> <li>Jobs that take hours or days</li> <li>Running jobs overnight or while you're away</li> </ul>"},{"location":"taaurus/guides/running-jobs/#specifying-job-resources","title":"Specifying Job Resources","text":"<p>Most jobs need specific resources like GPUs, memory, or time limits. You specify these using Slurm options.</p>"},{"location":"taaurus/guides/running-jobs/#common-resource-options","title":"Common Resource Options","text":"Option Description Example Notes <code>--mem</code> Memory allocation <code>--mem=32G</code> Per\u2011job request; node total 768 GB <code>--cpus-per-task</code> CPU cores <code>--cpus-per-task=6</code> Per\u2011task; node total 64 cores <code>--gres</code> GPUs <code>--gres=gpu:1</code> 8 GPUs per node (L40S, 48 GB) <code>--time</code> Time limit <code>--time=01:00:00</code> HH:MM:SS"},{"location":"taaurus/guides/running-jobs/#not-sure-what-to-request","title":"Not sure what to request?","text":"<ul> <li>Start with <code>--gres=gpu:1</code>, <code>--cpus-per-task=4\u20138</code>, <code>--mem=16\u201348G</code></li> <li>Increase CPUs if data loading or preprocessing is a bottleneck</li> <li>Increase memory for larger batches or models</li> <li>Only request multiple GPUs if your code supports it</li> </ul>"},{"location":"taaurus/guides/running-jobs/#using-options-with-srun","title":"Using Options with srun","text":"<p>Add options directly to your srun command:</p> <pre><code>srun --mem=32G --cpus-per-task=6 --gres=gpu:1 --time=01:00:00 hostname\n</code></pre>"},{"location":"taaurus/guides/running-jobs/#using-options-with-sbatch","title":"Using Options with sbatch","text":"<p>Add options as <code>#SBATCH</code> directives in your script:</p> my_job.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=my_training_job\n#SBATCH --output=training.out\n#SBATCH --error=training.err\n#SBATCH --mem=32G\n#SBATCH --cpus-per-task=6\n#SBATCH --gres=gpu:1\n#SBATCH --time=04:00:00\n\n# Your training commands here\npython train_model.py\n</code></pre> <p>Now that you know how to run jobs on TAAURUS, let's delve into how to get applications/containers </p>"},{"location":"taaurus/guides/using-containers/","title":"Using Containers to Run Jobs","text":"<p>Now that you know how to get containers, let's learn how to use them to run your computational tasks on TAAURUS.</p>"},{"location":"taaurus/guides/using-containers/#basic-container-usage","title":"Basic Container Usage","text":"<p>To run commands inside a container, you use <code>singularity exec</code> with either <code>srun</code> or <code>sbatch</code>.</p>"},{"location":"taaurus/guides/using-containers/#running-a-simple-command","title":"Running a Simple Command","text":"<p>Let's start with a basic example using a Python container:</p> <pre><code>srun --mem=24G --cpus-per-task=6 --gres=gpu:1 --time=01:00:00 singularity exec --nv /media/project/work/pytorch_25.05.sif python3 -c \"print('Hello from TAAURUS!')\"\n</code></pre> <p>Command breakdown:</p> <ul> <li><code>srun</code>: Run on a compute node with specified resources</li> <li><code>singularity exec</code>: Execute a command inside a container</li> <li><code>--nv</code>: Enable NVIDIA GPU drivers (required for GPU jobs)</li> <li><code>/media/project/work/pytorch_25.05.sif</code>: Path to the container (replace <code>project</code> with your projects name)</li> <li><code>python3 -c \"print('Hello from TAAURUS!')\"</code>: Command to run</li> </ul>"},{"location":"taaurus/guides/using-containers/#using-containers-with-sbatch","title":"Using Containers with sbatch","text":"<p>For longer jobs, create a batch script:</p> my_job.sh<pre><code>#!/bin/bash\n\n#SBATCH --job-name=my_python_job\n#SBATCH --output=my_job.out\n#SBATCH --error=my_job.err\n#SBATCH --mem=24G\n#SBATCH --cpus-per-task=15\n#SBATCH --gres=gpu:1\n#SBATCH --time=01:00:00\n\n# Run Python script in container\nsingularity exec --nv /media/project/work/pytorch_25.05.sif python3 my_script.py\n</code></pre> <p>Submit the job:</p> <pre><code>sbatch my_job.sh\n</code></pre> <p>Check the results:</p> <pre><code>cat my_job.out  # View output\ncat my_job.err  # View errors (if any)\n</code></pre>"},{"location":"taaurus/guides/using-containers/#cancelling-jobs","title":"Cancelling Jobs","text":"<p>Sometimes you need to cancel jobs that are running too long, stuck, or have incorrect parameters.</p>"},{"location":"taaurus/guides/using-containers/#check-your-jobs-first","title":"Check Your Jobs First","text":"<p>Before cancelling, see what jobs you have running:</p> <pre><code>squeue --me\n</code></pre> <p>This shows all your jobs with their IDs and status.</p>"},{"location":"taaurus/guides/using-containers/#cancel-a-specific-job","title":"Cancel a Specific Job","text":"<p>To cancel a single job, use its job ID:</p> <pre><code>scancel 12345  # Replace 12345 with your actual job ID\n</code></pre>"},{"location":"taaurus/guides/using-containers/#cancel-all-your-jobs","title":"Cancel All Your Jobs","text":"<p>To cancel all your jobs at once:</p> <pre><code>scancel --user=$USER\n</code></pre> <p>Now that you know how to run jobs using containers, let's delve into the last part about monitoring on TAAURUS </p>"},{"location":"ucloud/","title":"UCloud","text":"Researchers Indicates if the platform is accessible for researchers (e.g., PhD students, postdocs, faculty) for research purposes. Lecturers Indicates if the platform is accessible to lecturers for teaching purposes. Sensitive Data Whether the platform supports processing and storing sensitive or confidential data CPU processing Indicates if the platform supports computational tasks that only require CPU resources. GPU processing Indicates if the platform supports computational tasks that require GPU resources for acceleration (e.g., deep learning). Unlimited compute Whether the platform allows unrestricted compute usage, without limitations on the amount of usage time. Web interface The method used to access the platform. Pre-installed apps Indicates if the platform comes with pre-installed applications or frameworks for convenience (e.g., Ansys, PyTorch, TensorFlow). Collaboration friendly Indicates if the platform supports collaborative work (e.g., sharing resources, co-editing, team projects). Working interactively Indicates if the platform supports interactive workflows where users can interact with running processes (e.g., Jupyter notebooks). Possible to add GUI Whether it is possible to run graphical user interfaces (GUIs) on the platform (e.g., remote desktops, JupyterLab). Not for storage This platform is not designed for long term storage of research data."},{"location":"ucloud/#introduction","title":"Introduction","text":"<p>UCloud is a HPC research platform, engineered to provide high-performance computing with a focus on ease of use. UCloud provides an intuitive graphical user interface to powerful interactive high-performance computing and tools for data analytics and visualization. UCloud offers an \u201cApps\u201d section preloaded with popular applications and more applications can be customized and uploaded on-demand.</p> <p>Open call for DeiC's National HPC ressources</p> <p>Call \"H2-2026\" is open from the 13th of January 2026, and will close 10th of March 2026.</p> <p>This possibility is especially well suited for projects with large resource requirements.</p> <ul> <li> <p>Find more information on CLAAUDIA's page dedicated to this  DeiC HPC resources.</p> </li> <li> <p>Find the official call page  DeiC \"H2-2026\".</p> </li> </ul>"},{"location":"ucloud/#getting-started","title":"Getting Started","text":"<p>How to access</p> <p>Learn how to access UCloud</p> <p>Guides for UCloud</p> <p>Learn the basics on how to use UCloud</p> <p>Terms and Conditions</p> <p>Get an overview of the Terms and Conditions for UCloud</p>"},{"location":"ucloud/#key-features","title":"Key FeaturesHigh AccessibilitySecure, cloud-based resourcesPreloaded App Section","text":"<p>Access from any device\u2014workstations, laptops, and tablets\u2014ensuring flexibility and convenience for researchers.</p> <p>UCloud is designed to handle data at different [security levels](https://www.security.aau.dk/data-classification), and is especially handy if you\u2019re working with level 2 or 3 data.</p> <p>Access popular applications like MATLAB, RStudio, Jupyter Notebook, and more, preloaded for efficient workflows.</p>"},{"location":"ucloud/#common-use-cases","title":"Common Use Cases","text":"<p>Automated transcription services</p> <p>Generative AI for image trends</p> <p>High-performance computing for research</p> <p>Collaborative image processing</p> <p>Simulation and modeling projects</p> <p>Monte Carlo simulations</p> <p>Mobile applications and enhancements</p> <p>Satellite data and Earth models</p> <p>Virtual avatars and AI synthesis</p>"},{"location":"ucloud/#important-information","title":"Important Information","text":"<p>Review the terms and conditions</p> <p>Before getting started, take a few moments to review the terms and conditions of using UCloud, and don't hesitate to reach out to our support team if you have any questions or concerns.</p>"},{"location":"ucloud/external-collaborator/","title":"External collaborators","text":"<p>If your UCloud project involves an external collaborator who does not have standard WAYF access to UCloud, you need to follow the procedure below.</p>"},{"location":"ucloud/external-collaborator/#procedure-for-adding-external-collaborators-on-ucloud","title":"Procedure for Adding External Collaborators on UCloud","text":"<ol> <li> <p>Sensitive Data Projects:  </p> <ul> <li>If your project includes sensitive data, please follow the Sensitive Data Process before proceeding.<ul> <li>The external collaborator should be approved by grants and contacts to get access to the data. </li> </ul> </li> </ul> </li> <li> <p>Request a Guest Account:  </p> <ul> <li>The external collaborator must be registered as a guest researcher at your institute or department.  <ul> <li>You should contact the relevant person at their institute to request a guest AAU AD user account.</li> </ul> </li> </ul> </li> <li> <p>Log In and Accept Terms:  </p> </li> <li> <p>Once the guest account is created, the collaborator must log into UCloud and accept the platform's Terms and Conditions (SLA).</p> </li> <li> <p>Add the Collaborator to Your Project:  </p> </li> <li>The Principal Investigator (PI) can now add the collaborator to the project, just like any other pre-approved participant.</li> </ol>"},{"location":"ucloud/faq/","title":"Faq","text":"<p>??? info \"How do I get started with transcribing interviews using Transcriber or Whisper on UCloud?</p> <p>??? info \"How do I request or extend my HPC/GPU resources?</p> <p>??? info \"Why am I not getting any transcription output?</p> How do I handle sensitive or GDPR-level 2/3 data in UCloud? Is there a way to edit transcripts in UCloud while playing the audio? How can I troubleshoot jobs that crash, freeze, or time-out? Where do I find or create a Workzone reference number for data classification? Can I store all of my project files on UCloud, and how do I keep track of storage limits? How do I set up an environment (e.g., Python, R, MATLAB) and keep packages installed across sessions? How can I run COMSOL, ANSI, or MATLAB for longer compute jobs without disconnection? How do I get a public IP or direct SSH access on UCloud? Will my files be deleted if the project expires or resource allocations run out? How do I safely transfer data between my local computer and UCloud? What is the correct procedure for referencing HPC or Transcriber in a scientific paper? Which HPC solution is best suited for my project (Strato, AI Cloud, or UCloud)?"},{"location":"ucloud/how-to-access/","title":"How to access","text":""},{"location":"ucloud/how-to-access/#direct-access","title":"Direct access","text":"<p>All Aalborg University users automatically have access to UCloud and can simply log in using their WAYF credentials (university logon credentials). This gives you access to \"My Workspace\" with a starting quota of 2000 CPU-hours that can be used in the standard web app environment. This is the quickest and most user-friendly way to access HPC as a first-time user.</p> <p>Log in to UCloud</p>"},{"location":"ucloud/how-to-access/#projects","title":"Projects","text":"<p>If you require a larger CPU quota, access to GPU resources, a virtual machine, or need to work with sensitive data, you can apply for a project using CLAAUDIA\u2019s local resources.</p> <p>Important: If your project involves personally identifiable information, you must register your data with the Grant and Contract Unit. You can find detailed instructions for this process in our guide on handling sensitive data on UCloud.</p> <p>The diagram below outlines the process for getting your project approved and set up on UCloud:</p> <p>Apply for UCloud project</p> <pre><code>graph TD\n    A[\"\ud83d\udcdd Complete the &lt;br/&gt;application form\"] --&gt; B[\"\u2705 CLAAUDIA approval\"]\n    B --&gt; C[\"\ud83d\udcbb Enter the approved &lt;br/&gt;resources in UCloud\"]\n    C --&gt; D[\"\u2705 CLAAUDIA approval\"]\n    D --&gt; E[\"\u2b50 The project is now available\"]\n\n    click A \"https://forms.office.com/e/8Khbr1TJGC\" \"Open application form\" _blank\n    click C \"https://cloud.sdu.dk/app/dashboard\" \"Open UCloud dashboard\" _blank\n\n    %% Define classes for colors\n    classDef User fill:#e6f3ff,stroke:#1d70b8,color:#0b0c0c,font-size:14px;\n    classDef CLAAUDIA fill:#ffe5b4,stroke:#ff9900,color:#0b0c0c,font-size:14px;\n    classDef Completed fill:#66ff66,stroke:#006600,color:#0b0c0c,font-size:14px;\n\n    %% Assign classes\n    class A,C User;\n    class B,D CLAAUDIA;\n    class E Completed;</code></pre> <p>Sensitive data:</p> <ul> <li> You must have a WorkZone case number for your research project.           If you don't have one, you can apply through Grants and Contracts using their registration form.         </li> <li> Only SDU compute resources may be used to handle sensitive data.</li> <li> To get started, read our guide on how to handle sensitive data on UCloud.</li> </ul>"},{"location":"ucloud/how-to-access/#national-hpc-resources","title":"National HPC Resources","text":"<p>Twice a year it's possible to apply for a share in DeiC's National HPC resources. This possibility is especially well suited for projects with large resource requirements. To learn more about this oppurtunity, please find our page dedicated to this possibility: DeiC HPC resources.</p> <p>Open call for DeiC's National HPC ressources</p> <p>Call \"H2-2026\" is open from the 13th of January 2026, and will close 10th of March 2026.</p> <ul> <li> <p>Find more information on CLAAUDIA's page dedicated to this  DeiC HPC resources.</p> </li> <li> <p>Find the official call page  DeiC \"H2-2026\".</p> </li> </ul> <p>Need assistance? Reach us at the Service Portal</p>"},{"location":"ucloud/providers/","title":"Providers on UCloud","text":"<p>UCloud supports several providers that cater to different research and computational needs. This guide covers three primary providers: SDU/K8s, AAU/K8s, and AAU/VM.</p>"},{"location":"ucloud/providers/#sduk8s-aauk8s","title":"SDU/K8s &amp; AAU/K8s","text":"<p>Both SDU/K8s and AAU/K8s are Kubernetes-based environments designed for scalable research workloads. They allow users to quickly launch pre-built applications. However, there are important differences to consider before choosing one.</p>"},{"location":"ucloud/providers/#sduk8s-vs-aauk8s","title":"SDU/K8s vs. AAU/K8s","text":"<ul> <li>SDU/K8s provides:</li> <li>\u2705 Handling of sensitive data </li> <li>\u2705 SSH connections </li> <li>\u2705 Support for licensed software </li> <li> <p>\u2705 Fixed IP addresses</p> </li> <li> <p>AAU/K8s:</p> </li> <li>\u274c Does not accommodate sensitive data </li> <li>\u274c No SSH access </li> <li>\u274c No support for licensed software </li> <li>\u274c No fixed IP addresses </li> <li>\u2705 Offers access to a wide range of GPUs</li> </ul> <p>If you need any of the capabilities listed for SDU/K8s\u2014such as handling sensitive data, requiring SSH connections, or leveraging licensed software \u2014 choose SDU/K8s. </p>"},{"location":"ucloud/providers/#aauvm","title":"AAU/VM","text":"<p>AAU/VM is a traditional virtual machine provider for users requiring full control over their environment.</p>"},{"location":"ucloud/providers/#key-features","title":"Key Features:","text":"<ul> <li>\u2705 Customizable virtual machines </li> <li>\u2705 GPU support for compute-heavy tasks  </li> <li>\u2705 Complete OS control for specialized or custom software installations</li> </ul> <p>AAU/VM is ideal if you need an environment where you can configure the operating system extensively or run GPU-intensive workloads that demand tight control over system settings.</p>"},{"location":"ucloud/service-windows/","title":"Service windows","text":"<p>Four times a year, all of our platforms are subject to service windows where changes and security upgrades are implemented. During these, we reserve an entire day for maintainance of the systems.</p> <p>It should be expected that the platforms are offline for the entire day from 00:01 until 23:59 - but they may come online by the end of the days, as the work is finished.</p>"},{"location":"ucloud/service-windows/#schedule","title":"Schedule","text":"<p>A service window will take place on the following dates:</p> <p>AI Cloud, Strato, UCloud VM's &amp; UCloud Kubernetes</p> 2025 2026 2027 2028 11/02 10/02 09/02 08/02 13/05 12/05 11/05 09/05 16/09 15/09 14/09 12/09 02/12 01/12 30/11 28/11 <p>AI-LAB</p> 2025 2026 2027 2028 13/02 12/02 11/02 10/02 15/05 14/05 13/05 11/05 18/09 17/09 16/09 14/09 04/12 03/12 02/12 30/11 <p>TAAURUS</p> 2026 2027 2028 2029 03/02 - - - - - - - - - - - - - - - <p>Sign up for notifications on serviceinfo.dk</p> <p>Click this link to go to serviceinfo.dk. Then select Aalborg University, and under the tab Subscribe (or Abonn\u00e9r), select CLAAUDIA. Select email, SMS or calendar, according to your preferences:</p> <p> Go to ServiceInfo.dk</p>"},{"location":"ucloud/service-windows/#platform-specific-information","title":"Platform specific information","text":""},{"location":"ucloud/service-windows/#strato-and-ucloud-virtual-machines","title":"Strato and UCloud virtual machines","text":"<p>Be sure to save your work no later than the end of the day before the service window begins, as all virtual machines will be automatically shut down during the service window and any unsaved data will be lost.</p> <p>Usage Management Process </p> <p>1. Servers will NOT restart automatically after service windows     - All servers in the AAU availability zone will be shut down during service windows and will not restart automatically, unless they have been registered for automatic restart before the service window.      - You can easily restart your servers manually after the service window.</p> <p>2. Automatic server resizing after 48 hours of inactivity     - Servers that remain shut down for more than 48 hours will be automatically resized to the smallest CPU configuration.     - You will receive a notification when your instance has been resized.</p> <p>3. Automatic server deletion after 30 days of inactivity     - Servers that remain shut down for 30 days will be permanently deleted, but their volumes will be preserved.     - You will be notified in advance about any affected instances.</p> <p>4. Unused volume cleanup     - Volumes not attached to any server for 30 days will be deleted.     - A notification will be sent before deletion.</p> <p>All virtual machines should be removed when not in use.  Basic rule: keep your volumes, delete your unused VMs, and only run a VM with the size you really need right now. Please consult the page 'Delete and restart an instance from the volume' for instructions on how to do this.</p> <p>Apply for automatic restart of your Strato server</p> <p>Note: The deadline for requesting inclusion in the automatic restart list has now passed for the service window on the 2nd december.</p> <p>You could request automatic restarts for your server if all of the following conditions were met:</p> <ul> <li>The server is part of a Strato Project</li> <li>You can provide a valid motivation for needing automatic restart</li> <li>The server is in one of these availability zones:<ul> <li>AAU</li> <li>AAU-T4</li> <li>AAU-A10</li> <li>AAU-A40</li> </ul> </li> </ul> <p>Servers running in personal project spaces (such as default quota projects, e.g. <code>GK83DJ@aau.dk</code>) cannot be included. If you want to move your project, you can find instructions on how to apply for a Strato Project</p> <p>The application form for inclusion in the automatic restart list closed on November 25th: Strato service window: Automatic server restart inclusion form</p> <p>Link to Strato's web-interface: strato-new.claaudia.aau.dk</p>"},{"location":"ucloud/service-windows/#ai-cloud","title":"AI Cloud","text":"<p>In the days leading up to the service window, a reservation will be put in place for the entire cluster. The entirety of the cluster will therefore be unavailable for that day, but may come back online by the end of the day.</p> <p>You can still submit jobs in the days leading up to the service window. Since the <code>batch</code> and <code>prioritized</code> partitions have time limits of 12 hours and 6 days respectively, you will only be able to launch new jobs if you add the <code>--time</code> parameter to your Slurm command. If you do not set this parameter, and there are 5 days until the day of the service window, your job will not start until after the service window. You will thus need to calculate how much time there is left, and then submit the job with this parameter added. </p> <p>To submit a job that runs for 1 day and 8 hours, you can simply add <code>--time=1-08:00:00</code> to your Slurm command. </p> <p>Additionally you can read about our recommendations for using checkpointing to work with time limits.</p>"},{"location":"ucloud/service-windows/#ai-lab","title":"AI-LAB","text":"<p>In the days leading up to the service window, a time limit will be imposed, which will prevent you from launching jobs with end dates that surpass the date of the service window. </p> <p>In this period, you will only be able to launch new jobs, if you add the <code>--time</code> parameter to your Slurm command. If the time parameter is not included, Slurm assumes you ask for the default maximum time for the partition. You will thus have to calculate how much time you have before the service window, and then submit a job with this parameter added. </p> <p>To submit a job that runs for 12 hours, you should add: <code>--time=12:00:00</code>. Not setting the <code>--time</code> parameter will place your job in the queue, where it will wait until the service window has been completed.</p> <p>IMPORTANT: You can still run jobs in the days leading up to the service window</p> <p>If you have any questions, please open a case with us on serviceportal.aau.dk</p>"},{"location":"ucloud/service-windows/#ucloud-aauk8s","title":"UCloud (AAU/K8s)","text":"<p>The UCloud (AAU/K8s) cluster will be unavailable for the entire duration of the service window and may become available again by the end of the day. While it may be technically possible to start jobs on the day of the service window, please note that any running jobs will be terminated as part of the scheduled maintenance activities performed by the administrators. We recommend planning your work accordingly to avoid interruptions.</p>"},{"location":"ucloud/terms-and-conditions/","title":"Terms and Conditions","text":""},{"location":"ucloud/terms-and-conditions/#high-performance-computing-systems-at-aau-are-subjects-limited-by-the-ever-changing-availability-of-the-resources-dependant-on-the-users-thus-having-resources-granted-does-not-consequently-mean-that-it-is-possible-to-use-them-right-away-learn-about-the-guidelines-and-rules-to-ensure-a-smooth-and-efficient-computing-experience","title":"High-Performance Computing systems at AAU are subjects limited by the ever-changing availability of the resources, dependant on the users. Thus, having resources granted does not consequently mean that it is possible to use them right away. Learn about the guidelines and rules to ensure a smooth and efficient computing experience.","text":"<p>General principles and definitions of terms</p> <p>As a general principle, the HPC resources are intended to provide additional computational power to AAU researchers and staff.</p> <ul> <li>We refers to CLAAUDIA and or any other part of the Information Technology Services (ITS) department that is responsible for the provision, maintenance or support of HPC RESOURCES at Aalborg University.</li> <li>You refers to you the user, which may be an individual or other legal person.</li> <li>HPC refers to High Performance Computing resources</li> </ul> <p>What are the systems not intended for?</p> <ul> <li>They are not designed for long term storage of research data.</li> <li>They are not designed for production.</li> <li>They are not intended to host long term shared research projects.</li> </ul> <p>We offer custom solutions If you are in need of larger research project solutions, production virtual machines, or long term storage, please submit a request CLAAUDIA support team.</p>"},{"location":"ucloud/terms-and-conditions/#1-access-and-responsibility","title":"1. Access and Responsibility","text":"<p>The use of HPC RESOURCES requires that you are employed at AAU. You are responsible for any actions taken on these systems including the responsibility for ensuring that access is restricted to the appropriate individuals. Users are responsible for ensuring that their activities align with the guidelines and best practices outlined in the respective documentation of each platform.</p> <p>Only users authorized via the CLAAUDIA application form may have administrative access to the applied resources.</p>"},{"location":"ucloud/terms-and-conditions/#2-fair-and-sustainable-use-of-platforms","title":"2. Fair and Sustainable Use of Platforms","text":"<p>Responsibility for following guidelines</p> <p>It is imperative to follow the guidelines for virtual machine usage and resource allocation in AI Cloud, and to always prioritize consideration for fellow researchers when using these resources.</p>"},{"location":"ucloud/terms-and-conditions/#21-strato","title":"2.1. Strato","text":"<p>Active virtual machines prevent other users from accessing those resources. A virtual machine should only be kept running while it is in current and active use. Active use requires that the machine will be used for research purposes within the coming 48 hours. The setup of each virtual machine is stored on a block device volume, which can be used to new virtual machines \u201cfrom volumes\u201d at a later stage. All virtual machines that are not in use must be deleted. </p> <p>See this guide</p>"},{"location":"ucloud/terms-and-conditions/#22-ai-cloud","title":"2.2. AI Cloud","text":"<p>Users should be considerate of fellow researchers when allocating jobs in AI Cloud. Jobs should only run if they are actively utilising the computation resources that have been allocated to them. I.e. Interactive jobs should only be used very briefly for development purposes, and no job should allocate any GPU resources that are not used by the job. Users should test their applications for effective utilisation of GPU resources before starting any resource-heavy jobs.</p>"},{"location":"ucloud/terms-and-conditions/#3-gdpr-compliance-and-data-responsibility","title":"3. GDPR Compliance and Data Responsibility","text":"<p>Adherence to GDPR</p> <p>You must adhere to the General Data Protection Act (GDPR) regulations, e.g. gain consent when needed - links are available below in sections 3.1. and 3.2.. You are personally responsible for any data stored on any of the HPC RESOURCES.</p>"},{"location":"ucloud/terms-and-conditions/#31-gdpr-compliance-for-aau-employees","title":"3.1. GDPR compliance for AAU employees","text":"<p>If you are interested in using HPC RESOURCES in your research work as an AAU employee, you need to go to the GDPR website and complete and submit a notification of your data collection.</p> <p>You can find more information at AAU's website for GDPR related info for employees.</p>"},{"location":"ucloud/terms-and-conditions/#4-confidentiality-and-sensitivity-of-data","title":"4. Confidentiality and Sensitivity of Data","text":"<p>AI Cloud and virtual machines on Strato or UCloud must not be used to store confidential and/or sensitive data.</p> <p>UCloud projects with sensitive data</p> <p>Please read the procedure for working with sensitive data on UCloud that has been agreed upon with the Department of Grants and Contracts. </p>"},{"location":"ucloud/terms-and-conditions/#5-deletion-of-accounts-and-data","title":"5. Deletion of Accounts and Data","text":"<p>With regards to data stored on any of the HPC RESOURCES, it will automatically be deleted if the user is no longer registered as an active student or staff member.</p>"},{"location":"ucloud/terms-and-conditions/#51-deletion-of-strato-and-ai-cloud-student-accounts-and-data-extraction-responsibilities","title":"5.1. Deletion of Strato and AI Cloud Student Accounts and Data Extraction Responsibilities","text":"<p>All Strato and AI Cloud student accounts will be deleted at the end of each semester (01 February, and 01 August). Students are responsible for the extraction or saving of all data that is of value to them prior to these dates.</p>"},{"location":"ucloud/terms-and-conditions/#52-extract-or-delete-inactive-data","title":"5.2 Extract or delete inactive data","text":"<p>Once you\u2019ve finished processing your data, please make sure to either extract it or delete it\u2014\u201cfinished data\u201d means anything you\u2019re no longer actively working on. HPC platforms aren\u2019t meant for long-term storage, so when you\u2019re done, move your data to a dedicated storage solution like Datadeposit.</p>"},{"location":"ucloud/terms-and-conditions/#6-prohibited-usage-and-consequences","title":"6. Prohibited Usage and Consequences","text":"<p>HPC RESOURCES may not, under any circumstances, be used for any purpose outside the scope of staff research, teaching or administrative functions. Any misuse of the HPC RESOURCES will result in an immediate and permanent ban of the use of any HPC RESOURCES. Criminal or unlawful activity will be reported to the appropriate authorities.</p>"},{"location":"ucloud/terms-and-conditions/#7-service-windows","title":"7. Service Windows","text":"<p>What is a service window?</p> <p>A service window is a scheduled time when maintenance work is done on AAU's HPC systems that disrupt normal use. This maintenance can make the system temporarily unavailable or some resources unusable. AAU informs users in advance so they can plan their work around it. Once it's done, the system returns to normal and users can resume their work.</p> <ul> <li>Scheduled service windows: Four entire days each year are reserved for security updates. </li> <li>Planned service windows: Occur when sub-system maintenance is required between the existing scheduled service windows.</li> <li>Emergency service windows: All systems may be subject to emergency service windows. In the case of an accute emergency, all users will be informed of the nature and expected duration of the window.</li> </ul>"},{"location":"ucloud/terms-and-conditions/#71-scheduled-service-windows-for-strato-and-ai-cloud","title":"7.1. Scheduled service windows for Strato and AI Cloud","text":"<p>Four entire days each year are reserved for security updates. This may require that all hosts are restarted. Users should expect that all virtual machines will be shut off during this service window and the job queue will be cleared.</p> <p>Proposed schedule of service windows (these dates are subjects to change):</p> <p>2024 17/09, 03/12</p> <p>2025 11/02, 13/05, 16/09, 02/12</p> <p>2026 10/02, 12/05, 15/09, 01/12</p> <p>2027 09/02, 11/05, 14/09, 30/11</p> <p>2028 08/02, 09/05, 12/09, 28/11</p> <p>Check ServiceInfo.dk to learn more about current service windows</p>"},{"location":"ucloud/terms-and-conditions/#72-right-to-maintenance-and-modification-of-systems","title":"7.2. Right to maintenance and modification of systems","text":"<p>We reserve the right to periodically shut off entire systems for maintenance or security purposes. These systems require maintenance and updates at regular intervals, and we commit, where possible, to provide a minimum of two calendar weeks warning before any shut down period commences.</p> <p>We reserve the right to modify, redesign, disable or remove any of the existing services. Where possible, users will be notified of major modifications to the existing systems a minimum of three calendar months before these changes are implemented. Updates, upgrades and shutdown periods are not considered major modifications.</p>"},{"location":"ucloud/terms-and-conditions/#73-communication-policy-around-service-windows","title":"7.3. Communication policy around service windows","text":"Scheduled IT disruptionsPlanned IT disruptionsEmergency communication timeframes <ol> <li> <p>Service window date reminder email</p> <ul> <li>Sent to all users of Strato, AI Cloud</li> <li>Dispatched 6-8 weeks before service window</li> </ul> </li> <li> <p>Orientation email about service window</p> <ul> <li>Sent to the internal CLAAUDIA and ITS management list</li> <li>Dispatched 2 weeks before service window</li> </ul> </li> <li> <p>Notice of service window pre arranged on ServiceInfo.dk</p> <ul> <li>Put on 1 week before the service window.</li> </ul> </li> <li> <p>Orientation email to system owner forum, key stakeholders or research group leaders</p> <ul> <li>Dispatched 2 weeks before service window.</li> </ul> </li> <li> <p>Orientation email to all users</p> <ul> <li>Dispatched 1 week before service window.</li> </ul> </li> <li> <p>Completion of planned work changed on ServiceInfo.dk</p> <ul> <li>Changed on first working day after the service window.</li> </ul> </li> </ol> <ol> <li> <p>Service window date reminder email</p> <ul> <li>Sent to all users of Strato, AI Cloud</li> <li>Dispatched 6-8 weeks before service window</li> </ul> </li> <li> <p>Orientation email about service window</p> <ul> <li>Sent to the internal CLAAUDIA and ITS management list</li> <li>Dispatched 4 weeks before service window</li> </ul> </li> <li> <p>Notice of service window pre arranged on ServiceInfo.dk</p> <ul> <li>Put on 2-3 weeks before the service window</li> </ul> </li> <li> <p>Orientation email to system owner forum, key stakeholders or research group leaders</p> <ul> <li>Dispatched 3 weeks before service window.</li> </ul> </li> <li> <p>Orientation email to all users</p> <ul> <li>Dispatched 2 weeks before service window.</li> </ul> </li> <li> <p>Completion of planned work changed on ServiceInfo.dk</p> <ul> <li>Changed on first working day after the service window.</li> </ul> </li> </ol> <ol> <li> <p>After 1st hour</p> <ul> <li>Out of order notice posted on ServiceInfo.dk.</li> </ul> </li> <li> <p>Unresolved problems at end of day</p> <ul> <li>Update on status - even if no change has occurred.</li> </ul> </li> <li> <p>After problem resolution</p> <ul> <li>The issue will be marked as resolved on ServiceInfo.dk</li> </ul> </li> </ol>"},{"location":"ucloud/terms-and-conditions/#8-loan-of-physical-equipment","title":"8. Loan of physical equipment","text":""},{"location":"ucloud/terms-and-conditions/#81-responsibility-and-liability-for-physical-equipment-loaned-by-aau","title":"8.1. Responsibility and Liability for Physical Equipment Loaned by AAU","text":"<p>With regards to physical equipment, you are solely responsible for damage to or loss of the equipment during the loan period. In the event of damage, AAU determines whether the equipment shall be repaired or replaced. If AAU determines that it is not viable to repair the equipment or if the equipment is lost, you shall compensate AAU for the value of the equipment.</p> <p>If AAU determines that the equipment can be repaired, you shall pay for the repair.</p>"},{"location":"ucloud/terms-and-conditions/#82-ethical-use-and-legal-responsibility-for-physical-kits-with-cameras","title":"8.2. Ethical Use and Legal Responsibility for Physical Kits with Cameras","text":"<p>Physical kits are delivered with a camera. Please act ethically and refrain from using them in places where other people may consider it unpleasant or annoying. You are responsible for acting according to the legislation of the country in which you use the equipment and the Danish legal and ethical rules.</p>"},{"location":"ucloud/terms-and-conditions/#9-updates-to-terms-and-conditions","title":"9. Updates to Terms and Conditions","text":"<p>We reserve the right to make periodic changes to these terms and conditions, and commit to inform users of the changes made.</p>"},{"location":"ucloud/terms-and-conditions/#appendix","title":"Appendix","text":""},{"location":"ucloud/terms-and-conditions/#procedure-for-working-with-sensitive-data-on-ucloud-projects","title":"Procedure for working with sensitive data on UCloud projects","text":"<p>CLAAUDIA, Aalborg University</p> <p>2023-10-10</p> <p>v1.0</p> <p>As a user on the UCloud platform you have a workspace called \"My workspace\".</p> <p>It is also possible to apply for a separate \"Project\" workspace on the UCloud platform. Projects on UCloud allow for collaboration with separate storage, compute resources and management of user rights and responsibilities on the UCloud platform.</p> <p>The project environment is required for the following types of work on UCloud:</p> <ol> <li> <p>For employed researchers at AAU (VIP)</p> <p>a.  Sensitive data: All work on the UCloud platform that involves     research data in classification levels 2. a 2.  All users</p> <p>a.  GPU access on UCloud: All access to GPU resources on UCloud     require a project.</p> <p>b.  Additional compute resources that are allocated out of the AAU     pool of UCloud resources.</p> </li> </ol> <p>UCloud users at AAU must be familiar with the details of the following codes of conduct and policies:</p> <ol> <li> <p>The Danish Code of Conduct for Research     Integrity</p> </li> <li> <p>The AAU Policy for Research Data     Management</p> </li> <li> <p>The AAU policies with regards to     GDPR     (Available in English for     researchers     (VIP) and     teachers     (VIP);     Only in Danish for administration (TAP)     employees)</p> </li> <li> <p>The AAU data management     recommendations</p> </li> </ol> <p>These policies cover the general rules all researchers (and TAP staff for point 3.) should abide by with regards to what kind of data may be kept, for how long, whether data can be re-used or recycled, and how long it should be archived for, etc.</p> <p>Sensitive data: Registration of research projects at Grants and Contracts</p> <p>For researchers at AAU, working with sensitive personal data requires that you register your research project with \"Grants and Contracts\" by completing the digital form that matches your role in relation to the data, for example Data Controller or Data processor.</p> <p>Data processing agreement between AAU and the EScience center at SDU</p> <p>For AAU users, data analysis and processing may then take place on the UCloud platform according to the data processing agreement between AAU and EScience center at SDU.</p> <p>Steps required to working with projects on the UCloud platform</p> <ol> <li> <p>Identify the data classification of your data by reviewing the AAU     data classification     model.</p> </li> <li> <p>If you are a researcher, and working with personally identifiable information, you must register a research project with Grants and Contracts     using the relevant registration     form.</p> <p>a.  Once you have registered your research activity at Grants and     Contracts, you will get a receipt that contains a \"WorkZone case     number\" (To be included in your UCloud project application).</p> </li> </ol> <ol> <li> <p>All applicants for projects on UCloud must complete the CLAAUDIA     application form for DeiC Interactive HPC resources.</p> </li> <li> <p>Once approved, you will receive a UCloud project     number, and you must apply for a project in the UCloud     Interface,     including the resources that you had approved in the CLAAUDIA     application. (You can apply for additional resources later if     needed.)</p> <p>a.  As project applicant you will be the Principal Investigator for     the project, and you should be aware of your roles and     responsibilities.</p> <p>b. The project must use the same project title as provided in the CLAAUDIA application, and both the DeiC project number and the Grants and Contracts reference number should be included:</p> <pre><code>i. The DeiC project number should be entered in the \"DeiC Interactive HPC project number\" field.\nii. The WorkZone case number should be entered in the \"WorkZone reference number\" field.\n</code></pre> <p>c.  Once your project is approved, you will get access to project     storage (Drive(s)) on UCloud that is separate from your \"My     Workspace\" storage. No sensitive data may be stored in the \"My     workspace\" drives.</p> </li> <li> <p>Adding data to the UCloud platform:</p> <p>a.  Any data added to the project should be in a project folder and     this must be marked according to the level of data sensitivity,     as described in the AAU data classification     model.</p> <pre><code>i.  On the UCloud platform the corresponding classifications are\n    as follows:\n\n    - AAU Level 1  \u2192 UCloud: Inherit\n    - AAU Level 2  \u2192 UCloud: Private/Confidential\n    - AAU Level 3  \u2192 UCloud: Sensitive (Only permitted to be added to your registered \n    and approved project folder.) Sensitive data may **NOT** be added to My Workspace.\n    - AAU Level 4  \u2192 Not allowed\n</code></pre> </li> <li> <p>Collaboration on UCloud within projects: Fellow AAU persons</p> <p>a.  Only persons named in the project registered with Grants and     Contracts may be added to the UCloud project.</p> </li> <li> <p>Collaboration on UCloud within projects: Persons from outside     AAU</p> <p>a.  The collaborator's employer must have a Data Processing     agreement with SDU (SDU are hosting UCloud), or</p> <pre><code>i.  Where there is an agreement of shared data responsibility\n    (Agreement on Joint data controlling), that states that it\n    is agreed to use DeiC/SDU as the data processor, then it is\n    sufficient that AAU has an existing data processing\n    agreement with DeiC/SDU. In these cases AAU will be\n    responsible for the data processing agreement with DeiC/SDU.\n</code></pre> <p>b.  If this is not the case, you cannot invite the collaborator     inside the project folder in UCloud.</p> <p>c.  No person(s) that are not included in the data processing     agreement or the agreement on joint data controlling may be     invited to the project.</p> </li> <li> <p>UCloud project members and roles should be set appropriately.</p> <p>a.  Project \"admins\" can see all member files by activating the     \"show member files\" option. The Principal Investigator is     responsible for ensuring that all roles and     responsibilities     are properly assigned.</p> </li> <li> <p>Read and write privileges on UCloud</p> <p>a.  If collaborators are only allowed read or write to specific     parts of the data / dataset, you will need to follow the     following steps:</p> <pre><code>i.  Within the project, you will need to create a new \"Drive\".\n    (As drives are the only level to which you can specify read\n    and write permissions.)\n\n    1.  Only project \"admins\" can create new drives within a\n        project.\n\nii. Name the drive and then click the \"...\" button to modify the\n    permissions. Then choose the permissions (None / Read /\n    Write).\n</code></pre> </li> <li> <p>Permitted applications and uses</p> <p>a. Only the SDU/K8 provider is permitted for working with data classifications 2 and 3.</p> <p>b. The AAU/K8 and AAU virtual machine providers are only permitted to be used for data classified as level 1.</p> </li> <li> <p>On completion the project\u00a0</p> <p>a.  All data on the UCloud platform should be deleted.</p> <p>b.  The project should then be archived with a final date that     corresponds with the GDPR notification with 'Grants and     Contracts'.</p> <p>c.  All files in trash folders should be permanently deleted.</p> <p>d.  All complete data sets and metadata should be stored in a data     repository in accordance with The AAU Policy for Research Data     Management.     As of 2023-January, AAU     DataDeposit     as a local archiving solution, while a national solution is     under development.</p> </li> </ol>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/","title":"Guidelines for handling level 2 and 3 data on UCloud","text":"<p>If you are working with data level 2 or 3 in relation to AAU data classification please read the listed guidelines below. </p>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#procedure-sensitive-ucloud-projects","title":"Procedure sensitive UCloud projects","text":"<pre><code>graph TD\n    A[Register your project with Grants and Contracts] --&gt; B[\ud83d\udcdd Complete the application form]\n    B --&gt; C[\u2705 CLAAUDIA approval]\n    C --&gt; D[\ud83d\udcbb Enter the approved resources in UCloud]\n    D --&gt; E[\u2705 CLAAUDIA approval]\n    E --&gt; F[\u2b50 The project is now available]\n\n    click A \"https://aaudk.sharepoint.com/sites/persondata-ressourcer/SitePages/Registrations%20og%20reports%20(Online%20forms).aspx\" \"Open Grants and Contracts registration\" _blank\n    click B \"https://forms.office.com/e/8Khbr1TJGC\" \"Open application form\" _blank\n    click D \"https://cloud.sdu.dk/app/dashboard\" \"Open UCloud dashboard\" _blank\n\n\n        %% Define classes for colors\n  classDef User fill:#e6f3ff,stroke:#1d70b8,color:#0b0c0c,font-size:14px;\n  classDef CLAAUDIA fill:#ffe5b4,stroke:#ff9900,color:#0b0c0c,font-size:14px;\n  classDef Completed fill:#66ff66,stroke:#006600,color:#0b0c0c,font-size:14px;\n\n  %% Assign classes\n  class A,B,D User;\n  class C,E CLAAUDIA;\n  class F Completed;</code></pre> <p>Note:  As project applicant you will be the Principal Investigator for the project, and you should be aware of your roles and responsibilities.</p>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#providers","title":"Providers","text":"<p>Level 2 and 3 data must only be handled on SDU/K8s provider hardware. For more information about the differences between providers, see the provider page.</p>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#data-classification-on-ucloud","title":"Data classification on UCloud","text":"<ul> <li>On Ucloud you can work with level 1,2 and 3 categories of data form AAUs data classification model.</li> <li>Store all project data in a designated project folder labeled according to its data sensitivity, following the AAU Data Classification Model. This folder must be labeled according to its data sensitivity, following the AAU Data Classification Model. The equivalent UCloud classifications are:<ul> <li>AAU Level 1  \u2192 UCloud: Inherit</li> <li>AAU Level 2  \u2192 UCloud: Private/Confidential</li> <li>AAU Level 3  \u2192 UCloud: Sensitive</li> <li>AAU Level 4  \u2192 Not allowed (Sensitive data can only be added to registered and approved project folders and must NOT be placed in My Workspace.)</li> </ul> </li> </ul>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#sensitive-data-only-allowed-in-dedicated-projects","title":"Sensitive data only allowed in dedicated projects","text":"<p>Sensitive data may only be handled within a dedicated UCloud research project and must never be stored or processed inside your personal \"My Workspace.\" This ensures that all sensitive data is properly registered, tracked, and linked to a project with a workzone number for compliance.</p> <p></p>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#creating-a-sensitive-folder-on-ucloud","title":"Creating a sensitive folder on UCloud","text":"<p>Best practice for handlig sensitive data on UCloud require you to mark the folder with the data \"sensitive\" You can do this by going to your files and right-click on the folder select Change sensitivity.</p> <p></p> <p>Now click the dropdown and select *sensitive\" and write the reason for the sensitivity change. </p> <p></p>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#collaboration-within-ucloud-projects-aau-members","title":"Collaboration within UCloud projects (AAU Members)","text":"<ul> <li>Only individuals registered with the department of Grants and Contracts or those included via an approved data processing agreement may be added to UCloud projects.</li> </ul>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#collaboration-with-external-partners-non-aau-members","title":"Collaboration with external partners (Non-AAU Members)","text":"<ul> <li>The external collaborator\u2019s employer must have a Data Processing Agreement with SDU (who hosts UCloud through DeiC Interactive HPC), or there must be an Agreement on Joint Data Controlling. In such cases, AAU will be responsible for the data processing agreement with SDU/DeiC.  </li> <li>If no such agreement exists, the collaborator cannot be invited to the UCloud project folder.</li> <li>No individual who is not covered by the relevant agreements may be added to the project.</li> </ul>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#setting-ucloud-project-roles-and-permissions","title":"Setting UCloud project roles and permissions","text":"<ul> <li>Project Admins can view all member files by enabling the \u201cshow member files\u201d option.</li> <li>The Principal Investigator is responsible for ensuring all roles and responsibilities are correctly assigned. Detailed guidance on roles can be found here.</li> </ul>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#managing-read-and-write-access","title":"Managing read and write access","text":"<ul> <li>To assign specific read or write permissions:</li> <li>Create a new \"Drive\" within the project (as drives are the only entities where you can assign specific permissions).</li> <li>Only Project Admins can create new drives.</li> <li>Name the drive, then modify its permissions by clicking the \u201c\u2026\u201d button. Set permissions as either None / Read / Write.</li> </ul>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#applications","title":"Applications","text":"<ul> <li>It is not allowed to add a public link when running applications with data classified as level 2 and 3. </li> </ul>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#guides","title":"Guides","text":"<ul> <li>When using our guides, please check the \"Approved Data Classification Level\" icons at the top of each guide to ensure it is approved for sensitive data.</li> </ul>"},{"location":"ucloud/guides/sensitive-data-on-ucloud/#completing-a-project","title":"Completing a Project","text":"<ul> <li>Upon project completion:</li> <li>Store all completed datasets and metadata in a data repository according to AAU's Research Data Management Policy. You can find more information about out local archiving solution: DataDeposit </li> <li>Delete all data from the UCloud platform.</li> </ul> <ul> <li>Permanently delete any files in trash folders.</li> </ul>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/","title":"How to Connect Neo4j to VS Code on UCloud","text":""},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#overview","title":"Overview","text":"<p>This solution demonstrates how to harness UCloud aau/k8's internal networking to create a robust, distributed architecture. By connecting two instances, you can run a dedicated Neo4j database server on one instance while running your applications (LangGraph, LangChain, and LLM) on another instance. This approach gives you the best of both worlds: persistent, reliable database storage and flexible, scalable application deployment.</p> <p>Universal application: While this guide uses Neo4j as an example, the same connection procedure applies to many other services such as PostgreSQL, MySQL, Redis, MongoDB or any application that needs to communicate between UCloud instances.</p>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to UCloud with AAU/K8 instances</li> <li>Both instances should be in the same UCloud project for network access</li> </ul>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#step-by-step-solution","title":"Step-by-Step Solution","text":""},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#step-1-start-neo4j-server","title":"Step 1: Start Neo4j Server","text":"<ol> <li>Start your Neo4j server instance on UCloud</li> <li>Choose an appropriate instance size for your database needs</li> </ol>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#step-2-open-the-terminal-and-install-required-tools","title":"Step 2: Open the terminal and install required tools","text":"<pre><code># Update package lists\nsudo apt update\n</code></pre> <pre><code># Install iproute2 for network configuration\nsudo apt install iproute2\n</code></pre>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#step-3-find-your-instance-ip","title":"Step 3: Find Your Instance IP","text":"<pre><code># Find your instance's internal IP address\nip addr show | grep \"inet \" | grep -v 127.0.0.1\n</code></pre> <p>Look for a line like: <code>inet 10.14.11.155/32</code> - this is your internal IP address.</p>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#step-4-start-vs-code-and-connect","title":"Step 4: Start VS Code and Connect","text":"<ol> <li>Start VS Code on your application instance</li> <li>Activate \"connect jobs\" at the bottom by providing a host name and select the database server. </li> <li></li> </ol>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#step-5-connect-via-python-driver","title":"Step 5: Connect via Python Driver","text":"<p>Use the following Python code to connect to your Neo4j database:</p> <pre><code>from neo4j import GraphDatabase\n\n# Replace with your Neo4j instance's internal IP address\nuri = \"bolt://YOUR_INSTANCE_IP:7687\"\ndriver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"ucloud\"))\n\nwith driver.session() as session:\n    result = session.run(\"RETURN 1 AS test\")\n    for record in result:\n        print(record[\"test\"])\n</code></pre> <p>Important: Remember to change <code>\"bolt://YOUR_INSTANCE_IP:7687\"</code> to your actual IP address from the Neo4j server, and update the username and password if you have changed them.</p> <p>Example: If your Neo4j instance has the internal IP address <code>10.14.11.155/32</code>, your connection string would be: <pre><code>uri = \"bolt://10.14.11.155:7687\"\n</code></pre></p>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#troubleshooting","title":"Troubleshooting","text":"<p>If the connection doesn't work:</p> <ol> <li>Verify both instances are in the same UCloud project</li> <li>Check that Neo4j is running on the server instance</li> <li>Ensure the internal IP address is correct</li> <li>Test the connection with the provided Python code</li> <li>Make sure to start the instances in the correct order with Neo4j first and VS code afterwards.</li> </ol>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#benefits-of-this-approach","title":"Benefits of This Approach","text":"<ul> <li>Scalability: Run your database and applications on optimally-sized instances</li> <li>Reliability: Persistent database storage that survives instance restarts</li> <li>Flexibility: Easy to scale individual components without affecting others</li> <li>Performance: Dedicated resources for both database and application workloads</li> <li>Cost Efficiency: Optimize resource allocation for different types of workloads</li> </ul>"},{"location":"ucloud/guides/advanced-guides/connect-neo4j-to-vscode/#conclusion","title":"Conclusion","text":"<p>This setup demonstrates the power of UCloud's networking capabilities, enabling you to create sophisticated, distributed computing environments. By connecting two instances, you can build robust, scalable applications that leverage persistent databases while maintaining the flexibility to deploy and manage your workloads independently.</p> <p>Beyond Neo4j: The networking principles and connection procedures demonstrated in this guide are universal. Whether you're connecting to Neo4j, PostgreSQL, Redis, or any other service, the same approach applies. This makes UCloud an excellent platform for building complex, distributed architectures with any combination of databases, APIs, and applications.</p> <p>Note on Ports: Different applications use different default ports. For example, Neo4j uses port 7687, PostgreSQL typically uses port 5432, and Redis uses port 6379. You can find the specific port information for each application in the UCloud application documentation.</p>"},{"location":"ucloud/guides/application-guides/Dictaphone/","title":"Dictaphone","text":"Dictaphone <p>Approved for data classification level</p> 0 1 2      Technical specifications"},{"location":"ucloud/guides/application-guides/Dictaphone/#what-is-dictaphone","title":"What is Dictaphone?","text":"<p>Dictaphone is an application on UCloud designed to allow users to record audio using the microphone on their device; computer, a smartphone, or tablet (both Android and iOS). In addition, it is also possible to transcribe recordings directly utilising the embedded Transcriber functionality.</p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#handling-sensitive-data","title":"Handling sensitive data","text":"<p>Review UCloud guidelines:    Please make sure to review and follow our guidelines for handling sensitive data to ensure you understand how to work securely and meet all data protection requirements when using UCloud.</p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#1-using-the-dictaphone-application","title":"1. Using the Dictaphone application","text":""},{"location":"ucloud/guides/application-guides/Dictaphone/#11-finding-and-launching-the-application","title":"1.1 Finding and launching the application","text":"<ul> <li> <p>Go to the UCloud application page and use the search function to find Dictaphone.     </p> </li> <li> <p>Open the app by clicking on Dictaphone.</p> <p></p> </li> </ul>"},{"location":"ucloud/guides/application-guides/Dictaphone/#12-configuring-your-job","title":"1.2 Configuring your job","text":"<ul> <li> <p>Name your job: Choose a name that helps you identify the job later (e.g., \"Dictaphone Demo 1\").</p> <ul> <li>Note: Avoid special characters like \"!#&amp;\\$\".</li> </ul> </li> <li> <p>Hours: Specify how many hours you want the job to run. To avoid the job running out of time, choose more Hours than you estimate the recording will be.</p> <ul> <li>If you plan on using the direct transcriptions feature, then you also need to allocate time for that. For reference, a 1-hour audio typically takes about 1 hour to transcribe on a u1-standard-16 machine.</li> </ul> </li> <li> <p>Choose a machine: We recommend using u1-standard-16.</p> </li> <li> <p>Optional: Select folders to use. Here you can select the folder for your output </p> <ul> <li>Every time a new recording process is started (by adding and starting a new recording) a new folder is created, by default: 1_Recording_1, 2_Recording_2, and so on.</li> </ul> </li> </ul> <p></p> <ul> <li>Once you finish configuring, click Submit to start the Dictaphone job.</li> </ul> <p>After submitting your job, you'll be redirected to a new page where your Dictaphone machine is being prepared. Once it's ready, click the \"Open interface\" button to launch the Dictaphone application. - Note: It can take a couple of minutes to find a machine, so we recommend that you start the application some time before the actual recording.</p> <p></p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#13-recording-audio","title":"1.3 Recording Audio","text":"<p>To begin your recording, click on start recording. If you wish to create a new recording, click on the + symbol on the right.</p> <p></p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#14-recording-settings","title":"1.4 Recording settings","text":"<p>The Show settings button can be used to change the Microphone amplification level and boost the signal if the recording audio is too low. The microphone amplification level default is 1x, which means no amplification.</p> <p></p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#15-verification-of-recorded-data","title":"1.5 Verification of recorded data","text":"<p>When the Stop recording button is clicked the verification process is started. Once the recording is verified you can find your files in your UCloud project folder or begin the transcription process directly in the application.</p> <p>Under normal circumstances the verification status will be VERIFIED, but in case of client disconnection, server disconnection or loss of data packets the status may be different.</p> <p>The possible statuses are:</p> <ul> <li> <p>VERIFIED     This is the normal verification status.</p> </li> <li> <p>INTERRUPTED, VERIFIED     If the client disconnects during recording, e.g.\u00a0if the user closes the     browser window during recording, then the server will check that there     is no missing data up until that point.</p> </li> <li> <p>INTERRUPTED     If the server is unexpectedly stopped during recording, then an error     message will be shown instantly in the user interface. The recorded data     can still be found on the server, but since the server was shut down the     verification process will not be completed.</p> </li> <li> <p>DATA LOSS     This verification status means that the server detected missing data,     which could not be acquired from the client during the verification     process. In practice this is extremely unlikely, since the application     is designed to use request/resend of missing data both during recording     and in the verification process.</p> </li> </ul> <p></p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#16-transcription","title":"1.6 Transcription","text":"<p>To start a transcription of the recorded audio, click the Transcribe recording button like shown below.</p> <p></p> <p>The transcribed files will be available in your UCloud project folder and can also be downloaded directly from the application.</p> <ul> <li>Note: If you are working with confidential or sensitive data, remember that you may not download it directly to any personal or nonapproved devices.</li> </ul> <p></p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#17-transcription-settings","title":"1.7 Transcription settings","text":"<p>Transcription settings can be accessed by clicking on the Show settings button below the recording section. By default, the model choice is large-v3 and the language choice is Automatic. Using a smaller model will speed up the transcription at the cost of lower accuracy.</p> <p></p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#18-starting-the-dictaphone-from-a-mobile-device","title":"1.8 Starting the Dictaphone from a mobile device","text":"<p>This section has a few tips for starting the application from the UCloud interface. When selecting the UCloud workspace and machine type it will make the user experience better to use one of the following options.</p> <ul> <li>Tilt the mobile screen on the side. When using the Dictaphone application tilt the screen back to the original orientation.</li> <li>Use the Desktop site setting in Chrome (or equivalent) for the UCloud main site (see figure below).</li> </ul> <p></p>"},{"location":"ucloud/guides/application-guides/Dictaphone/#19-closing-the-application","title":"1.9 Closing the application","text":"<p>When you are finished using Dictaphone, remember to close the application on UCloud, so it does not continue consuming your resources.</p> <p></p>"},{"location":"ucloud/guides/application-guides/Voyant-Tools/","title":"Voyant Tools","text":"Voyant Tools <p>Approved for data classification levels</p> 0 1 2      Technical specifications    <p>Voyant is a text reading and analysis environment. It is possible to work with one or more texts in a variety of formats. </p>"},{"location":"ucloud/guides/application-guides/Voyant-Tools/#1-using-the-voyant-application","title":"1. Using the Voyant application","text":""},{"location":"ucloud/guides/application-guides/Voyant-Tools/#11-finding-the-application","title":"1.1 Finding the application","text":"<ul> <li>Click on the applications button   </li> </ul> <ul> <li>Click on search </li> </ul> <ul> <li>Search \u201dVoyant\u201d </li> </ul> <ul> <li>Click on Voyant</li> </ul>"},{"location":"ucloud/guides/application-guides/Voyant-Tools/#12-using-the-application","title":"1.2 Using the application","text":"<p>You should now see the following screen:</p> <p></p> <p></p> <p></p> <p>There are several options here, and it can seem overwhelming. For this example, we\u2019ll walk through the quickest way to start the app.</p>"},{"location":"ucloud/guides/application-guides/Voyant-Tools/#121-choose-a-name-for-your-job","title":"1.2.1 Choose a name for your job","text":"<ul> <li>Pick a name that makes it easy to find your work later and distinguish between different jobs</li> <li>Write the name under \u201cJob Name\u201d.</li> <li>Example: \"Voyant_demo1\". Note: Job and file names cannot include special characters such as \"\u00e6\u00f8\u00e5\".</li> </ul>"},{"location":"ucloud/guides/application-guides/Voyant-Tools/#122-select-the-duration-of-your-job","title":"1.2.2 Select the duration of your job","text":"<ul> <li>Select the duration of your job and enter the number under \u201cHours\u201d</li> <li>You need to estimate for how long time you will need to use the app. The application can take some time to show results, because it analyzes all text before showing you, afterwards you can edit what types of reading or analysis you will receive.</li> </ul> <p>Note: If you run out of allocated time, the application still shows the results, but you cannot use the functions or make any changes. You can allocate more time after starting the job if needed.</p>"},{"location":"ucloud/guides/application-guides/Voyant-Tools/#123-pick-a-machine-to-use","title":"1.2.3 Pick a machine to use","text":"<ul> <li>We recommend the u1-standard-1.</li> </ul> <p>Feel free to test what works best for you.</p> <p></p> <p>Now, you are ready to begin your work. Click Submit to start the process.</p> <p></p> <p></p> <p></p> <ul> <li>Click on \u201cOpen interface\u201d and the application will open. </li> </ul> <p>Note: There can be waiting time before the interface is ready for you. Just wait until it looks like this: </p> <p></p> <p></p> <p></p> <p>Now the application pops up in a new window and you can upload the files you would like to work on. The entire text collection you are working on is called corpus in the application. </p> <p>There are three main ways of selecting a corpus in Voyant Tools:</p> <ol> <li>Type or paste into the main text area.</li> <li>Insert a URL link to a webpage, one per line. </li> <li>Upload one or more files from your computer. </li> <li>Click on \u201copen\u201d if you want to use the pre uploaded texts (Frankenstein or novels by Jane Austin)  </li> </ol> <p>The upload file selector should allow you to choose one or more files using Ctrl and Shift keys. If you have several documents to add at once, it may be easiest to first create a zip archive containing the files and then upload the one zip file.</p> <p>It is possible to work on one or more files and have combination of files and webpages. </p> <ul> <li>Press \u201cReveal\u201d when you have all the texts for the corpus. </li> </ul> <p></p> <p></p> <p></p> <p>It can take some time for the application to read the corpus. Once the corpus is read you will be presented with the default skin. There are many more types of</p> <p></p> <p></p> <p></p> <p>You can choose other options of analysis here. The options are visible when you place the curser in the top bar of the analysis next to the questionmark.  </p> <p></p> <p></p> <p></p> <p>Here\u2019s a link to the different type of analysis called \u201cskins\u201d  Click Here</p> <p>You can edit the list of \u201cstopwords\u201d so the tools will not include the stopwords. Click on \u201cDefine options for this tool\u201d </p> <p></p> <p></p> <p></p> <p>Options pops up. Click on \u201cEdit List\u201d next to \u201cStopwords\u201d </p> <p></p> <p></p> <p></p> <p>Now you can add the words you don\u2019t want to see in your research, one term per line</p> <p></p> <p></p> <p></p> <p>Click \"Save\" and then \"Confirm\" in options</p>"},{"location":"ucloud/guides/application-guides/ChatUI/","title":"ChatUI","text":"ChatUI <p>Approved for data classification level</p> 0 1 2 3      Technical specifications"},{"location":"ucloud/guides/application-guides/ChatUI/#introduction","title":"Introduction","text":"<p>ChatUI on UCloud is an intuitive application designed for working with large language models (LLMs). This guide will walk you through the process of setting up, configuring, and effectively using ChatUI. It covers both personal use\u2014where ChatUI can handle sensitive data securely\u2014and shared use, where you can provide multiple users access via a public link, making it ideal for teaching or similar collaborative scenarios.</p>"},{"location":"ucloud/guides/application-guides/ChatUI/#configuring-the-chatui-application","title":"Configuring the ChatUI application","text":""},{"location":"ucloud/guides/application-guides/ChatUI/#1-create-a-data-directory","title":"1. Create a data directory","text":"<p>To save configurations and avoid repeated setups, create an empty folder on your drive in UCloud. This folder will later be used as the input parameter <code>DATA_DIR</code> . </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#2-find-and-start-the-chatui-application","title":"2. Find and start the ChatUI application","text":"<p>Search for \"chatui\" under the apps section of UCloud and select it to begin setup. </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#3-select-the-optimal-machine-configuration","title":"3. Select the optimal machine configuration","text":"<p>Choose a machine with one GPU, such as <code>u3-GPU</code> (SDU) or <code>uc1-l4</code>/<code>uc1-l40</code> (AAU/K8). Set the runtime duration in hours and select the previously created folder as <code>DATA_DIR</code>. </p> ChatUI public link for sharing with user outside UCloud <p>Note applying a public link will decrease the approved sensitivity level to only   1 </p> <p>To enable access outside UCloud, scroll down and click \"Add Public Link.\" Create a link within the same provider as the machine (<code>SDU</code> or <code>AAU/K8</code>) in this example we use the <code>AAU/K8</code>.   </p> <p>Once the link is created, click \"Use.\" This will generate a URL to access the application. </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#4-launch-the-application","title":"4. Launch the application","text":"<p>Click the green \"Submit\" button at the top of the page to start the application. After launching, wait for the application to build and then click \"Open Interface\" to access ChatUI. Refresh the page if it doesn't load. </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#5-set-up-admin-and-user-roles","title":"5. Set up admin and user roles","text":"<p>The next step is to create an account by clicking \"Sign Up.\" Enter your name, email, and password, then click \"Create Account.\" The first user (you) will automatically be assigned the admin role. </p> How to give access to other users <p>There are two options for allowing other users to access the ChatUI interface. 1. Enable the \"Allow New Sign-Ups\" option in the settings panel. This allows new users to apply for an account, which you can then review and approve.      </p> <p>2. Create a dedicated account for each user through the settings menu, as shown below. Ensure that new users are assigned the appropriate role \u2014 either \"User\" or \"Admin\"\u2014to maintain control over the application settings.  </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#6-download-and-manage-models","title":"6. Download and manage models","text":"<p>Go to Adminstrationpanel &gt; Settings &gt; Models to download models. If you\u2019re unsure of the model name, use the provided link to explore available options. For example, type \"llama3\" or \"mistral:7b\" and click the download button. </p> <p>Once downloaded, the model will appear in the Workspace under the Models section. By default, the model is only visible to the person who downloads it. To make the model accessible to all users, click on the model name, change the visibility to \"Public,\" and press Save.  </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#7-set-up-a-knowledge-base-for-rag-functionality","title":"7. Set up a knowledge base for RAG functionality","text":"<p>In the Knowledge section, you can create a knowledge base to upload documents for retrieval-augmented generation (RAG). </p> <p>Provide a name and description for the knowledge base, and select the visibility for other users. Afterwards you can upload documents or directories to the knowledge base. </p> <p></p> <p>Note: It may take some time for larger documents to be uploaded.</p>"},{"location":"ucloud/guides/application-guides/ChatUI/#using-chatui-for-inference","title":"Using ChatUI for inference","text":""},{"location":"ucloud/guides/application-guides/ChatUI/#1-start-a-new-chat","title":"1. Start a new chat","text":"<p>Click \"New Chat\" in the upper-left corner. Select the downloaded model (e.g., llama3) from the dropdown. Use <code>#</code> in the prompt input field to reference the knowledge base. </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#2-submit-queries-and-view-responses","title":"2. Submit queries and view responses","text":"<p>Type a query in the input field. Responses will indicate the source document used in the reply. </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#reusing-configurations","title":"Reusing configurations","text":"<p>Next time you want to use the same settings: 1. Click Import parameters on the app start page. 2. Import the configuration from the previous session. 3. Click \"Submit\" to relaunch the app. </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#faq","title":"FAQ","text":""},{"location":"ucloud/guides/application-guides/ChatUI/#1-why-does-the-first-response-take-longer-to-complete","title":"1. Why does the first response take longer to complete?","text":"<p>The model needs to load into memory before processing queries. Subsequent responses will be faster.</p>"},{"location":"ucloud/guides/application-guides/ChatUI/#2-why-is-there-no-response-to-my-first-query","title":"2. Why is there no response to my first query?","text":"<p>The model might not be fully loaded. Click \"Edit,\" then \"Save,\" and resend the query. Alternatively, monitor the log file <code>ollama-log.txt</code> to confirm the model is ready. </p>"},{"location":"ucloud/guides/application-guides/ChatUI/#3-how-to-extend-server-runtime","title":"3. How to extend server runtime?","text":"<p>Locate your server in UCloud\u2019s recent runs tab, select the instance, and add more time using the +1, +8, or +24-hour buttons.</p>"},{"location":"ucloud/guides/application-guides/ChatUI/#4-how-to-stop-the-server","title":"4. How to stop the server?","text":"<p>In the recent runs tab, select the server and click \"Stop application.\" Confirm the shutdown to free resources and avoid unnecessary costs.</p>"},{"location":"ucloud/guides/application-guides/ChatUI/#5-why-is-shutting-down-the-server-important","title":"5. Why is shutting down the server important?","text":"<ul> <li>Cost management: Servers consume resources billed by the hour.  </li> <li>Resource allocation: Free up resources for other users or projects.</li> </ul>"},{"location":"ucloud/guides/application-guides/ChatUI/#6-what-to-do-if-i-cannot-start-a-server-due-to-not-enough-credits","title":"6. What to do if I cannot start a server due to \"not enough credits\"?","text":"<p>Check if you\u2019re in the correct project. If resources are depleted, apply for more using the designated application form.</p>"},{"location":"ucloud/guides/application-guides/ChatUI/#7-what-does-job-is-unavailable-mean","title":"7. What does \"Job is unavailable\" mean?","text":"<p>This error appears if the server isn't ready. Wait 30 seconds and try \"Open Interface\" again.</p>"},{"location":"ucloud/guides/application-guides/transcriber/","title":"Transcriber","text":"Transcriber <p>Approved for data classification level</p> 0 1 2      Technical specifications    <p>New feature: Transcribe and stop</p> <p>Transcribe and stop is a new option in the Transcriber interface application that automatically stops the job once all selected files have been transcribed. Enabling this setting saves compute resources by ensuring the job only runs while actual transcription is taking place\u2014making your allocation more efficient and freeing up resources so you can complete more transcriptions overall.</p> <ul> <li>How it works: When this feature is enabled, the job will finish and automatically shut down as soon as all transcriptions are complete.</li> <li>Access your results: Your transcribed files are always available in the UCloud filesystem, either in the job folder or in your chosen output folder at startup.</li> </ul>"},{"location":"ucloud/guides/application-guides/transcriber/#what-is-transcriber","title":"What is Transcriber","text":"<p>Transcriber is an application on UCloud designed to automatically convert audio and video files into accurate, readable text. It leverages advanced speech recognition models to transcribe spoken content, making it easier to analyze, search, and share information from interviews, lectures, meetings, podcasts, and other recordings. Transcriber helps researchers save time and effort by providing fast, reliable transcriptions directly within the secure UCloud platform \u2014 no technical expertise required. Whether you need simple text output or more advanced features like speaker identification and multiple file formats, Transcriber streamlines the process of turning your recordings into useful, accessible documents.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#handling-sensitive-data","title":"Handling sensitive data","text":"<p>Review UCloud guidelines:    Please make sure to review and follow our guidelines for handling sensitive data to ensure you understand how to work securely and meet all data protection requirements when using UCloud.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#which-transcriber-should-i-use","title":"Which Transcriber should I use?","text":"<p>There are two ways to use Transcriber on UCloud:</p> Interface (Default) Batch Simple, modern screen with buttons No screen, just settings interface Designed for most users Designed for advanced users and batch jobs Add files by drag and drop from computer or UCloud folders Add files from UCloud folders only Download results from the app or UCloud folders Download results from UCloud folders Basic settings: language and model selection Advanced settings: language, model, number of speakers, and merge speaker entries <p>Select the guide of your choice below for step-by-step instructions for each version.</p> Transcriber Interface (Default version)Transcriber Batch <p> This guide will walk you through using the latest default version of Transcriber, featuring an improved, user-friendly interface for transcribing your audio and video files on UCloud.</p> <p> This guide provides step-by-step instructions for using the Transcriber Batch application, which offers advanced configuration options and is optimized for efficient, large-scale transcription tasks.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#1-using-the-transcriber-default-interface-application","title":"1. Using the Transcriber default (Interface) application","text":""},{"location":"ucloud/guides/application-guides/transcriber/#11-finding-and-launching-the-application","title":"1.1 Finding and launching the application","text":"<ul> <li> <p>Go to the UCloud application page and use the search function to find Transcriber. </p> </li> <li> <p>Open the app by clicking on Transcriber. </p> </li> </ul>"},{"location":"ucloud/guides/application-guides/transcriber/#12-configuring-your-job","title":"1.2 Configuring your job","text":"<ul> <li>Name your job: Choose a name that helps you identify the job later (e.g., \"Transcriber Demo 1\").</li> <li> <p>Note: Avoid special characters like \"\u00e6\u00f8\u00e5\".</p> </li> <li> <p>Set the duration: Specify how many hours the job should run. For reference, a 1-hour audio typically takes about 1 hour to transcribe on a <code>u1-standard-16</code> machine.</p> <ul> <li>You can stop the machine early or add more time later if needed.</li> </ul> </li> <li> <p>Choose a machine: We recommend u3-gpu-1 if available, otherwise use u1-standard-16.</p> </li> <li> <p>(Optional) Select folders to use: If you want to use UCloud folders, select the folder(s) containing your files.</p> </li> <li> <p>The app will scan these folders for compatible files.     &gt; Note: Folders named <code>UPLOADS</code> and <code>COMPLETED</code> are reserved by the app and won't be scanned.</p> </li> <li> <p>Once you finish configuring, click Submit to start the Transcriber job.</p> </li> </ul> <p></p> <p>After submitting your job, you'll be redirected to a new page where your Transcriber machine is being prepared. Once it's ready, click the Open interface button to launch the Transcriber application.</p> <p></p>"},{"location":"ucloud/guides/application-guides/transcriber/#13-adding-files-to-be-transcribed","title":"1.3 Adding files to be transcribed","text":"<p>Once the app starts, decide how you want to add files for transcription. You have two main options:</p> <ul> <li> <p>Use files from UCloud folders</p> <ul> <li>If you selected folders in the launch step, the app will automatically list the files detected there.</li> <li>Choose the files you want and click Add UCloud files to add them to your transcription queue.</li> <li>If you add new files to the folder after the job has started, click Scan UCloud folder to refresh the list. <p>Note: This section is only visible if you selected a folder when launching your Transcriber job on UCloud.</p> </li> </ul> </li> <li> <p>Upload files from your computer</p> <ul> <li>Drag and Drop your files directly into the upload area of the Transcriber app.</li> <li>Or click the upload area to browse your computer and select files.</li> <li>Multiple files can be added at once.</li> </ul> </li> </ul> <p>Info: The app can only process <code>.mp3</code>, <code>.mp4</code>, <code>.m4a</code>, <code>.wav</code>, and <code>.mpg</code> files. If your file is in another format, we recommend using VLC to convert it. VLC can be downloaded from the Software Center/Company Portal.</p> <p> </p>"},{"location":"ucloud/guides/application-guides/transcriber/#14-starting-the-transcription","title":"1.4 Starting the transcription","text":"<ul> <li>Once you have added all your desired files to the transcription queue, click Start Transcription.</li> <li>The app will begin transcribing your files and show a progress bar so you can track the transcription status in real time.     &gt; Note: The progress bar provides an estimated completion time for each file, but this estimate may change as the transcription proceeds. Factors such as the selected machine, the amount of speech in the audio, and the selected transcription model can affect how long each file takes.</li> </ul>"},{"location":"ucloud/guides/application-guides/transcriber/#15-downloading-your-transcriptions","title":"1.5 Downloading your transcriptions","text":"<ul> <li>While the job is running: You can download completed transcriptions directly from the app, either one by one or as a zip file. When downloading individual files, you can select your preferred output format (TXT, DOCX, VTT, etc.). If you choose to download as a zip file, you'll receive all available output formats for each transcription. <ul> <li>Important: If you are working with confidential or sensitive data, remember that you may not download it directly to any personal or nonapproved devices.</li> </ul> </li> </ul> <p>Note: For better readability and to save time on post-processing, you can download a merged speaker format of the transcription that combines consecutive text entries from the same speaker into natural, flowing sentences. This feature helps streamline your workflow by reducing the need for manual text editing.  </p> <ul> <li>After the job is finished: All transcriptions will be available on UCloud in the folder: <code>/Jobs/Transcriber/&lt;job-id&gt;/TRANSCRIPTIONS/</code>.</li> </ul>"},{"location":"ucloud/guides/application-guides/transcriber/#16-optional-adjusting-settings","title":"1.6 Optional: Adjusting settings","text":"<ul> <li> <p>Click Show settings at the top of the page to adjust:</p> </li> <li> <p>New feature: Transcribe and stop This setting allows the job to stop automatically once all selected files have been transcribed. Enabling this option is highly efficient in terms of compute hours allocated to your project, as the job remains active only while work is being performed. As always, the transcribed files can be found in the UCloud filesystem, either in the job folder or in the folder selected at startup.</p> </li> <li> <p>The transcription model (default is \"large-v3\").</p> </li> <li>The language (default is \"Automatic\"). <p>Note: If you're unsure, the default settings are usually best.</p> </li> </ul> <p>Need more advanced options? Try the Transcriber batch version, which offers extended configuration possibilities.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#1-using-the-transcriber-batch-application","title":"1. Using the Transcriber batch application","text":""},{"location":"ucloud/guides/application-guides/transcriber/#11-finding-the-application","title":"1.1 Finding the application","text":"<ul> <li>Go into the application and use the search function to find Transcriber.</li> </ul> <ul> <li>Click on Transcriber.</li> </ul>"},{"location":"ucloud/guides/application-guides/transcriber/#12-using-the-application","title":"1.2 Using the application","text":"<p>You should now see the following screen:</p> <p></p> <p>There are several options here, and it can seem overwhelming. For this example, we'll walk through the quickest way to start a transcription.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#121-choose-a-name-for-your-job","title":"1.2.1 Choose a name for your job","text":"<ul> <li>Pick a name that makes it easy to find your data later and distinguish between different jobs.</li> <li>Example: \"Transcriber demo 1\".</li> </ul> <p>Note: Job and file names cannot include special characters such as \"\u00e6\u00f8\u00e5\".</p>"},{"location":"ucloud/guides/application-guides/transcriber/#122-select-the-duration-of-your-job","title":"1.2.2 Select the duration of your job","text":"<ul> <li>The application can transcribe in 1:1 time. For instance, a 1-hour audio file will take approximately 1 hour to transcribe.</li> <li>We recommend allocating double the length of the audio file to avoid interruptions.</li> <li>Example: For a 1-hour audio file, allocate 2 hours.</li> </ul> <p>Note: If you run out of allocated time, the file being transcribed will fail. You can allocate more time after starting the job if needed.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#123-pick-a-machine-to-use","title":"1.2.3 Pick a machine to use","text":"<ul> <li>We recommend the u3-gpu-1 machine, which performed best in our tests. If the option is unavailable we recommend the u1-standard-16 as an alternative.</li> </ul> <p>Feel free to test with sample files to see what works best for you.</p> <p></p>"},{"location":"ucloud/guides/application-guides/transcriber/#124-select-the-input-file","title":"1.2.4 Select the input file","text":"<ul> <li>Click the \"use\" button.</li> </ul> <ul> <li>Click the text box to select your file.</li> </ul> <ul> <li>Navigate to your \"drives\" and select the folder with your file or click \"use\" if it's already listed.</li> </ul> <p>Note: The app can only process <code>.mp3</code>, <code>.mp4</code>, <code>.m4a</code>, <code>.wav</code>, and <code>.mpg</code> files. If your file is in another format, we recommend using VLC to convert it. VLC can be downloaded from the Software Center/Company Portal.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#125-select-the-output-directory","title":"1.2.5 Select the output directory","text":"<ul> <li>Choose where your output will be saved.</li> <li>Click \"use\" on \"option: --output_dir\".</li> </ul> <ul> <li>Select the folder you want for your transcription output.</li> </ul> <p>Note: The app supports <code>.mp3</code>, <code>.mp4</code>, <code>.m4a</code>, <code>.wav</code>, and <code>.mpg</code> files. For other formats, consider converting using VLC.</p> <p>Now, you are ready to begin your transcription. Click Submit to start the process.</p> <p>There are additional options available. These are covered in the \"Other Options\" section.</p> <p></p> <p>Once the process starts, you can close your computer. If you want to ensure everything is running smoothly, wait until a \"node\" is assigned. Your screen will look like this:</p> <p></p> <p>Once the transcription is complete, you will see the following screen:</p> <p></p> <p>Note: This is not the actual output of your transcription. The transcription files are located in the folder you selected for output. You\u2019ll find something like this:</p> <p></p>"},{"location":"ucloud/guides/application-guides/transcriber/#13-transcription-output-formats","title":"1.3 Transcription output formats","text":"<p>You will have several different files with your transcription. Commonly used formats include <code>.txt</code> and <code>.docx</code>. You can choose the format that suits your needs best. If you want a specific output format, refer to the \"output_format\" section under \"Other Options\".</p> <p>Note: It is not possible to preview <code>.docx</code> files directly within UCloud. To view the transcription in <code>.docx</code> format, you must first download the file to your own computer and open it with Microsoft Word or another compatible program.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#2-optional-parameters","title":"2. Optional parameters","text":""},{"location":"ucloud/guides/application-guides/transcriber/#21-option-output_format","title":"2.1 Option: --output_format","text":"<p>By default, the application produces all 8 formats. You can limit the output to a specific format by selecting one of the following:</p> <ul> <li>CSV: Contains all parameters outputted from the Whisper model.</li> <li>SRT: SubRip file format, a widely adopted subtitle format.</li> <li>TXT: Pure text file with the transcription.</li> <li>VTT: Web Video Text Tracks format, includes timestamps.</li> <li>JSON: JavaScript Object Notation.</li> <li>TSV: Tab-separated values file containing start, end, and text.</li> <li>DOTE: Transcription software developed by the BigSoftVideo team at AAU.</li> <li>DOCX: Text file with transcription and speaker recognition.</li> </ul>"},{"location":"ucloud/guides/application-guides/transcriber/#22-option-output_model","title":"2.2 Option: --output_model","text":"<p>Select the model size:</p> <ul> <li>Small: Faster but less accurate.</li> <li>Medium: Slightly slower, more accurate.</li> <li>Large: Most accurate but slowest.</li> </ul> <p>The default is Large. With a machine featuring 16 vCPUs and 96GB of memory, transcription speed is about the same as the audio length (e.g., 1 minute of audio takes approximately 1 minute to transcribe).</p>"},{"location":"ucloud/guides/application-guides/transcriber/#23-option-output_language","title":"2.3 Option: --output_language","text":"<p>Specify the language for transcription. The Whisper model can detect and automatically choose the language. If you select a language manually, the model will translate audio into that language.</p> <p>Note: The detected or chosen language determines the output language. For example, if the chosen language is English, the model will translate multiple languages into English.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#24-interactive-mode","title":"2.4 Interactive mode","text":"<p>Enable interactive mode for access to the app terminal or a web interface. The web interface includes a JupyterLab workspace for working with notebooks.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#25-archive-password","title":"2.5 Archive password","text":"<p>Encrypt and password-protect the ZIP output archive. Specify a password for the archive as a text string.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#26-minimum-and-maximum-number-of-speakers","title":"2.6 Minimum and maximum number of speakers","text":"<p>Specify the number of speakers to improve speaker diarization accuracy in some cases.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#27-merge-consecutive-text-entries-from-the-same-speaker-recommended","title":"2.7 Merge consecutive text entries from the same speaker (Recommended)","text":"<p>This option combines consecutive text entries from the same speaker into a single block, improving readability.</p> <ul> <li>When enabled, the app generates additional files with merged text in docx, dote, json, and csv formats. These files are named <code>filename_merged</code> and are created alongside the original files.</li> </ul> <p>To make the option visible, scroll down in the optional parameter window.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#need-assitance","title":"Need assitance?","text":"<p>Reachout to CLAAUDIA at https://serviceportal.aau.dk.</p>"},{"location":"ucloud/guides/application-guides/transcriber/#who-made-it","title":"Who made it?","text":"<p>Research &amp; development by</p> <ul> <li>CLAAUDIA, ITS, AAU </li> </ul> <p>With support from</p> <ul> <li>DeiC (The Danish e-Infrastructure consortium)</li> <li>Aalborg University</li> <li>University of Southern Denmark</li> <li>Aarhus University</li> <li>Center for Humanities Computing</li> </ul> <p>Citation</p> <p>CLAAUDIA, ITS, AAU (2024). Transcriber (Version1.0) [App]. UCloud interactive HPC system, eScience Center at the University of Southern Denmark. https://cloud.sdu.dk/app/jobs/create?app=transcriber&amp;version=1.7  </p>"},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/","title":"Transcriber","text":"<p>Approved for data classification level</p> <p> 0 1 2 </p> <p>Transcriber is an app for transcribing audio into text. Many apps can do this, but like it\u2019s sister transcription app, Whisper, Transcriber is a little different in a big way. Located on UCloud on the DeiC Interactive HPC it can handle sensitive data.\u202fTranscriber is developed to support features not available with the Whisper-based technology, such as speech recognition. Transcriber is available for everyone with access to UCloud.\u202f</p> <p>Download transcriber user guide (PDF)</p>"},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#video-guide","title":"Video guide","text":""},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#introduction-to-transcriber-17","title":"Introduction to Transcriber (1/7)","text":""},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#transcriber-working-with-sensitive-data-on-ucloud-deic-interactive-hpc-27","title":"Transcriber - Working with sensitive data on UCloud (DeiC Interactive HPC) (2/7)","text":""},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#transcriber-logging-in-to-ucloud-return-mail-37","title":"Transcriber - Logging in to UCloud + return mail (3/7)","text":""},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#transcriber-requesting-resources-for-ucloud-47","title":"Transcriber - Requesting resources for UCloud (4/7)","text":""},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#transcriber-create-folder-and-chose-classification-57","title":"Transcriber - Create folder and chose classification (5/7)","text":""},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#transcriber-upload-files-set-up-and-run-job-67","title":"Transcriber - Upload files, set up, and run job (6/7)","text":""},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#transcriber-reading-your-results-77","title":"Transcriber - Reading your results (7/7)","text":"<p>Feedback is appreciated</p> <p>Transcriber is still under development and getting new features. Please give us your feedback via the AAU service portal.</p>"},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#sensitive-data","title":"Sensitive data?","text":"<p>For employees at AAU:</p> <p>When working on the UCloud platform, the department of Grants and Contracts at AAU has determined that personal data must be handled inside of the Project environment. The Project environment is only available for employees at AAU.  </p> <p>If your audio files do not contain personal data, then you can simply use your \u201cMy workspace\u201d environment.\u200b</p> <p>All projects with sensitive data must include the following two project numbers:</p> <ol> <li>A project reference number from Grants and Contracts</li> <li>A DeiC Interactive HPC project number from CLAAUDIA</li> <li>How to get these numbers is described here.</li> </ol> <p>UCloud\u2019s data classification maps to the AAU data classification model in the following way:\u200b</p> <ul> <li>AAU Level 1  \u2192 UCloud: Inherit<ul> <li>AAU Level 2  \u2192 UCloud: Private/Confidential</li> <li>AAU Level 3  \u2192 UCloud: Sensitive (Only permitted to be added to your registered and approved project folder.) Sensitive data may NOT be added to My Workspace.</li> <li>AAU Level 4  \u2192 Not allowed </li> </ul> </li> </ul>"},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#news-and-key-features","title":"News and key features","text":"<p>Transcriber stands on the shoulders of the Whisper Transcription app and has additional features such as:</p> <p>Version 1.5</p> <ul> <li>Multiple speaker recognition</li> <li>Merge consecutive speaker entries </li> </ul>"},{"location":"ucloud/guides/application-guides/transcriber/transcriber-video/#who-made-it","title":"Who made it?","text":"<p>Research &amp; development by</p> <ul> <li>Nikolaj Andersen, CLAAUDIA, ITS, AAU </li> <li>Pelle Rosenbeck G\u00f8eg, CLAAUDIA, ITS, AAU </li> </ul> <p>With support from</p> <ul> <li>DeiC (The Danish e-Infrastructure consortium)</li> <li>Aalborg University</li> <li>University of Southern Denmark</li> <li>Aarhus University</li> <li>Center for Humanities Computing</li> </ul> <p>Citation</p> <p>Andersen, Nikolaj (CLAAUDIA); G\u00f8eg, Pelle Rosenbeck (CLAAUDIA) and OpenAI. (2024). Transcriber (Version1.0) [App]. UCloud interactive HPC system, eScience Center at the University of Southern Denmark. https://cloud.sdu.dk/app/jobs/create?app=transcriber&amp;version=1.0  </p>"},{"location":"ucloud/guides/getting-started/Licens/","title":"License management on UCloud","text":"<p>Managing software licenses on UCloud is essential for accessing Matlab, COMSOL or ANSYS on UCloud. </p> <p>For a detailed, step-by-step guide, visit the official UCloud documentation:</p> <p>License Management on UCloud</p>"},{"location":"ucloud/guides/getting-started/before-you-begin/","title":"Before you begin","text":"<p>Before diving into UCloud, ensure you have the necessary tools and knowledge for the best experience. Here's a brief overview:</p> <p>Request access</p> <p>If you haven't done so yet, please visit how to access to learn how to get approved for using UCloud.</p>"},{"location":"ucloud/guides/getting-started/before-you-begin/#preperations","title":"Preperations","text":"<p>Please review our Terms and Conditions, especially noting the following points:</p> <ul> <li>Only part of UCloud is  intended for working with confidential or sensitive data</li> <li>UCloud is not designed for long term storage of research data.</li> <li>UCloud is not designed for production.</li> </ul>"},{"location":"ucloud/guides/getting-started/transfer-files/","title":"UCloud file transfer guide","text":"<p>This guide will walk you through the steps to download and upload files on UCloud. Follow these steps for each task.</p>"},{"location":"ucloud/guides/getting-started/transfer-files/#guide-to-download-a-single-file-from-ucloud","title":"Guide to download a single file from UCloud","text":"<p>This guide will walk you through how to download a single file from UCloud in a few easy steps.</p>"},{"location":"ucloud/guides/getting-started/transfer-files/#step-1-go-to-files","title":"Step 1: Go to files","text":"<p>On the UCloud front page, navigate to the files section.</p> <p></p>"},{"location":"ucloud/guides/getting-started/transfer-files/#step-2-select-the-drive","title":"Step 2: Select the drive","text":"<p>Double-click on the drive and navigate to where your file is located.</p> <p></p>"},{"location":"ucloud/guides/getting-started/transfer-files/#step-3-download-the-file","title":"Step 3: Download the file","text":"<p>Click on the file you wish to download. The selected file will be highlighted in grey, confirming your selection. Keep in mind that UCloud only allows downloading one file at a time; downloading folders or multiple files simultaneously is not supported.</p> <p></p> <p>That's it! You've now successfully downloaded a single file from UCloud and stored it on your local PC.</p>"},{"location":"ucloud/guides/getting-started/transfer-files/#guide-to-upload-files-on-ucloud","title":"Guide to upload files on UCloud","text":""},{"location":"ucloud/guides/getting-started/transfer-files/#step-1-navigate-to-the-files-section","title":"Step 1: Navigate to the files section","text":"<p>On the UCloud front page, go to the files section to access your storage.</p> <p></p>"},{"location":"ucloud/guides/getting-started/transfer-files/#step-2-select-the-drive_1","title":"Step 2: Select the drive","text":"<p>Double-click on the drive where you want to upload your file. This will open the drive's contents.</p> <p></p>"},{"location":"ucloud/guides/getting-started/transfer-files/#step-3-upload-a-file","title":"Step 3: Upload a file","text":"<p>Click the \"Upload\" button: Look for the upload button, located at the top of the interface or in the toolbar. </p> <p>Upload the files: Drag and drop files to the upload files window or click on it to browse your computer's file system. </p> <p>Uploading: After selecting the file, it will start uploading the files to the selected location.</p> <p>Once the upload is complete, you will see the newly uploaded file in the drive where you placed it.</p>"},{"location":"ucloud/use-cases/voice-modification-schizophrenia/","title":"How UCloud supports research in voice modification for virtual reality therapy for people with schizophrenia","text":"<p>How does research create impact in the real world? In this use case, we explore how research into voice-modification algorithms can make a positive difference for people with schizophrenia \u2014 and how the High Performance Computing platform UCloud helps support this research.</p> Photo: Heka VR <p></p> <p>Anders R. Bargum is a PhD student at CREATE \u2013 the Institute of Architecture and Media Technology at Aalborg University, where he is currently completing an industrial PhD in collaboration with the company Heka VR. His project focuses on the development of an AI-based audio plugin for virtual reality\u2013based therapy for people with schizophrenia. Through an exposure-therapy approach, the solution helps patients better manage the voices they experience in their everyday lives by gradually exposing them to these voices in controlled settings.</p> <p>The software platform, Heka, creates a virtual reality environment in which the patient interacts with a therapist. During therapy, an avatar is used that can be designed to match the voice and character experienced by the patient. The voice's characteristics, including timbre, tone, expression, and visual appearance, are adjusted collaboratively by the therapist and the patient and form part of the exposure-therapy process.</p> <p>A key feature of the platform is the ability to modify the therapist's voice in real time while the conversation is taking place. The therapist speaks into a microphone, after which the voice is processed and transformed by the system and perceived by the patient as the voice and character used in the therapy. This real-time voice-modification algorithm constitutes the core of Anders' research project.</p>"},{"location":"ucloud/use-cases/voice-modification-schizophrenia/#the-technology","title":"The technology","text":"<p>In his research, Anders works with AI and deep learning, developing his own models and algorithms for voice transformation. While several existing technologies are capable of producing realistic synthetic voices, they are typically unable to adapt dynamically in real time. Anders' research addresses this limitation by developing models that can continuously modify voices during live interaction.</p> <p>The neural networks used in the project are trained over extended periods on large volumes of voice data, based on specific voice parameters and auditory attributes. The models learn to analyse and reconstruct voices so they can subsequently be used to create smooth and controlled voice transformations in real time. At present, the project has reached a stage where voices can be controlled and generated in real time with low latency, resulting in a concrete and usable product. At the same time, the therapy approach behind Heka is increasingly being implemented in practice and is now used in both public and private treatment contexts.</p>"},{"location":"ucloud/use-cases/voice-modification-schizophrenia/#ucloud-provides-access-to-the-necessary-computing-power","title":"UCloud provides access to the necessary computing power","text":"<p>The development and training of the AI and deep learning models place significant demands on computing power and access to GPU resources. The neural networks are trained over several days and require substantial memory and computational capacity\u2014requirements that cannot realistically be met using local computers alone.</p> <p>Here, the High Performance Computing platform UCloud plays a central role in Anders' research process. Through UCloud, he gains access to powerful GPUs, large memory capacity, and a scalable development environment, enabling him to train and test advanced voice models much more efficiently.</p> <p>\"Access to powerful GPUs means that I can speed up training and scale my experiments much faster than would be possible with the limited and relatively modest graphics cards typically available locally at the university.\" \u2014 Anders R. Bargum, PhD student, Aalborg University</p> <p>In practice, Anders works via virtual machines (VMs) on UCloud. A virtual machine is a flexible, cloud-based computing environment where the exact amount of computing power, memory, and GPU resources required for a given project can be configured. This approach allows computations to be scaled up and down quickly, ensuring optimal support for both development and training processes.</p>"},{"location":"ucloud/use-cases/voice-modification-schizophrenia/#get-started-with-ucloud","title":"Get started with UCloud","text":"<p>To begin using UCloud and access scalable high-performance computing resources for your research, simply log in to UCloud. If you are planning a larger project or have advanced requirements, visit the How to access page for detailed instructions on applying for additional resources and setting up your environment. If you are in doubt UCloud can also support your research, feel free to reach out to us on the serviceportal to learn more about your options and the support available.</p>"}]}