
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="The AAU HPC pages offers comprehensive information on high-performance computing infrastructure, tools, and support available to students and researchers at Aalborg University, helping them maximize their computational capabilities for academic and research purposes.">
      
      
        <meta name="author" content="CLAAUDIA, ITS, Aalborg University">
      
      
      
        <link rel="prev" href="../checking-the-status-of-compute-nodes/">
      
      
        <link rel="next" href="../../../ai-lab/">
      
      
      <link rel="icon" href="../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Batch LLM Inference - AAU HPC</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.84d31ad4.min.css">
      
      

  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2024%2024%22%3E%3Cpath%20d%3D%22M17%2013h-4v4h-2v-4H7v-2h4V7h2v4h4m-5-9A10%2010%200%200%200%202%2012a10%2010%200%200%200%2010%2010%2010%2010%200%200%200%2010-10A10%2010%200%200%200%2012%202%22/%3E%3C/svg%3E');}</style>


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=barlow:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"barlow";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
     
  <script
    src="https://code.jquery.com/jquery-3.7.1.slim.min.js"
    integrity="sha256-kmHvs0B+OpCW5GVHUNjv9rOmY0IvSIRcf7zGUDTDQM8="
    crossorigin="anonymous"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link href="https://fonts.googleapis.com/css2?family=Barlow:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap" rel="stylesheet">
  <link href="  https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Roboto:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&display=swap" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" rel="stylesheet" type='text/css'/>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0" />
  <link rel="stylesheet" href="https://cdn.datatables.net/2.1.4/css/dataTables.dataTables.css" />
  <script src="https://cdn.datatables.net/2.1.4/js/dataTables.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
  <meta name="{}"></meta>
  <script data-goatcounter="https://hpc-analytics.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>



  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#obtaining-a-hugging-face-access-token" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<!-- Uncomment this for alert on all hpc pages  read color: #ce2020; -->
<!-- <div style="background: #ce2020; position: fixed; bottom: 0; left: 0; width: 100%; text-align: center; z-index: 9999; box-shadow: 0 -2px 12px rgba(0,0,0,0.08);">
  <p style="text-align: center; font-size: 16px; color: white; max-width: 1500px; margin: auto; padding-left: 30px; padding-right: 30px; font-weight: 600; margin-bottom: 10px; margin-top: 10px;">
    <span style="color: #fff;">
      The AI-LAB cluster is currently experiencing issues with GPU driver mismatches, causing all GPU jobs to fail.
      We are actively working on a fix and will provide an update as soon as we have new information.<br>
      For questions or updates, please use the <a href="https://aau.service-now.com/serviceportal" target="_blank" style="color: #fff; text-decoration: underline;">AAU Service Portal</a>.<br>
      Thank you for your understanding.<br>
      <em>â€” Team CLAAUDIA</em>
    </span>
  </p>
</div> -->


<header class="custom-header md-header" data-md-component=header>
  <div class="custom-header-inner">
    <div class="custom-nav-left">
      <label class="md-header__button md-icon" for="__drawer">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>m
      </label>
      <a class="custom-logo" href="/">
        <img src="/assets/img/aau-logo-512x512.png" alt="logo">
        <div style="display: flex;flex-direction: column;vertical-align: middle;">
          <p class="custom-title">AAU HPC</p>
          <p class="custom-title" style="font-size: 12px; font-weight: 400;">By CLAAUDIA</p>
        </div>
      </a>
      <div class="custom-nav">
        <div class="custom-nav-inner">
          
            

  <!-- Determine classes -->
  
  

  <!-- Navigation item with nested items -->
  
    

    <!-- Recurse, if the first item has further nested items -->
    
        <a href="../../.." class="custom-nav-item">
          

  <!-- Navigation link icon -->
  

  <!-- Navigation link title -->
  Home

        </a>
    

  <!-- Navigation item -->
  

          
            

  <!-- Determine classes -->
  
  

  <!-- Navigation item with nested items -->
  
    

    <!-- Recurse, if the first item has further nested items -->
    
        <a href="../../../strato/" class="custom-nav-item">
          

  <!-- Navigation link icon -->
  

  <!-- Navigation link title -->
  Strato

        </a>
    

  <!-- Navigation item -->
  

          
            

  <!-- Determine classes -->
  
  

  <!-- Navigation item with nested items -->
  
    

    <!-- Recurse, if the first item has further nested items -->
    
        <a href="../../../ucloud/" class="custom-nav-item">
          

  <!-- Navigation link icon -->
  

  <!-- Navigation link title -->
  UCloud

        </a>
    

  <!-- Navigation item -->
  

          
            

  <!-- Determine classes -->
  
  
    
  

  <!-- Navigation item with nested items -->
  
    

    <!-- Recurse, if the first item has further nested items -->
    
        <a href="../../" class="custom-nav-item custom-nav-item--active">
          

  <!-- Navigation link icon -->
  

  <!-- Navigation link title -->
  AI Cloud

        </a>
    

  <!-- Navigation item -->
  

          
            

  <!-- Determine classes -->
  
  

  <!-- Navigation item with nested items -->
  
    

    <!-- Recurse, if the first item has further nested items -->
    
        <a href="../../../ai-lab/" class="custom-nav-item">
          

  <!-- Navigation link icon -->
  

  <!-- Navigation link title -->
  AI-LAB

        </a>
    

  <!-- Navigation item -->
  

          
            

  <!-- Determine classes -->
  
  

  <!-- Navigation item with nested items -->
  
    

    <!-- Recurse, if the first item has further nested items -->
    
        <a href="../../../external-hpc/" class="custom-nav-item">
          

  <!-- Navigation link icon -->
  

  <!-- Navigation link title -->
  External HPC

        </a>
    

  <!-- Navigation item -->
  

          
        </div>
      </div>
    </div>
    <div class="custom-nav-right">
      <!-- Button to open search modal -->
      
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <!-- Search interface -->
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
      <hr class="custom-nav-divider">
      <div class="custom-buttons">
        <div class="custom-buttons-inner">
          <a href="https://serviceportal.aau.dk/serviceportal?id=emp_taxonomy_topic&topic_id=82a253e8838fc21053711d447daad328" class="contact-button" target="_blank">Get Support</a>
        </div>
      </div>
    </div>
  </div>
</header>
    
    <div class="md-container" data-md-component="container">
      
      

      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="AAU HPC" class="md-nav__button md-logo" aria-label="AAU HPC" data-md-component="logo">
      
  <img src="../../../assets/img/aau-logo-512x512.png" alt="logo">

    </a>
    AAU HPC
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../service-windows/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Service windows
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_3" >
        
          
          <label class="md-nav__link" for="__nav_1_3" id="__nav_1_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tools
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_3">
            <span class="md-nav__icon md-icon"></span>
            Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../hpc-decision-tree/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    HPC Decision Tree
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../hpc-comparison-table/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    HPC Comparison Table
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Strato
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Strato
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About Strato
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/how-to-access/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How to access
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/terms-and-conditions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Terms and Conditions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/usage-management/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Usage Management
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5_1" >
        
          
          <label class="md-nav__link" for="__nav_2_5_1" id="__nav_2_5_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5_1">
            <span class="md-nav__icon md-icon"></span>
            Getting started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Before you begin
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/getting-started/launch-instance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Launch instance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/getting-started/access-instance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Access instance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/getting-started/transfer-files/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transfer files
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/getting-started/shutting-down/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shutting down
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5_2" >
        
          
          <label class="md-nav__link" for="__nav_2_5_2" id="__nav_2_5_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Application guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5_2">
            <span class="md-nav__icon md-icon"></span>
            Application guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/application-guides/strato-applications/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Strato applications
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/application-guides/matlab/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Matlab
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/application-guides/jupyter-notebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Jupyter Notebook
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/application-guides/docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5_3" >
        
          
          <label class="md-nav__link" for="__nav_2_5_3" id="__nav_2_5_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Advanced guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5_3">
            <span class="md-nav__icon md-icon"></span>
            Advanced guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/advanced-guides/command-line-interface-access/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Command line interface access
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/advanced-guides/custom-security-groups/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Custom security groups
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/advanced-guides/attaching-a-volume-for-additional-storage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attaching a volume for additional storage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/advanced-guides/persistent-terminal-sessions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Persistent terminal sessions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/advanced-guides/transfer-volume/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transfer volumes on Strato
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/advanced-guides/check-ownership-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Check ownership of instances and volumes on Strato
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5_4" >
        
          
          <label class="md-nav__link" for="__nav_2_5_4" id="__nav_2_5_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Best-practice guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5_4">
            <span class="md-nav__icon md-icon"></span>
            Best-practice guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/best-practice-guides/delete-and-restart-an-instance-from-the-volume/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Delete and restart an instance from the volume
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/best-practice-guides/stop-pause-and-delete-instances/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Stop, pause & delete instances
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/best-practice-guides/create-smaller-volumes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Create smaller volumes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../strato/best-practice-guides/how-to-minimize-the-risk-of-malware/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How to Minimize the Risk of Malware
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    UCloud
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            UCloud
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About UCloud
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/how-to-access/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How to access
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/terms-and-conditions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Terms and Conditions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/external-collaborator/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    External collaborators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/providers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Providers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6_1" >
        
          
          <label class="md-nav__link" for="__nav_3_6_1" id="__nav_3_6_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6_1">
            <span class="md-nav__icon md-icon"></span>
            Getting started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/guides/getting-started/before-you-begin/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Before you begin
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/guides/getting-started/transfer-files/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    File transfer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/guides/getting-started/Licens/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    License Management
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/guides/sensitive-data-on-ucloud/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Guidelines for handling sensitive data
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6_3" >
        
          
          <label class="md-nav__link" for="__nav_3_6_3" id="__nav_3_6_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Application guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6_3">
            <span class="md-nav__icon md-icon"></span>
            Application guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/guides/application-guides/ChatUI/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ChatUI
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/guides/application-guides/transcriber/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transcriber
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/guides/application-guides/Voyant-Tools/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Voyant Tools
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6_4" >
        
          
          <label class="md-nav__link" for="__nav_3_6_4" id="__nav_3_6_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Advanced guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6_4">
            <span class="md-nav__icon md-icon"></span>
            Advanced guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ucloud/guides/advanced-guides/connect-neo4j-to-vscode/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Connect Neo4j to VS Code
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    AI Cloud
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            AI Cloud
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About AI Cloud
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how-to-access/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How to access
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../system-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    System overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../terms-and-conditions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Terms and Conditions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fair-usage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Fair usage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6" checked>
        
          
          <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_6">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6_1" >
        
          
          <label class="md-nav__link" for="__nav_4_6_1" id="__nav_4_6_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6_1">
            <span class="md-nav__icon md-icon"></span>
            Getting started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prerequisites
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/login/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Log in
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/look-around/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Look around
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/file-management/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    File transfer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/container-images/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Container images
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/run-jobs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Run jobs
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6_2" checked>
        
          
          <label class="md-nav__link" for="__nav_4_6_2" id="__nav_4_6_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Additional guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_6_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_6_2">
            <span class="md-nav__icon md-icon"></span>
            Additional guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../understanding-linux-cli/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Understanding the Linux CLI
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../directories-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Directories overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6_2_3" >
        
          
          <label class="md-nav__link" for="__nav_4_6_2_3" id="__nav_4_6_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Container guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_6_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6_2_3">
            <span class="md-nav__icon md-icon"></span>
            Container guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../download-container-images/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pulling container images from the internet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../building-your-own-container-image/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Building your own container image
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../creating-a-virtual-environment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Creating a virtual environment
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6_2_4" >
        
          
          <label class="md-nav__link" for="__nav_4_6_2_4" id="__nav_4_6_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Running jobs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_6_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6_2_4">
            <span class="md-nav__icon md-icon"></span>
            Running jobs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multiple-gpus-with-pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multiple GPUs with PyTorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../checkpointing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Checkpointing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cpu-gpu-and-memory-allocation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CPU, GPU, and memory allocation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setting-a-time-limit/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Setting a time limit
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cancelling-jobs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cancelling jobs
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6_2_5" >
        
          
          <label class="md-nav__link" for="__nav_4_6_2_5" id="__nav_4_6_2_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Monitoring commands
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_6_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6_2_5">
            <span class="md-nav__icon md-icon"></span>
            Monitoring commands
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../checking-the-queue/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Checking the queue
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../checking-the-status-of-compute-nodes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Checking the status of compute nodes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_6_2_6" checked>
        
          
          <label class="md-nav__link" for="__nav_4_6_2_6" id="__nav_4_6_2_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Application examples
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_6_2_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4_6_2_6">
            <span class="md-nav__icon md-icon"></span>
            Application examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Batch LLM Inference
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Batch LLM Inference
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#obtaining-a-hugging-face-access-token" class="md-nav__link">
    <span class="md-ellipsis">
      Obtaining a Hugging Face Access Token
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-vllm-with-slurm" class="md-nav__link">
    <span class="md-ellipsis">
      Running vLLM with Slurm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-vllm-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Additional vLLM Examples
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-gpu-utilization" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-GPU Utilization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#batch-reasoning-with-deepseek-r1" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Reasoning with DeepSeek R1
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI-LAB
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            AI-LAB
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About AI-LAB
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/how-to-access/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How to access
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/system-overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    System overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/troubleshooting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Troubleshooting
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../assets/terms-and-conditions-ai-lab.pdf" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Terms and Conditions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/fair-usage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Fair Usage
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7" >
        
          
          <label class="md-nav__link" for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Index
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/video-onboarding-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Video Onboarding Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_3" >
        
          
          <label class="md-nav__link" for="__nav_5_7_3" id="__nav_5_7_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_3">
            <span class="md-nav__icon md-icon"></span>
            Getting started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/prerequisites/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Prerequisites
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/login/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. Login
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/file-handling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. File Handling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/running-jobs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. Running Jobs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/getting-containers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Getting Containers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/using-containers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. Using Containers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/monitoring/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Monitoring
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_4" >
        
          
          <label class="md-nav__link" for="__nav_5_7_4" id="__nav_5_7_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Additional Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_4">
            <span class="md-nav__icon md-icon"></span>
            Additional Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/batch-llm-inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Batch LLM Inference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/checkpointing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Checkpointing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/requeuing-jobs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Requeuing jobs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/guides/ci-cd-with-github-actions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    CI/CD with GitHub Actions
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_7_5" >
        
          
          <label class="md-nav__link" for="__nav_5_7_5" id="__nav_5_7_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Workshop
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7_5">
            <span class="md-nav__icon md-icon"></span>
            Workshop
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/1-Introduction-to-ai-lab/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1. Introduction to AI-LAB
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/2-what-is-ai-lab/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2. What is AI-LAB?
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/3-ai-lab-under-the-hood/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3. AI-LAB Under the Hood
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/4-the-ai-lab-workflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4. The AI-LAB Workflow
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/5-logging-into-ai-lab/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5. Logging into AI-LAB
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/6-file-handling-on-ai-lab/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6. File Handling on AI-LAB
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/7-essential-linux-commands/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7. Essential Linux Commands
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/8-transferring-files/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8. Transferring Files
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/9-slurm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9. Slurm
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/10-two-ways-of-running-jobs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10. Two Ways of Running Jobs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/11-exercise-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11. Exercise 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/12-creating-a-sbatch-script/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12. Creating a job script
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/13-exercise-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13. Exercise 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/14-allocating-resources/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    14. Allocating Resources
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/15-containers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    15. Containers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/16-getting-containers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    16. Getting Containers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/17-using-containers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    17. Using Containers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/18-exercise-3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18. Exercise 3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ai-lab/workshop/19-final-pointers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    19. Final pointers
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    External HPC
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            External HPC
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../external-hpc/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    External HPC facilities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../external-hpc/deic-resources/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DeiC HPC resources
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../external-hpc/eurohpc-resources/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    EuroHPC resources
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../external-hpc/lumi/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LUMI
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
  
                  



  <h1>Batch LLM Inference</h1>

<p>This guide explains how to run batch LLM inference using vLLM on AI Cloud, covering:</p>
<ul>
<li><strong>Setting up and running the vLLM container</strong></li>
<li><strong>Submitting inference jobs via Slurm</strong></li>
</ul>
<div class="admonition info">
<p class="admonition-title">What is Batch LLM Inference?</p>
<p>Batch LLM inference refers to processing multiple input prompts in a single inference pass rather than handling them individually. This approach enhances GPU utilization, increases throughput, and reduces overall latency, making it ideal for large-scale text processing tasks on a GPU cluster.</p>
</div>
<div class="admonition info">
<p class="admonition-title">What is vLLM?</p>
<p><a href="https://docs.vllm.ai/en/latest/">vLLM</a> is an optimized inference engine for large language models, designed to improve performance and efficiency. Using vLLM on AI Cloud ensures efficient model execution, particularly when multiple users or jobs run concurrently.</p>
</div>
<h2 id="obtaining-a-hugging-face-access-token">Obtaining a Hugging Face Access Token</h2>
<p>Many models on Hugging Face are restricted. To use them, you need an access token.</p>
<ol>
<li>Go to <a href="https://huggingface.co/">Hugging Face</a> and log in or create an account.</li>
<li>
<p>Navigate to <a href="https://huggingface.co/settings/tokens">Hugging Face tokens</a> and click <strong>Create new token</strong>.</p>
<p><img alt="Screenshot of Hugging Face" src="/assets/img/ai-cloud/batch-llm-inference-1.png" /></p>
</li>
<li>
<p>Under <strong>Token Type</strong>, select <code>Read</code>, enter a <strong>Token Name</strong>, and click <strong>Create Token</strong>.</p>
<p><img alt="Screenshot of Hugging Face" src="/assets/img/ai-cloud/batch-llm-inference-2.png" /></p>
</li>
<li>
<p>Copy the token value and click <strong>Done</strong>.</p>
<p><img alt="Screenshot of Hugging Face" src="/assets/img/ai-cloud/batch-llm-inference-3.png" /></p>
</li>
<li>
<p>On AI Cloud, add the token to your <code>~/.bashrc</code> to ensure it is always available:</p>
<div class="highlight"><pre><span></span><code><span class="nb">echo</span><span class="w"> </span><span class="s1">&#39;export HF_TOKEN=&quot;YOUR_TOKEN&quot;&#39;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>~/.bashrc
<span class="nb">source</span><span class="w"> </span>~/.bashrc
</code></pre></div>
</li>
<li>
<p>Replace <code>YOUR_TOKEN</code> with your actual token.</p>
</li>
<li>
<p>Verify the token is set correctly:</p>
<div class="highlight"><pre><span></span><code><span class="nb">echo</span><span class="w"> </span><span class="nv">$HF_TOKEN</span>
</code></pre></div>
</li>
</ol>
<h2 id="running-vllm-with-slurm">Running vLLM with Slurm</h2>
<p>Now that access is set up, we can submit a job via Slurm. The example below demonstrates the basic usage of vLLM to generate text.</p>
<h3 id="creating-a-python-script-for-vllm-inference">Creating a Python Script for vLLM Inference</h3>
<p>Create a new file called <code>basic.py</code> with the following code:</p>
<div class="highlight"><span class="filename">basic.py</span><pre><span></span><code><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1"># Modified by CLAAUDIA, ITS, AAU on 2025-03-04</span>
<span class="c1"># - Explicitly set the token before initializing LLM:</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">SamplingParams</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;HUGGING_FACE_HUB_TOKEN&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HF_TOKEN&quot;</span><span class="p">)</span>

<span class="c1"># Sample prompts.</span>
<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Hello, my name is&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The president of the United States is&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The capital of France is&quot;</span><span class="p">,</span>
    <span class="s2">&quot;The future of AI is&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Create a sampling params object.</span>
<span class="n">sampling_params</span> <span class="o">=</span> <span class="n">SamplingParams</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

<span class="c1"># Create an LLM instance.</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;facebook/opt-125m&quot;</span><span class="p">)</span>

<span class="c1"># Generate text.</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>

<span class="c1"># Print results.</span>
<span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">prompt</span><span class="si">!r}</span><span class="s2">, Generated text: </span><span class="si">{</span><span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<p>This script initializes vLLM's engine using the <a href="https://huggingface.co/facebook/opt-125m">facebook/opt-125m</a> model and generates text based on the given prompts. For more details, refer to the <a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html#offline-batched-inference">vLLM documentation</a>.</p>
<h3 id="submitting-a-slurm-job">Submitting a Slurm Job</h3>
<p>A pre-built vLLM container is available on AI Cloud at <code>/home/container/vllm-openai_latest.sif</code>. This container includes vLLM and all necessary dependencies.</p>
<p>Create a Slurm batch script <code>run_vllm.sh</code>:</p>
<div class="highlight"><span class="filename">run_vllm.sh</span><pre><span></span><code><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=vllm_textgen</span>
<span class="c1">#SBATCH --output=vllm_textgen_output.log</span>
<span class="c1">#SBATCH --error=vllm_textgen_error.log</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --mem=40G</span>
<span class="c1">#SBATCH --time=04:00:00</span>

singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>/home/container/vllm-openai_latest.sif<span class="w"> </span>python3<span class="w"> </span>basic.py
</code></pre></div>
<p>Submit the job using:</p>
<div class="highlight"><pre><span></span><code>sbatch<span class="w"> </span>run_vllm.sh
</code></pre></div>
<p>The job should complete quickly (~2 minutes). Check the <code>vllm_textgen_output.log</code> file for results:</p>
<div class="highlight"><pre><span></span><code>Prompt: &#39;Hello, my name is&#39;, Generated text: &#39; Joel, my dad is my friend and we are in a relationship. I am&#39;
Prompt: &#39;The president of the United States is&#39;, Generated text: &#39; speaking out against the release of some State Department documents which show the Russians were involved&#39;
Prompt: &#39;The capital of France is&#39;, Generated text: &#39; the most populous city in the world, with an annual population of nearly 3 million&#39;
Prompt: &#39;The future of AI is&#39;, Generated text: &#39; at stake\nThe world is going to change in the next 20 years, and&#39;
</code></pre></div>
<div class="admonition info">
<p class="admonition-title">Restricted Model Access Error</p>
<p>If you encounter an error such as:</p>
<div class="highlight"><pre><span></span><code>Access to model meta-llama/Llama-3.2-1B-Instruct is restricted and you are not in the authorized list.
</code></pre></div>
<p>You need to request access on Hugging Face. Visit the model page, such as <a href="https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct">meta-llama/Llama-3.2-1B-Instruct</a>, and click <strong>Agree and access repository</strong>.</p>
<p><img alt="Screenshot of Hugging Face" src="/assets/img/ai-cloud/batch-llm-inference-4.png" /></p>
</div>
<p>This guide provides the foundation for running batch LLM inference using vLLM on AI Cloud. Explore the official <a href="https://docs.vllm.ai/">vLLM documentation</a> for further customization and optimizations.</p>
<h2 id="additional-vllm-examples">Additional vLLM Examples</h2>
<p>Below are additional examples demonstrating different vLLM use cases. More advanced examples can be found in the <a href="https://github.com/vllm-project/vllm/tree/main/examples/offline_inference">vLLM GitHub repository</a>.</p>
<details class="info">
<summary>chat.py</summary>
<div class="highlight"><span class="filename">chat.py</span><pre><span></span><code><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1"># Modified by CLAAUDIA, ITS, AAU on 2025-03-04</span>
    <span class="c1"># - Explicitly set the token before initializing LLM:</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">EngineArgs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlexibleArgumentParser</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;HUGGING_FACE_HUB_TOKEN&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HF_TOKEN&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="c1"># Pop arguments not used by LLM</span>
    <span class="n">max_tokens</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">)</span>
    <span class="n">temperature</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">)</span>
    <span class="n">top_p</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;top_p&quot;</span><span class="p">)</span>
    <span class="n">top_k</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;top_k&quot;</span><span class="p">)</span>
    <span class="n">chat_template_path</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;chat_template_path&quot;</span><span class="p">)</span>

    <span class="c1"># Create an LLM</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># Create sampling params object</span>
    <span class="n">sampling_params</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">get_default_sampling_params</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">max_tokens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampling_params</span><span class="o">.</span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">max_tokens</span>
    <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampling_params</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
    <span class="k">if</span> <span class="n">top_p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampling_params</span><span class="o">.</span><span class="n">top_p</span> <span class="o">=</span> <span class="n">top_p</span>
    <span class="k">if</span> <span class="n">top_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampling_params</span><span class="o">.</span><span class="n">top_k</span> <span class="o">=</span> <span class="n">top_k</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">print_outputs</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">prompt</span>
            <span class="n">generated_text</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated text: </span><span class="si">{</span><span class="n">generated_text</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="c1"># In this script, we demonstrate how to pass input to the chat method:</span>
    <span class="n">conversation</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Hello&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Hello! How can I assist you today?&quot;</span>
        <span class="p">},</span>
        <span class="p">{</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span>
            <span class="s2">&quot;Write an essay about the importance of higher education.&quot;</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">]</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">conversation</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">use_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">print_outputs</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

    <span class="c1"># You can run batch inference with llm.chat API</span>
    <span class="n">conversations</span> <span class="o">=</span> <span class="p">[</span><span class="n">conversation</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

    <span class="c1"># We turn on tqdm progress bar to verify it&#39;s indeed running batch inference</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">conversations</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">,</span> <span class="n">use_tqdm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">print_outputs</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

    <span class="c1"># A chat template can be optionally supplied.</span>
    <span class="c1"># If not, the model will use its default chat template.</span>
    <span class="k">if</span> <span class="n">chat_template_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">chat_template_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">chat_template</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
            <span class="n">conversations</span><span class="p">,</span>
            <span class="n">sampling_params</span><span class="p">,</span>
            <span class="n">use_tqdm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">FlexibleArgumentParser</span><span class="p">()</span>
    <span class="c1"># Add engine args</span>
    <span class="n">engine_group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Engine arguments&quot;</span><span class="p">)</span>
    <span class="n">EngineArgs</span><span class="o">.</span><span class="n">add_cli_args</span><span class="p">(</span><span class="n">engine_group</span><span class="p">)</span>
    <span class="n">engine_group</span><span class="o">.</span><span class="n">set_defaults</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;meta-llama/Llama-3.2-1B-Instruct&quot;</span><span class="p">)</span>
    <span class="c1"># Add sampling params</span>
    <span class="n">sampling_group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Sampling parameters&quot;</span><span class="p">)</span>
    <span class="n">sampling_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--max-tokens&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">sampling_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--temperature&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">sampling_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--top-p&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">sampling_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--top-k&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="c1"># Add example params</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--chat-template-path&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
    <span class="n">args</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>
    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>
</details>
<details class="info">
<summary>classify.py</summary>
<div class="highlight"><span class="filename">classify.py</span><pre><span></span><code><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1"># Modified by CLAAUDIA, ITS, AAU on 2025-03-04</span>
    <span class="c1"># - Explicitly set the token before initializing LLM:</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">argparse</span><span class="w"> </span><span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">EngineArgs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlexibleArgumentParser</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;HUGGING_FACE_HUB_TOKEN&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HF_TOKEN&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">Namespace</span><span class="p">):</span>
    <span class="c1"># Sample prompts.</span>
    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;Hello, my name is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The president of the United States is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The capital of France is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The future of AI is&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="c1"># Create an LLM.</span>
    <span class="c1"># You should pass task=&quot;classify&quot; for classification models</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>

    <span class="c1"># Generate logits. The output is a list of ClassificationRequestOutputs.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>

    <span class="c1"># Print the outputs.</span>
    <span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">probs</span>
        <span class="n">probs_trimmed</span> <span class="o">=</span> <span class="p">((</span><span class="nb">str</span><span class="p">(</span><span class="n">probs</span><span class="p">[:</span><span class="mi">16</span><span class="p">])[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
                        <span class="s2">&quot;, ...]&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">16</span> <span class="k">else</span> <span class="n">probs</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">!r}</span><span class="s2"> | &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Class Probabilities: </span><span class="si">{</span><span class="n">probs_trimmed</span><span class="si">}</span><span class="s2"> (size=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">FlexibleArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">EngineArgs</span><span class="o">.</span><span class="n">add_cli_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="c1"># Set example specific arguments</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">set_defaults</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;jason9693/Qwen2.5-1.5B-apeach&quot;</span><span class="p">,</span>
                        <span class="n">task</span><span class="o">=</span><span class="s2">&quot;classify&quot;</span><span class="p">,</span>
                        <span class="n">enforce_eager</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>
</details>
<details class="info">
<summary>embed.py</summary>
<div class="highlight"><span class="filename">embed.py</span><pre><span></span><code><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1"># Modified by CLAAUDIA, ITS, AAU on 2025-03-04</span>
    <span class="c1"># - Explicitly set the token before initializing LLM:</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">argparse</span><span class="w"> </span><span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">EngineArgs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlexibleArgumentParser</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;HUGGING_FACE_HUB_TOKEN&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HF_TOKEN&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">Namespace</span><span class="p">):</span>
    <span class="c1"># Sample prompts.</span>
    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;Hello, my name is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The president of the United States is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The capital of France is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The future of AI is&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="c1"># Create an LLM.</span>
    <span class="c1"># You should pass task=&quot;embed&quot; for embedding models</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>

    <span class="c1"># Generate embedding. The output is a list of EmbeddingRequestOutputs.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>

    <span class="c1"># Print the outputs.</span>
    <span class="k">for</span> <span class="n">prompt</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">embedding</span>
        <span class="n">embeds_trimmed</span> <span class="o">=</span> <span class="p">((</span><span class="nb">str</span><span class="p">(</span><span class="n">embeds</span><span class="p">[:</span><span class="mi">16</span><span class="p">])[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span>
                        <span class="s2">&quot;, ...]&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">embeds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">16</span> <span class="k">else</span> <span class="n">embeds</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">!r}</span><span class="s2"> | &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Embeddings: </span><span class="si">{</span><span class="n">embeds_trimmed</span><span class="si">}</span><span class="s2"> (size=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">embeds</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">FlexibleArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">EngineArgs</span><span class="o">.</span><span class="n">add_cli_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="c1"># Set example specific arguments</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">set_defaults</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;intfloat/e5-mistral-7b-instruct&quot;</span><span class="p">,</span>
                        <span class="n">task</span><span class="o">=</span><span class="s2">&quot;embed&quot;</span><span class="p">,</span>
                        <span class="n">enforce_eager</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>
</details>
<details class="info">
<summary>generate.py</summary>
<div class="highlight"><span class="filename">generate.py</span><pre><span></span><code><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1"># Modified by CLAAUDIA, ITS, AAU on 2025-03-04</span>
    <span class="c1"># - Explicitly set the token before initializing LLM:</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">EngineArgs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlexibleArgumentParser</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;HUGGING_FACE_HUB_TOKEN&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HF_TOKEN&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="c1"># Pop arguments not used by LLM</span>
    <span class="n">max_tokens</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">)</span>
    <span class="n">temperature</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">)</span>
    <span class="n">top_p</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;top_p&quot;</span><span class="p">)</span>
    <span class="n">top_k</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;top_k&quot;</span><span class="p">)</span>

    <span class="c1"># Create an LLM</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="o">**</span><span class="n">args</span><span class="p">)</span>

    <span class="c1"># Create a sampling params object</span>
    <span class="n">sampling_params</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">get_default_sampling_params</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">max_tokens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampling_params</span><span class="o">.</span><span class="n">max_tokens</span> <span class="o">=</span> <span class="n">max_tokens</span>
    <span class="k">if</span> <span class="n">temperature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampling_params</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
    <span class="k">if</span> <span class="n">top_p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampling_params</span><span class="o">.</span><span class="n">top_p</span> <span class="o">=</span> <span class="n">top_p</span>
    <span class="k">if</span> <span class="n">top_k</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sampling_params</span><span class="o">.</span><span class="n">top_k</span> <span class="o">=</span> <span class="n">top_k</span>

    <span class="c1"># Generate texts from the prompts. The output is a list of RequestOutput</span>
    <span class="c1"># objects that contain the prompt, generated text, and other information.</span>
    <span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;Hello, my name is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The president of the United States is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The capital of France is&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The future of AI is&quot;</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">sampling_params</span><span class="p">)</span>
    <span class="c1"># Print the outputs.</span>
    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">prompt</span>
        <span class="n">generated_text</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">!r}</span><span class="s2">, Generated text: </span><span class="si">{</span><span class="n">generated_text</span><span class="si">!r}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">FlexibleArgumentParser</span><span class="p">()</span>
    <span class="c1"># Add engine args</span>
    <span class="n">engine_group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Engine arguments&quot;</span><span class="p">)</span>
    <span class="n">EngineArgs</span><span class="o">.</span><span class="n">add_cli_args</span><span class="p">(</span><span class="n">engine_group</span><span class="p">)</span>
    <span class="n">engine_group</span><span class="o">.</span><span class="n">set_defaults</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;meta-llama/Llama-3.2-1B-Instruct&quot;</span><span class="p">)</span>
    <span class="c1"># Add sampling params</span>
    <span class="n">sampling_group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s2">&quot;Sampling parameters&quot;</span><span class="p">)</span>
    <span class="n">sampling_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--max-tokens&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">sampling_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--temperature&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">sampling_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--top-p&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">sampling_group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--top-k&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">args</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>
    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>
</details>
<details class="info">
<summary>score.py</summary>
<div class="highlight"><span class="filename">score.py</span><pre><span></span><code><span class="c1"># SPDX-License-Identifier: Apache-2.0</span>
<span class="c1"># Modified by CLAAUDIA, ITS, AAU on 2025-03-04</span>
    <span class="c1"># - Explicitly set the token before initializing LLM:</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">argparse</span><span class="w"> </span><span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLM</span><span class="p">,</span> <span class="n">EngineArgs</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">vllm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlexibleArgumentParser</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;HUGGING_FACE_HUB_TOKEN&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;HF_TOKEN&quot;</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">Namespace</span><span class="p">):</span>
    <span class="c1"># Sample prompts.</span>
    <span class="n">text_1</span> <span class="o">=</span> <span class="s2">&quot;What is the capital of France?&quot;</span>
    <span class="n">texts_2</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;The capital of Brazil is Brasilia.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;The capital of France is Paris.&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="c1"># Create an LLM.</span>
    <span class="c1"># You should pass task=&quot;score&quot; for cross-encoder models</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LLM</span><span class="p">(</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>

    <span class="c1"># Generate scores. The output is a list of ScoringRequestOutputs.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">text_1</span><span class="p">,</span> <span class="n">texts_2</span><span class="p">)</span>

    <span class="c1"># Print the outputs.</span>
    <span class="k">for</span> <span class="n">text_2</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">texts_2</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">score</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pair: </span><span class="si">{</span><span class="p">[</span><span class="n">text_1</span><span class="p">,</span><span class="w"> </span><span class="n">text_2</span><span class="p">]</span><span class="si">!r}</span><span class="s2"> | Score: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">FlexibleArgumentParser</span><span class="p">()</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">EngineArgs</span><span class="o">.</span><span class="n">add_cli_args</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    <span class="c1"># Set example specific arguments</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">set_defaults</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;BAAI/bge-reranker-v2-m3&quot;</span><span class="p">,</span>
                        <span class="n">task</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">,</span>
                        <span class="n">enforce_eager</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</code></pre></div>
</details>
<h2 id="multi-gpu-utilization">Multi-GPU Utilization</h2>
<p>Some models like <code>meta-llama/Llama-3.3-70B-Instruct</code> is too large to fit in a single GPU on AI Cloud and you will get an out-of-memory (OOM) error. 
vLLM supports tensor parallelism, which allows the model to be distributed across multiple GPUs. To enable it, pass <code>tensor_parallel_size</code> to the EngineArgs in your script:</p>
<div class="highlight"><pre><span></span><code>engine_group.set_defaults(model=&quot;meta-llama/Llama-3.3-70B-Instruct&quot;, tensor_parallel_size=4)
</code></pre></div>
<p>And don't forget to set <code>--gres=gpu</code> to the number of GPUs you want to utilize, in this instance <code>--gres=gpu:l40s:4</code>. This will allocate 4 GPUs to the job on a arbitrary <code>l40s</code> node on AI Cloud.</p>
<h2 id="batch-reasoning-with-deepseek-r1">Batch Reasoning with DeepSeek R1</h2>
<p>vLLM offers support for reasoning models like DeepSeek R1, which are designed to generate outputs containing both reasoning steps and final conclusions. This guide explains how to use the DeepSeek model with batch processing on. It includes setting up the vLLM server, running inference, and using guided decoding for structured outputs.</p>
<h3 id="step-1-writing-the-inference-script">Step 1: Writing the Inference Script</h3>
<p>Create a Python script (<code>run_inference.py</code>) to interact with the vLLM server:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>

<span class="c1"># Modify OpenAI&#39;s API key and API base to use vLLM&#39;s API server.</span>
<span class="n">openai_api_key</span> <span class="o">=</span> <span class="s2">&quot;EMPTY&quot;</span>
<span class="n">openai_api_base</span> <span class="o">=</span> <span class="s2">&quot;http://localhost:8000/v1&quot;</span>

<span class="c1"># Initialize OpenAI client for vLLM</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">,</span>
    <span class="n">base_url</span><span class="o">=</span><span class="n">openai_api_base</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># List available models</span>
<span class="n">models</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">list</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">id</span>  <span class="c1"># Assumes the first model is the correct one</span>

<span class="c1"># Simple chat completion request</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;What is the capital of France?&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;guided_regex&quot;</span><span class="p">:</span> <span class="s2">&quot;(Paris|London)&quot;</span><span class="p">},</span>  <span class="c1"># Example of guided decoding</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reasoning:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Response:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="c1"># Guided decoding using JSON schema</span>
<span class="k">class</span><span class="w"> </span><span class="nc">People</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">age</span><span class="p">:</span> <span class="nb">int</span>

<span class="n">json_schema</span> <span class="o">=</span> <span class="n">People</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Generate a JSON with the name and age of one random person.&quot;</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
    <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;guided_json&quot;</span><span class="p">:</span> <span class="n">json_schema</span><span class="p">},</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reasoning:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">reasoning_content</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Response:&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</code></pre></div>
<h3 id="step-2-creating-the-slurm-job-script">Step 2: Creating the Slurm Job Script</h3>
<p>Create a Slurm batch script (<code>submit_vllm.sh</code>) to run the inference job:</p>
<div class="highlight"><pre><span></span><code><span class="ch">#!/bin/bash</span>
<span class="c1">#SBATCH --job-name=vllm_reasoning</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --cpus-per-task=8</span>
<span class="c1">#SBATCH --mem=32G</span>
<span class="c1">#SBATCH --time=01:00:00</span>
<span class="c1">#SBATCH --output=vllm_output_%j.log</span>
<span class="c1">#SBATCH --error=vllm_error_%j.log</span>

<span class="c1"># Path to vLLM container</span>
<span class="nv">VLLM_CONTAINER</span><span class="o">=</span><span class="s2">&quot;/home/container/vllm-openai_latest.sif&quot;</span>

<span class="c1"># Start the vLLM server in the background</span>
singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span><span class="nv">$VLLM_CONTAINER</span><span class="w"> </span>vllm<span class="w"> </span>serve<span class="w"> </span>deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--enable-reasoning<span class="w"> </span>--reasoning-parser<span class="w"> </span>deepseek_r1<span class="w"> </span><span class="p">&amp;</span>

<span class="c1"># Get the PID of the server</span>
<span class="nv">VLLM_PID</span><span class="o">=</span><span class="nv">$!</span>

<span class="c1"># Wait for server to be ready</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Waiting for vLLM server to start...&quot;</span>
<span class="k">while</span><span class="w"> </span>!<span class="w"> </span>curl<span class="w"> </span>-s<span class="w"> </span>http://localhost:8000/v1/models<span class="w"> </span>&gt;/dev/null<span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span>sleep<span class="w"> </span><span class="m">2</span><span class="w">  </span><span class="c1"># Check every 2 seconds</span>
<span class="k">done</span>

<span class="c1"># Run inference script</span>
singularity<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span><span class="nv">$VLLM_CONTAINER</span><span class="w"> </span>python3<span class="w"> </span>run_inference.py

<span class="c1"># Stop the server after inference is done</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Stopping vLLM server...&quot;</span>
<span class="nb">kill</span><span class="w"> </span><span class="nv">$VLLM_PID</span>
</code></pre></div>
<h3 id="step-3-submitting-the-job">Step 3: Submitting the Job</h3>
<p>Run the following command to submit the job to Slurm:</p>
<div class="highlight"><pre><span></span><code>sbatch<span class="w"> </span>submit_vllm.sh
</code></pre></div>
<h3 id="step-4-monitoring-and-debugging">Step 4: Monitoring and Debugging</h3>
<p>Check job status:</p>
<div class="highlight"><pre><span></span><code>squeue<span class="w"> </span>--me
</code></pre></div>
<p>Check job logs:</p>
<div class="highlight"><pre><span></span><code>tail<span class="w"> </span>-f<span class="w"> </span>vllm_output_&lt;job_id&gt;.log
</code></pre></div>
<p>If there are errors, inspect the error log:</p>
<div class="highlight"><pre><span></span><code>tail<span class="w"> </span>-f<span class="w"> </span>vllm_error_&lt;job_id&gt;.log
</code></pre></div>
<p>This guide provides the foundation for running batch LLM inference using vLLM on AI Cloud. Explore the official <a href="https://docs.vllm.ai/">vLLM documentation</a> for further customization and optimizations.</p>












                
  <footer role="contentinfo" class="container">
    <div class="footer-container">
    </div>
</footer>



              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "content.code.copy", "content.code.annotate", "navigation.sections", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../../javascripts/conditional.js"></script>
      
        <script src="https://unpkg.com/mermaid@10.9.1/dist/mermaid.min.js"></script>
      
        <script src="../../../javascripts/mermaid-init.js"></script>
      
    
  </body>
</html>